{"KSampler": {"input": {"required": {"model": ["MODEL", {"tooltip": "The model used for denoising the input latent."}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "The random seed used for creating the noise."}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "tooltip": "The number of steps used in the denoising process."}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01, "tooltip": "The Classifier-Free Guidance scale balances creativity and adherence to the prompt. Higher values result in images more closely matching the prompt however too high values will negatively impact quality."}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"], {"tooltip": "The algorithm used when sampling, this can affect the quality, speed, and style of the generated output."}], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"], {"tooltip": "The scheduler controls how noise is gradually removed to form the image."}], "positive": ["CONDITIONING", {"tooltip": "The conditioning describing the attributes you want to include in the image."}], "negative": ["CONDITIONING", {"tooltip": "The conditioning describing the attributes you want to exclude from the image."}], "latent_image": ["LATENT", {"tooltip": "The latent image to denoise."}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The amount of denoising applied, lower values will maintain the structure of the initial image allowing for image to image sampling."}]}}, "input_order": {"required": ["model", "seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "latent_image", "denoise"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "KSampler", "display_name": "KSampler", "description": "Uses the provided model, positive and negative conditioning to denoise the latent image.", "python_module": "nodes", "category": "sampling", "output_node": false, "output_tooltips": ["The denoised latent."]}, "CheckpointLoaderSimple": {"input": {"required": {"ckpt_name": [["Artfusion Surreal XL.safetensors", "Flux_dev_turbo_krea_mix.safetensors", "Flux_dev_v1.safetensors", "XLbluePencilXL_v700.safetensors", "XLrealbluejuggernautmi_v10.safetensors", "animagineXLRealistic_v5.safetensors", "animeIllustDiffusion_v08.safetensors", "artfusionXL_v11Lightning.safetensors", "cyberrealisticXL_v5.safetensors", "dreamshaperXL_v21TurboDPMSDE.safetensors", "electricDreams_electricDreamsV04.safetensors", "epicrealismXL_vxvAnewstoryRealism.safetensors", "illustrationStyleIV.nR7A.safetensors", "illustrationXL_v10.safetensors", "jibMixRealisticXL_v170SmokeSheen.safetensors", "jruTheJourneyRemains_v20XL.safetensors", "midgardPonyTHLSDXL_v32.safetensors", "pixniteXL_v10.safetensors", "reymixXL_v20.safetensors", "sd_xl_base_1.0.safetensors", "sd_xl_refiner_1.0.safetensors", "sdxlFaetastic_v10.safetensors", "sdxlInkpunkstyle_v01.safetensors", "v1-5-pruned-emaonly.safetensors", "xl6HEPHAISTOSSD10XLSFW_v331BF16Experimental.safetensors"], {"tooltip": "The name of the checkpoint (model) to load."}]}}, "input_order": {"required": ["ckpt_name"]}, "output": ["MODEL", "CLIP", "VAE"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "VAE"], "name": "CheckpointLoaderSimple", "display_name": "Load Checkpoint", "description": "Loads a diffusion model checkpoint, diffusion models are used to denoise latents.", "python_module": "nodes", "category": "loaders", "output_node": false, "output_tooltips": ["The model used for denoising latents.", "The CLIP model used for encoding text prompts.", "The VAE model used for encoding and decoding images to and from latent space."]}, "CLIPTextEncode": {"input": {"required": {"text": ["STRING", {"multiline": true, "dynamicPrompts": true, "tooltip": "The text to be encoded."}], "clip": ["CLIP", {"tooltip": "The CLIP model used for encoding the text."}]}}, "input_order": {"required": ["text", "clip"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "CLIPTextEncode", "display_name": "CLIP Text Encode (Prompt)", "description": "Encodes a text prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images.", "python_module": "nodes", "category": "conditioning", "output_node": false, "output_tooltips": ["A conditioning containing the embedded text used to guide the diffusion model."]}, "CLIPSetLastLayer": {"input": {"required": {"clip": ["CLIP"], "stop_at_clip_layer": ["INT", {"default": -1, "min": -24, "max": -1, "step": 1}]}}, "input_order": {"required": ["clip", "stop_at_clip_layer"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPSetLastLayer", "display_name": "CLIP Set Last Layer", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "VAEDecode": {"input": {"required": {"samples": ["LATENT", {"tooltip": "The latent to be decoded."}], "vae": ["VAE", {"tooltip": "The VAE model used for decoding the latent."}]}}, "input_order": {"required": ["samples", "vae"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "VAEDecode", "display_name": "VAE Decode", "description": "Decodes latent images back into pixel space images.", "python_module": "nodes", "category": "latent", "output_node": false, "output_tooltips": ["The decoded image."]}, "VAEEncode": {"input": {"required": {"pixels": ["IMAGE"], "vae": ["VAE"]}}, "input_order": {"required": ["pixels", "vae"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VAEEncode", "display_name": "VAE Encode", "description": "", "python_module": "nodes", "category": "latent", "output_node": false}, "VAEEncodeForInpaint": {"input": {"required": {"pixels": ["IMAGE"], "vae": ["VAE"], "mask": ["MASK"], "grow_mask_by": ["INT", {"default": 6, "min": 0, "max": 64, "step": 1}]}}, "input_order": {"required": ["pixels", "vae", "mask", "grow_mask_by"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VAEEncodeForInpaint", "display_name": "VAE Encode (for Inpainting)", "description": "", "python_module": "nodes", "category": "latent/inpaint", "output_node": false}, "VAELoader": {"input": {"required": {"vae_name": [["diffusion_pytorch_model.safetensors", "flux_vae.safetensors", "mochi_vae.safetensors", "sdxl_vae.safetensors", "vae-ft-ema-560000-ema.vae.pt", "wan2.2_vae.safetensors", "pixel_space"]]}}, "input_order": {"required": ["vae_name"]}, "output": ["VAE"], "output_is_list": [false], "output_name": ["VAE"], "name": "VAELoader", "display_name": "Load VAE", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "EmptyLatentImage": {"input": {"required": {"width": ["INT", {"default": 512, "min": 16, "max": 16384, "step": 8, "tooltip": "The width of the latent images in pixels."}], "height": ["INT", {"default": 512, "min": 16, "max": 16384, "step": 8, "tooltip": "The height of the latent images in pixels."}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096, "tooltip": "The number of latent images in the batch."}]}}, "input_order": {"required": ["width", "height", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "EmptyLatentImage", "display_name": "Empty Latent Image", "description": "Create a new batch of empty latent images to be denoised via sampling.", "python_module": "nodes", "category": "latent", "output_node": false, "output_tooltips": ["The empty latent image batch."]}, "LatentUpscale": {"input": {"required": {"samples": ["LATENT"], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "bislerp"]], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["samples", "upscale_method", "width", "height", "crop"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentUpscale", "display_name": "Upscale Latent", "description": "", "python_module": "nodes", "category": "latent", "output_node": false}, "LatentUpscaleBy": {"input": {"required": {"samples": ["LATENT"], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "bislerp"]], "scale_by": ["FLOAT", {"default": 1.5, "min": 0.01, "max": 8.0, "step": 0.01}]}}, "input_order": {"required": ["samples", "upscale_method", "scale_by"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentUpscaleBy", "display_name": "Upscale Latent By", "description": "", "python_module": "nodes", "category": "latent", "output_node": false}, "LatentFromBatch": {"input": {"required": {"samples": ["LATENT"], "batch_index": ["INT", {"default": 0, "min": 0, "max": 63}], "length": ["INT", {"default": 1, "min": 1, "max": 64}]}}, "input_order": {"required": ["samples", "batch_index", "length"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentFromBatch", "display_name": "Latent From Batch", "description": "", "python_module": "nodes", "category": "latent/batch", "output_node": false}, "RepeatLatentBatch": {"input": {"required": {"samples": ["LATENT"], "amount": ["INT", {"default": 1, "min": 1, "max": 64}]}}, "input_order": {"required": ["samples", "amount"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "RepeatLatentBatch", "display_name": "Repeat Latent Batch", "description": "", "python_module": "nodes", "category": "latent/batch", "output_node": false}, "SaveImage": {"input": {"required": {"images": ["IMAGE", {"tooltip": "The images to save."}], "filename_prefix": ["STRING", {"default": "ComfyUI", "tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes."}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveImage", "display_name": "Save Image", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "nodes", "category": "image", "output_node": true}, "PreviewImage": {"input": {"required": {"images": ["IMAGE"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "PreviewImage", "display_name": "Preview Image", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "nodes", "category": "image", "output_node": true}, "LoadImage": {"input": {"required": {"image": [["chicken-Shine-sxs.png", "chicken-shine-head-white-bg-1.4kx1.4k.png", "chicken-shine-head.png", "chicken_shine_16-9.png", "chicken_shine_big_banner_alt-Recovered.png", "example.png", "feedback_5bf4a783.png", "feedback_9e877b73.png", "feedback_d5b0860e.png", "feedback_f2885aca.png", "rs=w_1280,h_960 (1).webp"], {"image_upload": true}]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "LoadImage", "display_name": "Load Image", "description": "", "python_module": "nodes", "category": "image", "output_node": false}, "LoadImageMask": {"input": {"required": {"image": [["chicken-Shine-sxs.png", "chicken-shine-head-white-bg-1.4kx1.4k.png", "chicken-shine-head.png", "chicken_shine_16-9.png", "chicken_shine_big_banner_alt-Recovered.png", "example.png", "feedback_5bf4a783.png", "feedback_9e877b73.png", "feedback_d5b0860e.png", "feedback_f2885aca.png", "rs=w_1280,h_960 (1).webp"], {"image_upload": true}], "channel": [["alpha", "red", "green", "blue"]]}}, "input_order": {"required": ["image", "channel"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "LoadImageMask", "display_name": "Load Image (as Mask)", "description": "", "python_module": "nodes", "category": "mask", "output_node": false}, "LoadImageOutput": {"input": {"required": {"image": ["COMBO", {"image_upload": true, "image_folder": "output", "remote": {"route": "/internal/files/output", "refresh_button": true, "control_after_refresh": "first"}}]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "LoadImageOutput", "display_name": "Load Image (from Outputs)", "description": "Load an image from the output folder. When the refresh button is clicked, the node will update the image list and automatically select the first image, allowing for easy iteration.", "python_module": "nodes", "category": "image", "output_node": false, "experimental": true}, "ImageScale": {"input": {"required": {"image": ["IMAGE"], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["image", "upscale_method", "width", "height", "crop"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageScale", "display_name": "Upscale Image", "description": "", "python_module": "nodes", "category": "image/upscaling", "output_node": false}, "ImageScaleBy": {"input": {"required": {"image": ["IMAGE"], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]], "scale_by": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 8.0, "step": 0.01}]}}, "input_order": {"required": ["image", "upscale_method", "scale_by"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageScaleBy", "display_name": "Upscale Image By", "description": "", "python_module": "nodes", "category": "image/upscaling", "output_node": false}, "ImageInvert": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageInvert", "display_name": "Invert Image", "description": "", "python_module": "nodes", "category": "image", "output_node": false}, "ImageBatch": {"input": {"required": {"image1": ["IMAGE"], "image2": ["IMAGE"]}}, "input_order": {"required": ["image1", "image2"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageBatch", "display_name": "Batch Images", "description": "", "python_module": "nodes", "category": "image", "output_node": false}, "ImagePadForOutpaint": {"input": {"required": {"image": ["IMAGE"], "left": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "top": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "right": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "bottom": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "feathering": ["INT", {"default": 40, "min": 0, "max": 16384, "step": 1}]}}, "input_order": {"required": ["image", "left", "top", "right", "bottom", "feathering"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "ImagePadForOutpaint", "display_name": "Pad Image for Outpainting", "description": "", "python_module": "nodes", "category": "image", "output_node": false}, "EmptyImage": {"input": {"required": {"width": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "color": ["INT", {"default": 0, "min": 0, "max": 16777215, "step": 1, "display": "color"}]}}, "input_order": {"required": ["width", "height", "batch_size", "color"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "EmptyImage", "display_name": "EmptyImage", "description": "", "python_module": "nodes", "category": "image", "output_node": false}, "ConditioningAverage": {"input": {"required": {"conditioning_to": ["CONDITIONING"], "conditioning_from": ["CONDITIONING"], "conditioning_to_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning_to", "conditioning_from", "conditioning_to_strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningAverage", "display_name": "ConditioningAverage", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningCombine": {"input": {"required": {"conditioning_1": ["CONDITIONING"], "conditioning_2": ["CONDITIONING"]}}, "input_order": {"required": ["conditioning_1", "conditioning_2"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningCombine", "display_name": "Conditioning (Combine)", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningConcat": {"input": {"required": {"conditioning_to": ["CONDITIONING"], "conditioning_from": ["CONDITIONING"]}}, "input_order": {"required": ["conditioning_to", "conditioning_from"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningConcat", "display_name": "Conditioning (Concat)", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningSetArea": {"input": {"required": {"conditioning": ["CONDITIONING"], "width": ["INT", {"default": 64, "min": 64, "max": 16384, "step": 8}], "height": ["INT", {"default": 64, "min": 64, "max": 16384, "step": 8}], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "width", "height", "x", "y", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetArea", "display_name": "Conditioning (Set Area)", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningSetAreaPercentage": {"input": {"required": {"conditioning": ["CONDITIONING"], "width": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}], "height": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}], "x": ["FLOAT", {"default": 0, "min": 0, "max": 1.0, "step": 0.01}], "y": ["FLOAT", {"default": 0, "min": 0, "max": 1.0, "step": 0.01}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "width", "height", "x", "y", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetAreaPercentage", "display_name": "Conditioning (Set Area with Percentage)", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningSetAreaStrength": {"input": {"required": {"conditioning": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetAreaStrength", "display_name": "ConditioningSetAreaStrength", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningSetMask": {"input": {"required": {"conditioning": ["CONDITIONING"], "mask": ["MASK"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}}, "input_order": {"required": ["conditioning", "mask", "strength", "set_cond_area"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetMask", "display_name": "Conditioning (Set Mask)", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "KSamplerAdvanced": {"input": {"required": {"model": ["MODEL"], "add_noise": [["enable", "disable"]], "noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "latent_image": ["LATENT"], "start_at_step": ["INT", {"default": 0, "min": 0, "max": 10000}], "end_at_step": ["INT", {"default": 10000, "min": 0, "max": 10000}], "return_with_leftover_noise": [["disable", "enable"]]}}, "input_order": {"required": ["model", "add_noise", "noise_seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "latent_image", "start_at_step", "end_at_step", "return_with_leftover_noise"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "KSamplerAdvanced", "display_name": "KSampler (Advanced)", "description": "", "python_module": "nodes", "category": "sampling", "output_node": false}, "SetLatentNoiseMask": {"input": {"required": {"samples": ["LATENT"], "mask": ["MASK"]}}, "input_order": {"required": ["samples", "mask"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "SetLatentNoiseMask", "display_name": "Set Latent Noise Mask", "description": "", "python_module": "nodes", "category": "latent/inpaint", "output_node": false}, "LatentComposite": {"input": {"required": {"samples_to": ["LATENT"], "samples_from": ["LATENT"], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "feather": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}]}}, "input_order": {"required": ["samples_to", "samples_from", "x", "y", "feather"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentComposite", "display_name": "Latent Composite", "description": "", "python_module": "nodes", "category": "latent", "output_node": false}, "LatentBlend": {"input": {"required": {"samples1": ["LATENT"], "samples2": ["LATENT"], "blend_factor": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 0.01}]}}, "input_order": {"required": ["samples1", "samples2", "blend_factor"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentBlend", "display_name": "Latent Blend", "description": "", "python_module": "nodes", "category": "_for_testing", "output_node": false}, "LatentRotate": {"input": {"required": {"samples": ["LATENT"], "rotation": [["none", "90 degrees", "180 degrees", "270 degrees"]]}}, "input_order": {"required": ["samples", "rotation"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentRotate", "display_name": "Rotate Latent", "description": "", "python_module": "nodes", "category": "latent/transform", "output_node": false}, "LatentFlip": {"input": {"required": {"samples": ["LATENT"], "flip_method": [["x-axis: vertically", "y-axis: horizontally"]]}}, "input_order": {"required": ["samples", "flip_method"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentFlip", "display_name": "Flip Latent", "description": "", "python_module": "nodes", "category": "latent/transform", "output_node": false}, "LatentCrop": {"input": {"required": {"samples": ["LATENT"], "width": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "height": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}]}}, "input_order": {"required": ["samples", "width", "height", "x", "y"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentCrop", "display_name": "Crop Latent", "description": "", "python_module": "nodes", "category": "latent/transform", "output_node": false}, "LoraLoader": {"input": {"required": {"model": ["MODEL", {"tooltip": "The diffusion model the LoRA will be applied to."}], "clip": ["CLIP", {"tooltip": "The CLIP model the LoRA will be applied to."}], "lora_name": [["BiFangBird.safetensors", "DrugPony.safetensors", "Harrlogos_v2.0.safetensors", "Inquisition_v1.safetensors", "Iridescence.safetensors", "Luxury_Houses_V1-000009.safetensors", "MJ52_v2.0.safetensors", "Textimprover-FLUX-V0.4.safetensors", "animemix_v3_offset.safetensors", "ff7r_style_ned_offset.safetensors", "first_stage-10.safetensors", "fractalized.safetensors", "hyvideo_FastVideo_LoRA-fp8.safetensors", "neoclassical villa - PHK.safetensors", "pokemon_v3_offset.safetensors", "polyhedron_new_skin_v1.1.safetensors", "poms-funtime-mlora-emporium/LiquidAF-0-1.safetensors", "poms-funtime-mlora-emporium/Smoooth-0-1.safetensors", "poms-funtime-mlora-emporium/WAS26.safetensors", "psychedelic_portrait.safetensors", "sd_xl_offset_example-lora_1.0.safetensors"], {"tooltip": "The name of the LoRA."}], "strength_model": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01, "tooltip": "How strongly to modify the diffusion model. This value can be negative."}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01, "tooltip": "How strongly to modify the CLIP model. This value can be negative."}]}}, "input_order": {"required": ["model", "clip", "lora_name", "strength_model", "strength_clip"]}, "output": ["MODEL", "CLIP"], "output_is_list": [false, false], "output_name": ["MODEL", "CLIP"], "name": "LoraLoader", "display_name": "Load LoRA", "description": "LoRAs are used to modify diffusion and CLIP models, altering the way in which latents are denoised such as applying styles. Multiple LoRA nodes can be linked together.", "python_module": "nodes", "category": "loaders", "output_node": false, "output_tooltips": ["The modified diffusion model.", "The modified CLIP model."]}, "CLIPLoader": {"input": {"required": {"clip_name": [["clip_l.safetensors", "t5xxl_fp16.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "type": [["stable_diffusion", "stable_cascade", "sd3", "stable_audio", "mochi", "ltxv", "pixart", "cosmos", "lumina2", "wan", "hidream", "chroma", "ace", "omnigen2", "qwen_image", "hunyuan_image"]]}, "optional": {"device": [["default", "cpu"], {"advanced": true}]}}, "input_order": {"required": ["clip_name", "type"], "optional": ["device"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPLoader", "display_name": "Load CLIP", "description": "[Recipes]\n\nstable_diffusion: clip-l\nstable_cascade: clip-g\nsd3: t5 xxl/ clip-g / clip-l\nstable_audio: t5 base\nmochi: t5 xxl\ncosmos: old t5 xxl\nlumina2: gemma 2 2B\nwan: umt5 xxl\n hidream: llama-3.1 (Recommend) or t5\nomnigen2: qwen vl 2.5 3B", "python_module": "nodes", "category": "advanced/loaders", "output_node": false}, "UNETLoader": {"input": {"required": {"unet_name": [["wan2.2_ti2v_5B_fp16.safetensors"]], "weight_dtype": [["default", "fp8_e4m3fn", "fp8_e4m3fn_fast", "fp8_e5m2"]]}}, "input_order": {"required": ["unet_name", "weight_dtype"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "UNETLoader", "display_name": "Load Diffusion Model", "description": "", "python_module": "nodes", "category": "advanced/loaders", "output_node": false}, "DualCLIPLoader": {"input": {"required": {"clip_name1": [["clip_l.safetensors", "t5xxl_fp16.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "clip_name2": [["clip_l.safetensors", "t5xxl_fp16.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]], "type": [["sdxl", "sd3", "flux", "hunyuan_video", "hidream", "hunyuan_image"]]}, "optional": {"device": [["default", "cpu"], {"advanced": true}]}}, "input_order": {"required": ["clip_name1", "clip_name2", "type"], "optional": ["device"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "DualCLIPLoader", "display_name": "DualCLIPLoader", "description": "[Recipes]\n\nsdxl: clip-l, clip-g\nsd3: clip-l, clip-g / clip-l, t5 / clip-g, t5\nflux: clip-l, t5\nhidream: at least one of t5 or llama, recommended t5 and llama\nhunyuan_image: qwen2.5vl 7b and byt5 small", "python_module": "nodes", "category": "advanced/loaders", "output_node": false}, "CLIPVisionEncode": {"input": {"required": {"clip_vision": ["CLIP_VISION"], "image": ["IMAGE"], "crop": [["center", "none"]]}}, "input_order": {"required": ["clip_vision", "image", "crop"]}, "output": ["CLIP_VISION_OUTPUT"], "output_is_list": [false], "output_name": ["CLIP_VISION_OUTPUT"], "name": "CLIPVisionEncode", "display_name": "CLIP Vision Encode", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "StyleModelApply": {"input": {"required": {"conditioning": ["CONDITIONING"], "style_model": ["STYLE_MODEL"], "clip_vision_output": ["CLIP_VISION_OUTPUT"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "strength_type": [["multiply", "attn_bias"]]}}, "input_order": {"required": ["conditioning", "style_model", "clip_vision_output", "strength", "strength_type"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "StyleModelApply", "display_name": "Apply Style Model", "description": "", "python_module": "nodes", "category": "conditioning/style_model", "output_node": false}, "unCLIPConditioning": {"input": {"required": {"conditioning": ["CONDITIONING"], "clip_vision_output": ["CLIP_VISION_OUTPUT"], "strength": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "noise_augmentation": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "clip_vision_output", "strength", "noise_augmentation"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "unCLIPConditioning", "display_name": "unCLIPConditioning", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ControlNetApply": {"input": {"required": {"conditioning": ["CONDITIONING"], "control_net": ["CONTROL_NET"], "image": ["IMAGE"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "control_net", "image", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ControlNetApply", "display_name": "Apply ControlNet (OLD)", "description": "", "python_module": "nodes", "category": "conditioning/controlnet", "output_node": false, "deprecated": true}, "ControlNetApplyAdvanced": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "control_net": ["CONTROL_NET"], "image": ["IMAGE"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"vae": ["VAE"]}}, "input_order": {"required": ["positive", "negative", "control_net", "image", "strength", "start_percent", "end_percent"], "optional": ["vae"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ControlNetApplyAdvanced", "display_name": "Apply ControlNet", "description": "", "python_module": "nodes", "category": "conditioning/controlnet", "output_node": false}, "ControlNetLoader": {"input": {"required": {"control_net_name": [["controlnet-openpose-sdxl-1.0/diffusion_pytorch_model.safetensors", "controlnet-openpose-sdxl-1.0/diffusion_pytorch_model_twins.safetensors"]]}}, "input_order": {"required": ["control_net_name"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "ControlNetLoader", "display_name": "Load ControlNet Model", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "DiffControlNetLoader": {"input": {"required": {"model": ["MODEL"], "control_net_name": [["controlnet-openpose-sdxl-1.0/diffusion_pytorch_model.safetensors", "controlnet-openpose-sdxl-1.0/diffusion_pytorch_model_twins.safetensors"]]}}, "input_order": {"required": ["model", "control_net_name"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "DiffControlNetLoader", "display_name": "Load ControlNet Model (diff)", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "StyleModelLoader": {"input": {"required": {"style_model_name": [[]]}}, "input_order": {"required": ["style_model_name"]}, "output": ["STYLE_MODEL"], "output_is_list": [false], "output_name": ["STYLE_MODEL"], "name": "StyleModelLoader", "display_name": "Load Style Model", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "CLIPVisionLoader": {"input": {"required": {"clip_name": [[]]}}, "input_order": {"required": ["clip_name"]}, "output": ["CLIP_VISION"], "output_is_list": [false], "output_name": ["CLIP_VISION"], "name": "CLIPVisionLoader", "display_name": "Load CLIP Vision", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "VAEDecodeTiled": {"input": {"required": {"samples": ["LATENT"], "vae": ["VAE"], "tile_size": ["INT", {"default": 512, "min": 64, "max": 4096, "step": 32}], "overlap": ["INT", {"default": 64, "min": 0, "max": 4096, "step": 32}], "temporal_size": ["INT", {"default": 64, "min": 8, "max": 4096, "step": 4, "tooltip": "Only used for video VAEs: Amount of frames to decode at a time."}], "temporal_overlap": ["INT", {"default": 8, "min": 4, "max": 4096, "step": 4, "tooltip": "Only used for video VAEs: Amount of frames to overlap."}]}}, "input_order": {"required": ["samples", "vae", "tile_size", "overlap", "temporal_size", "temporal_overlap"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "VAEDecodeTiled", "display_name": "VAE Decode (Tiled)", "description": "", "python_module": "nodes", "category": "_for_testing", "output_node": false}, "VAEEncodeTiled": {"input": {"required": {"pixels": ["IMAGE"], "vae": ["VAE"], "tile_size": ["INT", {"default": 512, "min": 64, "max": 4096, "step": 64}], "overlap": ["INT", {"default": 64, "min": 0, "max": 4096, "step": 32}], "temporal_size": ["INT", {"default": 64, "min": 8, "max": 4096, "step": 4, "tooltip": "Only used for video VAEs: Amount of frames to encode at a time."}], "temporal_overlap": ["INT", {"default": 8, "min": 4, "max": 4096, "step": 4, "tooltip": "Only used for video VAEs: Amount of frames to overlap."}]}}, "input_order": {"required": ["pixels", "vae", "tile_size", "overlap", "temporal_size", "temporal_overlap"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VAEEncodeTiled", "display_name": "VAE Encode (Tiled)", "description": "", "python_module": "nodes", "category": "_for_testing", "output_node": false}, "unCLIPCheckpointLoader": {"input": {"required": {"ckpt_name": [["Artfusion Surreal XL.safetensors", "Flux_dev_turbo_krea_mix.safetensors", "Flux_dev_v1.safetensors", "XLbluePencilXL_v700.safetensors", "XLrealbluejuggernautmi_v10.safetensors", "animagineXLRealistic_v5.safetensors", "animeIllustDiffusion_v08.safetensors", "artfusionXL_v11Lightning.safetensors", "cyberrealisticXL_v5.safetensors", "dreamshaperXL_v21TurboDPMSDE.safetensors", "electricDreams_electricDreamsV04.safetensors", "epicrealismXL_vxvAnewstoryRealism.safetensors", "illustrationStyleIV.nR7A.safetensors", "illustrationXL_v10.safetensors", "jibMixRealisticXL_v170SmokeSheen.safetensors", "jruTheJourneyRemains_v20XL.safetensors", "midgardPonyTHLSDXL_v32.safetensors", "pixniteXL_v10.safetensors", "reymixXL_v20.safetensors", "sd_xl_base_1.0.safetensors", "sd_xl_refiner_1.0.safetensors", "sdxlFaetastic_v10.safetensors", "sdxlInkpunkstyle_v01.safetensors", "v1-5-pruned-emaonly.safetensors", "xl6HEPHAISTOSSD10XLSFW_v331BF16Experimental.safetensors"]]}}, "input_order": {"required": ["ckpt_name"]}, "output": ["MODEL", "CLIP", "VAE", "CLIP_VISION"], "output_is_list": [false, false, false, false], "output_name": ["MODEL", "CLIP", "VAE", "CLIP_VISION"], "name": "unCLIPCheckpointLoader", "display_name": "unCLIPCheckpointLoader", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "GLIGENLoader": {"input": {"required": {"gligen_name": [[]]}}, "input_order": {"required": ["gligen_name"]}, "output": ["GLIGEN"], "output_is_list": [false], "output_name": ["GLIGEN"], "name": "GLIGENLoader", "display_name": "GLIGENLoader", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "GLIGENTextBoxApply": {"input": {"required": {"conditioning_to": ["CONDITIONING"], "clip": ["CLIP"], "gligen_textbox_model": ["GLIGEN"], "text": ["STRING", {"multiline": true, "dynamicPrompts": true}], "width": ["INT", {"default": 64, "min": 8, "max": 16384, "step": 8}], "height": ["INT", {"default": 64, "min": 8, "max": 16384, "step": 8}], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}]}}, "input_order": {"required": ["conditioning_to", "clip", "gligen_textbox_model", "text", "width", "height", "x", "y"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "GLIGENTextBoxApply", "display_name": "GLIGENTextBoxApply", "description": "", "python_module": "nodes", "category": "conditioning/gligen", "output_node": false}, "InpaintModelConditioning": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "pixels": ["IMAGE"], "mask": ["MASK"], "noise_mask": ["BOOLEAN", {"default": true, "tooltip": "Add a noise mask to the latent so sampling will only happen within the mask. Might improve results or completely break things depending on the model."}]}}, "input_order": {"required": ["positive", "negative", "vae", "pixels", "mask", "noise_mask"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "InpaintModelConditioning", "display_name": "InpaintModelConditioning", "description": "", "python_module": "nodes", "category": "conditioning/inpaint", "output_node": false}, "CheckpointLoader": {"input": {"required": {"config_name": [["anything_v3.yaml", "v1-inference.yaml", "v1-inference_clip_skip_2.yaml", "v1-inference_clip_skip_2_fp16.yaml", "v1-inference_fp16.yaml", "v1-inpainting-inference.yaml", "v2-inference-v.yaml", "v2-inference-v_fp32.yaml", "v2-inference.yaml", "v2-inference_fp32.yaml", "v2-inpainting-inference.yaml"]], "ckpt_name": [["Artfusion Surreal XL.safetensors", "Flux_dev_turbo_krea_mix.safetensors", "Flux_dev_v1.safetensors", "XLbluePencilXL_v700.safetensors", "XLrealbluejuggernautmi_v10.safetensors", "animagineXLRealistic_v5.safetensors", "animeIllustDiffusion_v08.safetensors", "artfusionXL_v11Lightning.safetensors", "cyberrealisticXL_v5.safetensors", "dreamshaperXL_v21TurboDPMSDE.safetensors", "electricDreams_electricDreamsV04.safetensors", "epicrealismXL_vxvAnewstoryRealism.safetensors", "illustrationStyleIV.nR7A.safetensors", "illustrationXL_v10.safetensors", "jibMixRealisticXL_v170SmokeSheen.safetensors", "jruTheJourneyRemains_v20XL.safetensors", "midgardPonyTHLSDXL_v32.safetensors", "pixniteXL_v10.safetensors", "reymixXL_v20.safetensors", "sd_xl_base_1.0.safetensors", "sd_xl_refiner_1.0.safetensors", "sdxlFaetastic_v10.safetensors", "sdxlInkpunkstyle_v01.safetensors", "v1-5-pruned-emaonly.safetensors", "xl6HEPHAISTOSSD10XLSFW_v331BF16Experimental.safetensors"]]}}, "input_order": {"required": ["config_name", "ckpt_name"]}, "output": ["MODEL", "CLIP", "VAE"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "VAE"], "name": "CheckpointLoader", "display_name": "Load Checkpoint With Config (DEPRECATED)", "description": "", "python_module": "nodes", "category": "advanced/loaders", "output_node": false, "deprecated": true}, "DiffusersLoader": {"input": {"required": {"model_path": [[]]}}, "input_order": {"required": ["model_path"]}, "output": ["MODEL", "CLIP", "VAE"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "VAE"], "name": "DiffusersLoader", "display_name": "DiffusersLoader", "description": "", "python_module": "nodes", "category": "advanced/loaders/deprecated", "output_node": false}, "LoadLatent": {"input": {"required": {"latent": [[]]}}, "input_order": {"required": ["latent"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LoadLatent", "display_name": "LoadLatent", "description": "", "python_module": "nodes", "category": "_for_testing", "output_node": false}, "SaveLatent": {"input": {"required": {"samples": ["LATENT"], "filename_prefix": ["STRING", {"default": "latents/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["samples", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveLatent", "display_name": "SaveLatent", "description": "", "python_module": "nodes", "category": "_for_testing", "output_node": true}, "ConditioningZeroOut": {"input": {"required": {"conditioning": ["CONDITIONING"]}}, "input_order": {"required": ["conditioning"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningZeroOut", "display_name": "ConditioningZeroOut", "description": "", "python_module": "nodes", "category": "advanced/conditioning", "output_node": false}, "ConditioningSetTimestepRange": {"input": {"required": {"conditioning": ["CONDITIONING"], "start": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["conditioning", "start", "end"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetTimestepRange", "display_name": "ConditioningSetTimestepRange", "description": "", "python_module": "nodes", "category": "advanced/conditioning", "output_node": false}, "LoraLoaderModelOnly": {"input": {"required": {"model": ["MODEL"], "lora_name": [["BiFangBird.safetensors", "DrugPony.safetensors", "Harrlogos_v2.0.safetensors", "Inquisition_v1.safetensors", "Iridescence.safetensors", "Luxury_Houses_V1-000009.safetensors", "MJ52_v2.0.safetensors", "Textimprover-FLUX-V0.4.safetensors", "animemix_v3_offset.safetensors", "ff7r_style_ned_offset.safetensors", "first_stage-10.safetensors", "fractalized.safetensors", "hyvideo_FastVideo_LoRA-fp8.safetensors", "neoclassical villa - PHK.safetensors", "pokemon_v3_offset.safetensors", "polyhedron_new_skin_v1.1.safetensors", "poms-funtime-mlora-emporium/LiquidAF-0-1.safetensors", "poms-funtime-mlora-emporium/Smoooth-0-1.safetensors", "poms-funtime-mlora-emporium/WAS26.safetensors", "psychedelic_portrait.safetensors", "sd_xl_offset_example-lora_1.0.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "lora_name", "strength_model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "LoraLoaderModelOnly", "display_name": "LoraLoaderModelOnly", "description": "LoRAs are used to modify diffusion and CLIP models, altering the way in which latents are denoised such as applying styles. Multiple LoRA nodes can be linked together.", "python_module": "nodes", "category": "loaders", "output_node": false, "output_tooltips": ["The modified diffusion model.", "The modified CLIP model."]}, "LatentAdd": {"input": {"required": {"samples1": ["LATENT", {}], "samples2": ["LATENT", {}]}}, "input_order": {"required": ["samples1", "samples2"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentAdd", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentSubtract": {"input": {"required": {"samples1": ["LATENT", {}], "samples2": ["LATENT", {}]}}, "input_order": {"required": ["samples1", "samples2"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentSubtract", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentMultiply": {"input": {"required": {"samples": ["LATENT", {}], "multiplier": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["samples", "multiplier"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentMultiply", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentInterpolate": {"input": {"required": {"samples1": ["LATENT", {}], "samples2": ["LATENT", {}], "ratio": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["samples1", "samples2", "ratio"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentInterpolate", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentConcat": {"input": {"required": {"samples1": ["LATENT", {}], "samples2": ["LATENT", {}], "dim": ["COMBO", {"multiselect": false, "options": ["x", "-x", "y", "-y", "t", "-t"]}]}}, "input_order": {"required": ["samples1", "samples2", "dim"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentConcat", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentCut": {"input": {"required": {"samples": ["LATENT", {}], "dim": ["COMBO", {"multiselect": false, "options": ["x", "y", "t"]}], "index": ["INT", {"default": 0, "min": -16384, "max": 16384, "step": 1}], "amount": ["INT", {"default": 1, "min": 1, "max": 16384, "step": 1}]}}, "input_order": {"required": ["samples", "dim", "index", "amount"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentCut", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentBatch": {"input": {"required": {"samples1": ["LATENT", {}], "samples2": ["LATENT", {}]}}, "input_order": {"required": ["samples1", "samples2"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentBatch", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/batch", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentBatchSeedBehavior": {"input": {"required": {"samples": ["LATENT", {}], "seed_behavior": ["COMBO", {"default": "fixed", "multiselect": false, "options": ["random", "fixed"]}]}}, "input_order": {"required": ["samples", "seed_behavior"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentBatchSeedBehavior", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentApplyOperation": {"input": {"required": {"samples": ["LATENT", {}], "operation": ["LATENT_OPERATION", {}]}}, "input_order": {"required": ["samples", "operation"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentApplyOperation", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced/operations", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "LatentApplyOperationCFG": {"input": {"required": {"model": ["MODEL", {}], "operation": ["LATENT_OPERATION", {}]}}, "input_order": {"required": ["model", "operation"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "LatentApplyOperationCFG", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced/operations", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "LatentOperationTonemapReinhard": {"input": {"required": {"multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["multiplier"]}, "output": ["LATENT_OPERATION"], "output_is_list": [false], "output_name": ["LATENT_OPERATION"], "output_tooltips": [null], "name": "LatentOperationTonemapReinhard", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced/operations", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "LatentOperationSharpen": {"input": {"required": {"sharpen_radius": ["INT", {"default": 9, "min": 1, "max": 31, "step": 1}], "sigma": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 10.0, "step": 0.1}], "alpha": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 5.0, "step": 0.01}]}}, "input_order": {"required": ["sharpen_radius", "sigma", "alpha"]}, "output": ["LATENT_OPERATION"], "output_is_list": [false], "output_name": ["LATENT_OPERATION"], "output_tooltips": [null], "name": "LatentOperationSharpen", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced/operations", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "HypernetworkLoader": {"input": {"required": {"model": ["MODEL"], "hypernetwork_name": [[]], "strength": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "hypernetwork_name", "strength"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "HypernetworkLoader", "display_name": "HypernetworkLoader", "description": "", "python_module": "comfy_extras.nodes_hypernetwork", "category": "loaders", "output_node": false}, "UpscaleModelLoader": {"input": {"required": {"model_name": ["COMBO", {"multiselect": false, "options": ["DAT_x3.pth", "DAT_x4.pth", "ESRGAN_4x.pth", "GFPGANv1.4.pth", "RealESRGAN_x4plus.pth", "Upscalers/anime/2x-AnimeSharpV2_MoSR_Sharp.pth", "Upscalers/anime/2x-AnimeSharpV2_MoSR_Soft.pth", "Upscalers/anime/4xHFA2k_ludvae_realplksr_dysample.pth", "Upscalers/anime/4x_Fatality_Comix_260000_G.pth", "Upscalers/anime/4x_NMKD-UltraYandere_300k.pth", "Upscalers/anime/4x_NMKD-YandereNeoXL_200k.pth", "Upscalers/anime/WaifuGAN_v3_30000.pth", "Upscalers/anime/lollypop.pth", "Upscalers/general/001_classicalSR_DF2K_s64w8_SwinIR-M_x2.pth", "Upscalers/general/001_classicalSR_DF2K_s64w8_SwinIR-M_x3.pth", "Upscalers/general/001_classicalSR_DF2K_s64w8_SwinIR-M_x4.pth", "Upscalers/general/001_classicalSR_DF2K_s64w8_SwinIR-M_x8.pth", "Upscalers/general/003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x2_GAN-with-dict-keys-params-and-params_ema.pth", "Upscalers/general/16xPSNR.pth", "Upscalers/general/4x-UltraSharp.pth", "Upscalers/general/4x_NMKD-Superscale-Artisoftject_210000_G.pth", "Upscalers/general/4x_NMKD-Superscale-SP_178000_G.pth", "Upscalers/general/4x_NMKDSuperscale_Artisoft_120000_G.pth", "Upscalers/general/4x_foolhardy_Remacri.pth", "Upscalers/general/8xPSNR.pth", "Upscalers/general/8x_NMKD-Superscale_150000_G.pth", "Upscalers/general/A_ESRGAN_Single.pth", "Upscalers/general/BSRGAN.pth", "Upscalers/general/BSRNet.pth", "Upscalers/general/LDSR_model.ckpt", "Upscalers/general/Swin2SR_ClassicalSR_X2_64.pth", "Upscalers/general/Swin2SR_ClassicalSR_X4_64.pth", "Upscalers/photo/003_realSR_BSRGAN_DFOWMFC_s64w8_SwinIR-L_x4_GAN-with-dict-keys-params-and-params_ema.pth", "Upscalers/photo/4xNomos2_hq_dat2.pth", "Upscalers/photo/4xNomos2_realplksr_dysample.pth", "Upscalers/photo/4xNomos8kDAT.pth", "Upscalers/photo/4xNomosWebPhoto_RealPLKSR.pth", "Upscalers/photo/4x_CountryRoads_377000_G.pth", "Upscalers/photo/4x_RealisticRescaler_100000_G.pth", "Upscalers/photo/4x_Valar_v1.pth", "Upscalers/photo/Swin2SR_RealworldSR_X4_64_BSRGAN_PSNR.pth", "Upscalers/special/1xDeJPG_realplksr_otf.pth", "Upscalers/special/4xArtFaces_realplksr_dysample.pth", "Upscalers/special/4x_NickelbackFS_72000_G.pth", "Upscalers/text/2x_Text2HD_v.1-RealPLKSR.pth", "Upscalers/text/8x_NMKD-Typescale_175k.pth", "detection_Resnet50_Final.pth", "parsing_parsenet.pth"]}]}}, "input_order": {"required": ["model_name"]}, "output": ["UPSCALE_MODEL"], "output_is_list": [false], "output_name": ["UPSCALE_MODEL"], "output_tooltips": [null], "name": "UpscaleModelLoader", "display_name": "Load Upscale Model", "description": "", "python_module": "comfy_extras.nodes_upscale_model", "category": "loaders", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageUpscaleWithModel": {"input": {"required": {"upscale_model": ["UPSCALE_MODEL", {}], "image": ["IMAGE", {}]}}, "input_order": {"required": ["upscale_model", "image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ImageUpscaleWithModel", "display_name": "Upscale Image (using Model)", "description": "", "python_module": "comfy_extras.nodes_upscale_model", "category": "image/upscaling", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageBlend": {"input": {"required": {"image1": ["IMAGE", {}], "image2": ["IMAGE", {}], "blend_factor": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "blend_mode": ["COMBO", {"multiselect": false, "options": ["normal", "multiply", "screen", "overlay", "soft_light", "difference"]}]}}, "input_order": {"required": ["image1", "image2", "blend_factor", "blend_mode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ImageBlend", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_post_processing", "category": "image/postprocessing", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageBlur": {"input": {"required": {"image": ["IMAGE", {}], "blur_radius": ["INT", {"default": 1, "min": 1, "max": 31, "step": 1}], "sigma": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 10.0, "step": 0.1}]}}, "input_order": {"required": ["image", "blur_radius", "sigma"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ImageBlur", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_post_processing", "category": "image/postprocessing", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageQuantize": {"input": {"required": {"image": ["IMAGE", {}], "colors": ["INT", {"default": 256, "min": 1, "max": 256, "step": 1}], "dither": ["COMBO", {"multiselect": false, "options": ["none", "floyd-steinberg", "bayer-2", "bayer-4", "bayer-8", "bayer-16"]}]}}, "input_order": {"required": ["image", "colors", "dither"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ImageQuantize", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_post_processing", "category": "image/postprocessing", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageSharpen": {"input": {"required": {"image": ["IMAGE", {}], "sharpen_radius": ["INT", {"default": 1, "min": 1, "max": 31, "step": 1}], "sigma": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 10.0, "step": 0.01}], "alpha": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 5.0, "step": 0.01}]}}, "input_order": {"required": ["image", "sharpen_radius", "sigma", "alpha"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ImageSharpen", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_post_processing", "category": "image/postprocessing", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageScaleToTotalPixels": {"input": {"required": {"image": ["IMAGE", {}], "upscale_method": ["COMBO", {"multiselect": false, "options": ["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]}], "megapixels": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 16.0, "step": 0.01}]}}, "input_order": {"required": ["image", "upscale_method", "megapixels"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ImageScaleToTotalPixels", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_post_processing", "category": "image/upscaling", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentCompositeMasked": {"input": {"required": {"destination": ["LATENT"], "source": ["LATENT"], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "resize_source": ["BOOLEAN", {"default": false}]}, "optional": {"mask": ["MASK"]}}, "input_order": {"required": ["destination", "source", "x", "y", "resize_source"], "optional": ["mask"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentCompositeMasked", "display_name": "LatentCompositeMasked", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "latent", "output_node": false}, "ImageCompositeMasked": {"input": {"required": {"destination": ["IMAGE"], "source": ["IMAGE"], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "resize_source": ["BOOLEAN", {"default": false}]}, "optional": {"mask": ["MASK"]}}, "input_order": {"required": ["destination", "source", "x", "y", "resize_source"], "optional": ["mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageCompositeMasked", "display_name": "ImageCompositeMasked", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "image", "output_node": false}, "MaskToImage": {"input": {"required": {"mask": ["MASK"]}}, "input_order": {"required": ["mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "MaskToImage", "display_name": "Convert Mask to Image", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "ImageToMask": {"input": {"required": {"image": ["IMAGE"], "channel": [["red", "green", "blue", "alpha"]]}}, "input_order": {"required": ["image", "channel"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ImageToMask", "display_name": "Convert Image to Mask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "ImageColorToMask": {"input": {"required": {"image": ["IMAGE"], "color": ["INT", {"default": 0, "min": 0, "max": 16777215, "step": 1, "display": "color"}]}}, "input_order": {"required": ["image", "color"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ImageColorToMask", "display_name": "ImageColorToMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "SolidMask": {"input": {"required": {"value": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "width": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}]}}, "input_order": {"required": ["value", "width", "height"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "SolidMask", "display_name": "SolidMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "InvertMask": {"input": {"required": {"mask": ["MASK"]}}, "input_order": {"required": ["mask"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "InvertMask", "display_name": "InvertMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "CropMask": {"input": {"required": {"mask": ["MASK"], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "width": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}]}}, "input_order": {"required": ["mask", "x", "y", "width", "height"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "CropMask", "display_name": "CropMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "MaskComposite": {"input": {"required": {"destination": ["MASK"], "source": ["MASK"], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "operation": [["multiply", "add", "subtract", "and", "or", "xor"]]}}, "input_order": {"required": ["destination", "source", "x", "y", "operation"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "MaskComposite", "display_name": "MaskComposite", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "FeatherMask": {"input": {"required": {"mask": ["MASK"], "left": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "top": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "right": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "bottom": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}]}}, "input_order": {"required": ["mask", "left", "top", "right", "bottom"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "FeatherMask", "display_name": "FeatherMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "GrowMask": {"input": {"required": {"mask": ["MASK"], "expand": ["INT", {"default": 0, "min": -16384, "max": 16384, "step": 1}], "tapered_corners": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["mask", "expand", "tapered_corners"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "GrowMask", "display_name": "GrowMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "ThresholdMask": {"input": {"required": {"mask": ["MASK"], "value": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["mask", "value"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ThresholdMask", "display_name": "ThresholdMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "MaskPreview": {"input": {"required": {"mask": ["MASK"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["mask"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "MaskPreview", "display_name": "MaskPreview", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": true}, "PorterDuffImageComposite": {"input": {"required": {"source": ["IMAGE", {}], "source_alpha": ["MASK", {}], "destination": ["IMAGE", {}], "destination_alpha": ["MASK", {}], "mode": ["COMBO", {"default": "DST", "multiselect": false, "options": ["ADD", "CLEAR", "DARKEN", "DST", "DST_ATOP", "DST_IN", "DST_OUT", "DST_OVER", "LIGHTEN", "MULTIPLY", "OVERLAY", "SCREEN", "SRC", "SRC_ATOP", "SRC_IN", "SRC_OUT", "SRC_OVER", "XOR"]}]}}, "input_order": {"required": ["source", "source_alpha", "destination", "destination_alpha", "mode"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "output_tooltips": [null, null], "name": "PorterDuffImageComposite", "display_name": "Porter-Duff Image Composite", "description": "", "python_module": "comfy_extras.nodes_compositing", "category": "mask/compositing", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "SplitImageWithAlpha": {"input": {"required": {"image": ["IMAGE", {}]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "output_tooltips": [null, null], "name": "SplitImageWithAlpha", "display_name": "Split Image with Alpha", "description": "", "python_module": "comfy_extras.nodes_compositing", "category": "mask/compositing", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "JoinImageWithAlpha": {"input": {"required": {"image": ["IMAGE", {}], "alpha": ["MASK", {}]}}, "input_order": {"required": ["image", "alpha"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "JoinImageWithAlpha", "display_name": "Join Image with Alpha", "description": "", "python_module": "comfy_extras.nodes_compositing", "category": "mask/compositing", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RebatchLatents": {"input": {"required": {"latents": ["LATENT", {}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["latents", "batch_size"]}, "output": ["LATENT"], "output_is_list": [true], "output_name": ["LATENT"], "output_tooltips": [null], "name": "RebatchLatents", "display_name": "Rebatch Latents", "description": "", "python_module": "comfy_extras.nodes_rebatch", "category": "latent/batch", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RebatchImages": {"input": {"required": {"images": ["IMAGE", {}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["images", "batch_size"]}, "output": ["IMAGE"], "output_is_list": [true], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "RebatchImages", "display_name": "Rebatch Images", "description": "", "python_module": "comfy_extras.nodes_rebatch", "category": "image/batch", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ModelMergeSimple": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "ratio": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "ratio"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSimple", "display_name": "ModelMergeSimple", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "ModelMergeBlocks": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "input": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "out": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "input", "middle", "out"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeBlocks", "display_name": "ModelMergeBlocks", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "ModelMergeSubtract": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "multiplier": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "multiplier"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSubtract", "display_name": "ModelMergeSubtract", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "ModelMergeAdd": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"]}}, "input_order": {"required": ["model1", "model2"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeAdd", "display_name": "ModelMergeAdd", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "CheckpointSave": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "vae": ["VAE"], "filename_prefix": ["STRING", {"default": "checkpoints/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["model", "clip", "vae", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "CheckpointSave", "display_name": "Save Checkpoint", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": true}, "CLIPMergeSimple": {"input": {"required": {"clip1": ["CLIP"], "clip2": ["CLIP"], "ratio": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["clip1", "clip2", "ratio"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPMergeSimple", "display_name": "CLIPMergeSimple", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "CLIPMergeSubtract": {"input": {"required": {"clip1": ["CLIP"], "clip2": ["CLIP"], "multiplier": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["clip1", "clip2", "multiplier"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPMergeSubtract", "display_name": "CLIPMergeSubtract", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "CLIPMergeAdd": {"input": {"required": {"clip1": ["CLIP"], "clip2": ["CLIP"]}}, "input_order": {"required": ["clip1", "clip2"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPMergeAdd", "display_name": "CLIPMergeAdd", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "CLIPSave": {"input": {"required": {"clip": ["CLIP"], "filename_prefix": ["STRING", {"default": "clip/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["clip", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "CLIPSave", "display_name": "CLIPSave", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": true}, "VAESave": {"input": {"required": {"vae": ["VAE"], "filename_prefix": ["STRING", {"default": "vae/ComfyUI_vae"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["vae", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "VAESave", "display_name": "VAESave", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": true}, "ModelSave": {"input": {"required": {"model": ["MODEL"], "filename_prefix": ["STRING", {"default": "diffusion_models/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["model", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "ModelSave", "display_name": "ModelSave", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": true}, "TomePatchModel": {"input": {"required": {"model": ["MODEL", {}], "ratio": ["FLOAT", {"default": 0.3, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "ratio"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "TomePatchModel", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_tomesd", "category": "model_patches/unet", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CLIPTextEncodeSDXLRefiner": {"input": {"required": {"ascore": ["FLOAT", {"default": 6.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "width": ["INT", {"default": 1024, "min": 0, "max": 16384}], "height": ["INT", {"default": 1024, "min": 0, "max": 16384}], "text": ["STRING", {"multiline": true, "dynamicPrompts": true}], "clip": ["CLIP", {}]}}, "input_order": {"required": ["ascore", "width", "height", "text", "clip"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "CLIPTextEncodeSDXLRefiner", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_clip_sdxl", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CLIPTextEncodeSDXL": {"input": {"required": {"clip": ["CLIP", {}], "width": ["INT", {"default": 1024, "min": 0, "max": 16384}], "height": ["INT", {"default": 1024, "min": 0, "max": 16384}], "crop_w": ["INT", {"default": 0, "min": 0, "max": 16384}], "crop_h": ["INT", {"default": 0, "min": 0, "max": 16384}], "target_width": ["INT", {"default": 1024, "min": 0, "max": 16384}], "target_height": ["INT", {"default": 1024, "min": 0, "max": 16384}], "text_g": ["STRING", {"multiline": true, "dynamicPrompts": true}], "text_l": ["STRING", {"multiline": true, "dynamicPrompts": true}]}}, "input_order": {"required": ["clip", "width", "height", "crop_w", "crop_h", "target_width", "target_height", "text_g", "text_l"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "CLIPTextEncodeSDXL", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_clip_sdxl", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "Canny": {"input": {"required": {"image": ["IMAGE", {}], "low_threshold": ["FLOAT", {"default": 0.4, "min": 0.01, "max": 0.99, "step": 0.01}], "high_threshold": ["FLOAT", {"default": 0.8, "min": 0.01, "max": 0.99, "step": 0.01}]}}, "input_order": {"required": ["image", "low_threshold", "high_threshold"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "Canny", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_canny", "category": "image/preprocessors", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "FreeU": {"input": {"required": {"model": ["MODEL"], "b1": ["FLOAT", {"default": 1.1, "min": 0.0, "max": 10.0, "step": 0.01}], "b2": ["FLOAT", {"default": 1.2, "min": 0.0, "max": 10.0, "step": 0.01}], "s1": ["FLOAT", {"default": 0.9, "min": 0.0, "max": 10.0, "step": 0.01}], "s2": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "b1", "b2", "s1", "s2"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "FreeU", "display_name": "FreeU", "description": "", "python_module": "comfy_extras.nodes_freelunch", "category": "model_patches/unet", "output_node": false}, "FreeU_V2": {"input": {"required": {"model": ["MODEL"], "b1": ["FLOAT", {"default": 1.3, "min": 0.0, "max": 10.0, "step": 0.01}], "b2": ["FLOAT", {"default": 1.4, "min": 0.0, "max": 10.0, "step": 0.01}], "s1": ["FLOAT", {"default": 0.9, "min": 0.0, "max": 10.0, "step": 0.01}], "s2": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "b1", "b2", "s1", "s2"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "FreeU_V2", "display_name": "FreeU_V2", "description": "", "python_module": "comfy_extras.nodes_freelunch", "category": "model_patches/unet", "output_node": false}, "SamplerCustom": {"input": {"required": {"model": ["MODEL"], "add_noise": ["BOOLEAN", {"default": true}], "noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "sampler": ["SAMPLER"], "sigmas": ["SIGMAS"], "latent_image": ["LATENT"]}}, "input_order": {"required": ["model", "add_noise", "noise_seed", "cfg", "positive", "negative", "sampler", "sigmas", "latent_image"]}, "output": ["LATENT", "LATENT"], "output_is_list": [false, false], "output_name": ["output", "denoised_output"], "name": "SamplerCustom", "display_name": "SamplerCustom", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling", "output_node": false}, "BasicScheduler": {"input": {"required": {"model": ["MODEL"], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"]], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "scheduler", "steps", "denoise"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "BasicScheduler", "display_name": "BasicScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "KarrasScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "sigma_max": ["FLOAT", {"default": 14.614642, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "sigma_min": ["FLOAT", {"default": 0.0291675, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "rho": ["FLOAT", {"default": 7.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["steps", "sigma_max", "sigma_min", "rho"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "KarrasScheduler", "display_name": "KarrasScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "ExponentialScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "sigma_max": ["FLOAT", {"default": 14.614642, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "sigma_min": ["FLOAT", {"default": 0.0291675, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["steps", "sigma_max", "sigma_min"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "ExponentialScheduler", "display_name": "ExponentialScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "PolyexponentialScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "sigma_max": ["FLOAT", {"default": 14.614642, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "sigma_min": ["FLOAT", {"default": 0.0291675, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "rho": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["steps", "sigma_max", "sigma_min", "rho"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "PolyexponentialScheduler", "display_name": "PolyexponentialScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "LaplaceScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "sigma_max": ["FLOAT", {"default": 14.614642, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "sigma_min": ["FLOAT", {"default": 0.0291675, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "mu": ["FLOAT", {"default": 0.0, "min": -10.0, "max": 10.0, "step": 0.1, "round": false}], "beta": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 10.0, "step": 0.1, "round": false}]}}, "input_order": {"required": ["steps", "sigma_max", "sigma_min", "mu", "beta"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "LaplaceScheduler", "display_name": "LaplaceScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "VPScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "beta_d": ["FLOAT", {"default": 19.9, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "beta_min": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "eps_s": ["FLOAT", {"default": 0.001, "min": 0.0, "max": 1.0, "step": 0.0001, "round": false}]}}, "input_order": {"required": ["steps", "beta_d", "beta_min", "eps_s"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "VPScheduler", "display_name": "VPScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "BetaSamplingScheduler": {"input": {"required": {"model": ["MODEL"], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "alpha": ["FLOAT", {"default": 0.6, "min": 0.0, "max": 50.0, "step": 0.01, "round": false}], "beta": ["FLOAT", {"default": 0.6, "min": 0.0, "max": 50.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["model", "steps", "alpha", "beta"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "BetaSamplingScheduler", "display_name": "BetaSamplingScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "SDTurboScheduler": {"input": {"required": {"model": ["MODEL"], "steps": ["INT", {"default": 1, "min": 1, "max": 10}], "denoise": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "steps", "denoise"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "SDTurboScheduler", "display_name": "SDTurboScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "KSamplerSelect": {"input": {"required": {"sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"]]}}, "input_order": {"required": ["sampler_name"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "KSamplerSelect", "display_name": "KSamplerSelect", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerEulerAncestral": {"input": {"required": {"eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["eta", "s_noise"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerEulerAncestral", "display_name": "SamplerEulerAncestral", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerEulerAncestralCFGPP": {"input": {"required": {"eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["eta", "s_noise"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerEulerAncestralCFGPP", "display_name": "SamplerEulerAncestralCFG++", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerLMS": {"input": {"required": {"order": ["INT", {"default": 4, "min": 1, "max": 100}]}}, "input_order": {"required": ["order"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerLMS", "display_name": "SamplerLMS", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerDPMPP_3M_SDE": {"input": {"required": {"eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "noise_device": [["gpu", "cpu"]]}}, "input_order": {"required": ["eta", "s_noise", "noise_device"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerDPMPP_3M_SDE", "display_name": "SamplerDPMPP_3M_SDE", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerDPMPP_2M_SDE": {"input": {"required": {"solver_type": [["midpoint", "heun"]], "eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "noise_device": [["gpu", "cpu"]]}}, "input_order": {"required": ["solver_type", "eta", "s_noise", "noise_device"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerDPMPP_2M_SDE", "display_name": "SamplerDPMPP_2M_SDE", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerDPMPP_SDE": {"input": {"required": {"eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "r": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "noise_device": [["gpu", "cpu"]]}}, "input_order": {"required": ["eta", "s_noise", "r", "noise_device"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerDPMPP_SDE", "display_name": "SamplerDPMPP_SDE", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerDPMPP_2S_Ancestral": {"input": {"required": {"eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["eta", "s_noise"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerDPMPP_2S_Ancestral", "display_name": "SamplerDPMPP_2S_Ancestral", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerDPMAdaptative": {"input": {"required": {"order": ["INT", {"default": 3, "min": 2, "max": 3}], "rtol": ["FLOAT", {"default": 0.05, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "atol": ["FLOAT", {"default": 0.0078, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "h_init": ["FLOAT", {"default": 0.05, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "pcoeff": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "icoeff": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "dcoeff": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "accept_safety": ["FLOAT", {"default": 0.81, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "eta": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["order", "rtol", "atol", "h_init", "pcoeff", "icoeff", "dcoeff", "accept_safety", "eta", "s_noise"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerDPMAdaptative", "display_name": "SamplerDPMAdaptative", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerER_SDE": {"input": {"required": {"solver_type": ["COMBO", {"options": ["ER-SDE", "Reverse-time SDE", "ODE"]}], "max_stage": ["INT", {"default": 3, "min": 1, "max": 3}], "eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false, "tooltip": "Stochastic strength of reverse-time SDE.\nWhen eta=0, it reduces to deterministic ODE. This setting doesn't apply to ER-SDE solver type."}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["solver_type", "max_stage", "eta", "s_noise"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerER_SDE", "display_name": "SamplerER_SDE", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerSASolver": {"input": {"required": {"model": ["MODEL", {}], "eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01, "round": false}], "sde_start_percent": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0, "step": 0.001}], "sde_end_percent": ["FLOAT", {"default": 0.8, "min": 0.0, "max": 1.0, "step": 0.001}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "predictor_order": ["INT", {"default": 3, "min": 1, "max": 6}], "corrector_order": ["INT", {"default": 4, "min": 0, "max": 6}], "use_pece": ["BOOLEAN", {}], "simple_order_2": ["BOOLEAN", {}]}}, "input_order": {"required": ["model", "eta", "sde_start_percent", "sde_end_percent", "s_noise", "predictor_order", "corrector_order", "use_pece", "simple_order_2"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerSASolver", "display_name": "SamplerSASolver", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SplitSigmas": {"input": {"required": {"sigmas": ["SIGMAS"], "step": ["INT", {"default": 0, "min": 0, "max": 10000}]}}, "input_order": {"required": ["sigmas", "step"]}, "output": ["SIGMAS", "SIGMAS"], "output_is_list": [false, false], "output_name": ["high_sigmas", "low_sigmas"], "name": "SplitSigmas", "display_name": "SplitSigmas", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "SplitSigmasDenoise": {"input": {"required": {"sigmas": ["SIGMAS"], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["sigmas", "denoise"]}, "output": ["SIGMAS", "SIGMAS"], "output_is_list": [false, false], "output_name": ["high_sigmas", "low_sigmas"], "name": "SplitSigmasDenoise", "display_name": "SplitSigmasDenoise", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "FlipSigmas": {"input": {"required": {"sigmas": ["SIGMAS"]}}, "input_order": {"required": ["sigmas"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "FlipSigmas", "display_name": "FlipSigmas", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "SetFirstSigma": {"input": {"required": {"sigmas": ["SIGMAS"], "sigma": ["FLOAT", {"default": 136.0, "min": 0.0, "max": 20000.0, "step": 0.001, "round": false}]}}, "input_order": {"required": ["sigmas", "sigma"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "SetFirstSigma", "display_name": "SetFirstSigma", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "ExtendIntermediateSigmas": {"input": {"required": {"sigmas": ["SIGMAS"], "steps": ["INT", {"default": 2, "min": 1, "max": 100}], "start_at_sigma": ["FLOAT", {"default": -1.0, "min": -1.0, "max": 20000.0, "step": 0.01, "round": false}], "end_at_sigma": ["FLOAT", {"default": 12.0, "min": 0.0, "max": 20000.0, "step": 0.01, "round": false}], "spacing": [["linear", "cosine", "sine"]]}}, "input_order": {"required": ["sigmas", "steps", "start_at_sigma", "end_at_sigma", "spacing"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "ExtendIntermediateSigmas", "display_name": "ExtendIntermediateSigmas", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "SamplingPercentToSigma": {"input": {"required": {"model": ["MODEL", {}], "sampling_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.0001}], "return_actual_sigma": ["BOOLEAN", {"default": false, "tooltip": "Return the actual sigma value instead of the value used for interval checks.\nThis only affects results at 0.0 and 1.0."}]}}, "input_order": {"required": ["model", "sampling_percent", "return_actual_sigma"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["sigma_value"], "name": "SamplingPercentToSigma", "display_name": "SamplingPercentToSigma", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "CFGGuider": {"input": {"required": {"model": ["MODEL"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}]}}, "input_order": {"required": ["model", "positive", "negative", "cfg"]}, "output": ["GUIDER"], "output_is_list": [false], "output_name": ["GUIDER"], "name": "CFGGuider", "display_name": "CFGGuider", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/guiders", "output_node": false}, "DualCFGGuider": {"input": {"required": {"model": ["MODEL"], "cond1": ["CONDITIONING"], "cond2": ["CONDITIONING"], "negative": ["CONDITIONING"], "cfg_conds": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "cfg_cond2_negative": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "style": [["regular", "nested"]]}}, "input_order": {"required": ["model", "cond1", "cond2", "negative", "cfg_conds", "cfg_cond2_negative", "style"]}, "output": ["GUIDER"], "output_is_list": [false], "output_name": ["GUIDER"], "name": "DualCFGGuider", "display_name": "DualCFGGuider", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/guiders", "output_node": false}, "BasicGuider": {"input": {"required": {"model": ["MODEL"], "conditioning": ["CONDITIONING"]}}, "input_order": {"required": ["model", "conditioning"]}, "output": ["GUIDER"], "output_is_list": [false], "output_name": ["GUIDER"], "name": "BasicGuider", "display_name": "BasicGuider", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/guiders", "output_node": false}, "RandomNoise": {"input": {"required": {"noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}}, "input_order": {"required": ["noise_seed"]}, "output": ["NOISE"], "output_is_list": [false], "output_name": ["NOISE"], "name": "RandomNoise", "display_name": "RandomNoise", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/noise", "output_node": false}, "DisableNoise": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["NOISE"], "output_is_list": [false], "output_name": ["NOISE"], "name": "DisableNoise", "display_name": "DisableNoise", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/noise", "output_node": false}, "AddNoise": {"input": {"required": {"model": ["MODEL"], "noise": ["NOISE"], "sigmas": ["SIGMAS"], "latent_image": ["LATENT"]}}, "input_order": {"required": ["model", "noise", "sigmas", "latent_image"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "AddNoise", "display_name": "AddNoise", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "_for_testing/custom_sampling/noise", "output_node": false}, "SamplerCustomAdvanced": {"input": {"required": {"noise": ["NOISE"], "guider": ["GUIDER"], "sampler": ["SAMPLER"], "sigmas": ["SIGMAS"], "latent_image": ["LATENT"]}}, "input_order": {"required": ["noise", "guider", "sampler", "sigmas", "latent_image"]}, "output": ["LATENT", "LATENT"], "output_is_list": [false, false], "output_name": ["output", "denoised_output"], "name": "SamplerCustomAdvanced", "display_name": "SamplerCustomAdvanced", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling", "output_node": false}, "HyperTile": {"input": {"required": {"model": ["MODEL", {}], "tile_size": ["INT", {"default": 256, "min": 1, "max": 2048}], "swap_size": ["INT", {"default": 2, "min": 1, "max": 128}], "max_depth": ["INT", {"default": 0, "min": 0, "max": 10}], "scale_depth": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["model", "tile_size", "swap_size", "max_depth", "scale_depth"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "HyperTile", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hypertile", "category": "model_patches/unet", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ModelSamplingDiscrete": {"input": {"required": {"model": ["MODEL"], "sampling": [["eps", "v_prediction", "lcm", "x0", "img_to_img"]], "zsnr": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["model", "sampling", "zsnr"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingDiscrete", "display_name": "ModelSamplingDiscrete", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingContinuousEDM": {"input": {"required": {"model": ["MODEL"], "sampling": [["v_prediction", "edm", "edm_playground_v2.5", "eps", "cosmos_rflow"]], "sigma_max": ["FLOAT", {"default": 120.0, "min": 0.0, "max": 1000.0, "step": 0.001, "round": false}], "sigma_min": ["FLOAT", {"default": 0.002, "min": 0.0, "max": 1000.0, "step": 0.001, "round": false}]}}, "input_order": {"required": ["model", "sampling", "sigma_max", "sigma_min"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingContinuousEDM", "display_name": "ModelSamplingContinuousEDM", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingContinuousV": {"input": {"required": {"model": ["MODEL"], "sampling": [["v_prediction"]], "sigma_max": ["FLOAT", {"default": 500.0, "min": 0.0, "max": 1000.0, "step": 0.001, "round": false}], "sigma_min": ["FLOAT", {"default": 0.03, "min": 0.0, "max": 1000.0, "step": 0.001, "round": false}]}}, "input_order": {"required": ["model", "sampling", "sigma_max", "sigma_min"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingContinuousV", "display_name": "ModelSamplingContinuousV", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingStableCascade": {"input": {"required": {"model": ["MODEL"], "shift": ["FLOAT", {"default": 2.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "shift"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingStableCascade", "display_name": "ModelSamplingStableCascade", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingSD3": {"input": {"required": {"model": ["MODEL"], "shift": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "shift"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingSD3", "display_name": "ModelSamplingSD3", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingAuraFlow": {"input": {"required": {"model": ["MODEL"], "shift": ["FLOAT", {"default": 1.73, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "shift"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingAuraFlow", "display_name": "ModelSamplingAuraFlow", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingFlux": {"input": {"required": {"model": ["MODEL"], "max_shift": ["FLOAT", {"default": 1.15, "min": 0.0, "max": 100.0, "step": 0.01}], "base_shift": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 100.0, "step": 0.01}], "width": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 8}]}}, "input_order": {"required": ["model", "max_shift", "base_shift", "width", "height"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingFlux", "display_name": "ModelSamplingFlux", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "RescaleCFG": {"input": {"required": {"model": ["MODEL"], "multiplier": ["FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "multiplier"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "RescaleCFG", "display_name": "RescaleCFG", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelComputeDtype": {"input": {"required": {"model": ["MODEL"], "dtype": [["default", "fp32", "fp16", "bf16"]]}}, "input_order": {"required": ["model", "dtype"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelComputeDtype", "display_name": "ModelComputeDtype", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/debug/model", "output_node": false}, "PatchModelAddDownscale": {"input": {"required": {"model": ["MODEL", {}], "block_number": ["INT", {"default": 3, "min": 1, "max": 32, "step": 1}], "downscale_factor": ["FLOAT", {"default": 2.0, "min": 0.1, "max": 9.0, "step": 0.001}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 0.35, "min": 0.0, "max": 1.0, "step": 0.001}], "downscale_after_skip": ["BOOLEAN", {"default": true}], "downscale_method": ["COMBO", {"multiselect": false, "options": ["bicubic", "nearest-exact", "bilinear", "area", "bislerp"]}], "upscale_method": ["COMBO", {"multiselect": false, "options": ["bicubic", "nearest-exact", "bilinear", "area", "bislerp"]}]}}, "input_order": {"required": ["model", "block_number", "downscale_factor", "start_percent", "end_percent", "downscale_after_skip", "downscale_method", "upscale_method"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "PatchModelAddDownscale", "display_name": "PatchModelAddDownscale (Kohya Deep Shrink)", "description": "", "python_module": "comfy_extras.nodes_model_downscale", "category": "model_patches/unet", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageCrop": {"input": {"required": {"image": ["IMAGE"], "width": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}]}}, "input_order": {"required": ["image", "width", "height", "x", "y"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageCrop", "display_name": "Image Crop", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/transform", "output_node": false}, "RepeatImageBatch": {"input": {"required": {"image": ["IMAGE"], "amount": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["image", "amount"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "RepeatImageBatch", "display_name": "RepeatImageBatch", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/batch", "output_node": false}, "ImageFromBatch": {"input": {"required": {"image": ["IMAGE"], "batch_index": ["INT", {"default": 0, "min": 0, "max": 4095}], "length": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["image", "batch_index", "length"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageFromBatch", "display_name": "ImageFromBatch", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/batch", "output_node": false}, "ImageAddNoise": {"input": {"required": {"image": ["IMAGE"], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "The random seed used for creating the noise."}], "strength": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["image", "seed", "strength"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageAddNoise", "display_name": "ImageAddNoise", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image", "output_node": false}, "SaveAnimatedWEBP": {"input": {"required": {"images": ["IMAGE"], "filename_prefix": ["STRING", {"default": "ComfyUI"}], "fps": ["FLOAT", {"default": 6.0, "min": 0.01, "max": 1000.0, "step": 0.01}], "lossless": ["BOOLEAN", {"default": true}], "quality": ["INT", {"default": 80, "min": 0, "max": 100}], "method": [["default", "fastest", "slowest"]]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "filename_prefix", "fps", "lossless", "quality", "method"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveAnimatedWEBP", "display_name": "SaveAnimatedWEBP", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/animation", "output_node": true}, "SaveAnimatedPNG": {"input": {"required": {"images": ["IMAGE"], "filename_prefix": ["STRING", {"default": "ComfyUI"}], "fps": ["FLOAT", {"default": 6.0, "min": 0.01, "max": 1000.0, "step": 0.01}], "compress_level": ["INT", {"default": 4, "min": 0, "max": 9}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "filename_prefix", "fps", "compress_level"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveAnimatedPNG", "display_name": "SaveAnimatedPNG", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/animation", "output_node": true}, "SaveSVGNode": {"input": {"required": {"svg": ["SVG"], "filename_prefix": ["STRING", {"default": "svg/ComfyUI", "tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes."}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["svg", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveSVGNode", "display_name": "SaveSVGNode", "description": "Save SVG files on disk.", "python_module": "comfy_extras.nodes_images", "category": "image/save", "output_node": true}, "ImageStitch": {"input": {"required": {"image1": ["IMAGE"], "direction": [["right", "down", "left", "up"], {"default": "right"}], "match_image_size": ["BOOLEAN", {"default": true}], "spacing_width": ["INT", {"default": 0, "min": 0, "max": 1024, "step": 2}], "spacing_color": [["white", "black", "red", "green", "blue"], {"default": "white"}]}, "optional": {"image2": ["IMAGE"]}}, "input_order": {"required": ["image1", "direction", "match_image_size", "spacing_width", "spacing_color"], "optional": ["image2"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageStitch", "display_name": "Image Stitch", "description": "\nStitches image2 to image1 in the specified direction.\nIf image2 is not provided, returns image1 unchanged.\nOptional spacing can be added between images.\n", "python_module": "comfy_extras.nodes_images", "category": "image/transform", "output_node": false}, "ResizeAndPadImage": {"input": {"required": {"image": ["IMAGE"], "target_width": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "target_height": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "padding_color": [["white", "black"]], "interpolation": [["area", "bicubic", "nearest-exact", "bilinear", "lanczos"]]}}, "input_order": {"required": ["image", "target_width", "target_height", "padding_color", "interpolation"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ResizeAndPadImage", "display_name": "ResizeAndPadImage", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/transform", "output_node": false}, "GetImageSize": {"input": {"required": {"image": ["IMAGE"]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["image"], "hidden": ["unique_id"]}, "output": ["INT", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["width", "height", "batch_size"], "name": "GetImageSize", "display_name": "Get Image Size", "description": "Returns width and height of the image, and passes it through unchanged.", "python_module": "comfy_extras.nodes_images", "category": "image", "output_node": false}, "ImageRotate": {"input": {"required": {"image": ["IMAGE"], "rotation": [["none", "90 degrees", "180 degrees", "270 degrees"]]}}, "input_order": {"required": ["image", "rotation"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageRotate", "display_name": "ImageRotate", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/transform", "output_node": false}, "ImageFlip": {"input": {"required": {"image": ["IMAGE"], "flip_method": [["x-axis: vertically", "y-axis: horizontally"]]}}, "input_order": {"required": ["image", "flip_method"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageFlip", "display_name": "ImageFlip", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/transform", "output_node": false}, "ImageScaleToMaxDimension": {"input": {"required": {"image": ["IMAGE"], "upscale_method": [["area", "lanczos", "bilinear", "nearest-exact", "bilinear", "bicubic"]], "largest_size": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}]}}, "input_order": {"required": ["image", "upscale_method", "largest_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageScaleToMaxDimension", "display_name": "ImageScaleToMaxDimension", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/upscaling", "output_node": false}, "ImageOnlyCheckpointLoader": {"input": {"required": {"ckpt_name": [["Artfusion Surreal XL.safetensors", "Flux_dev_turbo_krea_mix.safetensors", "Flux_dev_v1.safetensors", "XLbluePencilXL_v700.safetensors", "XLrealbluejuggernautmi_v10.safetensors", "animagineXLRealistic_v5.safetensors", "animeIllustDiffusion_v08.safetensors", "artfusionXL_v11Lightning.safetensors", "cyberrealisticXL_v5.safetensors", "dreamshaperXL_v21TurboDPMSDE.safetensors", "electricDreams_electricDreamsV04.safetensors", "epicrealismXL_vxvAnewstoryRealism.safetensors", "illustrationStyleIV.nR7A.safetensors", "illustrationXL_v10.safetensors", "jibMixRealisticXL_v170SmokeSheen.safetensors", "jruTheJourneyRemains_v20XL.safetensors", "midgardPonyTHLSDXL_v32.safetensors", "pixniteXL_v10.safetensors", "reymixXL_v20.safetensors", "sd_xl_base_1.0.safetensors", "sd_xl_refiner_1.0.safetensors", "sdxlFaetastic_v10.safetensors", "sdxlInkpunkstyle_v01.safetensors", "v1-5-pruned-emaonly.safetensors", "xl6HEPHAISTOSSD10XLSFW_v331BF16Experimental.safetensors"]]}}, "input_order": {"required": ["ckpt_name"]}, "output": ["MODEL", "CLIP_VISION", "VAE"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP_VISION", "VAE"], "name": "ImageOnlyCheckpointLoader", "display_name": "Image Only Checkpoint Loader (img2vid model)", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "loaders/video_models", "output_node": false}, "SVD_img2vid_Conditioning": {"input": {"required": {"clip_vision": ["CLIP_VISION"], "init_image": ["IMAGE"], "vae": ["VAE"], "width": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 576, "min": 16, "max": 16384, "step": 8}], "video_frames": ["INT", {"default": 14, "min": 1, "max": 4096}], "motion_bucket_id": ["INT", {"default": 127, "min": 1, "max": 1023}], "fps": ["INT", {"default": 6, "min": 1, "max": 1024}], "augmentation_level": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["clip_vision", "init_image", "vae", "width", "height", "video_frames", "motion_bucket_id", "fps", "augmentation_level"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "SVD_img2vid_Conditioning", "display_name": "SVD_img2vid_Conditioning", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "conditioning/video_models", "output_node": false}, "VideoLinearCFGGuidance": {"input": {"required": {"model": ["MODEL"], "min_cfg": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.5, "round": 0.01}]}}, "input_order": {"required": ["model", "min_cfg"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "VideoLinearCFGGuidance", "display_name": "VideoLinearCFGGuidance", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "sampling/video_models", "output_node": false}, "VideoTriangleCFGGuidance": {"input": {"required": {"model": ["MODEL"], "min_cfg": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.5, "round": 0.01}]}}, "input_order": {"required": ["model", "min_cfg"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "VideoTriangleCFGGuidance", "display_name": "VideoTriangleCFGGuidance", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "sampling/video_models", "output_node": false}, "ImageOnlyCheckpointSave": {"input": {"required": {"model": ["MODEL"], "clip_vision": ["CLIP_VISION"], "vae": ["VAE"], "filename_prefix": ["STRING", {"default": "checkpoints/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["model", "clip_vision", "vae", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "ImageOnlyCheckpointSave", "display_name": "ImageOnlyCheckpointSave", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "advanced/model_merging", "output_node": true}, "ConditioningSetAreaPercentageVideo": {"input": {"required": {"conditioning": ["CONDITIONING"], "width": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}], "height": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}], "temporal": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}], "x": ["FLOAT", {"default": 0, "min": 0, "max": 1.0, "step": 0.01}], "y": ["FLOAT", {"default": 0, "min": 0, "max": 1.0, "step": 0.01}], "z": ["FLOAT", {"default": 0, "min": 0, "max": 1.0, "step": 0.01}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "width", "height", "temporal", "x", "y", "z", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetAreaPercentageVideo", "display_name": "ConditioningSetAreaPercentageVideo", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "conditioning", "output_node": false}, "TrainLoraNode": {"input": {"required": {"model": ["MODEL", {"tooltip": "The model to train the LoRA on."}], "latents": ["LATENT", {"tooltip": "The Latents to use for training, serve as dataset/input of the model."}], "positive": ["CONDITIONING", {"tooltip": "The positive conditioning to use for training."}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 10000, "step": 1, "tooltip": "The batch size to use for training."}], "grad_accumulation_steps": ["INT", {"default": 1, "min": 1, "max": 1024, "step": 1, "tooltip": "The number of gradient accumulation steps to use for training."}], "steps": ["INT", {"default": 16, "min": 1, "max": 100000, "tooltip": "The number of steps to train the LoRA for."}], "learning_rate": ["FLOAT", {"default": 0.0005, "min": 1e-07, "max": 1.0, "step": 1e-06, "tooltip": "The learning rate to use for training."}], "rank": ["INT", {"default": 8, "min": 1, "max": 128, "tooltip": "The rank of the LoRA layers."}], "optimizer": [["AdamW", "Adam", "SGD", "RMSprop"], {"default": "AdamW", "tooltip": "The optimizer to use for training."}], "loss_function": [["MSE", "L1", "Huber", "SmoothL1"], {"default": "MSE", "tooltip": "The loss function to use for training."}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "The seed to use for training (used in generator for LoRA weight initialization and noise sampling)"}], "training_dtype": [["bf16", "fp32"], {"default": "bf16", "tooltip": "The dtype to use for training."}], "lora_dtype": [["bf16", "fp32"], {"default": "bf16", "tooltip": "The dtype to use for lora."}], "algorithm": [["LoRA", "LoHa", "LoKr", "OFT"], {"default": "LoRA", "tooltip": "The algorithm to use for training."}], "gradient_checkpointing": ["BOOLEAN", {"default": true, "tooltip": "Use gradient checkpointing for training."}], "existing_lora": [["BiFangBird.safetensors", "DrugPony.safetensors", "Harrlogos_v2.0.safetensors", "Inquisition_v1.safetensors", "Iridescence.safetensors", "Luxury_Houses_V1-000009.safetensors", "MJ52_v2.0.safetensors", "Textimprover-FLUX-V0.4.safetensors", "animemix_v3_offset.safetensors", "ff7r_style_ned_offset.safetensors", "first_stage-10.safetensors", "fractalized.safetensors", "hyvideo_FastVideo_LoRA-fp8.safetensors", "neoclassical villa - PHK.safetensors", "pokemon_v3_offset.safetensors", "polyhedron_new_skin_v1.1.safetensors", "poms-funtime-mlora-emporium/LiquidAF-0-1.safetensors", "poms-funtime-mlora-emporium/Smoooth-0-1.safetensors", "poms-funtime-mlora-emporium/WAS26.safetensors", "psychedelic_portrait.safetensors", "sd_xl_offset_example-lora_1.0.safetensors", "[None]"], {"default": "[None]", "tooltip": "The existing LoRA to append to. Set to None for new LoRA."}]}}, "input_order": {"required": ["model", "latents", "positive", "batch_size", "grad_accumulation_steps", "steps", "learning_rate", "rank", "optimizer", "loss_function", "seed", "training_dtype", "lora_dtype", "algorithm", "gradient_checkpointing", "existing_lora"]}, "output": ["MODEL", "LORA_MODEL", "LOSS_MAP", "INT"], "output_is_list": [false, false, false, false], "output_name": ["model_with_lora", "lora", "loss", "steps"], "name": "TrainLoraNode", "display_name": "Train LoRA", "description": "", "python_module": "comfy_extras.nodes_train", "category": "training", "output_node": false, "experimental": true}, "SaveLoRANode": {"input": {"required": {"lora": ["LORA_MODEL", {"tooltip": "The LoRA model to save. Do not use the model with LoRA layers."}], "prefix": ["STRING", {"default": "loras/ComfyUI_trained_lora", "tooltip": "The prefix to use for the saved LoRA file."}]}, "optional": {"steps": ["INT", {"forceInput": true, "tooltip": "Optional: The number of steps to LoRA has been trained for, used to name the saved file."}]}}, "input_order": {"required": ["lora", "prefix"], "optional": ["steps"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveLoRANode", "display_name": "Save LoRA Weights", "description": "", "python_module": "comfy_extras.nodes_train", "category": "loaders", "output_node": true, "experimental": true}, "LoraModelLoader": {"input": {"required": {"model": ["MODEL", {"tooltip": "The diffusion model the LoRA will be applied to."}], "lora": ["LORA_MODEL", {"tooltip": "The LoRA model to apply to the diffusion model."}], "strength_model": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01, "tooltip": "How strongly to modify the diffusion model. This value can be negative."}]}}, "input_order": {"required": ["model", "lora", "strength_model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "LoraModelLoader", "display_name": "Load LoRA Model", "description": "Load Trained LoRA weights from Train LoRA node.", "python_module": "comfy_extras.nodes_train", "category": "loaders", "output_node": false, "output_tooltips": ["The modified diffusion model."], "experimental": true}, "LoadImageSetFromFolderNode": {"input": {"required": {"folder": [["3d"], {"tooltip": "The folder to load images from."}]}, "optional": {"resize_method": [["None", "Stretch", "Crop", "Pad"], {"default": "None"}]}}, "input_order": {"required": ["folder"], "optional": ["resize_method"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "LoadImageSetFromFolderNode", "display_name": "Load Image Dataset from Folder", "description": "Loads a batch of images from a directory for training.", "python_module": "comfy_extras.nodes_train", "category": "loaders", "output_node": false, "experimental": true}, "LoadImageTextSetFromFolderNode": {"input": {"required": {"folder": [["3d"], {"tooltip": "The folder to load images from."}], "clip": ["CLIP", {"tooltip": "The CLIP model used for encoding the text."}]}, "optional": {"resize_method": [["None", "Stretch", "Crop", "Pad"], {"default": "None"}], "width": ["INT", {"default": -1, "min": -1, "max": 10000, "step": 1, "tooltip": "The width to resize the images to. -1 means use the original width."}], "height": ["INT", {"default": -1, "min": -1, "max": 10000, "step": 1, "tooltip": "The height to resize the images to. -1 means use the original height."}]}}, "input_order": {"required": ["folder", "clip"], "optional": ["resize_method", "width", "height"]}, "output": ["IMAGE", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["IMAGE", "CONDITIONING"], "name": "LoadImageTextSetFromFolderNode", "display_name": "Load Image and Text Dataset from Folder", "description": "Loads a batch of images and caption from a directory for training.", "python_module": "comfy_extras.nodes_train", "category": "loaders", "output_node": false, "experimental": true}, "LossGraphNode": {"input": {"required": {"loss": ["LOSS_MAP", {"default": {}}], "filename_prefix": ["STRING", {"default": "loss_graph"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["loss", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "LossGraphNode", "display_name": "Plot Loss Graph", "description": "Plots the loss graph and saves it to the output directory.", "python_module": "comfy_extras.nodes_train", "category": "training", "output_node": true, "experimental": true}, "SelfAttentionGuidance": {"input": {"required": {"model": ["MODEL", {}], "scale": ["FLOAT", {"default": 0.5, "min": -2.0, "max": 5.0, "step": 0.01}], "blur_sigma": ["FLOAT", {"default": 2.0, "min": 0.0, "max": 10.0, "step": 0.1}]}}, "input_order": {"required": ["model", "scale", "blur_sigma"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "SelfAttentionGuidance", "display_name": "Self-Attention Guidance", "description": "", "python_module": "comfy_extras.nodes_sag", "category": "_for_testing", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "PerpNeg": {"input": {"required": {"model": ["MODEL", {}], "empty_conditioning": ["CONDITIONING", {}], "neg_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "empty_conditioning", "neg_scale"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "PerpNeg", "display_name": "Perp-Neg (DEPRECATED by PerpNegGuider)", "description": "", "python_module": "comfy_extras.nodes_perpneg", "category": "_for_testing", "output_node": false, "deprecated": true, "experimental": true, "api_node": false}, "PerpNegGuider": {"input": {"required": {"model": ["MODEL", {}], "positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "empty_conditioning": ["CONDITIONING", {}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "neg_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "positive", "negative", "empty_conditioning", "cfg", "neg_scale"]}, "output": ["GUIDER"], "output_is_list": [false], "output_name": ["GUIDER"], "output_tooltips": [null], "name": "PerpNegGuider", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_perpneg", "category": "_for_testing", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "StableZero123_Conditioning": {"input": {"required": {"clip_vision": ["CLIP_VISION", {}], "init_image": ["IMAGE", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 256, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 256, "min": 16, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "elevation": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}], "azimuth": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}]}}, "input_order": {"required": ["clip_vision", "init_image", "vae", "width", "height", "batch_size", "elevation", "azimuth"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "StableZero123_Conditioning", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_stable3d", "category": "conditioning/3d_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StableZero123_Conditioning_Batched": {"input": {"required": {"clip_vision": ["CLIP_VISION", {}], "init_image": ["IMAGE", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 256, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 256, "min": 16, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "elevation": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}], "azimuth": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}], "elevation_batch_increment": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}], "azimuth_batch_increment": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}]}}, "input_order": {"required": ["clip_vision", "init_image", "vae", "width", "height", "batch_size", "elevation", "azimuth", "elevation_batch_increment", "azimuth_batch_increment"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "StableZero123_Conditioning_Batched", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_stable3d", "category": "conditioning/3d_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "SV3D_Conditioning": {"input": {"required": {"clip_vision": ["CLIP_VISION", {}], "init_image": ["IMAGE", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 576, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 576, "min": 16, "max": 16384, "step": 8}], "video_frames": ["INT", {"default": 21, "min": 1, "max": 4096}], "elevation": ["FLOAT", {"default": 0.0, "min": -90.0, "max": 90.0, "step": 0.1, "round": false}]}}, "input_order": {"required": ["clip_vision", "init_image", "vae", "width", "height", "video_frames", "elevation"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "SV3D_Conditioning", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_stable3d", "category": "conditioning/3d_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "SD_4XUpscale_Conditioning": {"input": {"required": {"images": ["IMAGE", {}], "positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "scale_ratio": ["FLOAT", {"default": 4.0, "min": 0.0, "max": 10.0, "step": 0.01}], "noise_augmentation": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["images", "positive", "negative", "scale_ratio", "noise_augmentation"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "SD_4XUpscale_Conditioning", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_sdupscale", "category": "conditioning/upscale_diffusion", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "PhotoMakerLoader": {"input": {"required": {"photomaker_model_name": ["COMBO", {"multiselect": false, "options": []}]}}, "input_order": {"required": ["photomaker_model_name"]}, "output": ["PHOTOMAKER"], "output_is_list": [false], "output_name": ["PHOTOMAKER"], "output_tooltips": [null], "name": "PhotoMakerLoader", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_photomaker", "category": "_for_testing/photomaker", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "PhotoMakerEncode": {"input": {"required": {"photomaker": ["PHOTOMAKER", {}], "image": ["IMAGE", {}], "clip": ["CLIP", {}], "text": ["STRING", {"default": "photograph of photomaker", "multiline": true, "dynamicPrompts": true}]}}, "input_order": {"required": ["photomaker", "image", "clip", "text"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "PhotoMakerEncode", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_photomaker", "category": "_for_testing/photomaker", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "CLIPTextEncodePixArtAlpha": {"input": {"required": {"width": ["INT", {"default": 1024, "min": 0, "max": 16384}], "height": ["INT", {"default": 1024, "min": 0, "max": 16384}], "text": ["STRING", {"multiline": true, "dynamicPrompts": true}], "clip": ["CLIP", {}]}}, "input_order": {"required": ["width", "height", "text", "clip"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "CLIPTextEncodePixArtAlpha", "display_name": null, "description": "Encodes text and sets the resolution conditioning for PixArt Alpha. Does not apply to PixArt Sigma.", "python_module": "comfy_extras.nodes_pixart", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CLIPTextEncodeControlnet": {"input": {"required": {"clip": ["CLIP", {}], "conditioning": ["CONDITIONING", {}], "text": ["STRING", {"multiline": true, "dynamicPrompts": true}]}}, "input_order": {"required": ["clip", "conditioning", "text"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "CLIPTextEncodeControlnet", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_cond", "category": "_for_testing/conditioning", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "T5TokenizerOptions": {"input": {"required": {"clip": ["CLIP", {}], "min_padding": ["INT", {"default": 0, "min": 0, "max": 10000, "step": 1}], "min_length": ["INT", {"default": 0, "min": 0, "max": 10000, "step": 1}]}}, "input_order": {"required": ["clip", "min_padding", "min_length"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "output_tooltips": [null], "name": "T5TokenizerOptions", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_cond", "category": "_for_testing/conditioning", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "Morphology": {"input": {"required": {"image": ["IMAGE", {}], "operation": ["COMBO", {"multiselect": false, "options": ["erode", "dilate", "open", "close", "gradient", "bottom_hat", "top_hat"]}], "kernel_size": ["INT", {"default": 3, "min": 3, "max": 999, "step": 1}]}}, "input_order": {"required": ["image", "operation", "kernel_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "Morphology", "display_name": "ImageMorphology", "description": "", "python_module": "comfy_extras.nodes_morphology", "category": "image/postprocessing", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageRGBToYUV": {"input": {"required": {"image": ["IMAGE", {}]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "IMAGE", "IMAGE"], "output_is_list": [false, false, false], "output_name": ["Y", "U", "V"], "output_tooltips": [null, null, null], "name": "ImageRGBToYUV", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_morphology", "category": "image/batch", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageYUVToRGB": {"input": {"required": {"Y": ["IMAGE", {}], "U": ["IMAGE", {}], "V": ["IMAGE", {}]}}, "input_order": {"required": ["Y", "U", "V"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ImageYUVToRGB", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_morphology", "category": "image/batch", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StableCascade_EmptyLatentImage": {"input": {"required": {"width": ["INT", {"default": 1024, "min": 256, "max": 16384, "step": 8}], "height": ["INT", {"default": 1024, "min": 256, "max": 16384, "step": 8}], "compression": ["INT", {"default": 42, "min": 4, "max": 128, "step": 1}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "compression", "batch_size"]}, "output": ["LATENT", "LATENT"], "output_is_list": [false, false], "output_name": ["stage_c", "stage_b"], "output_tooltips": [null, null], "name": "StableCascade_EmptyLatentImage", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_stable_cascade", "category": "latent/stable_cascade", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StableCascade_StageB_Conditioning": {"input": {"required": {"conditioning": ["CONDITIONING", {}], "stage_c": ["LATENT", {}]}}, "input_order": {"required": ["conditioning", "stage_c"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "StableCascade_StageB_Conditioning", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_stable_cascade", "category": "conditioning/stable_cascade", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StableCascade_StageC_VAEEncode": {"input": {"required": {"image": ["IMAGE", {}], "vae": ["VAE", {}], "compression": ["INT", {"default": 42, "min": 4, "max": 128, "step": 1}]}}, "input_order": {"required": ["image", "vae", "compression"]}, "output": ["LATENT", "LATENT"], "output_is_list": [false, false], "output_name": ["stage_c", "stage_b"], "output_tooltips": [null, null], "name": "StableCascade_StageC_VAEEncode", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_stable_cascade", "category": "latent/stable_cascade", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StableCascade_SuperResolutionControlnet": {"input": {"required": {"image": ["IMAGE", {}], "vae": ["VAE", {}]}}, "input_order": {"required": ["image", "vae"]}, "output": ["IMAGE", "LATENT", "LATENT"], "output_is_list": [false, false, false], "output_name": ["controlnet_input", "stage_c", "stage_b"], "output_tooltips": [null, null, null], "name": "StableCascade_SuperResolutionControlnet", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_stable_cascade", "category": "_for_testing/stable_cascade", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "DifferentialDiffusion": {"input": {"required": {"model": ["MODEL", {}]}, "optional": {"strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model"], "optional": ["strength"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "DifferentialDiffusion", "display_name": "Differential Diffusion", "description": "", "python_module": "comfy_extras.nodes_differential_diffusion", "category": "_for_testing", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "InstructPixToPixConditioning": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "pixels": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "pixels"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "InstructPixToPixConditioning", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_ip2p", "category": "conditioning/instructpix2pix", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ModelMergeSD1": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "time_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "label_emb.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "out.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "time_embed.", "label_emb.", "input_blocks.0.", "input_blocks.1.", "input_blocks.2.", "input_blocks.3.", "input_blocks.4.", "input_blocks.5.", "input_blocks.6.", "input_blocks.7.", "input_blocks.8.", "input_blocks.9.", "input_blocks.10.", "input_blocks.11.", "middle_block.0.", "middle_block.1.", "middle_block.2.", "output_blocks.0.", "output_blocks.1.", "output_blocks.2.", "output_blocks.3.", "output_blocks.4.", "output_blocks.5.", "output_blocks.6.", "output_blocks.7.", "output_blocks.8.", "output_blocks.9.", "output_blocks.10.", "output_blocks.11.", "out."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSD1", "display_name": "ModelMergeSD1", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeSD2": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "time_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "label_emb.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "out.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "time_embed.", "label_emb.", "input_blocks.0.", "input_blocks.1.", "input_blocks.2.", "input_blocks.3.", "input_blocks.4.", "input_blocks.5.", "input_blocks.6.", "input_blocks.7.", "input_blocks.8.", "input_blocks.9.", "input_blocks.10.", "input_blocks.11.", "middle_block.0.", "middle_block.1.", "middle_block.2.", "output_blocks.0.", "output_blocks.1.", "output_blocks.2.", "output_blocks.3.", "output_blocks.4.", "output_blocks.5.", "output_blocks.6.", "output_blocks.7.", "output_blocks.8.", "output_blocks.9.", "output_blocks.10.", "output_blocks.11.", "out."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSD2", "display_name": "ModelMergeSD2", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeSDXL": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "time_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "label_emb.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.0": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.2": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.3": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.4": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.5": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.6": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.7": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.8": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.0": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.2": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.0": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.2": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.3": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.4": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.5": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.6": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.7": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.8": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "out.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "time_embed.", "label_emb.", "input_blocks.0", "input_blocks.1", "input_blocks.2", "input_blocks.3", "input_blocks.4", "input_blocks.5", "input_blocks.6", "input_blocks.7", "input_blocks.8", "middle_block.0", "middle_block.1", "middle_block.2", "output_blocks.0", "output_blocks.1", "output_blocks.2", "output_blocks.3", "output_blocks.4", "output_blocks.5", "output_blocks.6", "output_blocks.7", "output_blocks.8", "out."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSDXL", "display_name": "ModelMergeSDXL", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeSD3_2B": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "x_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "context_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "y_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embed.", "x_embedder.", "context_embedder.", "y_embedder.", "t_embedder.", "joint_blocks.0.", "joint_blocks.1.", "joint_blocks.2.", "joint_blocks.3.", "joint_blocks.4.", "joint_blocks.5.", "joint_blocks.6.", "joint_blocks.7.", "joint_blocks.8.", "joint_blocks.9.", "joint_blocks.10.", "joint_blocks.11.", "joint_blocks.12.", "joint_blocks.13.", "joint_blocks.14.", "joint_blocks.15.", "joint_blocks.16.", "joint_blocks.17.", "joint_blocks.18.", "joint_blocks.19.", "joint_blocks.20.", "joint_blocks.21.", "joint_blocks.22.", "joint_blocks.23.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSD3_2B", "display_name": "ModelMergeSD3_2B", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeAuraflow": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "init_x_linear.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "positional_encoding": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cond_seq_linear.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "register_tokens": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_layers.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_layers.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_layers.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_layers.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "modF.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_linear.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "init_x_linear.", "positional_encoding", "cond_seq_linear.", "register_tokens", "t_embedder.", "double_layers.0.", "double_layers.1.", "double_layers.2.", "double_layers.3.", "single_layers.0.", "single_layers.1.", "single_layers.2.", "single_layers.3.", "single_layers.4.", "single_layers.5.", "single_layers.6.", "single_layers.7.", "single_layers.8.", "single_layers.9.", "single_layers.10.", "single_layers.11.", "single_layers.12.", "single_layers.13.", "single_layers.14.", "single_layers.15.", "single_layers.16.", "single_layers.17.", "single_layers.18.", "single_layers.19.", "single_layers.20.", "single_layers.21.", "single_layers.22.", "single_layers.23.", "single_layers.24.", "single_layers.25.", "single_layers.26.", "single_layers.27.", "single_layers.28.", "single_layers.29.", "single_layers.30.", "single_layers.31.", "modF.", "final_linear."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeAuraflow", "display_name": "ModelMergeAuraflow", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeFlux1": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "img_in.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "time_in.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "guidance_in": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "vector_in.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "txt_in.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.36.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.37.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "img_in.", "time_in.", "guidance_in", "vector_in.", "txt_in.", "double_blocks.0.", "double_blocks.1.", "double_blocks.2.", "double_blocks.3.", "double_blocks.4.", "double_blocks.5.", "double_blocks.6.", "double_blocks.7.", "double_blocks.8.", "double_blocks.9.", "double_blocks.10.", "double_blocks.11.", "double_blocks.12.", "double_blocks.13.", "double_blocks.14.", "double_blocks.15.", "double_blocks.16.", "double_blocks.17.", "double_blocks.18.", "single_blocks.0.", "single_blocks.1.", "single_blocks.2.", "single_blocks.3.", "single_blocks.4.", "single_blocks.5.", "single_blocks.6.", "single_blocks.7.", "single_blocks.8.", "single_blocks.9.", "single_blocks.10.", "single_blocks.11.", "single_blocks.12.", "single_blocks.13.", "single_blocks.14.", "single_blocks.15.", "single_blocks.16.", "single_blocks.17.", "single_blocks.18.", "single_blocks.19.", "single_blocks.20.", "single_blocks.21.", "single_blocks.22.", "single_blocks.23.", "single_blocks.24.", "single_blocks.25.", "single_blocks.26.", "single_blocks.27.", "single_blocks.28.", "single_blocks.29.", "single_blocks.30.", "single_blocks.31.", "single_blocks.32.", "single_blocks.33.", "single_blocks.34.", "single_blocks.35.", "single_blocks.36.", "single_blocks.37.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeFlux1", "display_name": "ModelMergeFlux1", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeSD35_Large": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "x_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "context_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "y_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.36.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.37.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embed.", "x_embedder.", "context_embedder.", "y_embedder.", "t_embedder.", "joint_blocks.0.", "joint_blocks.1.", "joint_blocks.2.", "joint_blocks.3.", "joint_blocks.4.", "joint_blocks.5.", "joint_blocks.6.", "joint_blocks.7.", "joint_blocks.8.", "joint_blocks.9.", "joint_blocks.10.", "joint_blocks.11.", "joint_blocks.12.", "joint_blocks.13.", "joint_blocks.14.", "joint_blocks.15.", "joint_blocks.16.", "joint_blocks.17.", "joint_blocks.18.", "joint_blocks.19.", "joint_blocks.20.", "joint_blocks.21.", "joint_blocks.22.", "joint_blocks.23.", "joint_blocks.24.", "joint_blocks.25.", "joint_blocks.26.", "joint_blocks.27.", "joint_blocks.28.", "joint_blocks.29.", "joint_blocks.30.", "joint_blocks.31.", "joint_blocks.32.", "joint_blocks.33.", "joint_blocks.34.", "joint_blocks.35.", "joint_blocks.36.", "joint_blocks.37.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSD35_Large", "display_name": "ModelMergeSD35_Large", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeMochiPreview": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_frequencies.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t5_y_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t5_yproj.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.36.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.37.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.38.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.39.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.40.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.41.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.42.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.43.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.44.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.45.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.46.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.47.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_frequencies.", "t_embedder.", "t5_y_embedder.", "t5_yproj.", "blocks.0.", "blocks.1.", "blocks.2.", "blocks.3.", "blocks.4.", "blocks.5.", "blocks.6.", "blocks.7.", "blocks.8.", "blocks.9.", "blocks.10.", "blocks.11.", "blocks.12.", "blocks.13.", "blocks.14.", "blocks.15.", "blocks.16.", "blocks.17.", "blocks.18.", "blocks.19.", "blocks.20.", "blocks.21.", "blocks.22.", "blocks.23.", "blocks.24.", "blocks.25.", "blocks.26.", "blocks.27.", "blocks.28.", "blocks.29.", "blocks.30.", "blocks.31.", "blocks.32.", "blocks.33.", "blocks.34.", "blocks.35.", "blocks.36.", "blocks.37.", "blocks.38.", "blocks.39.", "blocks.40.", "blocks.41.", "blocks.42.", "blocks.43.", "blocks.44.", "blocks.45.", "blocks.46.", "blocks.47.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeMochiPreview", "display_name": "ModelMergeMochiPreview", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeLTXV": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "patchify_proj.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "adaln_single.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "caption_projection.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "scale_shift_table": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "proj_out.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "patchify_proj.", "adaln_single.", "caption_projection.", "transformer_blocks.0.", "transformer_blocks.1.", "transformer_blocks.2.", "transformer_blocks.3.", "transformer_blocks.4.", "transformer_blocks.5.", "transformer_blocks.6.", "transformer_blocks.7.", "transformer_blocks.8.", "transformer_blocks.9.", "transformer_blocks.10.", "transformer_blocks.11.", "transformer_blocks.12.", "transformer_blocks.13.", "transformer_blocks.14.", "transformer_blocks.15.", "transformer_blocks.16.", "transformer_blocks.17.", "transformer_blocks.18.", "transformer_blocks.19.", "transformer_blocks.20.", "transformer_blocks.21.", "transformer_blocks.22.", "transformer_blocks.23.", "transformer_blocks.24.", "transformer_blocks.25.", "transformer_blocks.26.", "transformer_blocks.27.", "scale_shift_table", "proj_out."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeLTXV", "display_name": "ModelMergeLTXV", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeCosmos7B": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "extra_pos_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "x_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "affline_norm.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embedder.", "extra_pos_embedder.", "x_embedder.", "t_embedder.", "affline_norm.", "blocks.block0.", "blocks.block1.", "blocks.block2.", "blocks.block3.", "blocks.block4.", "blocks.block5.", "blocks.block6.", "blocks.block7.", "blocks.block8.", "blocks.block9.", "blocks.block10.", "blocks.block11.", "blocks.block12.", "blocks.block13.", "blocks.block14.", "blocks.block15.", "blocks.block16.", "blocks.block17.", "blocks.block18.", "blocks.block19.", "blocks.block20.", "blocks.block21.", "blocks.block22.", "blocks.block23.", "blocks.block24.", "blocks.block25.", "blocks.block26.", "blocks.block27.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeCosmos7B", "display_name": "ModelMergeCosmos7B", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeCosmos14B": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "extra_pos_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "x_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "affline_norm.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embedder.", "extra_pos_embedder.", "x_embedder.", "t_embedder.", "affline_norm.", "blocks.block0.", "blocks.block1.", "blocks.block2.", "blocks.block3.", "blocks.block4.", "blocks.block5.", "blocks.block6.", "blocks.block7.", "blocks.block8.", "blocks.block9.", "blocks.block10.", "blocks.block11.", "blocks.block12.", "blocks.block13.", "blocks.block14.", "blocks.block15.", "blocks.block16.", "blocks.block17.", "blocks.block18.", "blocks.block19.", "blocks.block20.", "blocks.block21.", "blocks.block22.", "blocks.block23.", "blocks.block24.", "blocks.block25.", "blocks.block26.", "blocks.block27.", "blocks.block28.", "blocks.block29.", "blocks.block30.", "blocks.block31.", "blocks.block32.", "blocks.block33.", "blocks.block34.", "blocks.block35.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeCosmos14B", "display_name": "ModelMergeCosmos14B", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeWAN2_1": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "patch_embedding.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "time_embedding.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "time_projection.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "text_embedding.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "img_emb.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.36.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.37.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.38.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.39.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "head.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "patch_embedding.", "time_embedding.", "time_projection.", "text_embedding.", "img_emb.", "blocks.0.", "blocks.1.", "blocks.2.", "blocks.3.", "blocks.4.", "blocks.5.", "blocks.6.", "blocks.7.", "blocks.8.", "blocks.9.", "blocks.10.", "blocks.11.", "blocks.12.", "blocks.13.", "blocks.14.", "blocks.15.", "blocks.16.", "blocks.17.", "blocks.18.", "blocks.19.", "blocks.20.", "blocks.21.", "blocks.22.", "blocks.23.", "blocks.24.", "blocks.25.", "blocks.26.", "blocks.27.", "blocks.28.", "blocks.29.", "blocks.30.", "blocks.31.", "blocks.32.", "blocks.33.", "blocks.34.", "blocks.35.", "blocks.36.", "blocks.37.", "blocks.38.", "blocks.39.", "head."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeWAN2_1", "display_name": "ModelMergeWAN2_1", "description": "1.3B model has 30 blocks, 14B model has 40 blocks. Image to video model has the extra img_emb.", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeCosmosPredict2_2B": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "x_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedding_norm.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embedder.", "x_embedder.", "t_embedder.", "t_embedding_norm.", "blocks.0.", "blocks.1.", "blocks.2.", "blocks.3.", "blocks.4.", "blocks.5.", "blocks.6.", "blocks.7.", "blocks.8.", "blocks.9.", "blocks.10.", "blocks.11.", "blocks.12.", "blocks.13.", "blocks.14.", "blocks.15.", "blocks.16.", "blocks.17.", "blocks.18.", "blocks.19.", "blocks.20.", "blocks.21.", "blocks.22.", "blocks.23.", "blocks.24.", "blocks.25.", "blocks.26.", "blocks.27.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeCosmosPredict2_2B", "display_name": "ModelMergeCosmosPredict2_2B", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeCosmosPredict2_14B": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "x_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedding_norm.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embedder.", "x_embedder.", "t_embedder.", "t_embedding_norm.", "blocks.0.", "blocks.1.", "blocks.2.", "blocks.3.", "blocks.4.", "blocks.5.", "blocks.6.", "blocks.7.", "blocks.8.", "blocks.9.", "blocks.10.", "blocks.11.", "blocks.12.", "blocks.13.", "blocks.14.", "blocks.15.", "blocks.16.", "blocks.17.", "blocks.18.", "blocks.19.", "blocks.20.", "blocks.21.", "blocks.22.", "blocks.23.", "blocks.24.", "blocks.25.", "blocks.26.", "blocks.27.", "blocks.28.", "blocks.29.", "blocks.30.", "blocks.31.", "blocks.32.", "blocks.33.", "blocks.34.", "blocks.35.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeCosmosPredict2_14B", "display_name": "ModelMergeCosmosPredict2_14B", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeQwenImage": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embeds.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "img_in.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "txt_norm.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "txt_in.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "time_text_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.36.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.37.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.38.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.39.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.40.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.41.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.42.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.43.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.44.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.45.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.46.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.47.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.48.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.49.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.50.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.51.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.52.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.53.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.54.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.55.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.56.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.57.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.58.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.59.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "proj_out.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embeds.", "img_in.", "txt_norm.", "txt_in.", "time_text_embed.", "transformer_blocks.0.", "transformer_blocks.1.", "transformer_blocks.2.", "transformer_blocks.3.", "transformer_blocks.4.", "transformer_blocks.5.", "transformer_blocks.6.", "transformer_blocks.7.", "transformer_blocks.8.", "transformer_blocks.9.", "transformer_blocks.10.", "transformer_blocks.11.", "transformer_blocks.12.", "transformer_blocks.13.", "transformer_blocks.14.", "transformer_blocks.15.", "transformer_blocks.16.", "transformer_blocks.17.", "transformer_blocks.18.", "transformer_blocks.19.", "transformer_blocks.20.", "transformer_blocks.21.", "transformer_blocks.22.", "transformer_blocks.23.", "transformer_blocks.24.", "transformer_blocks.25.", "transformer_blocks.26.", "transformer_blocks.27.", "transformer_blocks.28.", "transformer_blocks.29.", "transformer_blocks.30.", "transformer_blocks.31.", "transformer_blocks.32.", "transformer_blocks.33.", "transformer_blocks.34.", "transformer_blocks.35.", "transformer_blocks.36.", "transformer_blocks.37.", "transformer_blocks.38.", "transformer_blocks.39.", "transformer_blocks.40.", "transformer_blocks.41.", "transformer_blocks.42.", "transformer_blocks.43.", "transformer_blocks.44.", "transformer_blocks.45.", "transformer_blocks.46.", "transformer_blocks.47.", "transformer_blocks.48.", "transformer_blocks.49.", "transformer_blocks.50.", "transformer_blocks.51.", "transformer_blocks.52.", "transformer_blocks.53.", "transformer_blocks.54.", "transformer_blocks.55.", "transformer_blocks.56.", "transformer_blocks.57.", "transformer_blocks.58.", "transformer_blocks.59.", "proj_out."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeQwenImage", "display_name": "ModelMergeQwenImage", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "PerturbedAttentionGuidance": {"input": {"required": {"model": ["MODEL", {}], "scale": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": 0.01}]}}, "input_order": {"required": ["model", "scale"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "PerturbedAttentionGuidance", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_pag", "category": "model_patches/unet", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "AlignYourStepsScheduler": {"input": {"required": {"model_type": ["COMBO", {"multiselect": false, "options": ["SD1", "SDXL", "SVD"]}], "steps": ["INT", {"default": 10, "min": 1, "max": 10000}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model_type", "steps", "denoise"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "output_tooltips": [null], "name": "AlignYourStepsScheduler", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_align_your_steps", "category": "sampling/custom_sampling/schedulers", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "UNetSelfAttentionMultiply": {"input": {"required": {"model": ["MODEL", {}], "q": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "k": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "v": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "out": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "q", "k", "v", "out"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "UNetSelfAttentionMultiply", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_attention_multiply", "category": "_for_testing/attention_experiments", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "UNetCrossAttentionMultiply": {"input": {"required": {"model": ["MODEL", {}], "q": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "k": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "v": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "out": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "q", "k", "v", "out"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "UNetCrossAttentionMultiply", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_attention_multiply", "category": "_for_testing/attention_experiments", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "CLIPAttentionMultiply": {"input": {"required": {"clip": ["CLIP", {}], "q": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "k": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "v": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "out": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["clip", "q", "k", "v", "out"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "output_tooltips": [null], "name": "CLIPAttentionMultiply", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_attention_multiply", "category": "_for_testing/attention_experiments", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "UNetTemporalAttentionMultiply": {"input": {"required": {"model": ["MODEL", {}], "self_structural": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "self_temporal": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "cross_structural": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "cross_temporal": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "self_structural", "self_temporal", "cross_structural", "cross_temporal"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "UNetTemporalAttentionMultiply", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_attention_multiply", "category": "_for_testing/attention_experiments", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "SamplerLCMUpscale": {"input": {"required": {"scale_ratio": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 20.0, "step": 0.01}], "scale_steps": ["INT", {"default": -1, "min": -1, "max": 1000, "step": 1}], "upscale_method": ["COMBO", {"multiselect": false, "options": ["bislerp", "nearest-exact", "bilinear", "area", "bicubic"]}]}}, "input_order": {"required": ["scale_ratio", "scale_steps", "upscale_method"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "output_tooltips": [null], "name": "SamplerLCMUpscale", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_advanced_samplers", "category": "sampling/custom_sampling/samplers", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "SamplerEulerCFGpp": {"input": {"required": {"version": ["COMBO", {"multiselect": false, "options": ["regular", "alternative"]}]}}, "input_order": {"required": ["version"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "output_tooltips": [null], "name": "SamplerEulerCFGpp", "display_name": "SamplerEulerCFG++", "description": "", "python_module": "comfy_extras.nodes_advanced_samplers", "category": "_for_testing", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "WebcamCapture": {"input": {"required": {"image": ["WEBCAM", {}], "width": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "height": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "capture_on_queue": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["image", "width", "height", "capture_on_queue"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "WebcamCapture", "display_name": "Webcam Capture", "description": "", "python_module": "comfy_extras.nodes_webcam", "category": "image", "output_node": false}, "EmptyLatentAudio": {"input": {"required": {"seconds": ["FLOAT", {"default": 47.6, "min": 1.0, "max": 1000.0, "step": 0.1}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096, "tooltip": "The number of latent images in the batch."}]}}, "input_order": {"required": ["seconds", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "EmptyLatentAudio", "display_name": "Empty Latent Audio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "latent/audio", "output_node": false}, "VAEEncodeAudio": {"input": {"required": {"audio": ["AUDIO"], "vae": ["VAE"]}}, "input_order": {"required": ["audio", "vae"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VAEEncodeAudio", "display_name": "VAE Encode Audio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "latent/audio", "output_node": false}, "VAEDecodeAudio": {"input": {"required": {"samples": ["LATENT"], "vae": ["VAE"]}}, "input_order": {"required": ["samples", "vae"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "VAEDecodeAudio", "display_name": "VAE Decode Audio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "latent/audio", "output_node": false}, "SaveAudio": {"input": {"required": {"audio": ["AUDIO"], "filename_prefix": ["STRING", {"default": "audio/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["audio", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveAudio", "display_name": "Save Audio (FLAC)", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": true}, "SaveAudioMP3": {"input": {"required": {"audio": ["AUDIO"], "filename_prefix": ["STRING", {"default": "audio/ComfyUI"}], "quality": [["V0", "128k", "320k"], {"default": "V0"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["audio", "filename_prefix", "quality"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveAudioMP3", "display_name": "Save Audio (MP3)", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": true}, "SaveAudioOpus": {"input": {"required": {"audio": ["AUDIO"], "filename_prefix": ["STRING", {"default": "audio/ComfyUI"}], "quality": [["64k", "96k", "128k", "192k", "320k"], {"default": "128k"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["audio", "filename_prefix", "quality"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveAudioOpus", "display_name": "Save Audio (Opus)", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": true}, "LoadAudio": {"input": {"required": {"audio": [[], {"audio_upload": true}]}}, "input_order": {"required": ["audio"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "LoadAudio", "display_name": "Load Audio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "PreviewAudio": {"input": {"required": {"audio": ["AUDIO"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["audio"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "PreviewAudio", "display_name": "Preview Audio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": true}, "ConditioningStableAudio": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "seconds_start": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.1}], "seconds_total": ["FLOAT", {"default": 47.0, "min": 0.0, "max": 1000.0, "step": 0.1}]}}, "input_order": {"required": ["positive", "negative", "seconds_start", "seconds_total"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ConditioningStableAudio", "display_name": "ConditioningStableAudio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "conditioning", "output_node": false}, "RecordAudio": {"input": {"required": {"audio": ["AUDIO_RECORD", {}]}}, "input_order": {"required": ["audio"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "RecordAudio", "display_name": "Record Audio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "TrimAudioDuration": {"input": {"required": {"audio": ["AUDIO"], "start_index": ["FLOAT", {"default": 0.0, "min": -18446744073709551615, "max": 18446744073709551615, "step": 0.01, "tooltip": "Start time in seconds, can be negative to count from the end (supports sub-seconds)."}], "duration": ["FLOAT", {"default": 60.0, "min": 0.0, "step": 0.01, "tooltip": "Duration in seconds"}]}}, "input_order": {"required": ["audio", "start_index", "duration"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "TrimAudioDuration", "display_name": "Trim Audio Duration", "description": "Trim audio tensor into chosen time range.", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "SplitAudioChannels": {"input": {"required": {"audio": ["AUDIO"]}}, "input_order": {"required": ["audio"]}, "output": ["AUDIO", "AUDIO"], "output_is_list": [false, false], "output_name": ["left", "right"], "name": "SplitAudioChannels", "display_name": "Split Audio Channels", "description": "Separates the audio into left and right channels.", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "AudioConcat": {"input": {"required": {"audio1": ["AUDIO"], "audio2": ["AUDIO"], "direction": [["after", "before"], {"default": "after", "tooltip": "Whether to append audio2 after or before audio1."}]}}, "input_order": {"required": ["audio1", "audio2", "direction"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "AudioConcat", "display_name": "Audio Concat", "description": "Concatenates the audio1 to audio2 in the specified direction.", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "AudioMerge": {"input": {"required": {"audio1": ["AUDIO"], "audio2": ["AUDIO"], "merge_method": [["add", "mean", "subtract", "multiply"], {"tooltip": "The method used to combine the audio waveforms."}]}}, "input_order": {"required": ["audio1", "audio2", "merge_method"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "AudioMerge", "display_name": "Audio Merge", "description": "Combine two audio tracks by overlaying their waveforms.", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "AudioAdjustVolume": {"input": {"required": {"audio": ["AUDIO"], "volume": ["INT", {"default": 1.0, "min": -100, "max": 100, "tooltip": "Volume adjustment in decibels (dB). 0 = no change, +6 = double, -6 = half, etc"}]}}, "input_order": {"required": ["audio", "volume"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "AudioAdjustVolume", "display_name": "Audio Adjust Volume", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "EmptyAudio": {"input": {"required": {"duration": ["FLOAT", {"default": 60.0, "min": 0.0, "max": 18446744073709551615, "step": 0.01, "tooltip": "Duration of the empty audio clip in seconds"}], "sample_rate": ["INT", {"default": 44100, "tooltip": "Sample rate of the empty audio clip."}], "channels": ["INT", {"default": 2, "min": 1, "max": 2, "tooltip": "Number of audio channels (1 for mono, 2 for stereo)."}]}}, "input_order": {"required": ["duration", "sample_rate", "channels"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "EmptyAudio", "display_name": "Empty Audio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "TripleCLIPLoader": {"input": {"required": {"clip_name1": ["COMBO", {"multiselect": false, "options": ["clip_l.safetensors", "t5xxl_fp16.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]}], "clip_name2": ["COMBO", {"multiselect": false, "options": ["clip_l.safetensors", "t5xxl_fp16.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]}], "clip_name3": ["COMBO", {"multiselect": false, "options": ["clip_l.safetensors", "t5xxl_fp16.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]}]}}, "input_order": {"required": ["clip_name1", "clip_name2", "clip_name3"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "output_tooltips": [null], "name": "TripleCLIPLoader", "display_name": null, "description": "[Recipes]\n\nsd3: clip-l, clip-g, t5", "python_module": "comfy_extras.nodes_sd3", "category": "advanced/loaders", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "EmptySD3LatentImage": {"input": {"required": {"width": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 16}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "EmptySD3LatentImage", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_sd3", "category": "latent/sd3", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CLIPTextEncodeSD3": {"input": {"required": {"clip": ["CLIP", {}], "clip_l": ["STRING", {"multiline": true, "dynamicPrompts": true}], "clip_g": ["STRING", {"multiline": true, "dynamicPrompts": true}], "t5xxl": ["STRING", {"multiline": true, "dynamicPrompts": true}], "empty_padding": ["COMBO", {"multiselect": false, "options": ["none", "empty_prompt"]}]}}, "input_order": {"required": ["clip", "clip_l", "clip_g", "t5xxl", "empty_padding"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "CLIPTextEncodeSD3", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_sd3", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ControlNetApplySD3": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "control_net": ["CONTROL_NET", {}], "vae": ["VAE", {}], "image": ["IMAGE", {}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["positive", "negative", "control_net", "vae", "image", "strength", "start_percent", "end_percent"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "output_tooltips": [null, null], "name": "ControlNetApplySD3", "display_name": "Apply Controlnet with VAE", "description": "", "python_module": "comfy_extras.nodes_sd3", "category": "conditioning/controlnet", "output_node": false, "deprecated": true, "experimental": false, "api_node": false}, "SkipLayerGuidanceSD3": {"input": {"required": {"model": ["MODEL", {}], "layers": ["STRING", {"default": "7, 8, 9", "multiline": false}], "scale": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 10.0, "step": 0.1}], "start_percent": ["FLOAT", {"default": 0.01, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 0.15, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["model", "layers", "scale", "start_percent", "end_percent"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "SkipLayerGuidanceSD3", "display_name": null, "description": "Generic version of SkipLayerGuidance node that can be used on every DiT model.", "python_module": "comfy_extras.nodes_sd3", "category": "advanced/guidance", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "GITSScheduler": {"input": {"required": {"coeff": ["FLOAT", {"default": 1.2, "min": 0.8, "max": 1.5, "step": 0.05}], "steps": ["INT", {"default": 10, "min": 2, "max": 1000}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["coeff", "steps", "denoise"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "output_tooltips": [null], "name": "GITSScheduler", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_gits", "category": "sampling/custom_sampling/schedulers", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "SetUnionControlNetType": {"input": {"required": {"control_net": ["CONTROL_NET", {}], "type": ["COMBO", {"multiselect": false, "options": ["auto", "openpose", "depth", "hed/pidi/scribble/ted", "canny/lineart/anime_lineart/mlsd", "normal", "segment", "tile", "repaint"]}]}}, "input_order": {"required": ["control_net", "type"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "output_tooltips": [null], "name": "SetUnionControlNetType", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_controlnet", "category": "conditioning/controlnet", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ControlNetInpaintingAliMamaApply": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "control_net": ["CONTROL_NET", {}], "vae": ["VAE", {}], "image": ["IMAGE", {}], "mask": ["MASK", {}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["positive", "negative", "control_net", "vae", "image", "mask", "strength", "start_percent", "end_percent"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "output_tooltips": [null, null], "name": "ControlNetInpaintingAliMamaApply", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_controlnet", "category": "conditioning/controlnet", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CLIPTextEncodeHunyuanDiT": {"input": {"required": {"clip": ["CLIP", {}], "bert": ["STRING", {"multiline": true, "dynamicPrompts": true}], "mt5xl": ["STRING", {"multiline": true, "dynamicPrompts": true}]}}, "input_order": {"required": ["clip", "bert", "mt5xl"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "CLIPTextEncodeHunyuanDiT", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hunyuan", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "TextEncodeHunyuanVideo_ImageToVideo": {"input": {"required": {"clip": ["CLIP", {}], "clip_vision_output": ["CLIP_VISION_OUTPUT", {}], "prompt": ["STRING", {"multiline": true, "dynamicPrompts": true}], "image_interleave": ["INT", {"tooltip": "How much the image influences things vs the text prompt. Higher number means more influence from the text prompt.", "default": 2, "min": 1, "max": 512}]}}, "input_order": {"required": ["clip", "clip_vision_output", "prompt", "image_interleave"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "TextEncodeHunyuanVideo_ImageToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hunyuan", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "EmptyHunyuanLatentVideo": {"input": {"required": {"width": ["INT", {"default": 848, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 25, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "length", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "EmptyHunyuanLatentVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hunyuan", "category": "latent/video", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "HunyuanImageToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 848, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 53, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "guidance_type": ["COMBO", {"multiselect": false, "options": ["v1 (concat)", "v2 (replace)", "custom"]}]}, "optional": {"start_image": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "vae", "width", "height", "length", "batch_size", "guidance_type"], "optional": ["start_image"]}, "output": ["CONDITIONING", "LATENT"], "output_is_list": [false, false], "output_name": ["positive", "latent"], "output_tooltips": [null, null], "name": "HunyuanImageToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hunyuan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "EmptyHunyuanImageLatent": {"input": {"required": {"width": ["INT", {"default": 2048, "min": 64, "max": 16384, "step": 32}], "height": ["INT", {"default": 2048, "min": 64, "max": 16384, "step": 32}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "EmptyHunyuanImageLatent", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hunyuan", "category": "latent", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "HunyuanRefinerLatent": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "latent": ["LATENT", {}], "noise_augmentation": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["positive", "negative", "latent", "noise_augmentation"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "HunyuanRefinerLatent", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hunyuan", "category": "sd", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "Epsilon Scaling": {"input": {"required": {"model": ["MODEL", {}], "scaling_factor": ["FLOAT", {"default": 1.005, "min": 0.5, "max": 1.5, "step": 0.001, "display": "number"}]}}, "input_order": {"required": ["model", "scaling_factor"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "Epsilon Scaling", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_eps", "category": "model_patches/unet", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "TemporalScoreRescaling": {"input": {"required": {"model": ["MODEL", {}], "tsr_k": ["FLOAT", {"tooltip": "Controls the rescaling strength.\nLower k produces more detailed results; higher k produces smoother results in image generation. Setting k = 1 disables rescaling.", "default": 0.95, "min": 0.01, "max": 100.0, "step": 0.001, "display": "number"}], "tsr_sigma": ["FLOAT", {"tooltip": "Controls how early rescaling takes effect.\nLarger values take effect earlier.", "default": 1.0, "min": 0.01, "max": 100.0, "step": 0.001, "display": "number"}]}}, "input_order": {"required": ["model", "tsr_k", "tsr_sigma"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["patched_model"], "output_tooltips": [null], "name": "TemporalScoreRescaling", "display_name": "TSR - Temporal Score Rescaling", "description": "[Post-CFG Function]\nTSR - Temporal Score Rescaling (2510.01184)\n\nRescaling the model's score or noise to steer the sampling diversity.\n", "python_module": "comfy_extras.nodes_eps", "category": "model_patches/unet", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CLIPTextEncodeFlux": {"input": {"required": {"clip": ["CLIP", {}], "clip_l": ["STRING", {"multiline": true, "dynamicPrompts": true}], "t5xxl": ["STRING", {"multiline": true, "dynamicPrompts": true}], "guidance": ["FLOAT", {"default": 3.5, "min": 0.0, "max": 100.0, "step": 0.1}]}}, "input_order": {"required": ["clip", "clip_l", "t5xxl", "guidance"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "CLIPTextEncodeFlux", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_flux", "category": "advanced/conditioning/flux", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "FluxGuidance": {"input": {"required": {"conditioning": ["CONDITIONING", {}], "guidance": ["FLOAT", {"default": 3.5, "min": 0.0, "max": 100.0, "step": 0.1}]}}, "input_order": {"required": ["conditioning", "guidance"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "FluxGuidance", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_flux", "category": "advanced/conditioning/flux", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "FluxDisableGuidance": {"input": {"required": {"conditioning": ["CONDITIONING", {}]}}, "input_order": {"required": ["conditioning"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "FluxDisableGuidance", "display_name": null, "description": "This node completely disables the guidance embed on Flux and Flux like models", "python_module": "comfy_extras.nodes_flux", "category": "advanced/conditioning/flux", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "FluxKontextImageScale": {"input": {"required": {"image": ["IMAGE", {}]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "FluxKontextImageScale", "display_name": null, "description": "This node resizes the image to one that is more optimal for flux kontext.", "python_module": "comfy_extras.nodes_flux", "category": "advanced/conditioning/flux", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "FluxKontextMultiReferenceLatentMethod": {"input": {"required": {"conditioning": ["CONDITIONING", {}], "reference_latents_method": ["COMBO", {"multiselect": false, "options": ["offset", "index", "uxo/uno"]}]}}, "input_order": {"required": ["conditioning", "reference_latents_method"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "FluxKontextMultiReferenceLatentMethod", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_flux", "category": "advanced/conditioning/flux", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "LoraSave": {"input": {"required": {"filename_prefix": ["STRING", {"default": "loras/ComfyUI_extracted_lora", "multiline": false}], "rank": ["INT", {"default": 8, "min": 1, "max": 4096, "step": 1}], "lora_type": ["COMBO", {"multiselect": false, "options": ["standard", "full_diff"]}], "bias_diff": ["BOOLEAN", {"default": true}]}, "optional": {"model_diff": ["MODEL", {"tooltip": "The ModelSubtract output to be converted to a lora."}], "text_encoder_diff": ["CLIP", {"tooltip": "The CLIPSubtract output to be converted to a lora."}]}, "hidden": {"prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["filename_prefix", "rank", "lora_type", "bias_diff"], "optional": ["model_diff", "text_encoder_diff"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "output_tooltips": [], "name": "LoraSave", "display_name": "Extract and Save Lora", "description": "", "python_module": "comfy_extras.nodes_lora_extract", "category": "_for_testing", "output_node": true, "deprecated": false, "experimental": true, "api_node": false}, "TorchCompileModel": {"input": {"required": {"model": ["MODEL", {}], "backend": ["COMBO", {"multiselect": false, "options": ["inductor", "cudagraphs"]}]}}, "input_order": {"required": ["model", "backend"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "TorchCompileModel", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_torch_compile", "category": "_for_testing", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "EmptyMochiLatentVideo": {"input": {"required": {"width": ["INT", {"default": 848, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 25, "min": 7, "max": 16384, "step": 6}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "length", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "EmptyMochiLatentVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_mochi", "category": "latent/video", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "SkipLayerGuidanceDiT": {"input": {"required": {"model": ["MODEL", {}], "double_layers": ["STRING", {"default": "7, 8, 9", "multiline": false}], "single_layers": ["STRING", {"default": "7, 8, 9", "multiline": false}], "scale": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 10.0, "step": 0.1}], "start_percent": ["FLOAT", {"default": 0.01, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 0.15, "min": 0.0, "max": 1.0, "step": 0.001}], "rescaling_scale": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "double_layers", "single_layers", "scale", "start_percent", "end_percent", "rescaling_scale"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "SkipLayerGuidanceDiT", "display_name": null, "description": "Generic version of SkipLayerGuidance node that can be used on every DiT model.", "python_module": "comfy_extras.nodes_slg", "category": "advanced/guidance", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "SkipLayerGuidanceDiTSimple": {"input": {"required": {"model": ["MODEL", {}], "double_layers": ["STRING", {"default": "7, 8, 9", "multiline": false}], "single_layers": ["STRING", {"default": "7, 8, 9", "multiline": false}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["model", "double_layers", "single_layers", "start_percent", "end_percent"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "SkipLayerGuidanceDiTSimple", "display_name": null, "description": "Simple version of the SkipLayerGuidanceDiT node that only modifies the uncond pass.", "python_module": "comfy_extras.nodes_slg", "category": "advanced/guidance", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "Mahiro": {"input": {"required": {"model": ["MODEL", {}]}}, "input_order": {"required": ["model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["patched_model"], "output_tooltips": [null], "name": "Mahiro", "display_name": "Mahiro is so cute that she deserves a better guidance function!! (\u3002\u30fb\u03c9\u30fb\u3002)", "description": "Modify the guidance to scale more on the 'direction' of the positive prompt rather than the difference between the negative prompt.", "python_module": "comfy_extras.nodes_mahiro", "category": "_for_testing", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "EmptyLTXVLatentVideo": {"input": {"required": {"width": ["INT", {"default": 768, "min": 64, "max": 16384, "step": 32}], "height": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 32}], "length": ["INT", {"default": 97, "min": 1, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "length", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "EmptyLTXVLatentVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lt", "category": "latent/video/ltxv", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LTXVImgToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "image": ["IMAGE", {}], "width": ["INT", {"default": 768, "min": 64, "max": 16384, "step": 32}], "height": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 32}], "length": ["INT", {"default": 97, "min": 9, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0}]}}, "input_order": {"required": ["positive", "negative", "vae", "image", "width", "height", "length", "batch_size", "strength"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "LTXVImgToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lt", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ModelSamplingLTXV": {"input": {"required": {"model": ["MODEL", {}], "max_shift": ["FLOAT", {"default": 2.05, "min": 0.0, "max": 100.0, "step": 0.01}], "base_shift": ["FLOAT", {"default": 0.95, "min": 0.0, "max": 100.0, "step": 0.01}]}, "optional": {"latent": ["LATENT", {}]}}, "input_order": {"required": ["model", "max_shift", "base_shift"], "optional": ["latent"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "ModelSamplingLTXV", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lt", "category": "advanced/model", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LTXVConditioning": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "frame_rate": ["FLOAT", {"default": 25.0, "min": 0.0, "max": 1000.0, "step": 0.01}]}}, "input_order": {"required": ["positive", "negative", "frame_rate"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "output_tooltips": [null, null], "name": "LTXVConditioning", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lt", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LTXVScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "max_shift": ["FLOAT", {"default": 2.05, "min": 0.0, "max": 100.0, "step": 0.01}], "base_shift": ["FLOAT", {"default": 0.95, "min": 0.0, "max": 100.0, "step": 0.01}], "stretch": ["BOOLEAN", {"tooltip": "Stretch the sigmas to be in the range [terminal, 1].", "default": true}], "terminal": ["FLOAT", {"tooltip": "The terminal value of the sigmas after stretching.", "default": 0.1, "min": 0.0, "max": 0.99, "step": 0.01}]}, "optional": {"latent": ["LATENT", {}]}}, "input_order": {"required": ["steps", "max_shift", "base_shift", "stretch", "terminal"], "optional": ["latent"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "output_tooltips": [null], "name": "LTXVScheduler", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lt", "category": "sampling/custom_sampling/schedulers", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LTXVAddGuide": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "latent": ["LATENT", {}], "image": ["IMAGE", {"tooltip": "Image or video to condition the latent video on. Must be 8*n + 1 frames. If the video is not 8*n + 1 frames, it will be cropped to the nearest 8*n + 1 frames."}], "frame_idx": ["INT", {"tooltip": "Frame index to start the conditioning at. For single-frame images or videos with 1-8 frames, any frame_idx value is acceptable. For videos with 9+ frames, frame_idx must be divisible by 8, otherwise it will be rounded down to the nearest multiple of 8. Negative values are counted from the end of the video.", "default": 0, "min": -9999, "max": 9999}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["positive", "negative", "vae", "latent", "image", "frame_idx", "strength"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "LTXVAddGuide", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lt", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LTXVPreprocess": {"input": {"required": {"image": ["IMAGE", {}], "img_compression": ["INT", {"tooltip": "Amount of compression to apply on image.", "default": 35, "min": 0, "max": 100}]}}, "input_order": {"required": ["image", "img_compression"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["output_image"], "output_tooltips": [null], "name": "LTXVPreprocess", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lt", "category": "image", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LTXVCropGuides": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "latent": ["LATENT", {}]}}, "input_order": {"required": ["positive", "negative", "latent"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "LTXVCropGuides", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lt", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CreateHookLora": {"input": {"required": {"lora_name": [["BiFangBird.safetensors", "DrugPony.safetensors", "Harrlogos_v2.0.safetensors", "Inquisition_v1.safetensors", "Iridescence.safetensors", "Luxury_Houses_V1-000009.safetensors", "MJ52_v2.0.safetensors", "Textimprover-FLUX-V0.4.safetensors", "animemix_v3_offset.safetensors", "ff7r_style_ned_offset.safetensors", "first_stage-10.safetensors", "fractalized.safetensors", "hyvideo_FastVideo_LoRA-fp8.safetensors", "neoclassical villa - PHK.safetensors", "pokemon_v3_offset.safetensors", "polyhedron_new_skin_v1.1.safetensors", "poms-funtime-mlora-emporium/LiquidAF-0-1.safetensors", "poms-funtime-mlora-emporium/Smoooth-0-1.safetensors", "poms-funtime-mlora-emporium/WAS26.safetensors", "psychedelic_portrait.safetensors", "sd_xl_offset_example-lora_1.0.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"prev_hooks": ["HOOKS"]}}, "input_order": {"required": ["lora_name", "strength_model", "strength_clip"], "optional": ["prev_hooks"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CreateHookLora", "display_name": "Create Hook LoRA", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/create", "output_node": false, "experimental": true}, "CreateHookLoraModelOnly": {"input": {"required": {"lora_name": [["BiFangBird.safetensors", "DrugPony.safetensors", "Harrlogos_v2.0.safetensors", "Inquisition_v1.safetensors", "Iridescence.safetensors", "Luxury_Houses_V1-000009.safetensors", "MJ52_v2.0.safetensors", "Textimprover-FLUX-V0.4.safetensors", "animemix_v3_offset.safetensors", "ff7r_style_ned_offset.safetensors", "first_stage-10.safetensors", "fractalized.safetensors", "hyvideo_FastVideo_LoRA-fp8.safetensors", "neoclassical villa - PHK.safetensors", "pokemon_v3_offset.safetensors", "polyhedron_new_skin_v1.1.safetensors", "poms-funtime-mlora-emporium/LiquidAF-0-1.safetensors", "poms-funtime-mlora-emporium/Smoooth-0-1.safetensors", "poms-funtime-mlora-emporium/WAS26.safetensors", "psychedelic_portrait.safetensors", "sd_xl_offset_example-lora_1.0.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"prev_hooks": ["HOOKS"]}}, "input_order": {"required": ["lora_name", "strength_model"], "optional": ["prev_hooks"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CreateHookLoraModelOnly", "display_name": "Create Hook LoRA (MO)", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/create", "output_node": false, "experimental": true}, "CreateHookModelAsLora": {"input": {"required": {"ckpt_name": [["Artfusion Surreal XL.safetensors", "Flux_dev_turbo_krea_mix.safetensors", "Flux_dev_v1.safetensors", "XLbluePencilXL_v700.safetensors", "XLrealbluejuggernautmi_v10.safetensors", "animagineXLRealistic_v5.safetensors", "animeIllustDiffusion_v08.safetensors", "artfusionXL_v11Lightning.safetensors", "cyberrealisticXL_v5.safetensors", "dreamshaperXL_v21TurboDPMSDE.safetensors", "electricDreams_electricDreamsV04.safetensors", "epicrealismXL_vxvAnewstoryRealism.safetensors", "illustrationStyleIV.nR7A.safetensors", "illustrationXL_v10.safetensors", "jibMixRealisticXL_v170SmokeSheen.safetensors", "jruTheJourneyRemains_v20XL.safetensors", "midgardPonyTHLSDXL_v32.safetensors", "pixniteXL_v10.safetensors", "reymixXL_v20.safetensors", "sd_xl_base_1.0.safetensors", "sd_xl_refiner_1.0.safetensors", "sdxlFaetastic_v10.safetensors", "sdxlInkpunkstyle_v01.safetensors", "v1-5-pruned-emaonly.safetensors", "xl6HEPHAISTOSSD10XLSFW_v331BF16Experimental.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"prev_hooks": ["HOOKS"]}}, "input_order": {"required": ["ckpt_name", "strength_model", "strength_clip"], "optional": ["prev_hooks"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CreateHookModelAsLora", "display_name": "Create Hook Model as LoRA", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/create", "output_node": false, "experimental": true}, "CreateHookModelAsLoraModelOnly": {"input": {"required": {"ckpt_name": [["Artfusion Surreal XL.safetensors", "Flux_dev_turbo_krea_mix.safetensors", "Flux_dev_v1.safetensors", "XLbluePencilXL_v700.safetensors", "XLrealbluejuggernautmi_v10.safetensors", "animagineXLRealistic_v5.safetensors", "animeIllustDiffusion_v08.safetensors", "artfusionXL_v11Lightning.safetensors", "cyberrealisticXL_v5.safetensors", "dreamshaperXL_v21TurboDPMSDE.safetensors", "electricDreams_electricDreamsV04.safetensors", "epicrealismXL_vxvAnewstoryRealism.safetensors", "illustrationStyleIV.nR7A.safetensors", "illustrationXL_v10.safetensors", "jibMixRealisticXL_v170SmokeSheen.safetensors", "jruTheJourneyRemains_v20XL.safetensors", "midgardPonyTHLSDXL_v32.safetensors", "pixniteXL_v10.safetensors", "reymixXL_v20.safetensors", "sd_xl_base_1.0.safetensors", "sd_xl_refiner_1.0.safetensors", "sdxlFaetastic_v10.safetensors", "sdxlInkpunkstyle_v01.safetensors", "v1-5-pruned-emaonly.safetensors", "xl6HEPHAISTOSSD10XLSFW_v331BF16Experimental.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"prev_hooks": ["HOOKS"]}}, "input_order": {"required": ["ckpt_name", "strength_model"], "optional": ["prev_hooks"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CreateHookModelAsLoraModelOnly", "display_name": "Create Hook Model as LoRA (MO)", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/create", "output_node": false, "experimental": true}, "SetHookKeyframes": {"input": {"required": {"hooks": ["HOOKS"]}, "optional": {"hook_kf": ["HOOK_KEYFRAMES"]}}, "input_order": {"required": ["hooks"], "optional": ["hook_kf"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "SetHookKeyframes", "display_name": "Set Hook Keyframes", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/scheduling", "output_node": false, "experimental": true}, "CreateHookKeyframe": {"input": {"required": {"strength_mult": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"prev_hook_kf": ["HOOK_KEYFRAMES"]}}, "input_order": {"required": ["strength_mult", "start_percent"], "optional": ["prev_hook_kf"]}, "output": ["HOOK_KEYFRAMES"], "output_is_list": [false], "output_name": ["HOOK_KF"], "name": "CreateHookKeyframe", "display_name": "Create Hook Keyframe", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/scheduling", "output_node": false, "experimental": true}, "CreateHookKeyframesInterpolated": {"input": {"required": {"strength_start": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "strength_end": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "keyframes_count": ["INT", {"default": 5, "min": 2, "max": 100, "step": 1}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_hook_kf": ["HOOK_KEYFRAMES"]}}, "input_order": {"required": ["strength_start", "strength_end", "interpolation", "start_percent", "end_percent", "keyframes_count", "print_keyframes"], "optional": ["prev_hook_kf"]}, "output": ["HOOK_KEYFRAMES"], "output_is_list": [false], "output_name": ["HOOK_KF"], "name": "CreateHookKeyframesInterpolated", "display_name": "Create Hook Keyframes Interp.", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/scheduling", "output_node": false, "experimental": true}, "CreateHookKeyframesFromFloats": {"input": {"required": {"floats_strength": ["FLOATS", {"default": -1, "min": -1, "step": 0.001, "forceInput": true}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_hook_kf": ["HOOK_KEYFRAMES"]}}, "input_order": {"required": ["floats_strength", "start_percent", "end_percent", "print_keyframes"], "optional": ["prev_hook_kf"]}, "output": ["HOOK_KEYFRAMES"], "output_is_list": [false], "output_name": ["HOOK_KF"], "name": "CreateHookKeyframesFromFloats", "display_name": "Create Hook Keyframes From Floats", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/scheduling", "output_node": false, "experimental": true}, "CombineHooks2": {"input": {"required": {}, "optional": {"hooks_A": ["HOOKS"], "hooks_B": ["HOOKS"]}}, "input_order": {"required": [], "optional": ["hooks_A", "hooks_B"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CombineHooks2", "display_name": "Combine Hooks [2]", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/combine", "output_node": false, "experimental": true}, "CombineHooks4": {"input": {"required": {}, "optional": {"hooks_A": ["HOOKS"], "hooks_B": ["HOOKS"], "hooks_C": ["HOOKS"], "hooks_D": ["HOOKS"]}}, "input_order": {"required": [], "optional": ["hooks_A", "hooks_B", "hooks_C", "hooks_D"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CombineHooks4", "display_name": "Combine Hooks [4]", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/combine", "output_node": false, "experimental": true}, "CombineHooks8": {"input": {"required": {}, "optional": {"hooks_A": ["HOOKS"], "hooks_B": ["HOOKS"], "hooks_C": ["HOOKS"], "hooks_D": ["HOOKS"], "hooks_E": ["HOOKS"], "hooks_F": ["HOOKS"], "hooks_G": ["HOOKS"], "hooks_H": ["HOOKS"]}}, "input_order": {"required": [], "optional": ["hooks_A", "hooks_B", "hooks_C", "hooks_D", "hooks_E", "hooks_F", "hooks_G", "hooks_H"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CombineHooks8", "display_name": "Combine Hooks [8]", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/combine", "output_node": false, "experimental": true}, "ConditioningSetProperties": {"input": {"required": {"cond_NEW": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"mask": ["MASK"], "hooks": ["HOOKS"], "timesteps": ["TIMESTEPS_RANGE"]}}, "input_order": {"required": ["cond_NEW", "strength", "set_cond_area"], "optional": ["mask", "hooks", "timesteps"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetProperties", "display_name": "Cond Set Props", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond single", "output_node": false, "experimental": true}, "ConditioningSetPropertiesAndCombine": {"input": {"required": {"cond": ["CONDITIONING"], "cond_NEW": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"mask": ["MASK"], "hooks": ["HOOKS"], "timesteps": ["TIMESTEPS_RANGE"]}}, "input_order": {"required": ["cond", "cond_NEW", "strength", "set_cond_area"], "optional": ["mask", "hooks", "timesteps"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetPropertiesAndCombine", "display_name": "Cond Set Props Combine", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond single", "output_node": false, "experimental": true}, "PairConditioningSetProperties": {"input": {"required": {"positive_NEW": ["CONDITIONING"], "negative_NEW": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"mask": ["MASK"], "hooks": ["HOOKS"], "timesteps": ["TIMESTEPS_RANGE"]}}, "input_order": {"required": ["positive_NEW", "negative_NEW", "strength", "set_cond_area"], "optional": ["mask", "hooks", "timesteps"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "PairConditioningSetProperties", "display_name": "Cond Pair Set Props", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond pair", "output_node": false, "experimental": true}, "PairConditioningSetPropertiesAndCombine": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "positive_NEW": ["CONDITIONING"], "negative_NEW": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"mask": ["MASK"], "hooks": ["HOOKS"], "timesteps": ["TIMESTEPS_RANGE"]}}, "input_order": {"required": ["positive", "negative", "positive_NEW", "negative_NEW", "strength", "set_cond_area"], "optional": ["mask", "hooks", "timesteps"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "PairConditioningSetPropertiesAndCombine", "display_name": "Cond Pair Set Props Combine", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond pair", "output_node": false, "experimental": true}, "ConditioningSetDefaultCombine": {"input": {"required": {"cond": ["CONDITIONING"], "cond_DEFAULT": ["CONDITIONING"]}, "optional": {"hooks": ["HOOKS"]}}, "input_order": {"required": ["cond", "cond_DEFAULT"], "optional": ["hooks"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetDefaultCombine", "display_name": "Cond Set Default Combine", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond single", "output_node": false, "experimental": true}, "PairConditioningSetDefaultCombine": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "positive_DEFAULT": ["CONDITIONING"], "negative_DEFAULT": ["CONDITIONING"]}, "optional": {"hooks": ["HOOKS"]}}, "input_order": {"required": ["positive", "negative", "positive_DEFAULT", "negative_DEFAULT"], "optional": ["hooks"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "PairConditioningSetDefaultCombine", "display_name": "Cond Pair Set Default Combine", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond pair", "output_node": false, "experimental": true}, "PairConditioningCombine": {"input": {"required": {"positive_A": ["CONDITIONING"], "negative_A": ["CONDITIONING"], "positive_B": ["CONDITIONING"], "negative_B": ["CONDITIONING"]}}, "input_order": {"required": ["positive_A", "negative_A", "positive_B", "negative_B"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "PairConditioningCombine", "display_name": "Cond Pair Combine", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond pair", "output_node": false, "experimental": true}, "SetClipHooks": {"input": {"required": {"clip": ["CLIP"], "apply_to_conds": ["BOOLEAN", {"default": true}], "schedule_clip": ["BOOLEAN", {"default": false}]}, "optional": {"hooks": ["HOOKS"]}}, "input_order": {"required": ["clip", "apply_to_conds", "schedule_clip"], "optional": ["hooks"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "SetClipHooks", "display_name": "Set CLIP Hooks", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/clip", "output_node": false, "experimental": true}, "ConditioningTimestepsRange": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["start_percent", "end_percent"]}, "output": ["TIMESTEPS_RANGE", "TIMESTEPS_RANGE", "TIMESTEPS_RANGE"], "output_is_list": [false, false, false], "output_name": ["TIMESTEPS_RANGE", "BEFORE_RANGE", "AFTER_RANGE"], "name": "ConditioningTimestepsRange", "display_name": "Timesteps Range", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks", "output_node": false, "experimental": true}, "Load3D": {"input": {"required": {"model_file": [[], {"file_upload": true}], "image": ["LOAD_3D", {}], "width": ["INT", {"default": 1024, "min": 1, "max": 4096, "step": 1}], "height": ["INT", {"default": 1024, "min": 1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["model_file", "image", "width", "height"]}, "output": ["IMAGE", "MASK", "STRING", "IMAGE", "IMAGE", "LOAD3D_CAMERA", "VIDEO"], "output_is_list": [false, false, false, false, false, false, false], "output_name": ["image", "mask", "mesh_path", "normal", "lineart", "camera_info", "recording_video"], "name": "Load3D", "display_name": "Load 3D", "description": "", "python_module": "comfy_extras.nodes_load_3d", "category": "3d", "output_node": false, "experimental": true}, "Load3DAnimation": {"input": {"required": {"model_file": [[], {"file_upload": true}], "image": ["LOAD_3D_ANIMATION", {}], "width": ["INT", {"default": 1024, "min": 1, "max": 4096, "step": 1}], "height": ["INT", {"default": 1024, "min": 1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["model_file", "image", "width", "height"]}, "output": ["IMAGE", "MASK", "STRING", "IMAGE", "LOAD3D_CAMERA", "VIDEO"], "output_is_list": [false, false, false, false, false, false], "output_name": ["image", "mask", "mesh_path", "normal", "camera_info", "recording_video"], "name": "Load3DAnimation", "display_name": "Load 3D - Animation", "description": "", "python_module": "comfy_extras.nodes_load_3d", "category": "3d", "output_node": false, "experimental": true}, "Preview3D": {"input": {"required": {"model_file": ["STRING", {"default": "", "multiline": false}]}, "optional": {"camera_info": ["LOAD3D_CAMERA", {}]}}, "input_order": {"required": ["model_file"], "optional": ["camera_info"]}, "output": [], "output_is_list": [], "output_name": [], "name": "Preview3D", "display_name": "Preview 3D", "description": "", "python_module": "comfy_extras.nodes_load_3d", "category": "3d", "output_node": true, "experimental": true}, "Preview3DAnimation": {"input": {"required": {"model_file": ["STRING", {"default": "", "multiline": false}]}, "optional": {"camera_info": ["LOAD3D_CAMERA", {}]}}, "input_order": {"required": ["model_file"], "optional": ["camera_info"]}, "output": [], "output_is_list": [], "output_name": [], "name": "Preview3DAnimation", "display_name": "Preview 3D - Animation", "description": "", "python_module": "comfy_extras.nodes_load_3d", "category": "3d", "output_node": true, "experimental": true}, "EmptyCosmosLatentVideo": {"input": {"required": {"width": ["INT", {"default": 1280, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 704, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 121, "min": 1, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "length", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "EmptyCosmosLatentVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_cosmos", "category": "latent/video", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CosmosImageToVideoLatent": {"input": {"required": {"vae": ["VAE", {}], "width": ["INT", {"default": 1280, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 704, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 121, "min": 1, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"start_image": ["IMAGE", {}], "end_image": ["IMAGE", {}]}}, "input_order": {"required": ["vae", "width", "height", "length", "batch_size"], "optional": ["start_image", "end_image"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "CosmosImageToVideoLatent", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_cosmos", "category": "conditioning/inpaint", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CosmosPredict2ImageToVideoLatent": {"input": {"required": {"vae": ["VAE", {}], "width": ["INT", {"default": 848, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 93, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"start_image": ["IMAGE", {}], "end_image": ["IMAGE", {}]}}, "input_order": {"required": ["vae", "width", "height", "length", "batch_size"], "optional": ["start_image", "end_image"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "CosmosPredict2ImageToVideoLatent", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_cosmos", "category": "conditioning/inpaint", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "SaveWEBM": {"input": {"required": {"images": ["IMAGE", {}], "filename_prefix": ["STRING", {"default": "ComfyUI", "multiline": false}], "codec": ["COMBO", {"multiselect": false, "options": ["vp9", "av1"]}], "fps": ["FLOAT", {"default": 24.0, "min": 0.01, "max": 1000.0, "step": 0.01}], "crf": ["FLOAT", {"tooltip": "Higher crf means lower quality with a smaller file size, lower crf means higher quality higher filesize.", "default": 32.0, "min": 0, "max": 63.0, "step": 1}]}, "hidden": {"prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["images", "filename_prefix", "codec", "fps", "crf"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "output_tooltips": [], "name": "SaveWEBM", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_video", "category": "image/video", "output_node": true, "deprecated": false, "experimental": true, "api_node": false}, "SaveVideo": {"input": {"required": {"video": ["VIDEO", {"tooltip": "The video to save."}], "filename_prefix": ["STRING", {"tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes.", "default": "video/ComfyUI", "multiline": false}], "format": ["COMBO", {"tooltip": "The format to save the video as.", "default": "auto", "multiselect": false, "options": ["auto", "mp4"]}], "codec": ["COMBO", {"tooltip": "The codec to use for the video.", "default": "auto", "multiselect": false, "options": ["auto", "h264"]}]}, "hidden": {"prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["video", "filename_prefix", "format", "codec"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "output_tooltips": [], "name": "SaveVideo", "display_name": "Save Video", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "comfy_extras.nodes_video", "category": "image/video", "output_node": true, "deprecated": false, "experimental": false, "api_node": false}, "CreateVideo": {"input": {"required": {"images": ["IMAGE", {"tooltip": "The images to create a video from."}], "fps": ["FLOAT", {"default": 30.0, "min": 1.0, "max": 120.0, "step": 1.0}]}, "optional": {"audio": ["AUDIO", {"tooltip": "The audio to add to the video."}]}}, "input_order": {"required": ["images", "fps"], "optional": ["audio"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "CreateVideo", "display_name": "Create Video", "description": "Create a video from images.", "python_module": "comfy_extras.nodes_video", "category": "image/video", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "GetVideoComponents": {"input": {"required": {"video": ["VIDEO", {"tooltip": "The video to extract components from."}]}}, "input_order": {"required": ["video"]}, "output": ["IMAGE", "AUDIO", "FLOAT"], "output_is_list": [false, false, false], "output_name": ["images", "audio", "fps"], "output_tooltips": [null, null, null], "name": "GetVideoComponents", "display_name": "Get Video Components", "description": "Extracts all components from a video: frames, audio, and framerate.", "python_module": "comfy_extras.nodes_video", "category": "image/video", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LoadVideo": {"input": {"required": {"file": ["COMBO", {"multiselect": false, "options": [], "video_upload": true}]}}, "input_order": {"required": ["file"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "LoadVideo", "display_name": "Load Video", "description": "", "python_module": "comfy_extras.nodes_video", "category": "image/video", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CLIPTextEncodeLumina2": {"input": {"required": {"system_prompt": ["COMBO", {"tooltip": "Lumina2 provide two types of system prompts:Superior: You are an assistant designed to generate superior images with the superior degree of image-text alignment based on textual prompts or user prompts. Alignment: You are an assistant designed to generate high-quality images with the highest degree of image-text alignment based on textual prompts.", "multiselect": false, "options": ["superior", "alignment"]}], "user_prompt": ["STRING", {"tooltip": "The text to be encoded.", "multiline": true, "dynamicPrompts": true}], "clip": ["CLIP", {"tooltip": "The CLIP model used for encoding the text."}]}}, "input_order": {"required": ["system_prompt", "user_prompt", "clip"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": ["A conditioning containing the embedded text used to guide the diffusion model."], "name": "CLIPTextEncodeLumina2", "display_name": "CLIP Text Encode for Lumina2", "description": "Encodes a system prompt and a user prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images.", "python_module": "comfy_extras.nodes_lumina2", "category": "conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RenormCFG": {"input": {"required": {"model": ["MODEL", {}], "cfg_trunc": ["FLOAT", {"default": 100, "min": 0.0, "max": 100.0, "step": 0.01}], "renorm_cfg": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "cfg_trunc", "renorm_cfg"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "RenormCFG", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lumina2", "category": "advanced/model", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanTrackToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "tracks": ["STRING", {"default": "[]", "multiline": true}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "temperature": ["FLOAT", {"default": 220.0, "min": 1.0, "max": 1000.0, "step": 0.1}], "topk": ["INT", {"default": 2, "min": 1, "max": 10}], "start_image": ["IMAGE", {}]}, "optional": {"clip_vision_output": ["CLIP_VISION_OUTPUT", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "tracks", "width", "height", "length", "batch_size", "temperature", "topk", "start_image"], "optional": ["clip_vision_output"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanTrackToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanImageToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"clip_vision_output": ["CLIP_VISION_OUTPUT", {}], "start_image": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["clip_vision_output", "start_image"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanImageToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanFunControlToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"clip_vision_output": ["CLIP_VISION_OUTPUT", {}], "start_image": ["IMAGE", {}], "control_video": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["clip_vision_output", "start_image", "control_video"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanFunControlToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "Wan22FunControlToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"ref_image": ["IMAGE", {}], "control_video": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["ref_image", "control_video"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "Wan22FunControlToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanFunInpaintToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"clip_vision_output": ["CLIP_VISION_OUTPUT", {}], "start_image": ["IMAGE", {}], "end_image": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["clip_vision_output", "start_image", "end_image"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanFunInpaintToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanFirstLastFrameToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"clip_vision_start_image": ["CLIP_VISION_OUTPUT", {}], "clip_vision_end_image": ["CLIP_VISION_OUTPUT", {}], "start_image": ["IMAGE", {}], "end_image": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["clip_vision_start_image", "clip_vision_end_image", "start_image", "end_image"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanFirstLastFrameToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanVaceToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1000.0, "step": 0.01}]}, "optional": {"control_video": ["IMAGE", {}], "control_masks": ["MASK", {}], "reference_image": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size", "strength"], "optional": ["control_video", "control_masks", "reference_image"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["positive", "negative", "latent", "trim_latent"], "output_tooltips": [null, null, null, null], "name": "WanVaceToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "TrimVideoLatent": {"input": {"required": {"samples": ["LATENT", {}], "trim_amount": ["INT", {"default": 0, "min": 0, "max": 99999}]}}, "input_order": {"required": ["samples", "trim_amount"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "TrimVideoLatent", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "latent/video", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanCameraImageToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"clip_vision_output": ["CLIP_VISION_OUTPUT", {}], "start_image": ["IMAGE", {}], "camera_conditions": ["WAN_CAMERA_EMBEDDING", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["clip_vision_output", "start_image", "camera_conditions"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanCameraImageToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanPhantomSubjectToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"images": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["images"]}, "output": ["CONDITIONING", "CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false, false], "output_name": ["positive", "negative_text", "negative_img_text", "latent"], "output_tooltips": [null, null, null, null], "name": "WanPhantomSubjectToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanSoundImageToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 77, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"audio_encoder_output": ["AUDIO_ENCODER_OUTPUT", {}], "ref_image": ["IMAGE", {}], "control_video": ["IMAGE", {}], "ref_motion": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["audio_encoder_output", "ref_image", "control_video", "ref_motion"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanSoundImageToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanSoundImageToVideoExtend": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "length": ["INT", {"default": 77, "min": 1, "max": 16384, "step": 4}], "video_latent": ["LATENT", {}]}, "optional": {"audio_encoder_output": ["AUDIO_ENCODER_OUTPUT", {}], "ref_image": ["IMAGE", {}], "control_video": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "length", "video_latent"], "optional": ["audio_encoder_output", "ref_image", "control_video"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanSoundImageToVideoExtend", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanHuMoImageToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 97, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"audio_encoder_output": ["AUDIO_ENCODER_OUTPUT", {}], "ref_image": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["audio_encoder_output", "ref_image"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanHuMoImageToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "WanAnimateToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 77, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "continue_motion_max_frames": ["INT", {"default": 5, "min": 1, "max": 16384, "step": 4}], "video_frame_offset": ["INT", {"tooltip": "The amount of frames to seek in all the input videos. Used for generating longer videos by chunk. Connect to the video_frame_offset output of the previous node for extending a video.", "default": 0, "min": 0, "max": 16384, "step": 1}]}, "optional": {"clip_vision_output": ["CLIP_VISION_OUTPUT", {}], "reference_image": ["IMAGE", {}], "face_video": ["IMAGE", {}], "pose_video": ["IMAGE", {}], "background_video": ["IMAGE", {}], "character_mask": ["MASK", {}], "continue_motion": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size", "continue_motion_max_frames", "video_frame_offset"], "optional": ["clip_vision_output", "reference_image", "face_video", "pose_video", "background_video", "character_mask", "continue_motion"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT", "INT", "INT", "INT"], "output_is_list": [false, false, false, false, false, false], "output_name": ["positive", "negative", "latent", "trim_latent", "trim_image", "video_frame_offset"], "output_tooltips": [null, null, null, null, null, null], "name": "WanAnimateToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "Wan22ImageToVideoLatent": {"input": {"required": {"vae": ["VAE", {}], "width": ["INT", {"default": 1280, "min": 32, "max": 16384, "step": 32}], "height": ["INT", {"default": 704, "min": 32, "max": 16384, "step": 32}], "length": ["INT", {"default": 49, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"start_image": ["IMAGE", {}]}}, "input_order": {"required": ["vae", "width", "height", "length", "batch_size"], "optional": ["start_image"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "Wan22ImageToVideoLatent", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/inpaint", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LotusConditioning": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["conditioning"], "output_tooltips": [null], "name": "LotusConditioning", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lotus", "category": "conditioning/lotus", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "EmptyLatentHunyuan3Dv2": {"input": {"required": {"resolution": ["INT", {"default": 3072, "min": 1, "max": 8192}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096, "tooltip": "The number of latent images in the batch."}]}}, "input_order": {"required": ["resolution", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "EmptyLatentHunyuan3Dv2", "display_name": "EmptyLatentHunyuan3Dv2", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "latent/3d", "output_node": false}, "Hunyuan3Dv2Conditioning": {"input": {"required": {"clip_vision_output": ["CLIP_VISION_OUTPUT"]}}, "input_order": {"required": ["clip_vision_output"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "Hunyuan3Dv2Conditioning", "display_name": "Hunyuan3Dv2Conditioning", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "conditioning/video_models", "output_node": false}, "Hunyuan3Dv2ConditioningMultiView": {"input": {"required": {}, "optional": {"front": ["CLIP_VISION_OUTPUT"], "left": ["CLIP_VISION_OUTPUT"], "back": ["CLIP_VISION_OUTPUT"], "right": ["CLIP_VISION_OUTPUT"]}}, "input_order": {"required": [], "optional": ["front", "left", "back", "right"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "Hunyuan3Dv2ConditioningMultiView", "display_name": "Hunyuan3Dv2ConditioningMultiView", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "conditioning/video_models", "output_node": false}, "VAEDecodeHunyuan3D": {"input": {"required": {"samples": ["LATENT"], "vae": ["VAE"], "num_chunks": ["INT", {"default": 8000, "min": 1000, "max": 500000}], "octree_resolution": ["INT", {"default": 256, "min": 16, "max": 512}]}}, "input_order": {"required": ["samples", "vae", "num_chunks", "octree_resolution"]}, "output": ["VOXEL"], "output_is_list": [false], "output_name": ["VOXEL"], "name": "VAEDecodeHunyuan3D", "display_name": "VAEDecodeHunyuan3D", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "latent/3d", "output_node": false}, "VoxelToMeshBasic": {"input": {"required": {"voxel": ["VOXEL"], "threshold": ["FLOAT", {"default": 0.6, "min": -1.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["voxel", "threshold"]}, "output": ["MESH"], "output_is_list": [false], "output_name": ["MESH"], "name": "VoxelToMeshBasic", "display_name": "VoxelToMeshBasic", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "3d", "output_node": false}, "VoxelToMesh": {"input": {"required": {"voxel": ["VOXEL"], "algorithm": [["surface net", "basic"]], "threshold": ["FLOAT", {"default": 0.6, "min": -1.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["voxel", "algorithm", "threshold"]}, "output": ["MESH"], "output_is_list": [false], "output_name": ["MESH"], "name": "VoxelToMesh", "display_name": "VoxelToMesh", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "3d", "output_node": false}, "SaveGLB": {"input": {"required": {"mesh": ["MESH"], "filename_prefix": ["STRING", {"default": "mesh/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["mesh", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveGLB", "display_name": "SaveGLB", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "3d", "output_node": true}, "PrimitiveString": {"input": {"required": {"value": ["STRING", {"multiline": false}]}}, "input_order": {"required": ["value"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "PrimitiveString", "display_name": "String", "description": "", "python_module": "comfy_extras.nodes_primitive", "category": "utils/primitive", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "PrimitiveStringMultiline": {"input": {"required": {"value": ["STRING", {"multiline": true}]}}, "input_order": {"required": ["value"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "PrimitiveStringMultiline", "display_name": "String (Multiline)", "description": "", "python_module": "comfy_extras.nodes_primitive", "category": "utils/primitive", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "PrimitiveInt": {"input": {"required": {"value": ["INT", {"min": -9223372036854775807, "max": 9223372036854775807, "control_after_generate": true}]}}, "input_order": {"required": ["value"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "output_tooltips": [null], "name": "PrimitiveInt", "display_name": "Int", "description": "", "python_module": "comfy_extras.nodes_primitive", "category": "utils/primitive", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "PrimitiveFloat": {"input": {"required": {"value": ["FLOAT", {"min": -9223372036854775807, "max": 9223372036854775807}]}}, "input_order": {"required": ["value"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "output_tooltips": [null], "name": "PrimitiveFloat", "display_name": "Float", "description": "", "python_module": "comfy_extras.nodes_primitive", "category": "utils/primitive", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "PrimitiveBoolean": {"input": {"required": {"value": ["BOOLEAN", {}]}}, "input_order": {"required": ["value"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "output_tooltips": [null], "name": "PrimitiveBoolean", "display_name": "Boolean", "description": "", "python_module": "comfy_extras.nodes_primitive", "category": "utils/primitive", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CFGZeroStar": {"input": {"required": {"model": ["MODEL", {}]}}, "input_order": {"required": ["model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["patched_model"], "output_tooltips": [null], "name": "CFGZeroStar", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_cfg", "category": "advanced/guidance", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CFGNorm": {"input": {"required": {"model": ["MODEL", {}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "strength"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["patched_model"], "output_tooltips": [null], "name": "CFGNorm", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_cfg", "category": "advanced/guidance", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "OptimalStepsScheduler": {"input": {"required": {"model_type": ["COMBO", {"multiselect": false, "options": ["FLUX", "Wan", "Chroma"]}], "steps": ["INT", {"default": 20, "min": 3, "max": 1000}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model_type", "steps", "denoise"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "output_tooltips": [null], "name": "OptimalStepsScheduler", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_optimalsteps", "category": "sampling/custom_sampling/schedulers", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "QuadrupleCLIPLoader": {"input": {"required": {"clip_name1": ["COMBO", {"multiselect": false, "options": ["clip_l.safetensors", "t5xxl_fp16.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]}], "clip_name2": ["COMBO", {"multiselect": false, "options": ["clip_l.safetensors", "t5xxl_fp16.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]}], "clip_name3": ["COMBO", {"multiselect": false, "options": ["clip_l.safetensors", "t5xxl_fp16.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]}], "clip_name4": ["COMBO", {"multiselect": false, "options": ["clip_l.safetensors", "t5xxl_fp16.safetensors", "umt5_xxl_fp8_e4m3fn_scaled.safetensors"]}]}}, "input_order": {"required": ["clip_name1", "clip_name2", "clip_name3", "clip_name4"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "output_tooltips": [null], "name": "QuadrupleCLIPLoader", "display_name": null, "description": "[Recipes]\n\nhidream: long clip-l, long clip-g, t5xxl, llama_8b_3.1_instruct", "python_module": "comfy_extras.nodes_hidream", "category": "advanced/loaders", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CLIPTextEncodeHiDream": {"input": {"required": {"clip": ["CLIP", {}], "clip_l": ["STRING", {"multiline": true, "dynamicPrompts": true}], "clip_g": ["STRING", {"multiline": true, "dynamicPrompts": true}], "t5xxl": ["STRING", {"multiline": true, "dynamicPrompts": true}], "llama": ["STRING", {"multiline": true, "dynamicPrompts": true}]}}, "input_order": {"required": ["clip", "clip_l", "clip_g", "t5xxl", "llama"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "CLIPTextEncodeHiDream", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hidream", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "FreSca": {"input": {"required": {"model": ["MODEL", {}], "scale_low": ["FLOAT", {"tooltip": "Scaling factor for low-frequency components", "default": 1.0, "min": 0, "max": 10, "step": 0.01}], "scale_high": ["FLOAT", {"tooltip": "Scaling factor for high-frequency components", "default": 1.25, "min": 0, "max": 10, "step": 0.01}], "freq_cutoff": ["INT", {"tooltip": "Number of frequency indices around center to consider as low-frequency", "default": 20, "min": 1, "max": 10000, "step": 1}]}}, "input_order": {"required": ["model", "scale_low", "scale_high", "freq_cutoff"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "FreSca", "display_name": "FreSca", "description": "Applies frequency-dependent scaling to the guidance", "python_module": "comfy_extras.nodes_fresca", "category": "_for_testing", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "APG": {"input": {"required": {"model": ["MODEL", {}], "eta": ["FLOAT", {"tooltip": "Controls the scale of the parallel guidance vector. Default CFG behavior at a setting of 1.", "default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "norm_threshold": ["FLOAT", {"tooltip": "Normalize guidance vector to this value, normalization disable at a setting of 0.", "default": 5.0, "min": 0.0, "max": 50.0, "step": 0.1}], "momentum": ["FLOAT", {"tooltip": "Controls a running average of guidance during diffusion, disabled at a setting of 0.", "default": 0.0, "min": -5.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "eta", "norm_threshold", "momentum"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "APG", "display_name": "Adaptive Projected Guidance", "description": "", "python_module": "comfy_extras.nodes_apg", "category": "sampling/custom_sampling", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "PreviewAny": {"input": {"required": {"source": ["*", {}]}}, "input_order": {"required": ["source"]}, "output": [], "output_is_list": [], "output_name": [], "name": "PreviewAny", "display_name": "Preview Any", "description": "", "python_module": "comfy_extras.nodes_preview_any", "category": "utils", "output_node": true}, "TextEncodeAceStepAudio": {"input": {"required": {"clip": ["CLIP", {}], "tags": ["STRING", {"multiline": true, "dynamicPrompts": true}], "lyrics": ["STRING", {"multiline": true, "dynamicPrompts": true}], "lyrics_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["clip", "tags", "lyrics", "lyrics_strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "TextEncodeAceStepAudio", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_ace", "category": "conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "EmptyAceStepLatentAudio": {"input": {"required": {"seconds": ["FLOAT", {"default": 120.0, "min": 1.0, "max": 1000.0, "step": 0.1}], "batch_size": ["INT", {"tooltip": "The number of latent images in the batch.", "default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["seconds", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "EmptyAceStepLatentAudio", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_ace", "category": "latent/audio", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StringConcatenate": {"input": {"required": {"string_a": ["STRING", {"multiline": true}], "string_b": ["STRING", {"multiline": true}], "delimiter": ["STRING", {"default": "", "multiline": false}]}}, "input_order": {"required": ["string_a", "string_b", "delimiter"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "StringConcatenate", "display_name": "Concatenate", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StringSubstring": {"input": {"required": {"string": ["STRING", {"multiline": true}], "start": ["INT", {}], "end": ["INT", {}]}}, "input_order": {"required": ["string", "start", "end"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "StringSubstring", "display_name": "Substring", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StringLength": {"input": {"required": {"string": ["STRING", {"multiline": true}]}}, "input_order": {"required": ["string"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["length"], "output_tooltips": [null], "name": "StringLength", "display_name": "Length", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CaseConverter": {"input": {"required": {"string": ["STRING", {"multiline": true}], "mode": ["COMBO", {"multiselect": false, "options": ["UPPERCASE", "lowercase", "Capitalize", "Title Case"]}]}}, "input_order": {"required": ["string", "mode"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "CaseConverter", "display_name": "Case Converter", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StringTrim": {"input": {"required": {"string": ["STRING", {"multiline": true}], "mode": ["COMBO", {"multiselect": false, "options": ["Both", "Left", "Right"]}]}}, "input_order": {"required": ["string", "mode"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "StringTrim", "display_name": "Trim", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StringReplace": {"input": {"required": {"string": ["STRING", {"multiline": true}], "find": ["STRING", {"multiline": true}], "replace": ["STRING", {"multiline": true}]}}, "input_order": {"required": ["string", "find", "replace"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "StringReplace", "display_name": "Replace", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StringContains": {"input": {"required": {"string": ["STRING", {"multiline": true}], "substring": ["STRING", {"multiline": true}], "case_sensitive": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["string", "substring", "case_sensitive"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["contains"], "output_tooltips": [null], "name": "StringContains", "display_name": "Contains", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StringCompare": {"input": {"required": {"string_a": ["STRING", {"multiline": true}], "string_b": ["STRING", {"multiline": true}], "mode": ["COMBO", {"multiselect": false, "options": ["Starts With", "Ends With", "Equal"]}], "case_sensitive": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["string_a", "string_b", "mode", "case_sensitive"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "output_tooltips": [null], "name": "StringCompare", "display_name": "Compare", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RegexMatch": {"input": {"required": {"string": ["STRING", {"multiline": true}], "regex_pattern": ["STRING", {"multiline": true}], "case_insensitive": ["BOOLEAN", {"default": true}], "multiline": ["BOOLEAN", {"default": false}], "dotall": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["string", "regex_pattern", "case_insensitive", "multiline", "dotall"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["matches"], "output_tooltips": [null], "name": "RegexMatch", "display_name": "Regex Match", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RegexExtract": {"input": {"required": {"string": ["STRING", {"multiline": true}], "regex_pattern": ["STRING", {"multiline": true}], "mode": ["COMBO", {"multiselect": false, "options": ["First Match", "All Matches", "First Group", "All Groups"]}], "case_insensitive": ["BOOLEAN", {"default": true}], "multiline": ["BOOLEAN", {"default": false}], "dotall": ["BOOLEAN", {"default": false}], "group_index": ["INT", {"default": 1, "min": 0, "max": 100}]}}, "input_order": {"required": ["string", "regex_pattern", "mode", "case_insensitive", "multiline", "dotall", "group_index"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "RegexExtract", "display_name": "Regex Extract", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RegexReplace": {"input": {"required": {"string": ["STRING", {"multiline": true}], "regex_pattern": ["STRING", {"multiline": true}], "replace": ["STRING", {"multiline": true}]}, "optional": {"case_insensitive": ["BOOLEAN", {"default": true}], "multiline": ["BOOLEAN", {"default": false}], "dotall": ["BOOLEAN", {"tooltip": "When enabled, the dot (.) character will match any character including newline characters. When disabled, dots won't match newlines.", "default": false}], "count": ["INT", {"tooltip": "Maximum number of replacements to make. Set to 0 to replace all occurrences (default). Set to 1 to replace only the first match, 2 for the first two matches, etc.", "default": 0, "min": 0, "max": 100}]}}, "input_order": {"required": ["string", "regex_pattern", "replace"], "optional": ["case_insensitive", "multiline", "dotall", "count"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "RegexReplace", "display_name": "Regex Replace", "description": "Find and replace text using regex patterns.", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanCameraEmbedding": {"input": {"required": {"camera_pose": ["COMBO", {"default": "Static", "multiselect": false, "options": ["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Anti Clockwise (ACW)", "ClockWise (CW)"]}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}]}, "optional": {"speed": ["FLOAT", {"default": 1.0, "min": 0, "max": 10.0, "step": 0.1}], "fx": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 1e-09}], "fy": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 1e-09}], "cx": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 0.01}], "cy": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 0.01}]}}, "input_order": {"required": ["camera_pose", "width", "height", "length"], "optional": ["speed", "fx", "fy", "cx", "cy"]}, "output": ["WAN_CAMERA_EMBEDDING", "INT", "INT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["camera_embedding", "width", "height", "length"], "output_tooltips": [null, null, null, null], "name": "WanCameraEmbedding", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_camera_trajectory", "category": "camera", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ReferenceLatent": {"input": {"required": {"conditioning": ["CONDITIONING", {}]}, "optional": {"latent": ["LATENT", {}]}}, "input_order": {"required": ["conditioning"], "optional": ["latent"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "ReferenceLatent", "display_name": null, "description": "This node sets the guiding latent for an edit model. If the model supports it you can chain multiple to set multiple reference images.", "python_module": "comfy_extras.nodes_edit_model", "category": "advanced/conditioning/edit_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "TCFG": {"input": {"required": {"model": ["MODEL", {}]}}, "input_order": {"required": ["model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["patched_model"], "output_tooltips": [null], "name": "TCFG", "display_name": "Tangential Damping CFG", "description": "TCFG \u2013 Tangential Damping CFG (2503.18137)\n\nRefine the uncond (negative) to align with the cond (positive) for improving quality.", "python_module": "comfy_extras.nodes_tcfg", "category": "advanced/guidance", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ContextWindowsManual": {"input": {"required": {"model": ["MODEL", {"tooltip": "The model to apply context windows to during sampling."}], "context_length": ["INT", {"tooltip": "The length of the context window.", "default": 16, "min": 1}], "context_overlap": ["INT", {"tooltip": "The overlap of the context window.", "default": 4, "min": 0}], "context_schedule": ["COMBO", {"tooltip": "The stride of the context window.", "multiselect": false, "options": ["standard_static", "standard_uniform", "looped_uniform", "batched"]}], "context_stride": ["INT", {"tooltip": "The stride of the context window; only applicable to uniform schedules.", "default": 1, "min": 1}], "closed_loop": ["BOOLEAN", {"tooltip": "Whether to close the context window loop; only applicable to looped schedules.", "default": false}], "fuse_method": ["COMBO", {"tooltip": "The method to use to fuse the context windows.", "default": "pyramid", "multiselect": false, "options": ["pyramid", "relative", "flat", "overlap-linear"]}], "dim": ["INT", {"tooltip": "The dimension to apply the context windows to.", "default": 0, "min": 0, "max": 5}]}}, "input_order": {"required": ["model", "context_length", "context_overlap", "context_schedule", "context_stride", "closed_loop", "fuse_method", "dim"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": ["The model with context windows applied during sampling."], "name": "ContextWindowsManual", "display_name": "Context Windows (Manual)", "description": "Manually set context windows.", "python_module": "comfy_extras.nodes_context_windows", "category": "context", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "WanContextWindowsManual": {"input": {"required": {"model": ["MODEL", {"tooltip": "The model to apply context windows to during sampling."}], "context_length": ["INT", {"tooltip": "The length of the context window.", "default": 81, "min": 1, "max": 16384, "step": 4}], "context_overlap": ["INT", {"tooltip": "The overlap of the context window.", "default": 30, "min": 0}], "context_schedule": ["COMBO", {"tooltip": "The stride of the context window.", "multiselect": false, "options": ["standard_static", "standard_uniform", "looped_uniform", "batched"]}], "context_stride": ["INT", {"tooltip": "The stride of the context window; only applicable to uniform schedules.", "default": 1, "min": 1}], "closed_loop": ["BOOLEAN", {"tooltip": "Whether to close the context window loop; only applicable to looped schedules.", "default": false}], "fuse_method": ["COMBO", {"tooltip": "The method to use to fuse the context windows.", "default": "pyramid", "multiselect": false, "options": ["pyramid", "relative", "flat", "overlap-linear"]}]}}, "input_order": {"required": ["model", "context_length", "context_overlap", "context_schedule", "context_stride", "closed_loop", "fuse_method"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": ["The model with context windows applied during sampling."], "name": "WanContextWindowsManual", "display_name": "WAN Context Windows (Manual)", "description": "Manually set context windows for WAN-like models (dim=2).", "python_module": "comfy_extras.nodes_context_windows", "category": "context", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "TextEncodeQwenImageEdit": {"input": {"required": {"clip": ["CLIP", {}], "prompt": ["STRING", {"multiline": true, "dynamicPrompts": true}]}, "optional": {"vae": ["VAE", {}], "image": ["IMAGE", {}]}}, "input_order": {"required": ["clip", "prompt"], "optional": ["vae", "image"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "TextEncodeQwenImageEdit", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_qwen", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "TextEncodeQwenImageEditPlus": {"input": {"required": {"clip": ["CLIP", {}], "prompt": ["STRING", {"multiline": true, "dynamicPrompts": true}]}, "optional": {"vae": ["VAE", {}], "image1": ["IMAGE", {}], "image2": ["IMAGE", {}], "image3": ["IMAGE", {}]}}, "input_order": {"required": ["clip", "prompt"], "optional": ["vae", "image1", "image2", "image3"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "TextEncodeQwenImageEditPlus", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_qwen", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "EmptyChromaRadianceLatentImage": {"input": {"required": {"width": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 16}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "EmptyChromaRadianceLatentImage", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_chroma_radiance", "category": "latent/chroma_radiance", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ChromaRadianceOptions": {"input": {"required": {"model": ["MODEL", {}], "preserve_wrapper": ["BOOLEAN", {"tooltip": "When enabled, will delegate to an existing model function wrapper if it exists. Generally should be left enabled.", "default": true}], "start_sigma": ["FLOAT", {"tooltip": "First sigma that these options will be in effect.", "default": 1.0, "min": 0.0, "max": 1.0}], "end_sigma": ["FLOAT", {"tooltip": "Last sigma that these options will be in effect.", "default": 0.0, "min": 0.0, "max": 1.0}], "nerf_tile_size": ["INT", {"tooltip": "Allows overriding the default NeRF tile size. -1 means use the default (32). 0 means use non-tiling mode (may require a lot of VRAM).", "default": -1, "min": -1}]}}, "input_order": {"required": ["model", "preserve_wrapper", "start_sigma", "end_sigma", "nerf_tile_size"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "ChromaRadianceOptions", "display_name": null, "description": "Allows setting advanced options for the Chroma Radiance model.", "python_module": "comfy_extras.nodes_chroma_radiance", "category": "model_patches/chroma_radiance", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ModelPatchLoader": {"input": {"required": {"name": [[]]}}, "input_order": {"required": ["name"]}, "output": ["MODEL_PATCH"], "output_is_list": [false], "output_name": ["MODEL_PATCH"], "name": "ModelPatchLoader", "display_name": "ModelPatchLoader", "description": "", "python_module": "comfy_extras.nodes_model_patch", "category": "advanced/loaders", "output_node": false, "experimental": true}, "QwenImageDiffsynthControlnet": {"input": {"required": {"model": ["MODEL"], "model_patch": ["MODEL_PATCH"], "vae": ["VAE"], "image": ["IMAGE"], "strength": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}, "optional": {"mask": ["MASK"]}}, "input_order": {"required": ["model", "model_patch", "vae", "image", "strength"], "optional": ["mask"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "QwenImageDiffsynthControlnet", "display_name": "QwenImageDiffsynthControlnet", "description": "", "python_module": "comfy_extras.nodes_model_patch", "category": "advanced/loaders/qwen", "output_node": false, "experimental": true}, "USOStyleReference": {"input": {"required": {"model": ["MODEL"], "model_patch": ["MODEL_PATCH"], "clip_vision_output": ["CLIP_VISION_OUTPUT"]}}, "input_order": {"required": ["model", "model_patch", "clip_vision_output"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "USOStyleReference", "display_name": "USOStyleReference", "description": "", "python_module": "comfy_extras.nodes_model_patch", "category": "advanced/model_patches/flux", "output_node": false, "experimental": true}, "EasyCache": {"input": {"required": {"model": ["MODEL", {"tooltip": "The model to add EasyCache to."}], "reuse_threshold": ["FLOAT", {"tooltip": "The threshold for reusing cached steps.", "default": 0.2, "min": 0.0, "max": 3.0, "step": 0.01}], "start_percent": ["FLOAT", {"tooltip": "The relative sampling step to begin use of EasyCache.", "default": 0.15, "min": 0.0, "max": 1.0, "step": 0.01}], "end_percent": ["FLOAT", {"tooltip": "The relative sampling step to end use of EasyCache.", "default": 0.95, "min": 0.0, "max": 1.0, "step": 0.01}], "verbose": ["BOOLEAN", {"tooltip": "Whether to log verbose information.", "default": false}]}}, "input_order": {"required": ["model", "reuse_threshold", "start_percent", "end_percent", "verbose"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": ["The model with EasyCache."], "name": "EasyCache", "display_name": "EasyCache", "description": "Native EasyCache implementation.", "python_module": "comfy_extras.nodes_easycache", "category": "advanced/debug/model", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "LazyCache": {"input": {"required": {"model": ["MODEL", {"tooltip": "The model to add LazyCache to."}], "reuse_threshold": ["FLOAT", {"tooltip": "The threshold for reusing cached steps.", "default": 0.2, "min": 0.0, "max": 3.0, "step": 0.01}], "start_percent": ["FLOAT", {"tooltip": "The relative sampling step to begin use of LazyCache.", "default": 0.15, "min": 0.0, "max": 1.0, "step": 0.01}], "end_percent": ["FLOAT", {"tooltip": "The relative sampling step to end use of LazyCache.", "default": 0.95, "min": 0.0, "max": 1.0, "step": 0.01}], "verbose": ["BOOLEAN", {"tooltip": "Whether to log verbose information.", "default": false}]}}, "input_order": {"required": ["model", "reuse_threshold", "start_percent", "end_percent", "verbose"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": ["The model with LazyCache."], "name": "LazyCache", "display_name": "LazyCache", "description": "A homebrew version of EasyCache - even 'easier' version of EasyCache to implement. Overall works worse than EasyCache, but better in some rare cases AND universal compatibility with everything in ComfyUI.", "python_module": "comfy_extras.nodes_easycache", "category": "advanced/debug/model", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "AudioEncoderLoader": {"input": {"required": {"audio_encoder_name": ["COMBO", {"multiselect": false, "options": []}]}}, "input_order": {"required": ["audio_encoder_name"]}, "output": ["AUDIO_ENCODER"], "output_is_list": [false], "output_name": ["AUDIO_ENCODER"], "output_tooltips": [null], "name": "AudioEncoderLoader", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_audio_encoder", "category": "loaders", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "AudioEncoderEncode": {"input": {"required": {"audio_encoder": ["AUDIO_ENCODER", {}], "audio": ["AUDIO", {}]}}, "input_order": {"required": ["audio_encoder", "audio"]}, "output": ["AUDIO_ENCODER_OUTPUT"], "output_is_list": [false], "output_name": ["AUDIO_ENCODER_OUTPUT"], "output_tooltips": [null], "name": "AudioEncoderEncode", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_audio_encoder", "category": "conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ScaleROPE": {"input": {"required": {"model": ["MODEL", {}], "scale_x": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.1}], "shift_x": ["FLOAT", {"default": 0.0, "min": -256.0, "max": 256.0, "step": 0.1}], "scale_y": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.1}], "shift_y": ["FLOAT", {"default": 0.0, "min": -256.0, "max": 256.0, "step": 0.1}], "scale_t": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.1}], "shift_t": ["FLOAT", {"default": 0.0, "min": -256.0, "max": 256.0, "step": 0.1}]}}, "input_order": {"required": ["model", "scale_x", "shift_x", "scale_y", "shift_y", "scale_t", "shift_t"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "ScaleROPE", "display_name": null, "description": "Scale and shift the ROPE of the model.", "python_module": "comfy_extras.nodes_rope", "category": "advanced/model_patches", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "IdeogramV1": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation", "default": "", "multiline": true}], "turbo": ["BOOLEAN", {"tooltip": "Whether to use turbo mode (faster generation, potentially lower quality)", "default": false}]}, "optional": {"aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio for image generation.", "default": "1:1", "multiselect": false, "options": ["1:1", "4:3", "3:4", "16:9", "9:16", "2:1", "1:2", "3:2", "2:3", "4:5", "5:4"]}], "magic_prompt_option": ["COMBO", {"tooltip": "Determine if MagicPrompt should be used in generation", "default": "AUTO", "multiselect": false, "options": ["AUTO", "ON", "OFF"]}], "seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "negative_prompt": ["STRING", {"tooltip": "Description of what to exclude from the image", "default": "", "multiline": true}], "num_images": ["INT", {"default": 1, "min": 1, "max": 8, "step": 1, "display": "number"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "turbo"], "optional": ["aspect_ratio", "magic_prompt_option", "seed", "negative_prompt", "num_images"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "IdeogramV1", "display_name": "Ideogram V1", "description": "Generates images using the Ideogram V1 model.", "python_module": "comfy_api_nodes.nodes_ideogram", "category": "api node/image/Ideogram", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "IdeogramV2": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation", "default": "", "multiline": true}], "turbo": ["BOOLEAN", {"tooltip": "Whether to use turbo mode (faster generation, potentially lower quality)", "default": false}]}, "optional": {"aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio for image generation. Ignored if resolution is not set to AUTO.", "default": "1:1", "multiselect": false, "options": ["1:1", "4:3", "3:4", "16:9", "9:16", "2:1", "1:2", "3:2", "2:3", "4:5", "5:4"]}], "resolution": ["COMBO", {"tooltip": "The resolution for image generation. If not set to AUTO, this overrides the aspect_ratio setting.", "default": "Auto", "multiselect": false, "options": ["Auto", "512 x 1536", "576 x 1408", "576 x 1472", "576 x 1536", "640 x 1024", "640 x 1344", "640 x 1408", "640 x 1472", "640 x 1536", "704 x 1152", "704 x 1216", "704 x 1280", "704 x 1344", "704 x 1408", "704 x 1472", "720 x 1280", "736 x 1312", "768 x 1024", "768 x 1088", "768 x 1152", "768 x 1216", "768 x 1232", "768 x 1280", "768 x 1344", "832 x 960", "832 x 1024", "832 x 1088", "832 x 1152", "832 x 1216", "832 x 1248", "864 x 1152", "896 x 960", "896 x 1024", "896 x 1088", "896 x 1120", "896 x 1152", "960 x 832", "960 x 896", "960 x 1024", "960 x 1088", "1024 x 640", "1024 x 768", "1024 x 832", "1024 x 896", "1024 x 960", "1024 x 1024", "1088 x 768", "1088 x 832", "1088 x 896", "1088 x 960", "1120 x 896", "1152 x 704", "1152 x 768", "1152 x 832", "1152 x 864", "1152 x 896", "1216 x 704", "1216 x 768", "1216 x 832", "1232 x 768", "1248 x 832", "1280 x 704", "1280 x 720", "1280 x 768", "1280 x 800", "1312 x 736", "1344 x 640", "1344 x 704", "1344 x 768", "1408 x 576", "1408 x 640", "1408 x 704", "1472 x 576", "1472 x 640", "1472 x 704", "1536 x 512", "1536 x 576", "1536 x 640"]}], "magic_prompt_option": ["COMBO", {"tooltip": "Determine if MagicPrompt should be used in generation", "default": "AUTO", "multiselect": false, "options": ["AUTO", "ON", "OFF"]}], "seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "style_type": ["COMBO", {"tooltip": "Style type for generation (V2 only)", "default": "NONE", "multiselect": false, "options": ["AUTO", "GENERAL", "REALISTIC", "DESIGN", "RENDER_3D", "ANIME"]}], "negative_prompt": ["STRING", {"tooltip": "Description of what to exclude from the image", "default": "", "multiline": true}], "num_images": ["INT", {"default": 1, "min": 1, "max": 8, "step": 1, "display": "number"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "turbo"], "optional": ["aspect_ratio", "resolution", "magic_prompt_option", "seed", "style_type", "negative_prompt", "num_images"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "IdeogramV2", "display_name": "Ideogram V2", "description": "Generates images using the Ideogram V2 model.", "python_module": "comfy_api_nodes.nodes_ideogram", "category": "api node/image/Ideogram", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "IdeogramV3": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation or editing", "default": "", "multiline": true}]}, "optional": {"image": ["IMAGE", {"tooltip": "Optional reference image for image editing."}], "mask": ["MASK", {"tooltip": "Optional mask for inpainting (white areas will be replaced)"}], "aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio for image generation. Ignored if resolution is not set to Auto.", "default": "1:1", "multiselect": false, "options": ["1:3", "3:1", "1:2", "2:1", "9:16", "16:9", "10:16", "16:10", "2:3", "3:2", "3:4", "4:3", "4:5", "5:4", "1:1"]}], "resolution": ["COMBO", {"tooltip": "The resolution for image generation. If not set to Auto, this overrides the aspect_ratio setting.", "default": "Auto", "multiselect": false, "options": ["Auto", "512x1536", "576x1408", "576x1472", "576x1536", "640x1344", "640x1408", "640x1472", "640x1536", "704x1152", "704x1216", "704x1280", "704x1344", "704x1408", "704x1472", "736x1312", "768x1088", "768x1216", "768x1280", "768x1344", "800x1280", "832x960", "832x1024", "832x1088", "832x1152", "832x1216", "832x1248", "864x1152", "896x960", "896x1024", "896x1088", "896x1120", "896x1152", "960x832", "960x896", "960x1024", "960x1088", "1024x832", "1024x896", "1024x960", "1024x1024", "1088x768", "1088x832", "1088x896", "1088x960", "1120x896", "1152x704", "1152x832", "1152x864", "1152x896", "1216x704", "1216x768", "1216x832", "1248x832", "1280x704", "1280x768", "1280x800", "1312x736", "1344x640", "1344x704", "1344x768", "1408x576", "1408x640", "1408x704", "1472x576", "1472x640", "1472x704", "1536x512", "1536x576", "1536x640"]}], "magic_prompt_option": ["COMBO", {"tooltip": "Determine if MagicPrompt should be used in generation", "default": "AUTO", "multiselect": false, "options": ["AUTO", "ON", "OFF"]}], "seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "num_images": ["INT", {"default": 1, "min": 1, "max": 8, "step": 1, "display": "number"}], "rendering_speed": ["COMBO", {"tooltip": "Controls the trade-off between generation speed and quality", "default": "DEFAULT", "multiselect": false, "options": ["DEFAULT", "TURBO", "QUALITY"]}], "character_image": ["IMAGE", {"tooltip": "Image to use as character reference."}], "character_mask": ["MASK", {"tooltip": "Optional mask for character reference image."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt"], "optional": ["image", "mask", "aspect_ratio", "resolution", "magic_prompt_option", "seed", "num_images", "rendering_speed", "character_image", "character_mask"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "IdeogramV3", "display_name": "Ideogram V3", "description": "Generates images using the Ideogram V3 model. Supports both regular image generation from text prompts and image editing with mask.", "python_module": "comfy_api_nodes.nodes_ideogram", "category": "api node/image/Ideogram", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "OpenAIDalle2": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Text prompt for DALL\u00b7E"}]}, "optional": {"seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "step": 1, "display": "number", "control_after_generate": true, "tooltip": "not implemented yet in backend"}], "size": ["COMBO", {"options": ["256x256", "512x512", "1024x1024"], "default": "1024x1024", "tooltip": "Image size"}], "n": ["INT", {"default": 1, "min": 1, "max": 8, "step": 1, "display": "number", "tooltip": "How many images to generate"}], "image": ["IMAGE", {"default": null, "tooltip": "Optional reference image for image editing."}], "mask": ["MASK", {"default": null, "tooltip": "Optional mask for inpainting (white areas will be replaced)"}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["prompt"], "optional": ["seed", "size", "n", "image", "mask"], "hidden": ["auth_token", "comfy_api_key", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "OpenAIDalle2", "display_name": "OpenAI DALL\u00b7E 2", "description": "Generates images synchronously via OpenAI's DALL\u00b7E 2 endpoint.", "python_module": "comfy_api_nodes.nodes_openai", "category": "api node/image/OpenAI", "output_node": false, "api_node": true}, "OpenAIDalle3": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Text prompt for DALL\u00b7E"}]}, "optional": {"seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "step": 1, "display": "number", "control_after_generate": true, "tooltip": "not implemented yet in backend"}], "quality": ["COMBO", {"options": ["standard", "hd"], "default": "standard", "tooltip": "Image quality"}], "style": ["COMBO", {"options": ["natural", "vivid"], "default": "natural", "tooltip": "Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images."}], "size": ["COMBO", {"options": ["1024x1024", "1024x1792", "1792x1024"], "default": "1024x1024", "tooltip": "Image size"}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["prompt"], "optional": ["seed", "quality", "style", "size"], "hidden": ["auth_token", "comfy_api_key", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "OpenAIDalle3", "display_name": "OpenAI DALL\u00b7E 3", "description": "Generates images synchronously via OpenAI's DALL\u00b7E 3 endpoint.", "python_module": "comfy_api_nodes.nodes_openai", "category": "api node/image/OpenAI", "output_node": false, "api_node": true}, "OpenAIGPTImage1": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Text prompt for GPT Image 1"}]}, "optional": {"seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "step": 1, "display": "number", "control_after_generate": true, "tooltip": "not implemented yet in backend"}], "quality": ["COMBO", {"options": ["low", "medium", "high"], "default": "low", "tooltip": "Image quality, affects cost and generation time."}], "background": ["COMBO", {"options": ["opaque", "transparent"], "default": "opaque", "tooltip": "Return image with or without background"}], "size": ["COMBO", {"options": ["auto", "1024x1024", "1024x1536", "1536x1024"], "default": "auto", "tooltip": "Image size"}], "n": ["INT", {"default": 1, "min": 1, "max": 8, "step": 1, "display": "number", "tooltip": "How many images to generate"}], "image": ["IMAGE", {"default": null, "tooltip": "Optional reference image for image editing."}], "mask": ["MASK", {"default": null, "tooltip": "Optional mask for inpainting (white areas will be replaced)"}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["prompt"], "optional": ["seed", "quality", "background", "size", "n", "image", "mask"], "hidden": ["auth_token", "comfy_api_key", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "OpenAIGPTImage1", "display_name": "OpenAI GPT Image 1", "description": "Generates images synchronously via OpenAI's GPT Image 1 endpoint.", "python_module": "comfy_api_nodes.nodes_openai", "category": "api node/image/OpenAI", "output_node": false, "api_node": true}, "OpenAIChatNode": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "default": "", "tooltip": "Text inputs to the model, used to generate a response."}], "persist_context": ["BOOLEAN", {"default": true, "tooltip": "Persist chat context between calls (multi-turn conversation)"}], "model": ["COMBO", {"options": ["o4-mini", "o1", "o3", "o1-pro", "gpt-4o", "gpt-4.1", "gpt-4.1-mini", "gpt-4.1-nano", "gpt-5", "gpt-5-mini", "gpt-5-nano"], "default": null, "tooltip": "The model used to generate the response"}]}, "optional": {"images": ["IMAGE", {"default": null, "tooltip": "Optional image(s) to use as context for the model. To include multiple images, you can use the Batch Images node."}], "files": ["OPENAI_INPUT_FILES", {"default": null, "tooltip": "Optional file(s) to use as context for the model. Accepts inputs from the OpenAI Chat Input Files node."}], "advanced_options": ["OPENAI_CHAT_CONFIG", {"default": null, "tooltip": "Optional configuration for the model. Accepts inputs from the OpenAI Chat Advanced Options node."}]}, "hidden": {"auth_token": "AUTH_TOKEN_COMFY_ORG", "comfy_api_key": "API_KEY_COMFY_ORG", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["prompt", "persist_context", "model"], "optional": ["images", "files", "advanced_options"], "hidden": ["auth_token", "comfy_api_key", "unique_id"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "OpenAIChatNode", "display_name": "OpenAI ChatGPT", "description": "Generate text responses from an OpenAI model.", "python_module": "comfy_api_nodes.nodes_openai", "category": "api node/text/OpenAI", "output_node": false, "api_node": true}, "OpenAIInputFiles": {"input": {"required": {"file": ["COMBO", {"tooltip": "Input files to include as context for the model. Only accepts text (.txt) and PDF (.pdf) files for now.", "options": [], "default": null}]}, "optional": {"OPENAI_INPUT_FILES": ["OPENAI_INPUT_FILES", {"tooltip": "An optional additional file(s) to batch together with the file loaded from this node. Allows chaining of input files so that a single message can include multiple input files.", "default": null}]}}, "input_order": {"required": ["file"], "optional": ["OPENAI_INPUT_FILES"]}, "output": ["OPENAI_INPUT_FILES"], "output_is_list": [false], "output_name": ["OPENAI_INPUT_FILES"], "name": "OpenAIInputFiles", "display_name": "OpenAI ChatGPT Input Files", "description": "Loads and prepares input files (text, pdf, etc.) to include as inputs for the OpenAI Chat Node. The files will be read by the OpenAI model when generating a response. \ud83d\udec8 TIP: Can be chained together with other OpenAI Input File nodes.", "python_module": "comfy_api_nodes.nodes_openai", "category": "api node/text/OpenAI", "output_node": false}, "OpenAIChatConfig": {"input": {"required": {"truncation": ["COMBO", {"options": ["auto", "disabled"], "default": "auto", "tooltip": "The truncation strategy to use for the model response. auto: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.disabled: If a model response will exceed the context window size for a model, the request will fail with a 400 error"}]}, "optional": {"max_output_tokens": ["INT", {"default": 4096, "tooltip": "An upper bound for the number of tokens that can be generated for a response, including visible output tokens", "min": 16, "max": 16384}], "instructions": ["STRING", {"default": null, "tooltip": "Instructions for the model on how to generate the response", "multiline": true}]}}, "input_order": {"required": ["truncation"], "optional": ["max_output_tokens", "instructions"]}, "output": ["OPENAI_CHAT_CONFIG"], "output_is_list": [false], "output_name": ["OPENAI_CHAT_CONFIG"], "name": "OpenAIChatConfig", "display_name": "OpenAI ChatGPT Advanced Options", "description": "Allows specifying advanced configuration options for the OpenAI Chat Nodes.", "python_module": "comfy_api_nodes.nodes_openai", "category": "api node/text/OpenAI", "output_node": false}, "MinimaxTextToVideoNode": {"input": {"required": {"prompt_text": ["STRING", {"tooltip": "Text prompt to guide the video generation", "default": "", "multiline": true}], "model": ["COMBO", {"tooltip": "Model to use for video generation", "default": "T2V-01", "multiselect": false, "options": ["T2V-01", "T2V-01-Director"]}]}, "optional": {"seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 18446744073709551615, "step": 1, "control_after_generate": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt_text", "model"], "optional": ["seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "MinimaxTextToVideoNode", "display_name": "MiniMax Text to Video", "description": "Generates videos synchronously based on a prompt, and optional parameters.", "python_module": "comfy_api_nodes.nodes_minimax", "category": "api node/video/MiniMax", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "MinimaxImageToVideoNode": {"input": {"required": {"image": ["IMAGE", {"tooltip": "Image to use as first frame of video generation"}], "prompt_text": ["STRING", {"tooltip": "Text prompt to guide the video generation", "default": "", "multiline": true}], "model": ["COMBO", {"tooltip": "Model to use for video generation", "default": "I2V-01", "multiselect": false, "options": ["I2V-01-Director", "I2V-01", "I2V-01-live"]}]}, "optional": {"seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 18446744073709551615, "step": 1, "control_after_generate": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt_text", "model"], "optional": ["seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "MinimaxImageToVideoNode", "display_name": "MiniMax Image to Video", "description": "Generates videos synchronously based on an image and prompt, and optional parameters.", "python_module": "comfy_api_nodes.nodes_minimax", "category": "api node/video/MiniMax", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "MinimaxHailuoVideoNode": {"input": {"required": {"prompt_text": ["STRING", {"tooltip": "Text prompt to guide the video generation.", "default": "", "multiline": true}]}, "optional": {"seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 18446744073709551615, "step": 1, "control_after_generate": true}], "first_frame_image": ["IMAGE", {"tooltip": "Optional image to use as the first frame to generate a video."}], "prompt_optimizer": ["BOOLEAN", {"tooltip": "Optimize prompt to improve generation quality when needed.", "default": true}], "duration": ["COMBO", {"tooltip": "The length of the output video in seconds.", "default": 6, "multiselect": false, "options": [6, 10]}], "resolution": ["COMBO", {"tooltip": "The dimensions of the video display. 1080p is 1920x1080, 768p is 1366x768.", "default": "768P", "multiselect": false, "options": ["768P", "1080P"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt_text"], "optional": ["seed", "first_frame_image", "prompt_optimizer", "duration", "resolution"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "MinimaxHailuoVideoNode", "display_name": "MiniMax Hailuo Video", "description": "Generates videos from prompt, with optional start frame using the new MiniMax Hailuo-02 model.", "python_module": "comfy_api_nodes.nodes_minimax", "category": "api node/video/MiniMax", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "VeoVideoGenerationNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text description of the video", "default": "", "multiline": true}], "aspect_ratio": ["COMBO", {"tooltip": "Aspect ratio of the output video", "default": "16:9", "multiselect": false, "options": ["16:9", "9:16"]}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "Negative text prompt to guide what to avoid in the video", "default": "", "multiline": true}], "duration_seconds": ["INT", {"tooltip": "Duration of the output video in seconds", "default": 5, "min": 5, "max": 8, "step": 1, "display": "number"}], "enhance_prompt": ["BOOLEAN", {"tooltip": "Whether to enhance the prompt with AI assistance", "default": true}], "person_generation": ["COMBO", {"tooltip": "Whether to allow generating people in the video", "default": "ALLOW", "multiselect": false, "options": ["ALLOW", "BLOCK"]}], "seed": ["INT", {"tooltip": "Seed for video generation (0 for random)", "default": 0, "min": 0, "max": 4294967295, "step": 1, "control_after_generate": true, "display": "number"}], "image": ["IMAGE", {"tooltip": "Optional reference image to guide video generation"}], "model": ["COMBO", {"tooltip": "Veo 2 model to use for video generation", "default": "veo-2.0-generate-001", "multiselect": false, "options": ["veo-2.0-generate-001"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "aspect_ratio"], "optional": ["negative_prompt", "duration_seconds", "enhance_prompt", "person_generation", "seed", "image", "model"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "VeoVideoGenerationNode", "display_name": "Google Veo 2 Video Generation", "description": "Generates videos from text prompts using Google's Veo 2 API", "python_module": "comfy_api_nodes.nodes_veo2", "category": "api node/video/Veo", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Veo3VideoGenerationNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text description of the video", "default": "", "multiline": true}], "aspect_ratio": ["COMBO", {"tooltip": "Aspect ratio of the output video", "default": "16:9", "multiselect": false, "options": ["16:9", "9:16"]}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "Negative text prompt to guide what to avoid in the video", "default": "", "multiline": true}], "duration_seconds": ["INT", {"tooltip": "Duration of the output video in seconds (Veo 3 only supports 8 seconds)", "default": 8, "min": 8, "max": 8, "step": 1, "display": "number"}], "enhance_prompt": ["BOOLEAN", {"tooltip": "Whether to enhance the prompt with AI assistance", "default": true}], "person_generation": ["COMBO", {"tooltip": "Whether to allow generating people in the video", "default": "ALLOW", "multiselect": false, "options": ["ALLOW", "BLOCK"]}], "seed": ["INT", {"tooltip": "Seed for video generation (0 for random)", "default": 0, "min": 0, "max": 4294967295, "step": 1, "control_after_generate": true, "display": "number"}], "image": ["IMAGE", {"tooltip": "Optional reference image to guide video generation"}], "model": ["COMBO", {"tooltip": "Veo 3 model to use for video generation", "default": "veo-3.0-generate-001", "multiselect": false, "options": ["veo-3.1-generate", "veo-3.1-fast-generate", "veo-3.0-generate-001", "veo-3.0-fast-generate-001"]}], "generate_audio": ["BOOLEAN", {"tooltip": "Generate audio for the video. Supported by all Veo 3 models.", "default": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "aspect_ratio"], "optional": ["negative_prompt", "duration_seconds", "enhance_prompt", "person_generation", "seed", "image", "model", "generate_audio"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "Veo3VideoGenerationNode", "display_name": "Google Veo 3 Video Generation", "description": "Generates videos from text prompts using Google's Veo 3 API", "python_module": "comfy_api_nodes.nodes_veo2", "category": "api node/video/Veo", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingCameraControls": {"input": {"required": {"camera_control_type": ["COMBO", {"multiselect": false, "options": ["simple", "down_back", "forward_up", "right_turn_forward", "left_turn_forward"]}], "horizontal_movement": ["FLOAT", {"tooltip": "Controls camera's movement along horizontal axis (x-axis). Negative indicates left, positive indicates right", "default": 0.0, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider"}], "vertical_movement": ["FLOAT", {"tooltip": "Controls camera's movement along vertical axis (y-axis). Negative indicates downward, positive indicates upward.", "default": 0.0, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider"}], "pan": ["FLOAT", {"tooltip": "Controls camera's rotation in vertical plane (x-axis). Negative indicates downward rotation, positive indicates upward rotation.", "default": 0.5, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider"}], "tilt": ["FLOAT", {"tooltip": "Controls camera's rotation in horizontal plane (y-axis). Negative indicates left rotation, positive indicates right rotation.", "default": 0.0, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider"}], "roll": ["FLOAT", {"tooltip": "Controls camera's rolling amount (z-axis). Negative indicates counterclockwise, positive indicates clockwise.", "default": 0.0, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider"}], "zoom": ["FLOAT", {"tooltip": "Controls change in camera's focal length. Negative indicates narrower field of view, positive indicates wider field of view.", "default": 0.0, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider"}]}}, "input_order": {"required": ["camera_control_type", "horizontal_movement", "vertical_movement", "pan", "tilt", "roll", "zoom"]}, "output": ["CAMERA_CONTROL"], "output_is_list": [false], "output_name": ["camera_control"], "output_tooltips": [null], "name": "KlingCameraControls", "display_name": "Kling Camera Controls", "description": "Allows specifying configuration options for Kling Camera Controls and motion control effects.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "KlingTextToVideoNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative text prompt", "multiline": true}], "cfg_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0}], "aspect_ratio": ["COMBO", {"default": "16:9", "multiselect": false, "options": ["16:9", "9:16", "1:1"]}], "mode": ["COMBO", {"tooltip": "The configuration to use for the video generation following the format: mode / duration / model_name.", "default": "standard mode / 5s duration / kling-v1-6", "multiselect": false, "options": ["standard mode / 5s duration / kling-v1", "standard mode / 10s duration / kling-v1", "pro mode / 5s duration / kling-v1", "pro mode / 10s duration / kling-v1", "standard mode / 5s duration / kling-v1-6", "standard mode / 10s duration / kling-v1-6", "pro mode / 5s duration / kling-v2-master", "pro mode / 10s duration / kling-v2-master", "standard mode / 5s duration / kling-v2-master", "standard mode / 10s duration / kling-v2-master", "pro mode / 5s duration / kling-v2-1-master", "pro mode / 10s duration / kling-v2-1-master", "pro mode / 5s duration / kling-v2-5-turbo", "pro mode / 10s duration / kling-v2-5-turbo"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "negative_prompt", "cfg_scale", "aspect_ratio", "mode"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingTextToVideoNode", "display_name": "Kling Text to Video", "description": "Kling Text to Video Node", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingImage2VideoNode": {"input": {"required": {"start_frame": ["IMAGE", {"tooltip": "The reference image used to generate the video."}], "prompt": ["STRING", {"tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative text prompt", "multiline": true}], "model_name": ["COMBO", {"default": "kling-v2-master", "multiselect": false, "options": ["kling-v1", "kling-v1-5", "kling-v1-6", "kling-v2-master", "kling-v2-1", "kling-v2-1-master", "kling-v2-5-turbo"]}], "cfg_scale": ["FLOAT", {"default": 0.8, "min": 0.0, "max": 1.0}], "mode": ["COMBO", {"default": "std", "multiselect": false, "options": ["std", "pro"]}], "aspect_ratio": ["COMBO", {"default": "16:9", "multiselect": false, "options": ["16:9", "9:16", "1:1"]}], "duration": ["COMBO", {"default": "5", "multiselect": false, "options": ["5", "10"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["start_frame", "prompt", "negative_prompt", "model_name", "cfg_scale", "mode", "aspect_ratio", "duration"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingImage2VideoNode", "display_name": "Kling Image to Video", "description": "Kling Image to Video Node", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingCameraControlI2VNode": {"input": {"required": {"start_frame": ["IMAGE", {"tooltip": "Reference Image - URL or Base64 encoded string, cannot exceed 10MB, resolution not less than 300*300px, aspect ratio between 1:2.5 ~ 2.5:1. Base64 should not include data:image prefix."}], "prompt": ["STRING", {"tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative text prompt", "multiline": true}], "cfg_scale": ["FLOAT", {"default": 0.75, "min": 0.0, "max": 1.0}], "aspect_ratio": ["COMBO", {"default": "16:9", "multiselect": false, "options": ["16:9", "9:16", "1:1"]}], "camera_control": ["CAMERA_CONTROL", {"tooltip": "Can be created using the Kling Camera Controls node. Controls the camera movement and motion during the video generation."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["start_frame", "prompt", "negative_prompt", "cfg_scale", "aspect_ratio", "camera_control"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingCameraControlI2VNode", "display_name": "Kling Image to Video (Camera Control)", "description": "Transform still images into cinematic videos with professional camera movements that simulate real-world cinematography. Control virtual camera actions including zoom, rotation, pan, tilt, and first-person view, while maintaining focus on your original image.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingCameraControlT2VNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative text prompt", "multiline": true}], "cfg_scale": ["FLOAT", {"default": 0.75, "min": 0.0, "max": 1.0}], "aspect_ratio": ["COMBO", {"default": "16:9", "multiselect": false, "options": ["16:9", "9:16", "1:1"]}], "camera_control": ["CAMERA_CONTROL", {"tooltip": "Can be created using the Kling Camera Controls node. Controls the camera movement and motion during the video generation."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "negative_prompt", "cfg_scale", "aspect_ratio", "camera_control"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingCameraControlT2VNode", "display_name": "Kling Text to Video (Camera Control)", "description": "Transform text into cinematic videos with professional camera movements that simulate real-world cinematography. Control virtual camera actions including zoom, rotation, pan, tilt, and first-person view, while maintaining focus on your original text.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingStartEndFrameNode": {"input": {"required": {"start_frame": ["IMAGE", {"tooltip": "Reference Image - URL or Base64 encoded string, cannot exceed 10MB, resolution not less than 300*300px, aspect ratio between 1:2.5 ~ 2.5:1. Base64 should not include data:image prefix."}], "end_frame": ["IMAGE", {"tooltip": "Reference Image - End frame control. URL or Base64 encoded string, cannot exceed 10MB, resolution not less than 300*300px. Base64 should not include data:image prefix."}], "prompt": ["STRING", {"tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative text prompt", "multiline": true}], "cfg_scale": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0}], "aspect_ratio": ["COMBO", {"default": "16:9", "multiselect": false, "options": ["16:9", "9:16", "1:1"]}], "mode": ["COMBO", {"tooltip": "The configuration to use for the video generation following the format: mode / duration / model_name.", "default": "pro mode / 5s duration / kling-v1-5", "multiselect": false, "options": ["standard mode / 5s duration / kling-v1", "pro mode / 5s duration / kling-v1", "pro mode / 5s duration / kling-v1-5", "pro mode / 10s duration / kling-v1-5", "pro mode / 5s duration / kling-v1-6", "pro mode / 10s duration / kling-v1-6", "pro mode / 5s duration / kling-v2-1", "pro mode / 10s duration / kling-v2-1"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["start_frame", "end_frame", "prompt", "negative_prompt", "cfg_scale", "aspect_ratio", "mode"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingStartEndFrameNode", "display_name": "Kling Start-End Frame to Video", "description": "Generate a video sequence that transitions between your provided start and end images. The node creates all frames in between, producing a smooth transformation from the first frame to the last.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingVideoExtendNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Positive text prompt for guiding the video extension", "multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative text prompt for elements to avoid in the extended video", "multiline": true}], "cfg_scale": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0}], "video_id": ["STRING", {"tooltip": "The ID of the video to be extended. Supports videos generated by text-to-video, image-to-video, and previous video extension operations. Cannot exceed 3 minutes total duration after extension.", "forceInput": true, "multiline": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "negative_prompt", "cfg_scale", "video_id"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingVideoExtendNode", "display_name": "Kling Video Extend", "description": "Kling Video Extend Node. Extend videos made by other Kling nodes. The video_id is created by using other Kling Nodes.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingLipSyncAudioToVideoNode": {"input": {"required": {"video": ["VIDEO", {}], "audio": ["AUDIO", {}], "voice_language": ["COMBO", {"default": "en", "multiselect": false, "options": ["zh", "en"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["video", "audio", "voice_language"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingLipSyncAudioToVideoNode", "display_name": "Kling Lip Sync Video with Audio", "description": "Kling Lip Sync Audio to Video Node. Syncs mouth movements in a video file to the audio content of an audio file. When using, ensure that the audio contains clearly distinguishable vocals and that the video contains a distinct face. The audio file should not be larger than 5MB. The video file should not be larger than 100MB, should have height/width between 720px and 1920px, and should be between 2s and 10s in length.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingLipSyncTextToVideoNode": {"input": {"required": {"video": ["VIDEO", {}], "text": ["STRING", {"tooltip": "Text Content for Lip-Sync Video Generation. Required when mode is text2video. Maximum length is 120 characters.", "multiline": true}], "voice": ["COMBO", {"default": "Melody", "multiselect": false, "options": ["Melody", "Sunny", "Sage", "Ace", "Blossom", "Peppy", "Dove", "Shine", "Anchor", "Lyric", "Tender", "Siren", "Zippy", "Bud", "Sprite", "Candy", "Beacon", "Rock", "Titan", "Grace", "Helen", "Lore", "Crag", "Prattle", "Hearth", "The Reader", "Commercial Lady", "\u9633\u5149\u5c11\u5e74", "\u61c2\u4e8b\u5c0f\u5f1f", "\u8fd0\u52a8\u5c11\u5e74", "\u9752\u6625\u5c11\u5973", "\u6e29\u67d4\u5c0f\u59b9", "\u5143\u6c14\u5c11\u5973", "\u9633\u5149\u7537\u751f", "\u5e7d\u9ed8\u5c0f\u54e5", "\u6587\u827a\u5c0f\u54e5", "\u751c\u7f8e\u90bb\u5bb6", "\u6e29\u67d4\u59d0\u59d0", "\u804c\u573a\u5973\u9752", "\u6d3b\u6cfc\u7537\u7ae5", "\u4fcf\u76ae\u5973\u7ae5", "\u7a33\u91cd\u8001\u7238", "\u6e29\u67d4\u5988\u5988", "\u4e25\u8083\u4e0a\u53f8", "\u4f18\u96c5\u8d35\u5987", "\u6148\u7965\u7237\u7237", "\u5520\u53e8\u7237\u7237", "\u5520\u53e8\u5976\u5976", "\u548c\u853c\u5976\u5976", "\u4e1c\u5317\u8001\u94c1", "\u91cd\u5e86\u5c0f\u4f19", "\u56db\u5ddd\u59b9\u5b50", "\u6f6e\u6c55\u5927\u53d4", "\u53f0\u6e7e\u7537\u751f", "\u897f\u5b89\u638c\u67dc", "\u5929\u6d25\u59d0\u59d0", "\u65b0\u95fb\u64ad\u62a5\u7537", "\u8bd1\u5236\u7247\u7537", "\u6492\u5a07\u5973\u53cb", "\u5200\u7247\u70df\u55d3", "\u4e56\u5de7\u6b63\u592a"]}], "voice_speed": ["FLOAT", {"tooltip": "Speech Rate. Valid range: 0.8~2.0, accurate to one decimal place.", "default": 1, "min": 0.8, "max": 2.0, "display": "slider"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["video", "text", "voice", "voice_speed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingLipSyncTextToVideoNode", "display_name": "Kling Lip Sync Video with Text", "description": "Kling Lip Sync Text to Video Node. Syncs mouth movements in a video file to a text prompt. The video file should not be larger than 100MB, should have height/width between 720px and 1920px, and should be between 2s and 10s in length.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingVirtualTryOnNode": {"input": {"required": {"human_image": ["IMAGE", {}], "cloth_image": ["IMAGE", {}], "model_name": ["COMBO", {"default": "kolors-virtual-try-on-v1", "multiselect": false, "options": ["kolors-virtual-try-on-v1", "kolors-virtual-try-on-v1-5"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["human_image", "cloth_image", "model_name"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "KlingVirtualTryOnNode", "display_name": "Kling Virtual Try On", "description": "Kling Virtual Try On Node. Input a human image and a cloth image to try on the cloth on the human. You can merge multiple clothing item pictures into one image with a white background.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/image/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingImageGenerationNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative text prompt", "multiline": true}], "image_type": ["COMBO", {"multiselect": false, "options": ["subject", "face"]}], "image_fidelity": ["FLOAT", {"tooltip": "Reference intensity for user-uploaded images", "default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01, "display": "slider"}], "human_fidelity": ["FLOAT", {"tooltip": "Subject reference similarity", "default": 0.45, "min": 0.0, "max": 1.0, "step": 0.01, "display": "slider"}], "model_name": ["COMBO", {"default": "kling-v1", "multiselect": false, "options": ["kling-v1", "kling-v1-5", "kling-v2"]}], "aspect_ratio": ["COMBO", {"default": "16:9", "multiselect": false, "options": ["16:9", "9:16", "1:1", "4:3", "3:4", "3:2", "2:3", "21:9"]}], "n": ["INT", {"tooltip": "Number of generated images", "default": 1, "min": 1, "max": 9}]}, "optional": {"image": ["IMAGE", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "negative_prompt", "image_type", "image_fidelity", "human_fidelity", "model_name", "aspect_ratio", "n"], "optional": ["image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "KlingImageGenerationNode", "display_name": "Kling Image Generation", "description": "Kling Image Generation Node. Generate an image from a text prompt with an optional reference image.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/image/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingSingleImageVideoEffectNode": {"input": {"required": {"image": ["IMAGE", {"tooltip": " Reference Image. URL or Base64 encoded string (without data:image prefix). File size cannot exceed 10MB, resolution not less than 300*300px, aspect ratio between 1:2.5 ~ 2.5:1"}], "effect_scene": ["COMBO", {"multiselect": false, "options": ["bloombloom", "dizzydizzy", "fuzzyfuzzy", "squish", "expansion"]}], "model_name": ["COMBO", {"multiselect": false, "options": ["kling-v1-6"]}], "duration": ["COMBO", {"multiselect": false, "options": ["5", "10"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "effect_scene", "model_name", "duration"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingSingleImageVideoEffectNode", "display_name": "Kling Video Effects", "description": "Achieve different special effects when generating a video based on the effect_scene.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingDualCharacterVideoEffectNode": {"input": {"required": {"image_left": ["IMAGE", {"tooltip": "Left side image"}], "image_right": ["IMAGE", {"tooltip": "Right side image"}], "effect_scene": ["COMBO", {"multiselect": false, "options": ["hug", "kiss", "heart_gesture"]}], "model_name": ["COMBO", {"default": "kling-v1", "multiselect": false, "options": ["kling-v1", "kling-v1-5", "kling-v1-6"]}], "mode": ["COMBO", {"default": "std", "multiselect": false, "options": ["std", "pro"]}], "duration": ["COMBO", {"multiselect": false, "options": ["5", "10"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image_left", "image_right", "effect_scene", "model_name", "mode", "duration"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING"], "output_is_list": [false, false], "output_name": ["VIDEO", "duration"], "output_tooltips": [null, null], "name": "KlingDualCharacterVideoEffectNode", "display_name": "Kling Dual Character Video Effects", "description": "Achieve different special effects when generating a video based on the effect_scene. First image will be positioned on left side, second on right side of the composite.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "FluxProUltraImageNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation", "default": "", "multiline": true}], "prompt_upsampling": ["BOOLEAN", {"tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result).", "default": false}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}], "aspect_ratio": ["STRING", {"tooltip": "Aspect ratio of image; must be between 1:4 and 4:1.", "default": "16:9", "multiline": false}], "raw": ["BOOLEAN", {"tooltip": "When True, generate less processed, more natural-looking images.", "default": false}]}, "optional": {"image_prompt": ["IMAGE", {}], "image_prompt_strength": ["FLOAT", {"tooltip": "Blend between the prompt and the image prompt.", "default": 0.1, "min": 0.0, "max": 1.0, "step": 0.01}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "prompt_upsampling", "seed", "aspect_ratio", "raw"], "optional": ["image_prompt", "image_prompt_strength"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "FluxProUltraImageNode", "display_name": "Flux 1.1 [pro] Ultra Image", "description": "Generates images using Flux Pro 1.1 Ultra via api based on prompt and resolution.", "python_module": "comfy_api_nodes.nodes_bfl", "category": "api node/image/BFL", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "FluxKontextProImageNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation - specify what and how to edit.", "default": "", "multiline": true}], "aspect_ratio": ["STRING", {"tooltip": "Aspect ratio of image; must be between 1:4 and 4:1.", "default": "16:9", "multiline": false}], "guidance": ["FLOAT", {"tooltip": "Guidance strength for the image generation process", "default": 3.0, "min": 0.1, "max": 99.0, "step": 0.1}], "steps": ["INT", {"tooltip": "Number of steps for the image generation process", "default": 50, "min": 1, "max": 150}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 1234, "min": 0, "max": 18446744073709551615, "control_after_generate": true}], "prompt_upsampling": ["BOOLEAN", {"tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result).", "default": false}]}, "optional": {"input_image": ["IMAGE", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "aspect_ratio", "guidance", "steps", "seed", "prompt_upsampling"], "optional": ["input_image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "FluxKontextProImageNode", "display_name": "Flux.1 Kontext [pro] Image", "description": "Edits images using Flux.1 Kontext [pro] via api based on prompt and aspect ratio.", "python_module": "comfy_api_nodes.nodes_bfl", "category": "api node/image/BFL", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "FluxKontextMaxImageNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation - specify what and how to edit.", "default": "", "multiline": true}], "aspect_ratio": ["STRING", {"tooltip": "Aspect ratio of image; must be between 1:4 and 4:1.", "default": "16:9", "multiline": false}], "guidance": ["FLOAT", {"tooltip": "Guidance strength for the image generation process", "default": 3.0, "min": 0.1, "max": 99.0, "step": 0.1}], "steps": ["INT", {"tooltip": "Number of steps for the image generation process", "default": 50, "min": 1, "max": 150}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 1234, "min": 0, "max": 18446744073709551615, "control_after_generate": true}], "prompt_upsampling": ["BOOLEAN", {"tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result).", "default": false}]}, "optional": {"input_image": ["IMAGE", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "aspect_ratio", "guidance", "steps", "seed", "prompt_upsampling"], "optional": ["input_image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "FluxKontextMaxImageNode", "display_name": "Flux.1 Kontext [max] Image", "description": "Edits images using Flux.1 Kontext [max] via api based on prompt and aspect ratio.", "python_module": "comfy_api_nodes.nodes_bfl", "category": "api node/image/BFL", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "FluxProExpandNode": {"input": {"required": {"image": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "Prompt for the image generation", "default": "", "multiline": true}], "prompt_upsampling": ["BOOLEAN", {"tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result).", "default": false}], "top": ["INT", {"tooltip": "Number of pixels to expand at the top of the image", "default": 0, "min": 0, "max": 2048}], "bottom": ["INT", {"tooltip": "Number of pixels to expand at the bottom of the image", "default": 0, "min": 0, "max": 2048}], "left": ["INT", {"tooltip": "Number of pixels to expand at the left of the image", "default": 0, "min": 0, "max": 2048}], "right": ["INT", {"tooltip": "Number of pixels to expand at the right of the image", "default": 0, "min": 0, "max": 2048}], "guidance": ["FLOAT", {"tooltip": "Guidance strength for the image generation process", "default": 60, "min": 1.5, "max": 100}], "steps": ["INT", {"tooltip": "Number of steps for the image generation process", "default": 50, "min": 15, "max": 50}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt", "prompt_upsampling", "top", "bottom", "left", "right", "guidance", "steps", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "FluxProExpandNode", "display_name": "Flux.1 Expand Image", "description": "Outpaints image based on prompt.", "python_module": "comfy_api_nodes.nodes_bfl", "category": "api node/image/BFL", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "FluxProFillNode": {"input": {"required": {"image": ["IMAGE", {}], "mask": ["MASK", {}], "prompt": ["STRING", {"tooltip": "Prompt for the image generation", "default": "", "multiline": true}], "prompt_upsampling": ["BOOLEAN", {"tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result).", "default": false}], "guidance": ["FLOAT", {"tooltip": "Guidance strength for the image generation process", "default": 60, "min": 1.5, "max": 100}], "steps": ["INT", {"tooltip": "Number of steps for the image generation process", "default": 50, "min": 15, "max": 50}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "mask", "prompt", "prompt_upsampling", "guidance", "steps", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "FluxProFillNode", "display_name": "Flux.1 Fill Image", "description": "Inpaints image based on mask and prompt.", "python_module": "comfy_api_nodes.nodes_bfl", "category": "api node/image/BFL", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ByteDanceImageNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "seedream-3-0-t2i-250415", "multiselect": false, "options": ["seedream-3-0-t2i-250415"]}], "prompt": ["STRING", {"tooltip": "The text prompt used to generate the image", "multiline": true}], "size_preset": ["COMBO", {"tooltip": "Pick a recommended size. Select Custom to use the width and height below", "multiselect": false, "options": ["1024x1024 (1:1)", "864x1152 (3:4)", "1152x864 (4:3)", "1280x720 (16:9)", "720x1280 (9:16)", "832x1248 (2:3)", "1248x832 (3:2)", "1512x648 (21:9)", "2048x2048 (1:1)", "Custom"]}], "width": ["INT", {"tooltip": "Custom width for image. Value is working only if `size_preset` is set to `Custom`", "default": 1024, "min": 512, "max": 2048, "step": 64}], "height": ["INT", {"tooltip": "Custom height for image. Value is working only if `size_preset` is set to `Custom`", "default": 1024, "min": 512, "max": 2048, "step": 64}]}, "optional": {"seed": ["INT", {"tooltip": "Seed to use for generation", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "guidance_scale": ["FLOAT", {"tooltip": "Higher value makes the image follow the prompt more closely", "default": 2.5, "min": 1.0, "max": 10.0, "step": 0.01, "display": "number"}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the image", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "size_preset", "width", "height"], "optional": ["seed", "guidance_scale", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ByteDanceImageNode", "display_name": "ByteDance Image", "description": "Generate images using ByteDance models via api based on prompt", "python_module": "comfy_api_nodes.nodes_bytedance", "category": "api node/image/ByteDance", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ByteDanceImageEditNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "seededit-3-0-i2i-250628", "multiselect": false, "options": ["seededit-3-0-i2i-250628"]}], "image": ["IMAGE", {"tooltip": "The base image to edit"}], "prompt": ["STRING", {"tooltip": "Instruction to edit image", "default": "", "multiline": true}]}, "optional": {"seed": ["INT", {"tooltip": "Seed to use for generation", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "guidance_scale": ["FLOAT", {"tooltip": "Higher value makes the image follow the prompt more closely", "default": 5.5, "min": 1.0, "max": 10.0, "step": 0.01, "display": "number"}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the image", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "image", "prompt"], "optional": ["seed", "guidance_scale", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ByteDanceImageEditNode", "display_name": "ByteDance Image Edit", "description": "Edit images using ByteDance models via api based on prompt", "python_module": "comfy_api_nodes.nodes_bytedance", "category": "api node/image/ByteDance", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ByteDanceSeedreamNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "multiselect": false, "options": ["seedream-4-0-250828"]}], "prompt": ["STRING", {"tooltip": "Text prompt for creating or editing an image.", "default": "", "multiline": true}], "size_preset": ["COMBO", {"tooltip": "Pick a recommended size. Select Custom to use the width and height below.", "multiselect": false, "options": ["2048x2048 (1:1)", "2304x1728 (4:3)", "1728x2304 (3:4)", "2560x1440 (16:9)", "1440x2560 (9:16)", "2496x1664 (3:2)", "1664x2496 (2:3)", "3024x1296 (21:9)", "4096x4096 (1:1)", "Custom"]}]}, "optional": {"image": ["IMAGE", {"tooltip": "Input image(s) for image-to-image generation. List of 1-10 images for single or multi-reference generation."}], "width": ["INT", {"tooltip": "Custom width for image. Value is working only if `size_preset` is set to `Custom`", "default": 2048, "min": 1024, "max": 4096, "step": 64}], "height": ["INT", {"tooltip": "Custom height for image. Value is working only if `size_preset` is set to `Custom`", "default": 2048, "min": 1024, "max": 4096, "step": 64}], "sequential_image_generation": ["COMBO", {"tooltip": "Group image generation mode. 'disabled' generates a single image. 'auto' lets the model decide whether to generate multiple related images (e.g., story scenes, character variations).", "multiselect": false, "options": ["disabled", "auto"]}], "max_images": ["INT", {"tooltip": "Maximum number of images to generate when sequential_image_generation='auto'. Total images (input + generated) cannot exceed 15.", "default": 1, "min": 1, "max": 15, "step": 1, "display": "number"}], "seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the image.", "default": true}], "fail_on_partial": ["BOOLEAN", {"tooltip": "If enabled, abort execution if any requested images are missing or return an error.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "size_preset"], "optional": ["image", "width", "height", "sequential_image_generation", "max_images", "seed", "watermark", "fail_on_partial"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ByteDanceSeedreamNode", "display_name": "ByteDance Seedream 4", "description": "Unified text-to-image generation and precise single-sentence editing at up to 4K resolution.", "python_module": "comfy_api_nodes.nodes_bytedance", "category": "api node/image/ByteDance", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ByteDanceTextToVideoNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "seedance-1-0-pro-250528", "multiselect": false, "options": ["seedance-1-0-pro-250528", "seedance-1-0-lite-t2v-250428"]}], "prompt": ["STRING", {"tooltip": "The text prompt used to generate the video.", "multiline": true}], "resolution": ["COMBO", {"tooltip": "The resolution of the output video.", "multiselect": false, "options": ["480p", "720p", "1080p"]}], "aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio of the output video.", "multiselect": false, "options": ["16:9", "4:3", "1:1", "3:4", "9:16", "21:9"]}], "duration": ["INT", {"tooltip": "The duration of the output video in seconds.", "default": 5, "min": 3, "max": 12, "step": 1, "display": "slider"}]}, "optional": {"seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "camera_fixed": ["BOOLEAN", {"tooltip": "Specifies whether to fix the camera. The platform appends an instruction to fix the camera to your prompt, but does not guarantee the actual effect.", "default": false}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the video.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "resolution", "aspect_ratio", "duration"], "optional": ["seed", "camera_fixed", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "ByteDanceTextToVideoNode", "display_name": "ByteDance Text to Video", "description": "Generate video using ByteDance models via api based on prompt", "python_module": "comfy_api_nodes.nodes_bytedance", "category": "api node/video/ByteDance", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ByteDanceImageToVideoNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "seedance-1-0-pro-250528", "multiselect": false, "options": ["seedance-1-0-pro-250528", "seedance-1-0-lite-i2v-250428"]}], "prompt": ["STRING", {"tooltip": "The text prompt used to generate the video.", "multiline": true}], "image": ["IMAGE", {"tooltip": "First frame to be used for the video."}], "resolution": ["COMBO", {"tooltip": "The resolution of the output video.", "multiselect": false, "options": ["480p", "720p", "1080p"]}], "aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio of the output video.", "multiselect": false, "options": ["adaptive", "16:9", "4:3", "1:1", "3:4", "9:16", "21:9"]}], "duration": ["INT", {"tooltip": "The duration of the output video in seconds.", "default": 5, "min": 3, "max": 12, "step": 1, "display": "slider"}]}, "optional": {"seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "camera_fixed": ["BOOLEAN", {"tooltip": "Specifies whether to fix the camera. The platform appends an instruction to fix the camera to your prompt, but does not guarantee the actual effect.", "default": false}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the video.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "image", "resolution", "aspect_ratio", "duration"], "optional": ["seed", "camera_fixed", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "ByteDanceImageToVideoNode", "display_name": "ByteDance Image to Video", "description": "Generate video using ByteDance models via api based on image and prompt", "python_module": "comfy_api_nodes.nodes_bytedance", "category": "api node/video/ByteDance", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ByteDanceFirstLastFrameNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "seedance-1-0-lite-i2v-250428", "multiselect": false, "options": ["seedance-1-0-pro-250528", "seedance-1-0-lite-i2v-250428"]}], "prompt": ["STRING", {"tooltip": "The text prompt used to generate the video.", "multiline": true}], "first_frame": ["IMAGE", {"tooltip": "First frame to be used for the video."}], "last_frame": ["IMAGE", {"tooltip": "Last frame to be used for the video."}], "resolution": ["COMBO", {"tooltip": "The resolution of the output video.", "multiselect": false, "options": ["480p", "720p", "1080p"]}], "aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio of the output video.", "multiselect": false, "options": ["adaptive", "16:9", "4:3", "1:1", "3:4", "9:16", "21:9"]}], "duration": ["INT", {"tooltip": "The duration of the output video in seconds.", "default": 5, "min": 3, "max": 12, "step": 1, "display": "slider"}]}, "optional": {"seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "camera_fixed": ["BOOLEAN", {"tooltip": "Specifies whether to fix the camera. The platform appends an instruction to fix the camera to your prompt, but does not guarantee the actual effect.", "default": false}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the video.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "first_frame", "last_frame", "resolution", "aspect_ratio", "duration"], "optional": ["seed", "camera_fixed", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "ByteDanceFirstLastFrameNode", "display_name": "ByteDance First-Last-Frame to Video", "description": "Generate video using prompt and first and last frames.", "python_module": "comfy_api_nodes.nodes_bytedance", "category": "api node/video/ByteDance", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ByteDanceImageReferenceNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "seedance-1-0-lite-i2v-250428", "multiselect": false, "options": ["seedance-1-0-lite-i2v-250428"]}], "prompt": ["STRING", {"tooltip": "The text prompt used to generate the video.", "multiline": true}], "images": ["IMAGE", {"tooltip": "One to four images."}], "resolution": ["COMBO", {"tooltip": "The resolution of the output video.", "multiselect": false, "options": ["480p", "720p"]}], "aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio of the output video.", "multiselect": false, "options": ["adaptive", "16:9", "4:3", "1:1", "3:4", "9:16", "21:9"]}], "duration": ["INT", {"tooltip": "The duration of the output video in seconds.", "default": 5, "min": 3, "max": 12, "step": 1, "display": "slider"}]}, "optional": {"seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the video.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "images", "resolution", "aspect_ratio", "duration"], "optional": ["seed", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "ByteDanceImageReferenceNode", "display_name": "ByteDance Reference Images to Video", "description": "Generate video using prompt and reference images.", "python_module": "comfy_api_nodes.nodes_bytedance", "category": "api node/video/ByteDance", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "LtxvApiTextToVideo": {"input": {"required": {"model": ["COMBO", {"multiselect": false, "options": ["LTX-2 (Pro)", "LTX-2 (Fast)"]}], "prompt": ["STRING", {"default": "", "multiline": true}], "duration": ["COMBO", {"default": 8, "multiselect": false, "options": [6, 8, 10]}], "resolution": ["COMBO", {"multiselect": false, "options": ["1920x1080", "2560x1440", "3840x2160"]}], "fps": ["COMBO", {"default": 25, "multiselect": false, "options": [25, 50]}]}, "optional": {"generate_audio": ["BOOLEAN", {"tooltip": "When true, the generated video will include AI-generated audio matching the scene.", "default": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "duration", "resolution", "fps"], "optional": ["generate_audio"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "LtxvApiTextToVideo", "display_name": "LTXV Text To Video", "description": "Professional-quality videos with customizable duration and resolution.", "python_module": "comfy_api_nodes.nodes_ltxv", "category": "api node/video/LTXV", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "LtxvApiImageToVideo": {"input": {"required": {"image": ["IMAGE", {"tooltip": "First frame to be used for the video."}], "model": ["COMBO", {"multiselect": false, "options": ["LTX-2 (Pro)", "LTX-2 (Fast)"]}], "prompt": ["STRING", {"default": "", "multiline": true}], "duration": ["COMBO", {"default": 8, "multiselect": false, "options": [6, 8, 10]}], "resolution": ["COMBO", {"multiselect": false, "options": ["1920x1080", "2560x1440", "3840x2160"]}], "fps": ["COMBO", {"default": 25, "multiselect": false, "options": [25, 50]}]}, "optional": {"generate_audio": ["BOOLEAN", {"tooltip": "When true, the generated video will include AI-generated audio matching the scene.", "default": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "model", "prompt", "duration", "resolution", "fps"], "optional": ["generate_audio"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "LtxvApiImageToVideo", "display_name": "LTXV Image To Video", "description": "Professional-quality videos with customizable duration and resolution based on start image.", "python_module": "comfy_api_nodes.nodes_ltxv", "category": "api node/video/LTXV", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "LumaImageNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation", "default": "", "multiline": true}], "model": ["COMBO", {"multiselect": false, "options": ["photon-1", "photon-flash-1"]}], "aspect_ratio": ["COMBO", {"default": "16:9", "multiselect": false, "options": ["1:1", "16:9", "9:16", "4:3", "3:4", "21:9", "9:21"]}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}], "style_image_weight": ["FLOAT", {"tooltip": "Weight of style image. Ignored if no style_image provided.", "default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"image_luma_ref": ["LUMA_REF", {"tooltip": "Luma Reference node connection to influence generation with input images; up to 4 images can be considered."}], "style_image": ["IMAGE", {"tooltip": "Style reference image; only 1 image will be used."}], "character_image": ["IMAGE", {"tooltip": "Character reference images; can be a batch of multiple, up to 4 images can be considered."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "model", "aspect_ratio", "seed", "style_image_weight"], "optional": ["image_luma_ref", "style_image", "character_image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "LumaImageNode", "display_name": "Luma Text to Image", "description": "Generates images synchronously based on prompt and aspect ratio.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/image/Luma", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "LumaImageModifyNode": {"input": {"required": {"image": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "Prompt for the image generation", "default": "", "multiline": true}], "image_weight": ["FLOAT", {"tooltip": "Weight of the image; the closer to 1.0, the less the image will be modified.", "default": 0.1, "min": 0.0, "max": 0.98, "step": 0.01}], "model": ["COMBO", {"multiselect": false, "options": ["photon-1", "photon-flash-1"]}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt", "image_weight", "model", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "LumaImageModifyNode", "display_name": "Luma Image to Image", "description": "Modifies images synchronously based on prompt and aspect ratio.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/image/Luma", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "LumaVideoNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the video generation", "default": "", "multiline": true}], "model": ["COMBO", {"multiselect": false, "options": ["ray-2", "ray-flash-2", "ray-1-6"]}], "aspect_ratio": ["COMBO", {"default": "16:9", "multiselect": false, "options": ["1:1", "16:9", "9:16", "4:3", "3:4", "21:9", "9:21"]}], "resolution": ["COMBO", {"default": "540p", "multiselect": false, "options": ["540p", "720p", "1080p", "4k"]}], "duration": ["COMBO", {"multiselect": false, "options": ["5s", "9s"]}], "loop": ["BOOLEAN", {"default": false}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"luma_concepts": ["LUMA_CONCEPTS", {"tooltip": "Optional Camera Concepts to dictate camera motion via the Luma Concepts node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "model", "aspect_ratio", "resolution", "duration", "loop", "seed"], "optional": ["luma_concepts"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "LumaVideoNode", "display_name": "Luma Text to Video", "description": "Generates videos synchronously based on prompt and output_size.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/video/Luma", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "LumaImageToVideoNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the video generation", "default": "", "multiline": true}], "model": ["COMBO", {"multiselect": false, "options": ["ray-2", "ray-flash-2", "ray-1-6"]}], "resolution": ["COMBO", {"default": "540p", "multiselect": false, "options": ["540p", "720p", "1080p", "4k"]}], "duration": ["COMBO", {"multiselect": false, "options": ["5s", "9s"]}], "loop": ["BOOLEAN", {"default": false}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"first_image": ["IMAGE", {"tooltip": "First frame of generated video."}], "last_image": ["IMAGE", {"tooltip": "Last frame of generated video."}], "luma_concepts": ["LUMA_CONCEPTS", {"tooltip": "Optional Camera Concepts to dictate camera motion via the Luma Concepts node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "model", "resolution", "duration", "loop", "seed"], "optional": ["first_image", "last_image", "luma_concepts"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "LumaImageToVideoNode", "display_name": "Luma Image to Video", "description": "Generates videos synchronously based on prompt, input images, and output_size.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/video/Luma", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "LumaReferenceNode": {"input": {"required": {"image": ["IMAGE", {"tooltip": "Image to use as reference."}], "weight": ["FLOAT", {"tooltip": "Weight of image reference.", "default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"luma_ref": ["LUMA_REF", {}]}}, "input_order": {"required": ["image", "weight"], "optional": ["luma_ref"]}, "output": ["LUMA_REF"], "output_is_list": [false], "output_name": ["luma_ref"], "output_tooltips": [null], "name": "LumaReferenceNode", "display_name": "Luma Reference", "description": "Holds an image and weight for use with Luma Generate Image node.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/image/Luma", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LumaConceptsNode": {"input": {"required": {"concept1": ["COMBO", {"multiselect": false, "options": ["None", "truck_left", "pan_right", "pedestal_down", "low_angle", "pedestal_up", "selfie", "pan_left", "roll_right", "zoom_in", "over_the_shoulder", "orbit_right", "orbit_left", "static", "tiny_planet", "high_angle", "bolt_cam", "dolly_zoom", "overhead", "zoom_out", "handheld", "roll_left", "pov", "aerial_drone", "push_in", "crane_down", "truck_right", "tilt_down", "elevator_doors", "tilt_up", "ground_level", "pull_out", "aerial", "crane_up", "eye_level"]}], "concept2": ["COMBO", {"multiselect": false, "options": ["None", "truck_left", "pan_right", "pedestal_down", "low_angle", "pedestal_up", "selfie", "pan_left", "roll_right", "zoom_in", "over_the_shoulder", "orbit_right", "orbit_left", "static", "tiny_planet", "high_angle", "bolt_cam", "dolly_zoom", "overhead", "zoom_out", "handheld", "roll_left", "pov", "aerial_drone", "push_in", "crane_down", "truck_right", "tilt_down", "elevator_doors", "tilt_up", "ground_level", "pull_out", "aerial", "crane_up", "eye_level"]}], "concept3": ["COMBO", {"multiselect": false, "options": ["None", "truck_left", "pan_right", "pedestal_down", "low_angle", "pedestal_up", "selfie", "pan_left", "roll_right", "zoom_in", "over_the_shoulder", "orbit_right", "orbit_left", "static", "tiny_planet", "high_angle", "bolt_cam", "dolly_zoom", "overhead", "zoom_out", "handheld", "roll_left", "pov", "aerial_drone", "push_in", "crane_down", "truck_right", "tilt_down", "elevator_doors", "tilt_up", "ground_level", "pull_out", "aerial", "crane_up", "eye_level"]}], "concept4": ["COMBO", {"multiselect": false, "options": ["None", "truck_left", "pan_right", "pedestal_down", "low_angle", "pedestal_up", "selfie", "pan_left", "roll_right", "zoom_in", "over_the_shoulder", "orbit_right", "orbit_left", "static", "tiny_planet", "high_angle", "bolt_cam", "dolly_zoom", "overhead", "zoom_out", "handheld", "roll_left", "pov", "aerial_drone", "push_in", "crane_down", "truck_right", "tilt_down", "elevator_doors", "tilt_up", "ground_level", "pull_out", "aerial", "crane_up", "eye_level"]}]}, "optional": {"luma_concepts": ["LUMA_CONCEPTS", {"tooltip": "Optional Camera Concepts to add to the ones chosen here."}]}}, "input_order": {"required": ["concept1", "concept2", "concept3", "concept4"], "optional": ["luma_concepts"]}, "output": ["LUMA_CONCEPTS"], "output_is_list": [false], "output_name": ["luma_concepts"], "output_tooltips": [null], "name": "LumaConceptsNode", "display_name": "Luma Concepts", "description": "Camera Concepts for use with Luma Text to Video and Luma Image to Video nodes.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/video/Luma", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RecraftTextToImageNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation.", "default": "", "multiline": true}], "size": ["COMBO", {"tooltip": "The size of the generated image.", "default": "1024x1024", "multiselect": false, "options": ["1024x1024", "1365x1024", "1024x1365", "1536x1024", "1024x1536", "1820x1024", "1024x1820", "1024x2048", "2048x1024", "1434x1024", "1024x1434", "1024x1280", "1280x1024", "1024x1707", "1707x1024"]}], "n": ["INT", {"tooltip": "The number of images to generate.", "default": 1, "min": 1, "max": 6}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"recraft_style": ["RECRAFT_V3_STYLE", {}], "negative_prompt": ["STRING", {"tooltip": "An optional text description of undesired elements on an image.", "default": "", "forceInput": true, "multiline": false}], "recraft_controls": ["RECRAFT_CONTROLS", {"tooltip": "Optional additional controls over the generation via the Recraft Controls node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "size", "n", "seed"], "optional": ["recraft_style", "negative_prompt", "recraft_controls"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "RecraftTextToImageNode", "display_name": "Recraft Text to Image", "description": "Generates images synchronously based on prompt and resolution.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftImageToImageNode": {"input": {"required": {"image": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "Prompt for the image generation.", "default": "", "multiline": true}], "n": ["INT", {"tooltip": "The number of images to generate.", "default": 1, "min": 1, "max": 6}], "strength": ["FLOAT", {"tooltip": "Defines the difference with the original image, should lie in [0, 1], where 0 means almost identical, and 1 means miserable similarity.", "default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"recraft_style": ["RECRAFT_V3_STYLE", {}], "negative_prompt": ["STRING", {"tooltip": "An optional text description of undesired elements on an image.", "default": "", "forceInput": true, "multiline": false}], "recraft_controls": ["RECRAFT_CONTROLS", {"tooltip": "Optional additional controls over the generation via the Recraft Controls node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt", "n", "strength", "seed"], "optional": ["recraft_style", "negative_prompt", "recraft_controls"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "RecraftImageToImageNode", "display_name": "Recraft Image to Image", "description": "Modify image based on prompt and strength.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftImageInpaintingNode": {"input": {"required": {"image": ["IMAGE", {}], "mask": ["MASK", {}], "prompt": ["STRING", {"tooltip": "Prompt for the image generation.", "default": "", "multiline": true}], "n": ["INT", {"tooltip": "The number of images to generate.", "default": 1, "min": 1, "max": 6}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"recraft_style": ["RECRAFT_V3_STYLE", {}], "negative_prompt": ["STRING", {"tooltip": "An optional text description of undesired elements on an image.", "default": "", "forceInput": true, "multiline": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "mask", "prompt", "n", "seed"], "optional": ["recraft_style", "negative_prompt"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "RecraftImageInpaintingNode", "display_name": "Recraft Image Inpainting", "description": "Modify image based on prompt and mask.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftTextToVectorNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation.", "default": "", "multiline": true}], "substyle": ["COMBO", {"multiselect": false, "options": ["None", "bold_stroke", "chemistry", "colored_stencil", "contour_pop_art", "cosmics", "cutout", "depressive", "editorial", "emotional_flat", "engraving", "infographical", "line_art", "line_circuit", "linocut", "marker_outline", "mosaic", "naivector", "roundish_flat", "seamless", "segmented_colors", "sharp_contrast", "thin", "vector_photo", "vivid_shapes"]}], "size": ["COMBO", {"tooltip": "The size of the generated image.", "default": "1024x1024", "multiselect": false, "options": ["1024x1024", "1365x1024", "1024x1365", "1536x1024", "1024x1536", "1820x1024", "1024x1820", "1024x2048", "2048x1024", "1434x1024", "1024x1434", "1024x1280", "1280x1024", "1024x1707", "1707x1024"]}], "n": ["INT", {"tooltip": "The number of images to generate.", "default": 1, "min": 1, "max": 6}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "An optional text description of undesired elements on an image.", "default": "", "forceInput": true, "multiline": false}], "recraft_controls": ["RECRAFT_CONTROLS", {"tooltip": "Optional additional controls over the generation via the Recraft Controls node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "substyle", "size", "n", "seed"], "optional": ["negative_prompt", "recraft_controls"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["SVG"], "output_is_list": [false], "output_name": ["SVG"], "output_tooltips": [null], "name": "RecraftTextToVectorNode", "display_name": "Recraft Text to Vector", "description": "Generates SVG synchronously based on prompt and resolution.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftVectorizeImageNode": {"input": {"required": {"image": ["IMAGE", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["SVG"], "output_is_list": [false], "output_name": ["SVG"], "output_tooltips": [null], "name": "RecraftVectorizeImageNode", "display_name": "Recraft Vectorize Image", "description": "Generates SVG synchronously from an input image.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftRemoveBackgroundNode": {"input": {"required": {"image": ["IMAGE", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "output_tooltips": [null, null], "name": "RecraftRemoveBackgroundNode", "display_name": "Recraft Remove Background", "description": "Remove background from image, and return processed image and mask.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftReplaceBackgroundNode": {"input": {"required": {"image": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "Prompt for the image generation.", "default": "", "multiline": true}], "n": ["INT", {"tooltip": "The number of images to generate.", "default": 1, "min": 1, "max": 6}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"recraft_style": ["RECRAFT_V3_STYLE", {}], "negative_prompt": ["STRING", {"tooltip": "An optional text description of undesired elements on an image.", "default": "", "forceInput": true, "multiline": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt", "n", "seed"], "optional": ["recraft_style", "negative_prompt"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "RecraftReplaceBackgroundNode", "display_name": "Recraft Replace Background", "description": "Replace background on image, based on provided prompt.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftCrispUpscaleNode": {"input": {"required": {"image": ["IMAGE", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "RecraftCrispUpscaleNode", "display_name": "Recraft Crisp Upscale Image", "description": "Upscale image synchronously.\nEnhances a given raster image using \u2018crisp upscale\u2019 tool, increasing image resolution, making the image sharper and cleaner.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftCreativeUpscaleNode": {"input": {"required": {"image": ["IMAGE", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "RecraftCreativeUpscaleNode", "display_name": "Recraft Creative Upscale Image", "description": "Upscale image synchronously.\nEnhances a given raster image using \u2018creative upscale\u2019 tool, boosting resolution with a focus on refining small details and faces.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftStyleV3RealisticImage": {"input": {"required": {"substyle": ["COMBO", {"multiselect": false, "options": ["None", "b_and_w", "enterprise", "evening_light", "faded_nostalgia", "forest_life", "hard_flash", "hdr", "motion_blur", "mystic_naturalism", "natural_light", "natural_tones", "organic_calm", "real_life_glow", "retro_realism", "retro_snapshot", "studio_portrait", "urban_drama", "village_realism", "warm_folk"]}]}}, "input_order": {"required": ["substyle"]}, "output": ["RECRAFT_V3_STYLE"], "output_is_list": [false], "output_name": ["recraft_style"], "output_tooltips": [null], "name": "RecraftStyleV3RealisticImage", "display_name": "Recraft Style - Realistic Image", "description": "Select realistic_image style and optional substyle.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RecraftStyleV3DigitalIllustration": {"input": {"required": {"substyle": ["COMBO", {"multiselect": false, "options": ["None", "2d_art_poster", "2d_art_poster_2", "antiquarian", "bold_fantasy", "child_book", "child_books", "cover", "crosshatch", "digital_engraving", "engraving_color", "expressionism", "freehand_details", "grain", "grain_20", "graphic_intensity", "hand_drawn", "hand_drawn_outline", "handmade_3d", "hard_comics", "infantile_sketch", "long_shadow", "modern_folk", "multicolor", "neon_calm", "noir", "nostalgic_pastel", "outline_details", "pastel_gradient", "pastel_sketch", "pixel_art", "plastic", "pop_art", "pop_renaissance", "seamless", "street_art", "tablet_sketch", "urban_glow", "urban_sketching", "vanilla_dreams", "young_adult_book", "young_adult_book_2"]}]}}, "input_order": {"required": ["substyle"]}, "output": ["RECRAFT_V3_STYLE"], "output_is_list": [false], "output_name": ["recraft_style"], "output_tooltips": [null], "name": "RecraftStyleV3DigitalIllustration", "display_name": "Recraft Style - Digital Illustration", "description": "Select realistic_image style and optional substyle.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RecraftStyleV3LogoRaster": {"input": {"required": {"substyle": ["COMBO", {"multiselect": false, "options": ["emblem_graffiti", "emblem_pop_art", "emblem_punk", "emblem_stamp", "emblem_vintage"]}]}}, "input_order": {"required": ["substyle"]}, "output": ["RECRAFT_V3_STYLE"], "output_is_list": [false], "output_name": ["recraft_style"], "output_tooltips": [null], "name": "RecraftStyleV3LogoRaster", "display_name": "Recraft Style - Logo Raster", "description": "Select realistic_image style and optional substyle.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RecraftStyleV3InfiniteStyleLibrary": {"input": {"required": {"style_id": ["STRING", {"tooltip": "UUID of style from Infinite Style Library.", "default": "", "multiline": false}]}}, "input_order": {"required": ["style_id"]}, "output": ["RECRAFT_V3_STYLE"], "output_is_list": [false], "output_name": ["recraft_style"], "output_tooltips": [null], "name": "RecraftStyleV3InfiniteStyleLibrary", "display_name": "Recraft Style - Infinite Style Library", "description": "Select style based on preexisting UUID from Recraft's Infinite Style Library.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RecraftColorRGB": {"input": {"required": {"r": ["INT", {"tooltip": "Red value of color.", "default": 0, "min": 0, "max": 255}], "g": ["INT", {"tooltip": "Green value of color.", "default": 0, "min": 0, "max": 255}], "b": ["INT", {"tooltip": "Blue value of color.", "default": 0, "min": 0, "max": 255}]}, "optional": {"recraft_color": ["RECRAFT_COLOR", {}]}}, "input_order": {"required": ["r", "g", "b"], "optional": ["recraft_color"]}, "output": ["RECRAFT_COLOR"], "output_is_list": [false], "output_name": ["recraft_color"], "output_tooltips": [null], "name": "RecraftColorRGB", "display_name": "Recraft Color RGB", "description": "Create Recraft Color by choosing specific RGB values.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RecraftControls": {"input": {"required": {}, "optional": {"colors": ["RECRAFT_COLOR", {}], "background_color": ["RECRAFT_COLOR", {}]}}, "input_order": {"required": [], "optional": ["colors", "background_color"]}, "output": ["RECRAFT_CONTROLS"], "output_is_list": [false], "output_name": ["recraft_controls"], "output_tooltips": [null], "name": "RecraftControls", "display_name": "Recraft Controls", "description": "Create Recraft Controls for customizing Recraft generation.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "PixverseTextToVideoNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the video generation", "default": "", "multiline": true}], "aspect_ratio": ["COMBO", {"multiselect": false, "options": ["16:9", "4:3", "1:1", "3:4", "9:16"]}], "quality": ["COMBO", {"default": "540p", "multiselect": false, "options": ["360p", "540p", "720p", "1080p"]}], "duration_seconds": ["COMBO", {"multiselect": false, "options": [5, 8]}], "motion_mode": ["COMBO", {"multiselect": false, "options": ["normal", "fast"]}], "seed": ["INT", {"tooltip": "Seed for video generation.", "default": 0, "min": 0, "max": 2147483647, "control_after_generate": true}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "An optional text description of undesired elements on an image.", "default": "", "multiline": true}], "pixverse_template": ["PIXVERSE_TEMPLATE", {"tooltip": "An optional template to influence style of generation, created by the PixVerse Template node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "aspect_ratio", "quality", "duration_seconds", "motion_mode", "seed"], "optional": ["negative_prompt", "pixverse_template"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "PixverseTextToVideoNode", "display_name": "PixVerse Text to Video", "description": "Generates videos based on prompt and output_size.", "python_module": "comfy_api_nodes.nodes_pixverse", "category": "api node/video/PixVerse", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "PixverseImageToVideoNode": {"input": {"required": {"image": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "Prompt for the video generation", "default": "", "multiline": true}], "quality": ["COMBO", {"default": "540p", "multiselect": false, "options": ["360p", "540p", "720p", "1080p"]}], "duration_seconds": ["COMBO", {"multiselect": false, "options": [5, 8]}], "motion_mode": ["COMBO", {"multiselect": false, "options": ["normal", "fast"]}], "seed": ["INT", {"tooltip": "Seed for video generation.", "default": 0, "min": 0, "max": 2147483647, "control_after_generate": true}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "An optional text description of undesired elements on an image.", "default": "", "multiline": true}], "pixverse_template": ["PIXVERSE_TEMPLATE", {"tooltip": "An optional template to influence style of generation, created by the PixVerse Template node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt", "quality", "duration_seconds", "motion_mode", "seed"], "optional": ["negative_prompt", "pixverse_template"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "PixverseImageToVideoNode", "display_name": "PixVerse Image to Video", "description": "Generates videos based on prompt and output_size.", "python_module": "comfy_api_nodes.nodes_pixverse", "category": "api node/video/PixVerse", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "PixverseTransitionVideoNode": {"input": {"required": {"first_frame": ["IMAGE", {}], "last_frame": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "Prompt for the video generation", "default": "", "multiline": true}], "quality": ["COMBO", {"default": "540p", "multiselect": false, "options": ["360p", "540p", "720p", "1080p"]}], "duration_seconds": ["COMBO", {"multiselect": false, "options": [5, 8]}], "motion_mode": ["COMBO", {"multiselect": false, "options": ["normal", "fast"]}], "seed": ["INT", {"tooltip": "Seed for video generation.", "default": 0, "min": 0, "max": 2147483647, "control_after_generate": true}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "An optional text description of undesired elements on an image.", "default": "", "multiline": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["first_frame", "last_frame", "prompt", "quality", "duration_seconds", "motion_mode", "seed"], "optional": ["negative_prompt"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "PixverseTransitionVideoNode", "display_name": "PixVerse Transition Video", "description": "Generates videos based on prompt and output_size.", "python_module": "comfy_api_nodes.nodes_pixverse", "category": "api node/video/PixVerse", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "PixverseTemplateNode": {"input": {"required": {"template": ["COMBO", {"multiselect": false, "options": ["Microwave", "Suit Swagger", "Anything, Robot", "Subject 3 Fever", "kiss kiss"]}]}}, "input_order": {"required": ["template"]}, "output": ["PIXVERSE_TEMPLATE"], "output_is_list": [false], "output_name": ["pixverse_template"], "output_tooltips": [null], "name": "PixverseTemplateNode", "display_name": "PixVerse Template", "description": "", "python_module": "comfy_api_nodes.nodes_pixverse", "category": "api node/video/PixVerse", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StabilityStableImageUltraNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defineselements, colors, and subjects will lead to better results. To control the weight of a given word use the format `(word:weight)`,where `word` is the word you'd like to control the weight of and `weight`is a value between 0 and 1. For example: `The sky was a crisp (blue:0.3) and (green:0.8)`would convey a sky that was blue and green, but more green than blue.", "default": "", "multiline": true}], "aspect_ratio": ["COMBO", {"tooltip": "Aspect ratio of generated image.", "default": "1:1", "multiselect": false, "options": ["1:1", "16:9", "9:16", "3:2", "2:3", "5:4", "4:5", "21:9", "9:21"]}], "style_preset": ["COMBO", {"tooltip": "Optional desired style of generated image.", "multiselect": false, "options": ["None", "3d-model", "analog-film", "anime", "cinematic", "comic-book", "digital-art", "enhance", "fantasy-art", "isometric", "line-art", "low-poly", "modeling-compound", "neon-punk", "origami", "photographic", "pixel-art", "tile-texture"]}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 4294967294, "step": 1, "control_after_generate": true, "display": "number"}]}, "optional": {"image": ["IMAGE", {}], "negative_prompt": ["STRING", {"tooltip": "A blurb of text describing what you do not wish to see in the output image. This is an advanced feature.", "default": "", "forceInput": true, "multiline": false}], "image_denoise": ["FLOAT", {"tooltip": "Denoise of input image; 0.0 yields image identical to input, 1.0 is as if no image was provided at all.", "default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "aspect_ratio", "style_preset", "seed"], "optional": ["image", "negative_prompt", "image_denoise"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "StabilityStableImageUltraNode", "display_name": "Stability AI Stable Image Ultra", "description": "Generates images synchronously based on prompt and resolution.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/image/Stability AI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "StabilityStableImageSD_3_5Node": {"input": {"required": {"prompt": ["STRING", {"tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defines elements, colors, and subjects will lead to better results.", "default": "", "multiline": true}], "model": ["COMBO", {"multiselect": false, "options": ["sd3.5-large", "sd3.5-medium"]}], "aspect_ratio": ["COMBO", {"tooltip": "Aspect ratio of generated image.", "default": "1:1", "multiselect": false, "options": ["1:1", "16:9", "9:16", "3:2", "2:3", "5:4", "4:5", "21:9", "9:21"]}], "style_preset": ["COMBO", {"tooltip": "Optional desired style of generated image.", "multiselect": false, "options": ["None", "3d-model", "analog-film", "anime", "cinematic", "comic-book", "digital-art", "enhance", "fantasy-art", "isometric", "line-art", "low-poly", "modeling-compound", "neon-punk", "origami", "photographic", "pixel-art", "tile-texture"]}], "cfg_scale": ["FLOAT", {"tooltip": "How strictly the diffusion process adheres to the prompt text (higher values keep your image closer to your prompt)", "default": 4.0, "min": 1.0, "max": 10.0, "step": 0.1}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 4294967294, "step": 1, "control_after_generate": true, "display": "number"}]}, "optional": {"image": ["IMAGE", {}], "negative_prompt": ["STRING", {"tooltip": "Keywords of what you do not wish to see in the output image. This is an advanced feature.", "default": "", "forceInput": true, "multiline": false}], "image_denoise": ["FLOAT", {"tooltip": "Denoise of input image; 0.0 yields image identical to input, 1.0 is as if no image was provided at all.", "default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "model", "aspect_ratio", "style_preset", "cfg_scale", "seed"], "optional": ["image", "negative_prompt", "image_denoise"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "StabilityStableImageSD_3_5Node", "display_name": "Stability AI Stable Diffusion 3.5 Image", "description": "Generates images synchronously based on prompt and resolution.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/image/Stability AI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "StabilityUpscaleConservativeNode": {"input": {"required": {"image": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defines elements, colors, and subjects will lead to better results.", "default": "", "multiline": true}], "creativity": ["FLOAT", {"tooltip": "Controls the likelihood of creating additional details not heavily conditioned by the init image.", "default": 0.35, "min": 0.2, "max": 0.5, "step": 0.01}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 4294967294, "step": 1, "control_after_generate": true, "display": "number"}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "Keywords of what you do not wish to see in the output image. This is an advanced feature.", "default": "", "forceInput": true, "multiline": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt", "creativity", "seed"], "optional": ["negative_prompt"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "StabilityUpscaleConservativeNode", "display_name": "Stability AI Upscale Conservative", "description": "Upscale image with minimal alterations to 4K resolution.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/image/Stability AI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "StabilityUpscaleCreativeNode": {"input": {"required": {"image": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defines elements, colors, and subjects will lead to better results.", "default": "", "multiline": true}], "creativity": ["FLOAT", {"tooltip": "Controls the likelihood of creating additional details not heavily conditioned by the init image.", "default": 0.3, "min": 0.1, "max": 0.5, "step": 0.01}], "style_preset": ["COMBO", {"tooltip": "Optional desired style of generated image.", "multiselect": false, "options": ["None", "3d-model", "analog-film", "anime", "cinematic", "comic-book", "digital-art", "enhance", "fantasy-art", "isometric", "line-art", "low-poly", "modeling-compound", "neon-punk", "origami", "photographic", "pixel-art", "tile-texture"]}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 4294967294, "step": 1, "control_after_generate": true, "display": "number"}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "Keywords of what you do not wish to see in the output image. This is an advanced feature.", "default": "", "forceInput": true, "multiline": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt", "creativity", "style_preset", "seed"], "optional": ["negative_prompt"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "StabilityUpscaleCreativeNode", "display_name": "Stability AI Upscale Creative", "description": "Upscale image with minimal alterations to 4K resolution.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/image/Stability AI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "StabilityUpscaleFastNode": {"input": {"required": {"image": ["IMAGE", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "StabilityUpscaleFastNode", "display_name": "Stability AI Upscale Fast", "description": "Quickly upscales an image via Stability API call to 4x its original size; intended for upscaling low-quality/compressed images.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/image/Stability AI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "StabilityTextToAudio": {"input": {"required": {"model": ["COMBO", {"multiselect": false, "options": ["stable-audio-2.5"]}], "prompt": ["STRING", {"default": "", "multiline": true}]}, "optional": {"duration": ["INT", {"tooltip": "Controls the duration in seconds of the generated audio.", "default": 190, "min": 1, "max": 190, "step": 1}], "seed": ["INT", {"tooltip": "The random seed used for generation.", "default": 0, "min": 0, "max": 4294967294, "step": 1, "control_after_generate": true, "display": "number"}], "steps": ["INT", {"tooltip": "Controls the number of sampling steps.", "default": 8, "min": 4, "max": 8, "step": 1}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt"], "optional": ["duration", "seed", "steps"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "output_tooltips": [null], "name": "StabilityTextToAudio", "display_name": "Stability AI Text To Audio", "description": "Generates high-quality music and sound effects from text descriptions.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/audio/Stability AI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "StabilityAudioToAudio": {"input": {"required": {"model": ["COMBO", {"multiselect": false, "options": ["stable-audio-2.5"]}], "prompt": ["STRING", {"default": "", "multiline": true}], "audio": ["AUDIO", {"tooltip": "Audio must be between 6 and 190 seconds long."}]}, "optional": {"duration": ["INT", {"tooltip": "Controls the duration in seconds of the generated audio.", "default": 190, "min": 1, "max": 190, "step": 1}], "seed": ["INT", {"tooltip": "The random seed used for generation.", "default": 0, "min": 0, "max": 4294967294, "step": 1, "control_after_generate": true, "display": "number"}], "steps": ["INT", {"tooltip": "Controls the number of sampling steps.", "default": 8, "min": 4, "max": 8, "step": 1}], "strength": ["FLOAT", {"tooltip": "Parameter controls how much influence the audio parameter has on the generated audio.", "default": 1, "min": 0.01, "max": 1.0, "step": 0.01, "display": "slider"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "audio"], "optional": ["duration", "seed", "steps", "strength"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "output_tooltips": [null], "name": "StabilityAudioToAudio", "display_name": "Stability AI Audio To Audio", "description": "Transforms existing audio samples into new high-quality compositions using text instructions.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/audio/Stability AI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "StabilityAudioInpaint": {"input": {"required": {"model": ["COMBO", {"multiselect": false, "options": ["stable-audio-2.5"]}], "prompt": ["STRING", {"default": "", "multiline": true}], "audio": ["AUDIO", {"tooltip": "Audio must be between 6 and 190 seconds long."}]}, "optional": {"duration": ["INT", {"tooltip": "Controls the duration in seconds of the generated audio.", "default": 190, "min": 1, "max": 190, "step": 1}], "seed": ["INT", {"tooltip": "The random seed used for generation.", "default": 0, "min": 0, "max": 4294967294, "step": 1, "control_after_generate": true, "display": "number"}], "steps": ["INT", {"tooltip": "Controls the number of sampling steps.", "default": 8, "min": 4, "max": 8, "step": 1}], "mask_start": ["INT", {"default": 30, "min": 0, "max": 190, "step": 1}], "mask_end": ["INT", {"default": 190, "min": 0, "max": 190, "step": 1}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "audio"], "optional": ["duration", "seed", "steps", "mask_start", "mask_end"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "output_tooltips": [null], "name": "StabilityAudioInpaint", "display_name": "Stability AI Audio Inpaint", "description": "Transforms part of existing audio sample using text instructions.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/audio/Stability AI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "PikaImageToVideoNode2_2": {"input": {"required": {"image": ["IMAGE", {"tooltip": "The image to convert to video"}], "prompt_text": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"multiline": true}], "seed": ["INT", {"min": 0, "max": 4294967295, "control_after_generate": true}], "resolution": ["COMBO", {"default": "1080p", "multiselect": false, "options": ["1080p", "720p"]}], "duration": ["COMBO", {"default": 5, "multiselect": false, "options": [5, 10]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt_text", "negative_prompt", "seed", "resolution", "duration"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "PikaImageToVideoNode2_2", "display_name": "Pika Image to Video", "description": "Sends an image and prompt to the Pika API v2.2 to generate a video.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "PikaTextToVideoNode2_2": {"input": {"required": {"prompt_text": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"multiline": true}], "seed": ["INT", {"min": 0, "max": 4294967295, "control_after_generate": true}], "resolution": ["COMBO", {"default": "1080p", "multiselect": false, "options": ["1080p", "720p"]}], "duration": ["COMBO", {"default": 5, "multiselect": false, "options": [5, 10]}], "aspect_ratio": ["FLOAT", {"tooltip": "Aspect ratio (width / height)", "default": 1.7777777777777777, "min": 0.4, "max": 2.5, "step": 0.001}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt_text", "negative_prompt", "seed", "resolution", "duration", "aspect_ratio"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "PikaTextToVideoNode2_2", "display_name": "Pika Text to Video", "description": "Sends a text prompt to the Pika API v2.2 to generate a video.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "PikaScenesV2_2": {"input": {"required": {"prompt_text": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"multiline": true}], "seed": ["INT", {"min": 0, "max": 4294967295, "control_after_generate": true}], "resolution": ["COMBO", {"default": "1080p", "multiselect": false, "options": ["1080p", "720p"]}], "duration": ["COMBO", {"default": 5, "multiselect": false, "options": [5, 10]}], "ingredients_mode": ["COMBO", {"default": "creative", "multiselect": false, "options": ["creative", "precise"]}], "aspect_ratio": ["FLOAT", {"tooltip": "Aspect ratio (width / height)", "default": 1.7777777777777777, "min": 0.4, "max": 2.5, "step": 0.001}]}, "optional": {"image_ingredient_1": ["IMAGE", {"tooltip": "Image that will be used as ingredient to create a video."}], "image_ingredient_2": ["IMAGE", {"tooltip": "Image that will be used as ingredient to create a video."}], "image_ingredient_3": ["IMAGE", {"tooltip": "Image that will be used as ingredient to create a video."}], "image_ingredient_4": ["IMAGE", {"tooltip": "Image that will be used as ingredient to create a video."}], "image_ingredient_5": ["IMAGE", {"tooltip": "Image that will be used as ingredient to create a video."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt_text", "negative_prompt", "seed", "resolution", "duration", "ingredients_mode", "aspect_ratio"], "optional": ["image_ingredient_1", "image_ingredient_2", "image_ingredient_3", "image_ingredient_4", "image_ingredient_5"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "PikaScenesV2_2", "display_name": "Pika Scenes (Video Image Composition)", "description": "Combine your images to create a video with the objects in them. Upload multiple images as ingredients and generate a high-quality video that incorporates all of them.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Pikadditions": {"input": {"required": {"video": ["VIDEO", {"tooltip": "The video to add an image to."}], "image": ["IMAGE", {"tooltip": "The image to add to the video."}], "prompt_text": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"multiline": true}], "seed": ["INT", {"min": 0, "max": 4294967295, "control_after_generate": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["video", "image", "prompt_text", "negative_prompt", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "Pikadditions", "display_name": "Pikadditions (Video Object Insertion)", "description": "Add any object or image into your video. Upload a video and specify what you'd like to add to create a seamlessly integrated result.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Pikaswaps": {"input": {"required": {"video": ["VIDEO", {"tooltip": "The video to swap an object in."}]}, "optional": {"image": ["IMAGE", {"tooltip": "The image used to replace the masked object in the video."}], "mask": ["MASK", {"tooltip": "Use the mask to define areas in the video to replace."}], "prompt_text": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"multiline": true}], "seed": ["INT", {"min": 0, "max": 4294967295, "control_after_generate": true}], "region_to_modify": ["STRING", {"tooltip": "Plaintext description of the object / region to modify.", "multiline": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["video"], "optional": ["image", "mask", "prompt_text", "negative_prompt", "seed", "region_to_modify"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "Pikaswaps", "display_name": "Pika Swaps (Video Object Replacement)", "description": "Swap out any object or region of your video with a new image or object. Define areas to replace either with a mask or coordinates.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Pikaffects": {"input": {"required": {"image": ["IMAGE", {"tooltip": "The reference image to apply the Pikaffect to."}], "pikaffect": ["COMBO", {"default": "Cake-ify", "multiselect": false, "options": ["Cake-ify", "Crumble", "Crush", "Decapitate", "Deflate", "Dissolve", "Explode", "Eye-pop", "Inflate", "Levitate", "Melt", "Peel", "Poke", "Squish", "Ta-da", "Tear"]}], "prompt_text": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"multiline": true}], "seed": ["INT", {"min": 0, "max": 4294967295, "control_after_generate": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "pikaffect", "prompt_text", "negative_prompt", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "Pikaffects", "display_name": "Pikaffects (Video Effects)", "description": "Generate a video with a specific Pikaffect. Supported Pikaffects: Cake-ify, Crumble, Crush, Decapitate, Deflate, Dissolve, Explode, Eye-pop, Inflate, Levitate, Melt, Peel, Poke, Squish, Ta-da, Tear", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "PikaStartEndFrameNode2_2": {"input": {"required": {"image_start": ["IMAGE", {"tooltip": "The first image to combine."}], "image_end": ["IMAGE", {"tooltip": "The last image to combine."}], "prompt_text": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"multiline": true}], "seed": ["INT", {"min": 0, "max": 4294967295, "control_after_generate": true}], "resolution": ["COMBO", {"default": "1080p", "multiselect": false, "options": ["1080p", "720p"]}], "duration": ["COMBO", {"default": 5, "multiselect": false, "options": [5, 10]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image_start", "image_end", "prompt_text", "negative_prompt", "seed", "resolution", "duration"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "PikaStartEndFrameNode2_2", "display_name": "Pika Start and End Frame to Video", "description": "Generate a video by combining your first and last frame. Upload two images to define the start and end points, and let the AI create a smooth transition between them.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RunwayFirstLastFrameNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text prompt for the generation", "default": "", "multiline": true}], "start_frame": ["IMAGE", {"tooltip": "Start frame to be used for the video"}], "end_frame": ["IMAGE", {"tooltip": "End frame to be used for the video. Supported for gen3a_turbo only."}], "duration": ["COMBO", {"multiselect": false, "options": [5, 10]}], "ratio": ["COMBO", {"multiselect": false, "options": ["768:1280", "1280:768"]}], "seed": ["INT", {"tooltip": "Random seed for generation", "default": 0, "min": 0, "max": 4294967295, "step": 1, "control_after_generate": true, "display": "number"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "start_frame", "end_frame", "duration", "ratio", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "RunwayFirstLastFrameNode", "display_name": "Runway First-Last-Frame to Video", "description": "Upload first and last keyframes, draft a prompt, and generate a video. More complex transitions, such as cases where the Last frame is completely different from the First frame, may benefit from the longer 10s duration. This would give the generation more time to smoothly transition between the two inputs. Before diving in, review these best practices to ensure that your input selections will set your generation up for success: https://help.runwayml.com/hc/en-us/articles/34170748696595-Creating-with-Keyframes-on-Gen-3.", "python_module": "comfy_api_nodes.nodes_runway", "category": "api node/video/Runway", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RunwayImageToVideoNodeGen3a": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text prompt for the generation", "default": "", "multiline": true}], "start_frame": ["IMAGE", {"tooltip": "Start frame to be used for the video"}], "duration": ["COMBO", {"multiselect": false, "options": [5, 10]}], "ratio": ["COMBO", {"multiselect": false, "options": ["768:1280", "1280:768"]}], "seed": ["INT", {"tooltip": "Random seed for generation", "default": 0, "min": 0, "max": 4294967295, "step": 1, "control_after_generate": true, "display": "number"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "start_frame", "duration", "ratio", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "RunwayImageToVideoNodeGen3a", "display_name": "Runway Image to Video (Gen3a Turbo)", "description": "Generate a video from a single starting frame using Gen3a Turbo model. Before diving in, review these best practices to ensure that your input selections will set your generation up for success: https://help.runwayml.com/hc/en-us/articles/33927968552339-Creating-with-Act-One-on-Gen-3-Alpha-and-Turbo.", "python_module": "comfy_api_nodes.nodes_runway", "category": "api node/video/Runway", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RunwayImageToVideoNodeGen4": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text prompt for the generation", "default": "", "multiline": true}], "start_frame": ["IMAGE", {"tooltip": "Start frame to be used for the video"}], "duration": ["COMBO", {"multiselect": false, "options": [5, 10]}], "ratio": ["COMBO", {"multiselect": false, "options": ["1280:720", "720:1280", "1104:832", "832:1104", "960:960", "1584:672"]}], "seed": ["INT", {"tooltip": "Random seed for generation", "default": 0, "min": 0, "max": 4294967295, "step": 1, "control_after_generate": true, "display": "number"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "start_frame", "duration", "ratio", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "RunwayImageToVideoNodeGen4", "display_name": "Runway Image to Video (Gen4 Turbo)", "description": "Generate a video from a single starting frame using Gen4 Turbo model. Before diving in, review these best practices to ensure that your input selections will set your generation up for success: https://help.runwayml.com/hc/en-us/articles/37327109429011-Creating-with-Gen-4-Video.", "python_module": "comfy_api_nodes.nodes_runway", "category": "api node/video/Runway", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RunwayTextToImageNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text prompt for the generation", "default": "", "multiline": true}], "ratio": ["COMBO", {"multiselect": false, "options": ["1920:1080", "1080:1920", "1024:1024", "1360:768", "1080:1080", "1168:880", "1440:1080", "1080:1440", "1808:768", "2112:912"]}]}, "optional": {"reference_image": ["IMAGE", {"tooltip": "Optional reference image to guide the generation"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "ratio"], "optional": ["reference_image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "RunwayTextToImageNode", "display_name": "Runway Text to Image", "description": "Generate an image from a text prompt using Runway's Gen 4 model. You can also include reference image to guide the generation.", "python_module": "comfy_api_nodes.nodes_runway", "category": "api node/image/Runway", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "OpenAIVideoSora2": {"input": {"required": {"model": ["COMBO", {"default": "sora-2", "multiselect": false, "options": ["sora-2", "sora-2-pro"]}], "prompt": ["STRING", {"tooltip": "Guiding text; may be empty if an input image is present.", "default": "", "multiline": true}], "size": ["COMBO", {"default": "1280x720", "multiselect": false, "options": ["720x1280", "1280x720", "1024x1792", "1792x1024"]}], "duration": ["COMBO", {"default": 8, "multiselect": false, "options": [4, 8, 12]}]}, "optional": {"image": ["IMAGE", {}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "size", "duration"], "optional": ["image", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "OpenAIVideoSora2", "display_name": "OpenAI Sora - Video", "description": "OpenAI video and audio generation.", "python_module": "comfy_api_nodes.nodes_sora", "category": "api node/video/Sora", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "TripoTextToModelNode": {"input": {"required": {"prompt": ["STRING", {"multiline": true}]}, "optional": {"negative_prompt": ["STRING", {"multiline": true}], "model_version": ["COMBO", {"default": "v2.5-20250123", "multiselect": false, "options": ["v2.5-20250123", "v2.0-20240919", "v1.4-20240625"]}], "style": ["COMBO", {"default": "None", "multiselect": false, "options": ["person:person2cartoon", "animal:venom", "object:clay", "object:steampunk", "object:christmas", "object:barbie", "gold", "ancient_bronze", "None"]}], "texture": ["BOOLEAN", {"default": true}], "pbr": ["BOOLEAN", {"default": true}], "image_seed": ["INT", {"default": 42}], "model_seed": ["INT", {"default": 42}], "texture_seed": ["INT", {"default": 42}], "texture_quality": ["COMBO", {"default": "standard", "multiselect": false, "options": ["standard", "detailed"]}], "face_limit": ["INT", {"default": -1, "min": -1, "max": 500000}], "quad": ["BOOLEAN", {"default": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"], "prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["prompt"], "optional": ["negative_prompt", "model_version", "style", "texture", "pbr", "image_seed", "model_seed", "texture_seed", "texture_quality", "face_limit", "quad"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id", "prompt", "extra_pnginfo"]}, "output": ["STRING", "MODEL_TASK_ID"], "output_is_list": [false, false], "output_name": ["model_file", "model task_id"], "output_tooltips": [null, null], "name": "TripoTextToModelNode", "display_name": "Tripo: Text to Model", "description": "", "python_module": "comfy_api_nodes.nodes_tripo", "category": "api node/3d/Tripo", "output_node": true, "deprecated": false, "experimental": false, "api_node": true}, "TripoImageToModelNode": {"input": {"required": {"image": ["IMAGE", {}]}, "optional": {"model_version": ["COMBO", {"tooltip": "The model version to use for generation", "multiselect": false, "options": ["v2.5-20250123", "v2.0-20240919", "v1.4-20240625"]}], "style": ["COMBO", {"default": "None", "multiselect": false, "options": ["person:person2cartoon", "animal:venom", "object:clay", "object:steampunk", "object:christmas", "object:barbie", "gold", "ancient_bronze", "None"]}], "texture": ["BOOLEAN", {"default": true}], "pbr": ["BOOLEAN", {"default": true}], "model_seed": ["INT", {"default": 42}], "orientation": ["COMBO", {"default": "default", "multiselect": false, "options": ["align_image", "default"]}], "texture_seed": ["INT", {"default": 42}], "texture_quality": ["COMBO", {"default": "standard", "multiselect": false, "options": ["standard", "detailed"]}], "texture_alignment": ["COMBO", {"default": "original_image", "multiselect": false, "options": ["original_image", "geometry"]}], "face_limit": ["INT", {"default": -1, "min": -1, "max": 500000}], "quad": ["BOOLEAN", {"default": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"], "prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["image"], "optional": ["model_version", "style", "texture", "pbr", "model_seed", "orientation", "texture_seed", "texture_quality", "texture_alignment", "face_limit", "quad"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id", "prompt", "extra_pnginfo"]}, "output": ["STRING", "MODEL_TASK_ID"], "output_is_list": [false, false], "output_name": ["model_file", "model task_id"], "output_tooltips": [null, null], "name": "TripoImageToModelNode", "display_name": "Tripo: Image to Model", "description": "", "python_module": "comfy_api_nodes.nodes_tripo", "category": "api node/3d/Tripo", "output_node": true, "deprecated": false, "experimental": false, "api_node": true}, "TripoMultiviewToModelNode": {"input": {"required": {"image": ["IMAGE", {}]}, "optional": {"image_left": ["IMAGE", {}], "image_back": ["IMAGE", {}], "image_right": ["IMAGE", {}], "model_version": ["COMBO", {"tooltip": "The model version to use for generation", "multiselect": false, "options": ["v2.5-20250123", "v2.0-20240919", "v1.4-20240625"]}], "orientation": ["COMBO", {"default": "default", "multiselect": false, "options": ["align_image", "default"]}], "texture": ["BOOLEAN", {"default": true}], "pbr": ["BOOLEAN", {"default": true}], "model_seed": ["INT", {"default": 42}], "texture_seed": ["INT", {"default": 42}], "texture_quality": ["COMBO", {"default": "standard", "multiselect": false, "options": ["standard", "detailed"]}], "texture_alignment": ["COMBO", {"default": "original_image", "multiselect": false, "options": ["original_image", "geometry"]}], "face_limit": ["INT", {"default": -1, "min": -1, "max": 500000}], "quad": ["BOOLEAN", {"default": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"], "prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["image"], "optional": ["image_left", "image_back", "image_right", "model_version", "orientation", "texture", "pbr", "model_seed", "texture_seed", "texture_quality", "texture_alignment", "face_limit", "quad"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id", "prompt", "extra_pnginfo"]}, "output": ["STRING", "MODEL_TASK_ID"], "output_is_list": [false, false], "output_name": ["model_file", "model task_id"], "output_tooltips": [null, null], "name": "TripoMultiviewToModelNode", "display_name": "Tripo: Multiview to Model", "description": "", "python_module": "comfy_api_nodes.nodes_tripo", "category": "api node/3d/Tripo", "output_node": true, "deprecated": false, "experimental": false, "api_node": true}, "TripoTextureNode": {"input": {"required": {"model_task_id": ["MODEL_TASK_ID", {}]}, "optional": {"texture": ["BOOLEAN", {"default": true}], "pbr": ["BOOLEAN", {"default": true}], "texture_seed": ["INT", {"default": 42}], "texture_quality": ["COMBO", {"default": "standard", "multiselect": false, "options": ["standard", "detailed"]}], "texture_alignment": ["COMBO", {"default": "original_image", "multiselect": false, "options": ["original_image", "geometry"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"], "prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["model_task_id"], "optional": ["texture", "pbr", "texture_seed", "texture_quality", "texture_alignment"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id", "prompt", "extra_pnginfo"]}, "output": ["STRING", "MODEL_TASK_ID"], "output_is_list": [false, false], "output_name": ["model_file", "model task_id"], "output_tooltips": [null, null], "name": "TripoTextureNode", "display_name": "Tripo: Texture model", "description": "", "python_module": "comfy_api_nodes.nodes_tripo", "category": "api node/3d/Tripo", "output_node": true, "deprecated": false, "experimental": false, "api_node": true}, "TripoRefineNode": {"input": {"required": {"model_task_id": ["MODEL_TASK_ID", {"tooltip": "Must be a v1.4 Tripo model"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"], "prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["model_task_id"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id", "prompt", "extra_pnginfo"]}, "output": ["STRING", "MODEL_TASK_ID"], "output_is_list": [false, false], "output_name": ["model_file", "model task_id"], "output_tooltips": [null, null], "name": "TripoRefineNode", "display_name": "Tripo: Refine Draft model", "description": "Refine a draft model created by v1.4 Tripo models only.", "python_module": "comfy_api_nodes.nodes_tripo", "category": "api node/3d/Tripo", "output_node": true, "deprecated": false, "experimental": false, "api_node": true}, "TripoRigNode": {"input": {"required": {"original_model_task_id": ["MODEL_TASK_ID", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"], "prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["original_model_task_id"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id", "prompt", "extra_pnginfo"]}, "output": ["STRING", "RIG_TASK_ID"], "output_is_list": [false, false], "output_name": ["model_file", "rig task_id"], "output_tooltips": [null, null], "name": "TripoRigNode", "display_name": "Tripo: Rig model", "description": "", "python_module": "comfy_api_nodes.nodes_tripo", "category": "api node/3d/Tripo", "output_node": true, "deprecated": false, "experimental": false, "api_node": true}, "TripoRetargetNode": {"input": {"required": {"original_model_task_id": ["RIG_TASK_ID", {}], "animation": ["COMBO", {"multiselect": false, "options": ["preset:idle", "preset:walk", "preset:climb", "preset:jump", "preset:slash", "preset:shoot", "preset:hurt", "preset:fall", "preset:turn"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"], "prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["original_model_task_id", "animation"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id", "prompt", "extra_pnginfo"]}, "output": ["STRING", "RETARGET_TASK_ID"], "output_is_list": [false, false], "output_name": ["model_file", "retarget task_id"], "output_tooltips": [null, null], "name": "TripoRetargetNode", "display_name": "Tripo: Retarget rigged model", "description": "", "python_module": "comfy_api_nodes.nodes_tripo", "category": "api node/3d/Tripo", "output_node": true, "deprecated": false, "experimental": false, "api_node": true}, "TripoConversionNode": {"input": {"required": {"original_model_task_id": ["MODEL_TASK_ID,RIG_TASK_ID,RETARGET_TASK_ID", {}], "format": ["COMBO", {"multiselect": false, "options": ["GLTF", "USDZ", "FBX", "OBJ", "STL", "3MF"]}]}, "optional": {"quad": ["BOOLEAN", {"default": false}], "face_limit": ["INT", {"default": -1, "min": -1, "max": 500000}], "texture_size": ["INT", {"default": 4096, "min": 128, "max": 4096}], "texture_format": ["COMBO", {"default": "JPEG", "multiselect": false, "options": ["BMP", "DPX", "HDR", "JPEG", "OPEN_EXR", "PNG", "TARGA", "TIFF", "WEBP"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"], "prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["original_model_task_id", "format"], "optional": ["quad", "face_limit", "texture_size", "texture_format"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id", "prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "output_tooltips": [], "name": "TripoConversionNode", "display_name": "Tripo: Convert model", "description": "", "python_module": "comfy_api_nodes.nodes_tripo", "category": "api node/3d/Tripo", "output_node": true, "deprecated": false, "experimental": false, "api_node": true}, "MoonvalleyImg2VideoNode": {"input": {"required": {"image": ["IMAGE", {"tooltip": "The reference image used to generate the video"}], "prompt": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative prompt text", "default": "<synthetic> <scene cut> gopro, bright, contrast, static, overexposed, vignette, artifacts, still, noise, texture, scanlines, videogame, 360 camera, VR, transition, flare, saturation, distorted, warped, wide angle, saturated, vibrant, glowing, cross dissolve, cheesy, ugly hands, mutated hands, mutant, disfigured, extra fingers, blown out, horrible, blurry, worst quality, bad, dissolve, melt, fade in, fade out, wobbly, weird, low quality, plastic, stock footage, video camera, boring", "multiline": true}], "resolution": ["COMBO", {"tooltip": "Resolution of the output video", "default": "16:9 (1920 x 1080)", "multiselect": false, "options": ["16:9 (1920 x 1080)", "9:16 (1080 x 1920)", "1:1 (1152 x 1152)", "4:3 (1536 x 1152)", "3:4 (1152 x 1536)"]}], "prompt_adherence": ["FLOAT", {"tooltip": "Guidance scale for generation control", "default": 4.5, "min": 1.0, "max": 20.0, "step": 1.0}], "seed": ["INT", {"tooltip": "Random seed value", "default": 9, "min": 0, "max": 4294967295, "step": 1, "control_after_generate": true, "display": "number"}], "steps": ["INT", {"tooltip": "Number of denoising steps", "default": 33, "min": 1, "max": 100, "step": 1}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt", "negative_prompt", "resolution", "prompt_adherence", "seed", "steps"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "MoonvalleyImg2VideoNode", "display_name": "Moonvalley Marey Image to Video", "description": "Moonvalley Marey Image to Video Node", "python_module": "comfy_api_nodes.nodes_moonvalley", "category": "api node/video/Moonvalley Marey", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "MoonvalleyTxt2VideoNode": {"input": {"required": {"prompt": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative prompt text", "default": "<synthetic> <scene cut> gopro, bright, contrast, static, overexposed, vignette, artifacts, still, noise, texture, scanlines, videogame, 360 camera, VR, transition, flare, saturation, distorted, warped, wide angle, saturated, vibrant, glowing, cross dissolve, cheesy, ugly hands, mutated hands, mutant, disfigured, extra fingers, blown out, horrible, blurry, worst quality, bad, dissolve, melt, fade in, fade out, wobbly, weird, low quality, plastic, stock footage, video camera, boring", "multiline": true}], "resolution": ["COMBO", {"tooltip": "Resolution of the output video", "default": "16:9 (1920 x 1080)", "multiselect": false, "options": ["16:9 (1920 x 1080)", "9:16 (1080 x 1920)", "1:1 (1152 x 1152)", "4:3 (1536 x 1152)", "3:4 (1152 x 1536)", "21:9 (2560 x 1080)"]}], "prompt_adherence": ["FLOAT", {"tooltip": "Guidance scale for generation control", "default": 4.0, "min": 1.0, "max": 20.0, "step": 1.0}], "seed": ["INT", {"tooltip": "Random seed value", "default": 9, "min": 0, "max": 4294967295, "step": 1, "control_after_generate": true, "display": "number"}], "steps": ["INT", {"tooltip": "Inference steps", "default": 33, "min": 1, "max": 100, "step": 1}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "negative_prompt", "resolution", "prompt_adherence", "seed", "steps"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "MoonvalleyTxt2VideoNode", "display_name": "Moonvalley Marey Text to Video", "description": "", "python_module": "comfy_api_nodes.nodes_moonvalley", "category": "api node/video/Moonvalley Marey", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "MoonvalleyVideo2VideoNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Describes the video to generate", "multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative prompt text", "default": "<synthetic> <scene cut> gopro, bright, contrast, static, overexposed, vignette, artifacts, still, noise, texture, scanlines, videogame, 360 camera, VR, transition, flare, saturation, distorted, warped, wide angle, saturated, vibrant, glowing, cross dissolve, cheesy, ugly hands, mutated hands, mutant, disfigured, extra fingers, blown out, horrible, blurry, worst quality, bad, dissolve, melt, fade in, fade out, wobbly, weird, low quality, plastic, stock footage, video camera, boring", "multiline": true}], "seed": ["INT", {"tooltip": "Random seed value", "default": 9, "min": 0, "max": 4294967295, "step": 1, "control_after_generate": false, "display": "number"}], "video": ["VIDEO", {"tooltip": "The reference video used to generate the output video. Must be at least 5 seconds long. Videos longer than 5s will be automatically trimmed. Only MP4 format supported."}], "steps": ["INT", {"tooltip": "Number of inference steps", "default": 33, "min": 1, "max": 100, "step": 1, "display": "number"}]}, "optional": {"control_type": ["COMBO", {"default": "Motion Transfer", "multiselect": false, "options": ["Motion Transfer", "Pose Transfer"]}], "motion_intensity": ["INT", {"tooltip": "Only used if control_type is 'Motion Transfer'", "default": 100, "min": 0, "max": 100, "step": 1}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "negative_prompt", "seed", "video", "steps"], "optional": ["control_type", "motion_intensity"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "MoonvalleyVideo2VideoNode", "display_name": "Moonvalley Marey Video to Video", "description": "", "python_module": "comfy_api_nodes.nodes_moonvalley", "category": "api node/video/Moonvalley Marey", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Rodin3D_Regular": {"input": {"required": {"Images": ["IMAGE", {}]}, "optional": {"Seed": ["INT", {"default": 0, "min": 0, "max": 65535, "display": "number"}], "Material_Type": ["COMBO", {"default": "PBR", "multiselect": false, "options": ["PBR", "Shaded"]}], "Polygon_count": ["COMBO", {"default": "18K-Quad", "multiselect": false, "options": ["4K-Quad", "8K-Quad", "18K-Quad", "50K-Quad", "200K-Triangle"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"]}}, "input_order": {"required": ["Images"], "optional": ["Seed", "Material_Type", "Polygon_count"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["3D Model Path"], "output_tooltips": [null], "name": "Rodin3D_Regular", "display_name": "Rodin 3D Generate - Regular Generate", "description": "Generate 3D Assets using Rodin API", "python_module": "comfy_api_nodes.nodes_rodin", "category": "api node/3d/Rodin", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Rodin3D_Detail": {"input": {"required": {"Images": ["IMAGE", {}]}, "optional": {"Seed": ["INT", {"default": 0, "min": 0, "max": 65535, "display": "number"}], "Material_Type": ["COMBO", {"default": "PBR", "multiselect": false, "options": ["PBR", "Shaded"]}], "Polygon_count": ["COMBO", {"default": "18K-Quad", "multiselect": false, "options": ["4K-Quad", "8K-Quad", "18K-Quad", "50K-Quad", "200K-Triangle"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"]}}, "input_order": {"required": ["Images"], "optional": ["Seed", "Material_Type", "Polygon_count"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["3D Model Path"], "output_tooltips": [null], "name": "Rodin3D_Detail", "display_name": "Rodin 3D Generate - Detail Generate", "description": "Generate 3D Assets using Rodin API", "python_module": "comfy_api_nodes.nodes_rodin", "category": "api node/3d/Rodin", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Rodin3D_Smooth": {"input": {"required": {"Images": ["IMAGE", {}]}, "optional": {"Seed": ["INT", {"default": 0, "min": 0, "max": 65535, "display": "number"}], "Material_Type": ["COMBO", {"default": "PBR", "multiselect": false, "options": ["PBR", "Shaded"]}], "Polygon_count": ["COMBO", {"default": "18K-Quad", "multiselect": false, "options": ["4K-Quad", "8K-Quad", "18K-Quad", "50K-Quad", "200K-Triangle"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"]}}, "input_order": {"required": ["Images"], "optional": ["Seed", "Material_Type", "Polygon_count"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["3D Model Path"], "output_tooltips": [null], "name": "Rodin3D_Smooth", "display_name": "Rodin 3D Generate - Smooth Generate", "description": "Generate 3D Assets using Rodin API", "python_module": "comfy_api_nodes.nodes_rodin", "category": "api node/3d/Rodin", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Rodin3D_Sketch": {"input": {"required": {"Images": ["IMAGE", {}]}, "optional": {"Seed": ["INT", {"default": 0, "min": 0, "max": 65535, "display": "number"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"]}}, "input_order": {"required": ["Images"], "optional": ["Seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["3D Model Path"], "output_tooltips": [null], "name": "Rodin3D_Sketch", "display_name": "Rodin 3D Generate - Sketch Generate", "description": "Generate 3D Assets using Rodin API", "python_module": "comfy_api_nodes.nodes_rodin", "category": "api node/3d/Rodin", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Rodin3D_Gen2": {"input": {"required": {"Images": ["IMAGE", {}], "TAPose": ["BOOLEAN", {"default": false}]}, "optional": {"Seed": ["INT", {"default": 0, "min": 0, "max": 65535, "display": "number"}], "Material_Type": ["COMBO", {"default": "PBR", "multiselect": false, "options": ["PBR", "Shaded"]}], "Polygon_count": ["COMBO", {"default": "500K-Triangle", "multiselect": false, "options": ["4K-Quad", "8K-Quad", "18K-Quad", "50K-Quad", "2K-Triangle", "20K-Triangle", "150K-Triangle", "500K-Triangle"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"]}}, "input_order": {"required": ["Images", "TAPose"], "optional": ["Seed", "Material_Type", "Polygon_count"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["3D Model Path"], "output_tooltips": [null], "name": "Rodin3D_Gen2", "display_name": "Rodin 3D Generate - Gen-2 Generate", "description": "Generate 3D Assets using Rodin API", "python_module": "comfy_api_nodes.nodes_rodin", "category": "api node/3d/Rodin", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "GeminiNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text inputs to the model, used to generate a response. You can include detailed instructions, questions, or context for the model.", "default": "", "multiline": true}], "model": ["COMBO", {"tooltip": "The Gemini model to use for generating responses.", "default": "gemini-2.5-pro", "multiselect": false, "options": ["gemini-2.5-pro-preview-05-06", "gemini-2.5-flash-preview-04-17", "gemini-2.5-pro", "gemini-2.5-flash"]}], "seed": ["INT", {"tooltip": "When seed is fixed to a specific value, the model makes a best effort to provide the same response for repeated requests. Deterministic output isn't guaranteed. Also, changing the model or parameter settings, such as the temperature, can cause variations in the response even when you use the same seed value. By default, a random seed value is used.", "default": 42, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"images": ["IMAGE", {"tooltip": "Optional image(s) to use as context for the model. To include multiple images, you can use the Batch Images node."}], "audio": ["AUDIO", {"tooltip": "Optional audio to use as context for the model."}], "video": ["VIDEO", {"tooltip": "Optional video to use as context for the model."}], "files": ["GEMINI_INPUT_FILES", {"tooltip": "Optional file(s) to use as context for the model. Accepts inputs from the Gemini Generate Content Input Files node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "model", "seed"], "optional": ["images", "audio", "video", "files"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "GeminiNode", "display_name": "Google Gemini", "description": "Generate text responses with Google's Gemini AI model. You can provide multiple types of inputs (text, images, audio, video) as context for generating more relevant and meaningful responses.", "python_module": "comfy_api_nodes.nodes_gemini", "category": "api node/text/Gemini", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "GeminiImageNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text prompt for generation", "default": "", "multiline": true}], "model": ["COMBO", {"tooltip": "The Gemini model to use for generating responses.", "default": "gemini-2.5-flash-image", "multiselect": false, "options": ["gemini-2.5-flash-image-preview", "gemini-2.5-flash-image"]}], "seed": ["INT", {"tooltip": "When seed is fixed to a specific value, the model makes a best effort to provide the same response for repeated requests. Deterministic output isn't guaranteed. Also, changing the model or parameter settings, such as the temperature, can cause variations in the response even when you use the same seed value. By default, a random seed value is used.", "default": 42, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"images": ["IMAGE", {"tooltip": "Optional image(s) to use as context for the model. To include multiple images, you can use the Batch Images node."}], "files": ["GEMINI_INPUT_FILES", {"tooltip": "Optional file(s) to use as context for the model. Accepts inputs from the Gemini Generate Content Input Files node."}], "aspect_ratio": ["COMBO", {"tooltip": "Defaults to matching the output image size to that of your input image, or otherwise generates 1:1 squares.", "default": "auto", "multiselect": false, "options": ["auto", "1:1", "2:3", "3:2", "3:4", "4:3", "4:5", "5:4", "9:16", "16:9", "21:9"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "model", "seed"], "optional": ["images", "files", "aspect_ratio"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE", "STRING"], "output_is_list": [false, false], "output_name": ["IMAGE", "STRING"], "output_tooltips": [null, null], "name": "GeminiImageNode", "display_name": "Google Gemini Image", "description": "Edit images synchronously via Google API.", "python_module": "comfy_api_nodes.nodes_gemini", "category": "api node/image/Gemini", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "GeminiInputFiles": {"input": {"required": {"file": ["COMBO", {"tooltip": "Input files to include as context for the model. Only accepts text (.txt) and PDF (.pdf) files for now.", "multiselect": false, "options": []}]}, "optional": {"GEMINI_INPUT_FILES": ["GEMINI_INPUT_FILES", {"tooltip": "An optional additional file(s) to batch together with the file loaded from this node. Allows chaining of input files so that a single message can include multiple input files."}]}}, "input_order": {"required": ["file"], "optional": ["GEMINI_INPUT_FILES"]}, "output": ["GEMINI_INPUT_FILES"], "output_is_list": [false], "output_name": ["GEMINI_INPUT_FILES"], "output_tooltips": [null], "name": "GeminiInputFiles", "display_name": "Gemini Input Files", "description": "Loads and prepares input files to include as inputs for Gemini LLM nodes. The files will be read by the Gemini model when generating a response. The contents of the text file count toward the token limit. \ud83d\udec8 TIP: Can be chained together with other Gemini Input File nodes.", "python_module": "comfy_api_nodes.nodes_gemini", "category": "api node/text/Gemini", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ViduTextToVideoNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "viduq1", "multiselect": false, "options": ["viduq1"]}], "prompt": ["STRING", {"tooltip": "A textual description for video generation", "multiline": true}]}, "optional": {"duration": ["INT", {"tooltip": "Duration of the output video in seconds", "default": 5, "min": 5, "max": 5, "step": 1, "display": "number"}], "seed": ["INT", {"tooltip": "Seed for video generation (0 for random)", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio of the output video", "default": "16:9", "multiselect": false, "options": ["16:9", "9:16", "1:1"]}], "resolution": ["COMBO", {"tooltip": "Supported values may vary by model & duration", "default": "1080p", "multiselect": false, "options": ["1080p"]}], "movement_amplitude": ["COMBO", {"tooltip": "The movement amplitude of objects in the frame", "default": "auto", "multiselect": false, "options": ["auto", "small", "medium", "large"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt"], "optional": ["duration", "seed", "aspect_ratio", "resolution", "movement_amplitude"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "ViduTextToVideoNode", "display_name": "Vidu Text To Video Generation", "description": "Generate video from text prompt", "python_module": "comfy_api_nodes.nodes_vidu", "category": "api node/video/Vidu", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ViduImageToVideoNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "viduq1", "multiselect": false, "options": ["viduq1"]}], "image": ["IMAGE", {"tooltip": "An image to be used as the start frame of the generated video"}]}, "optional": {"prompt": ["STRING", {"tooltip": "A textual description for video generation", "default": "", "multiline": true}], "duration": ["INT", {"tooltip": "Duration of the output video in seconds", "default": 5, "min": 5, "max": 5, "step": 1, "display": "number"}], "seed": ["INT", {"tooltip": "Seed for video generation (0 for random)", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "resolution": ["COMBO", {"tooltip": "Supported values may vary by model & duration", "default": "1080p", "multiselect": false, "options": ["1080p"]}], "movement_amplitude": ["COMBO", {"tooltip": "The movement amplitude of objects in the frame", "default": "auto", "multiselect": false, "options": ["auto", "small", "medium", "large"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "image"], "optional": ["prompt", "duration", "seed", "resolution", "movement_amplitude"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "ViduImageToVideoNode", "display_name": "Vidu Image To Video Generation", "description": "Generate video from image and optional prompt", "python_module": "comfy_api_nodes.nodes_vidu", "category": "api node/video/Vidu", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ViduReferenceVideoNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "viduq1", "multiselect": false, "options": ["viduq1"]}], "images": ["IMAGE", {"tooltip": "Images to use as references to generate a video with consistent subjects (max 7 images)."}], "prompt": ["STRING", {"tooltip": "A textual description for video generation", "multiline": true}]}, "optional": {"duration": ["INT", {"tooltip": "Duration of the output video in seconds", "default": 5, "min": 5, "max": 5, "step": 1, "display": "number"}], "seed": ["INT", {"tooltip": "Seed for video generation (0 for random)", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio of the output video", "default": "16:9", "multiselect": false, "options": ["16:9", "9:16", "1:1"]}], "resolution": ["COMBO", {"tooltip": "Supported values may vary by model & duration", "default": "1080p", "multiselect": false, "options": ["1080p"]}], "movement_amplitude": ["COMBO", {"tooltip": "The movement amplitude of objects in the frame", "default": "auto", "multiselect": false, "options": ["auto", "small", "medium", "large"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "images", "prompt"], "optional": ["duration", "seed", "aspect_ratio", "resolution", "movement_amplitude"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "ViduReferenceVideoNode", "display_name": "Vidu Reference To Video Generation", "description": "Generate video from multiple images and prompt", "python_module": "comfy_api_nodes.nodes_vidu", "category": "api node/video/Vidu", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ViduStartEndToVideoNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "viduq1", "multiselect": false, "options": ["viduq1"]}], "first_frame": ["IMAGE", {"tooltip": "Start frame"}], "end_frame": ["IMAGE", {"tooltip": "End frame"}]}, "optional": {"prompt": ["STRING", {"tooltip": "A textual description for video generation", "multiline": true}], "duration": ["INT", {"tooltip": "Duration of the output video in seconds", "default": 5, "min": 5, "max": 5, "step": 1, "display": "number"}], "seed": ["INT", {"tooltip": "Seed for video generation (0 for random)", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "resolution": ["COMBO", {"tooltip": "Supported values may vary by model & duration", "default": "1080p", "multiselect": false, "options": ["1080p"]}], "movement_amplitude": ["COMBO", {"tooltip": "The movement amplitude of objects in the frame", "default": "auto", "multiselect": false, "options": ["auto", "small", "medium", "large"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "first_frame", "end_frame"], "optional": ["prompt", "duration", "seed", "resolution", "movement_amplitude"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "ViduStartEndToVideoNode", "display_name": "Vidu Start End To Video Generation", "description": "Generate a video from start and end frames and a prompt", "python_module": "comfy_api_nodes.nodes_vidu", "category": "api node/video/Vidu", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "WanTextToImageApi": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model to use.", "default": "wan2.5-t2i-preview", "multiselect": false, "options": ["wan2.5-t2i-preview"]}], "prompt": ["STRING", {"tooltip": "Prompt used to describe the elements and visual features, supports English/Chinese.", "default": "", "multiline": true}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "Negative text prompt to guide what to avoid.", "default": "", "multiline": true}], "width": ["INT", {"default": 1024, "min": 768, "max": 1440, "step": 32}], "height": ["INT", {"default": 1024, "min": 768, "max": 1440, "step": 32}], "seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "prompt_extend": ["BOOLEAN", {"tooltip": "Whether to enhance the prompt with AI assistance.", "default": true}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the result.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt"], "optional": ["negative_prompt", "width", "height", "seed", "prompt_extend", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "WanTextToImageApi", "display_name": "Wan Text to Image", "description": "Generates image based on text prompt.", "python_module": "comfy_api_nodes.nodes_wan", "category": "api node/image/Wan", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "WanImageToImageApi": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model to use.", "default": "wan2.5-i2i-preview", "multiselect": false, "options": ["wan2.5-i2i-preview"]}], "image": ["IMAGE", {"tooltip": "Single-image editing or multi-image fusion, maximum 2 images."}], "prompt": ["STRING", {"tooltip": "Prompt used to describe the elements and visual features, supports English/Chinese.", "default": "", "multiline": true}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "Negative text prompt to guide what to avoid.", "default": "", "multiline": true}], "seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the result.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "image", "prompt"], "optional": ["negative_prompt", "seed", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "WanImageToImageApi", "display_name": "Wan Image to Image", "description": "Generates an image from one or two input images and a text prompt. The output image is currently fixed at 1.6 MP; its aspect ratio matches the input image(s).", "python_module": "comfy_api_nodes.nodes_wan", "category": "api node/image/Wan", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "WanTextToVideoApi": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model to use.", "default": "wan2.5-t2v-preview", "multiselect": false, "options": ["wan2.5-t2v-preview"]}], "prompt": ["STRING", {"tooltip": "Prompt used to describe the elements and visual features, supports English/Chinese.", "default": "", "multiline": true}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "Negative text prompt to guide what to avoid.", "default": "", "multiline": true}], "size": ["COMBO", {"default": "480p: 1:1 (624x624)", "multiselect": false, "options": ["480p: 1:1 (624x624)", "480p: 16:9 (832x480)", "480p: 9:16 (480x832)", "720p: 1:1 (960x960)", "720p: 16:9 (1280x720)", "720p: 9:16 (720x1280)", "720p: 4:3 (1088x832)", "720p: 3:4 (832x1088)", "1080p: 1:1 (1440x1440)", "1080p: 16:9 (1920x1080)", "1080p: 9:16 (1080x1920)", "1080p: 4:3 (1632x1248)", "1080p: 3:4 (1248x1632)"]}], "duration": ["INT", {"tooltip": "Available durations: 5 and 10 seconds", "default": 5, "min": 5, "max": 10, "step": 5, "display": "number"}], "audio": ["AUDIO", {"tooltip": "Audio must contain a clear, loud voice, without extraneous noise, background music."}], "seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "generate_audio": ["BOOLEAN", {"tooltip": "If there is no audio input, generate audio automatically.", "default": false}], "prompt_extend": ["BOOLEAN", {"tooltip": "Whether to enhance the prompt with AI assistance.", "default": true}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the result.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt"], "optional": ["negative_prompt", "size", "duration", "audio", "seed", "generate_audio", "prompt_extend", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "WanTextToVideoApi", "display_name": "Wan Text to Video", "description": "Generates video based on text prompt.", "python_module": "comfy_api_nodes.nodes_wan", "category": "api node/video/Wan", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "WanImageToVideoApi": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model to use.", "default": "wan2.5-i2v-preview", "multiselect": false, "options": ["wan2.5-i2v-preview"]}], "image": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "Prompt used to describe the elements and visual features, supports English/Chinese.", "default": "", "multiline": true}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "Negative text prompt to guide what to avoid.", "default": "", "multiline": true}], "resolution": ["COMBO", {"default": "480P", "multiselect": false, "options": ["480P", "720P", "1080P"]}], "duration": ["INT", {"tooltip": "Available durations: 5 and 10 seconds", "default": 5, "min": 5, "max": 10, "step": 5, "display": "number"}], "audio": ["AUDIO", {"tooltip": "Audio must contain a clear, loud voice, without extraneous noise, background music."}], "seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "generate_audio": ["BOOLEAN", {"tooltip": "If there is no audio input, generate audio automatically.", "default": false}], "prompt_extend": ["BOOLEAN", {"tooltip": "Whether to enhance the prompt with AI assistance.", "default": true}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the result.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "image", "prompt"], "optional": ["negative_prompt", "resolution", "duration", "audio", "seed", "generate_audio", "prompt_extend", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "WanImageToVideoApi", "display_name": "Wan Image to Video", "description": "Generates video based on the first frame and text prompt.", "python_module": "comfy_api_nodes.nodes_wan", "category": "api node/video/Wan", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "UltimateSDUpscale": {"input": {"required": {"image": ["IMAGE"], "model": ["MODEL"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "upscale_by": ["FLOAT", {"default": 2, "min": 0.05, "max": 4, "step": 0.05}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "step": 1}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"]], "denoise": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0, "step": 0.01}], "upscale_model": ["UPSCALE_MODEL"], "mode_type": [["Linear", "Chess", "None"]], "tile_width": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "tile_height": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "mask_blur": ["INT", {"default": 8, "min": 0, "max": 64, "step": 1}], "tile_padding": ["INT", {"default": 32, "min": 0, "max": 8192, "step": 8}], "seam_fix_mode": [["None", "Band Pass", "Half Tile", "Half Tile + Intersections"]], "seam_fix_denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "seam_fix_width": ["INT", {"default": 64, "min": 0, "max": 8192, "step": 8}], "seam_fix_mask_blur": ["INT", {"default": 8, "min": 0, "max": 64, "step": 1}], "seam_fix_padding": ["INT", {"default": 16, "min": 0, "max": 8192, "step": 8}], "force_uniform_tiles": ["BOOLEAN", {"default": true}], "tiled_decode": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["image", "model", "positive", "negative", "vae", "upscale_by", "seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "upscale_model", "mode_type", "tile_width", "tile_height", "mask_blur", "tile_padding", "seam_fix_mode", "seam_fix_denoise", "seam_fix_width", "seam_fix_mask_blur", "seam_fix_padding", "force_uniform_tiles", "tiled_decode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "UltimateSDUpscale", "display_name": "Ultimate SD Upscale", "description": "", "python_module": "custom_nodes.ComfyUI_UltimateSDUpscale", "category": "image/upscaling", "output_node": false}, "UltimateSDUpscaleNoUpscale": {"input": {"required": {"upscaled_image": ["IMAGE"], "model": ["MODEL"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "step": 1}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"]], "denoise": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0, "step": 0.01}], "mode_type": [["Linear", "Chess", "None"]], "tile_width": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "tile_height": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "mask_blur": ["INT", {"default": 8, "min": 0, "max": 64, "step": 1}], "tile_padding": ["INT", {"default": 32, "min": 0, "max": 8192, "step": 8}], "seam_fix_mode": [["None", "Band Pass", "Half Tile", "Half Tile + Intersections"]], "seam_fix_denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "seam_fix_width": ["INT", {"default": 64, "min": 0, "max": 8192, "step": 8}], "seam_fix_mask_blur": ["INT", {"default": 8, "min": 0, "max": 64, "step": 1}], "seam_fix_padding": ["INT", {"default": 16, "min": 0, "max": 8192, "step": 8}], "force_uniform_tiles": ["BOOLEAN", {"default": true}], "tiled_decode": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["upscaled_image", "model", "positive", "negative", "vae", "seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "mode_type", "tile_width", "tile_height", "mask_blur", "tile_padding", "seam_fix_mode", "seam_fix_denoise", "seam_fix_width", "seam_fix_mask_blur", "seam_fix_padding", "force_uniform_tiles", "tiled_decode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "UltimateSDUpscaleNoUpscale", "display_name": "Ultimate SD Upscale (No Upscale)", "description": "", "python_module": "custom_nodes.ComfyUI_UltimateSDUpscale", "category": "image/upscaling", "output_node": false}, "UltimateSDUpscaleCustomSample": {"input": {"required": {"image": ["IMAGE"], "model": ["MODEL"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "upscale_by": ["FLOAT", {"default": 2, "min": 0.05, "max": 4, "step": 0.05}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "step": 1}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"]], "denoise": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0, "step": 0.01}], "mode_type": [["Linear", "Chess", "None"]], "tile_width": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "tile_height": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "mask_blur": ["INT", {"default": 8, "min": 0, "max": 64, "step": 1}], "tile_padding": ["INT", {"default": 32, "min": 0, "max": 8192, "step": 8}], "seam_fix_mode": [["None", "Band Pass", "Half Tile", "Half Tile + Intersections"]], "seam_fix_denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "seam_fix_width": ["INT", {"default": 64, "min": 0, "max": 8192, "step": 8}], "seam_fix_mask_blur": ["INT", {"default": 8, "min": 0, "max": 64, "step": 1}], "seam_fix_padding": ["INT", {"default": 16, "min": 0, "max": 8192, "step": 8}], "force_uniform_tiles": ["BOOLEAN", {"default": true}], "tiled_decode": ["BOOLEAN", {"default": false}]}, "optional": {"upscale_model": ["UPSCALE_MODEL"], "custom_sampler": ["SAMPLER"], "custom_sigmas": ["SIGMAS"]}}, "input_order": {"required": ["image", "model", "positive", "negative", "vae", "upscale_by", "seed", "steps", "cfg", "sampler_name", "scheduler", "denoise", "mode_type", "tile_width", "tile_height", "mask_blur", "tile_padding", "seam_fix_mode", "seam_fix_denoise", "seam_fix_width", "seam_fix_mask_blur", "seam_fix_padding", "force_uniform_tiles", "tiled_decode"], "optional": ["upscale_model", "custom_sampler", "custom_sigmas"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "UltimateSDUpscaleCustomSample", "display_name": "Ultimate SD Upscale (Custom Sample)", "description": "", "python_module": "custom_nodes.ComfyUI_UltimateSDUpscale", "category": "image/upscaling", "output_node": false}, "TilePreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"pyrUp_iters": ["INT", {"default": 3, "min": 1, "max": 10, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["pyrUp_iters", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "TilePreprocessor", "display_name": "Tile", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/tile", "output_node": false}, "TTPlanet_TileGF_Preprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"scale_factor": ["FLOAT", {"default": 1.0, "min": 1.0, "max": 8.0, "step": 0.01}], "blur_strength": ["FLOAT", {"default": 2.0, "min": 1.0, "max": 10.0, "step": 0.01}], "radius": ["INT", {"default": 7, "min": 1, "max": 20, "step": 1}], "eps": ["FLOAT", {"default": 0.01, "min": 0.001, "max": 0.1, "step": 0.001}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["scale_factor", "blur_strength", "radius", "eps", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "TTPlanet_TileGF_Preprocessor", "display_name": "TTPlanet Tile GuidedFilter", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/tile", "output_node": false}, "TTPlanet_TileSimple_Preprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"scale_factor": ["FLOAT", {"default": 1.0, "min": 1.0, "max": 8.0, "step": 0.01}], "blur_strength": ["FLOAT", {"default": 2.0, "min": 1.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["image"], "optional": ["scale_factor", "blur_strength"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "TTPlanet_TileSimple_Preprocessor", "display_name": "TTPlanet Tile Simple", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/tile", "output_node": false}, "MediaPipe-FaceMeshPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"max_faces": ["INT", {"default": 10, "min": 1, "max": 50, "step": 1}], "min_confidence": ["FLOAT", {"default": 0.5, "min": 0.1, "max": 1, "step": 0.01}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["max_faces", "min_confidence", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "MediaPipe-FaceMeshPreprocessor", "display_name": "MediaPipe Face Mesh", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Faces and Poses Estimators", "output_node": false}, "OneFormer-COCO-SemSegPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "OneFormer-COCO-SemSegPreprocessor", "display_name": "OneFormer COCO Segmentor", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Semantic Segmentation", "output_node": false}, "OneFormer-ADE20K-SemSegPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "OneFormer-ADE20K-SemSegPreprocessor", "display_name": "OneFormer ADE20K Segmentor", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Semantic Segmentation", "output_node": false}, "DepthAnythingV2Preprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"ckpt_name": [["depth_anything_v2_vitg.pth", "depth_anything_v2_vitl.pth", "depth_anything_v2_vitb.pth", "depth_anything_v2_vits.pth"], {"default": "depth_anything_v2_vitl.pth"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["ckpt_name", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "DepthAnythingV2Preprocessor", "display_name": "Depth Anything V2 - Relative", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "M-LSDPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"score_threshold": ["FLOAT", {"default": 0.1, "min": 0.01, "max": 2.0, "step": 0.01}], "dist_threshold": ["FLOAT", {"default": 0.1, "min": 0.01, "max": 20.0, "step": 0.01}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["score_threshold", "dist_threshold", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "M-LSDPreprocessor", "display_name": "M-LSD Lines", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "HEDPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"safe": [["enable", "disable"], {"default": "enable"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["safe", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "HEDPreprocessor", "display_name": "HED Soft-Edge Lines", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "FakeScribblePreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"safe": [["enable", "disable"], {"default": "enable"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["safe", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FakeScribblePreprocessor", "display_name": "Fake Scribble Lines (aka scribble_hed)", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "InpaintPreprocessor": {"input": {"required": {"image": ["IMAGE"], "mask": ["MASK"]}, "optional": {"black_pixel_for_xinsir_cn": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["image", "mask"], "optional": ["black_pixel_for_xinsir_cn"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "InpaintPreprocessor", "display_name": "Inpaint Preprocessor", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/others", "output_node": false}, "ColorPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ColorPreprocessor", "display_name": "Color Pallete", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/T2IAdapter-only", "output_node": false}, "PyraCannyPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"low_threshold": ["INT", {"default": 64, "min": 0, "max": 255, "step": 1}], "high_threshold": ["INT", {"default": 128, "min": 0, "max": 255, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["low_threshold", "high_threshold", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "PyraCannyPreprocessor", "display_name": "PyraCanny", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "ScribblePreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ScribblePreprocessor", "display_name": "Scribble Lines", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "Scribble_XDoG_Preprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"threshold": ["INT", {"default": 32, "min": 1, "max": 64, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["threshold", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Scribble_XDoG_Preprocessor", "display_name": "Scribble XDoG Lines", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "Scribble_PiDiNet_Preprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"safe": [["enable", "disable"]], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["safe", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Scribble_PiDiNet_Preprocessor", "display_name": "Scribble PiDiNet Lines", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "Zoe-DepthMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Zoe-DepthMapPreprocessor", "display_name": "Zoe Depth Map", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "CannyEdgePreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"low_threshold": ["INT", {"default": 100, "min": 0, "max": 255, "step": 1}], "high_threshold": ["INT", {"default": 200, "min": 0, "max": 255, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["low_threshold", "high_threshold", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "CannyEdgePreprocessor", "display_name": "Canny Edge", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "BAE-NormalMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "BAE-NormalMapPreprocessor", "display_name": "BAE Normal Map", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "ShufflePreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["image"], "optional": ["resolution", "seed"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ShufflePreprocessor", "display_name": "Content Shuffle", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/T2IAdapter-only", "output_node": false}, "MiDaS-NormalMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"a": ["FLOAT", {"default": 6.283185307179586, "min": 0.0, "max": 15.707963267948966, "step": 0.01}], "bg_threshold": ["FLOAT", {"default": 0.1, "min": 0, "max": 1, "step": 0.01}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["a", "bg_threshold", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "MiDaS-NormalMapPreprocessor", "display_name": "MiDaS Normal Map", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "MiDaS-DepthMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"a": ["FLOAT", {"default": 6.283185307179586, "min": 0.0, "max": 15.707963267948966, "step": 0.01}], "bg_threshold": ["FLOAT", {"default": 0.1, "min": 0, "max": 1, "step": 0.01}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["a", "bg_threshold", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "MiDaS-DepthMapPreprocessor", "display_name": "MiDaS Depth Map", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "AnimeFace_SemSegPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"remove_background_using_abg": ["BOOLEAN", {"default": true}], "resolution": ["INT", {"default": 512, "min": 512, "max": 512, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["remove_background_using_abg", "resolution"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "ABG_CHARACTER_MASK (MASK)"], "name": "AnimeFace_SemSegPreprocessor", "display_name": "Anime Face Segmentor", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Semantic Segmentation", "output_node": false}, "DiffusionEdge_Preprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"environment": [["indoor", "urban", "natrual"], {"default": "indoor"}], "patch_batch_size": ["INT", {"default": 4, "min": 1, "max": 16, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["environment", "patch_batch_size", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "DiffusionEdge_Preprocessor", "display_name": "Diffusion Edge (batch size \u2191 => speed \u2191, VRAM \u2191)", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "UniFormer-SemSegPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "UniFormer-SemSegPreprocessor", "display_name": "UniFormer Segmentor", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Semantic Segmentation", "output_node": false}, "SemSegPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "SemSegPreprocessor", "display_name": "Semantic Segmentor (legacy, alias for UniFormer)", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Semantic Segmentation", "output_node": false}, "AnyLineArtPreprocessor_aux": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"merge_with_lineart": [["lineart_standard", "lineart_realisitic", "lineart_anime", "manga_line"], {"default": "lineart_standard"}], "resolution": ["INT", {"default": 1280, "min": 64, "max": 16384, "step": 8}], "lineart_lower_bound": ["FLOAT", {"default": 0, "min": 0, "max": 1, "step": 0.01}], "lineart_upper_bound": ["FLOAT", {"default": 1, "min": 0, "max": 1, "step": 0.01}], "object_min_size": ["INT", {"default": 36, "min": 1, "max": 16384, "step": 1}], "object_connectivity": ["INT", {"default": 1, "min": 1, "max": 16384, "step": 1}]}}, "input_order": {"required": ["image"], "optional": ["merge_with_lineart", "resolution", "lineart_lower_bound", "lineart_upper_bound", "object_min_size", "object_connectivity"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "AnyLineArtPreprocessor_aux", "display_name": "AnyLine Lineart", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "DSINE-NormalMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"fov": ["FLOAT", {"default": 60.0, "min": 0, "max": 365.0, "step": 0.01}], "iterations": ["INT", {"default": 5, "min": 1, "max": 20, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["fov", "iterations", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "DSINE-NormalMapPreprocessor", "display_name": "DSINE Normal Map", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "LineArtPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"coarse": [["disable", "enable"], {"default": "disable"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["coarse", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "LineArtPreprocessor", "display_name": "Realistic Lineart", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "OpenposePreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"detect_hand": [["enable", "disable"], {"default": "enable"}], "detect_body": [["enable", "disable"], {"default": "enable"}], "detect_face": [["enable", "disable"], {"default": "enable"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}], "scale_stick_for_xinsr_cn": [["disable", "enable"], {"default": "disable"}]}}, "input_order": {"required": ["image"], "optional": ["detect_hand", "detect_body", "detect_face", "resolution", "scale_stick_for_xinsr_cn"]}, "output": ["IMAGE", "POSE_KEYPOINT"], "output_is_list": [false, false], "output_name": ["IMAGE", "POSE_KEYPOINT"], "name": "OpenposePreprocessor", "display_name": "OpenPose Pose", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Faces and Poses Estimators", "output_node": false}, "BinaryPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"bin_threshold": ["INT", {"default": 100, "min": 0, "max": 255, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["bin_threshold", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "BinaryPreprocessor", "display_name": "Binary Lines", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "AnimeLineArtPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "AnimeLineArtPreprocessor", "display_name": "Anime Lineart", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "DepthAnythingPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"ckpt_name": [["depth_anything_vitl14.pth", "depth_anything_vitb14.pth", "depth_anything_vits14.pth"], {"default": "depth_anything_vitl14.pth"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["ckpt_name", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "DepthAnythingPreprocessor", "display_name": "Depth Anything", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "Zoe_DepthAnythingPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"environment": [["indoor", "outdoor"], {"default": "indoor"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["environment", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Zoe_DepthAnythingPreprocessor", "display_name": "Zoe Depth Anything", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "Manga2Anime_LineArt_Preprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Manga2Anime_LineArt_Preprocessor", "display_name": "Manga Lineart (aka lineart_anime_denoise)", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "LineartStandardPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"guassian_sigma": ["FLOAT", {"default": 6.0, "min": 0, "max": 100.0, "step": 0.01}], "intensity_threshold": ["INT", {"default": 8, "min": 0, "max": 16, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["guassian_sigma", "intensity_threshold", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "LineartStandardPreprocessor", "display_name": "Standard Lineart", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "SAMPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "SAMPreprocessor", "display_name": "SAM Segmentor", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/others", "output_node": false}, "ImageLuminanceDetector": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"gamma_correction": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 2.0, "step": 0.01}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["gamma_correction", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageLuminanceDetector", "display_name": "Image Luminance", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Recolor", "output_node": false}, "ImageIntensityDetector": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"gamma_correction": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 2.0, "step": 0.01}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["gamma_correction", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageIntensityDetector", "display_name": "Image Intensity", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Recolor", "output_node": false}, "PiDiNetPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"safe": [["enable", "disable"], {"default": "enable"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["safe", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "PiDiNetPreprocessor", "display_name": "PiDiNet Soft-Edge Lines", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "DensePosePreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"model": [["densepose_r50_fpn_dl.torchscript", "densepose_r101_fpn_dl.torchscript"], {"default": "densepose_r50_fpn_dl.torchscript"}], "cmap": [["Viridis (MagicAnimate)", "Parula (CivitAI)"], {"default": "Viridis (MagicAnimate)"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["model", "cmap", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "DensePosePreprocessor", "display_name": "DensePose Estimator", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Faces and Poses Estimators", "output_node": false}, "Metric3D-DepthMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"backbone": [["vit-small", "vit-large", "vit-giant2"], {"default": "vit-small"}], "fx": ["INT", {"default": 1000, "min": 1, "max": 16384, "step": 1}], "fy": ["INT", {"default": 1000, "min": 1, "max": 16384, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["backbone", "fx", "fy", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Metric3D-DepthMapPreprocessor", "display_name": "Metric3D Depth Map", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "Metric3D-NormalMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"backbone": [["vit-small", "vit-large", "vit-giant2"], {"default": "vit-small"}], "fx": ["INT", {"default": 1000, "min": 1, "max": 16384, "step": 1}], "fy": ["INT", {"default": 1000, "min": 1, "max": 16384, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["backbone", "fx", "fy", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Metric3D-NormalMapPreprocessor", "display_name": "Metric3D Normal Map", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "MeshGraphormer-DepthMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"mask_bbox_padding": ["INT", {"default": 30, "min": 0, "max": 100}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}], "mask_type": [["based_on_depth", "tight_bboxes", "original"], {"default": "based_on_depth"}], "mask_expand": ["INT", {"default": 5, "min": -16384, "max": 16384, "step": 1}], "rand_seed": ["INT", {"default": 88, "min": 0, "max": 18446744073709551615, "step": 1}], "detect_thr": ["FLOAT", {"default": 0.6, "min": 0.1, "max": 1, "step": 0.01}], "presence_thr": ["FLOAT", {"default": 0.6, "min": 0.1, "max": 1, "step": 0.01}]}}, "input_order": {"required": ["image"], "optional": ["mask_bbox_padding", "resolution", "mask_type", "mask_expand", "rand_seed", "detect_thr", "presence_thr"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "INPAINTING_MASK"], "name": "MeshGraphormer-DepthMapPreprocessor", "display_name": "MeshGraphormer Hand Refiner", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "MeshGraphormer+ImpactDetector-DepthMapPreprocessor": {"input": {"required": {"image": ["IMAGE"], "bbox_detector": ["BBOX_DETECTOR"]}, "optional": {"bbox_threshold": ["FLOAT", {"default": 0.5, "min": 0.1, "max": 1, "step": 0.01}], "bbox_dilation": ["INT", {"default": 10, "min": -512, "max": 512, "step": 1}], "bbox_crop_factor": ["FLOAT", {"default": 3.0, "min": 1.0, "max": 10.0, "step": 0.01}], "drop_size": ["INT", {"default": 10, "min": 1, "max": 16384, "step": 1}], "mask_bbox_padding": ["INT", {"default": 30, "min": 0, "max": 100, "step": 1}], "mask_type": [["based_on_depth", "tight_bboxes", "original"], {"default": "based_on_depth"}], "mask_expand": ["INT", {"default": 5, "min": -16384, "max": 16384, "step": 1}], "rand_seed": ["INT", {"default": 88, "min": 0, "max": 18446744073709551615, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image", "bbox_detector"], "optional": ["bbox_threshold", "bbox_dilation", "bbox_crop_factor", "drop_size", "mask_bbox_padding", "mask_type", "mask_expand", "rand_seed", "resolution"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "INPAINTING_MASK"], "name": "MeshGraphormer+ImpactDetector-DepthMapPreprocessor", "display_name": "MeshGraphormer Hand Refiner With External Detector", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "LeReS-DepthMapPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"rm_nearest": ["FLOAT", {"default": 0, "min": 0, "max": 100.0, "step": 0.01}], "rm_background": ["FLOAT", {"default": 0, "min": 0, "max": 100.0, "step": 0.01}], "boost": [["disable", "enable"], {"default": "disable"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["rm_nearest", "rm_background", "boost", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "LeReS-DepthMapPreprocessor", "display_name": "LeReS Depth Map (enable boost for leres++)", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Normal and Depth Estimators", "output_node": false}, "TEEDPreprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"safe_steps": ["INT", {"default": 2, "min": 0, "max": 10, "step": 1}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["safe_steps", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "TEEDPreprocessor", "display_name": "TEEDPreprocessor", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Line Extractors", "output_node": false}, "Unimatch_OptFlowPreprocessor": {"input": {"required": {"image": ["IMAGE"], "ckpt_name": [["gmflow-scale1-mixdata.pth", "gmflow-scale2-mixdata.pth", "gmflow-scale2-regrefine6-mixdata.pth"], {"default": "gmflow-scale2-regrefine6-mixdata.pth"}], "backward_flow": ["BOOLEAN", {"default": false}], "bidirectional_flow": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["image", "ckpt_name", "backward_flow", "bidirectional_flow"]}, "output": ["OPTICAL_FLOW", "IMAGE"], "output_is_list": [false, false], "output_name": ["OPTICAL_FLOW", "PREVIEW_IMAGE"], "name": "Unimatch_OptFlowPreprocessor", "display_name": "Unimatch Optical Flow", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Optical Flow", "output_node": false}, "MaskOptFlow": {"input": {"required": {"optical_flow": ["OPTICAL_FLOW"], "mask": ["MASK"]}}, "input_order": {"required": ["optical_flow", "mask"]}, "output": ["OPTICAL_FLOW", "IMAGE"], "output_is_list": [false, false], "output_name": ["OPTICAL_FLOW", "PREVIEW_IMAGE"], "name": "MaskOptFlow", "display_name": "Mask Optical Flow (DragNUWA)", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors/Optical Flow", "output_node": false}, "AIO_Preprocessor": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"preprocessor": [["none", "TilePreprocessor", "TTPlanet_TileGF_Preprocessor", "TTPlanet_TileSimple_Preprocessor", "MediaPipe-FaceMeshPreprocessor", "OneFormer-COCO-SemSegPreprocessor", "OneFormer-ADE20K-SemSegPreprocessor", "DepthAnythingV2Preprocessor", "M-LSDPreprocessor", "HEDPreprocessor", "FakeScribblePreprocessor", "ColorPreprocessor", "PyraCannyPreprocessor", "ScribblePreprocessor", "Scribble_XDoG_Preprocessor", "Scribble_PiDiNet_Preprocessor", "Zoe-DepthMapPreprocessor", "CannyEdgePreprocessor", "BAE-NormalMapPreprocessor", "ShufflePreprocessor", "MiDaS-NormalMapPreprocessor", "MiDaS-DepthMapPreprocessor", "AnimeFace_SemSegPreprocessor", "UniFormer-SemSegPreprocessor", "SemSegPreprocessor", "AnyLineArtPreprocessor_aux", "DSINE-NormalMapPreprocessor", "LineArtPreprocessor", "OpenposePreprocessor", "BinaryPreprocessor", "AnimeLineArtPreprocessor", "DepthAnythingPreprocessor", "Zoe_DepthAnythingPreprocessor", "Manga2Anime_LineArt_Preprocessor", "LineartStandardPreprocessor", "SAMPreprocessor", "ImageLuminanceDetector", "ImageIntensityDetector", "PiDiNetPreprocessor", "DensePosePreprocessor", "Metric3D-DepthMapPreprocessor", "Metric3D-NormalMapPreprocessor", "MeshGraphormer-DepthMapPreprocessor", "LeReS-DepthMapPreprocessor", "TEEDPreprocessor"], {"default": "none"}], "resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["preprocessor", "resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "AIO_Preprocessor", "display_name": "AIO Aux Preprocessor", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors", "output_node": false}, "ControlNetPreprocessorSelector": {"input": {"required": {"preprocessor": [["none", "TilePreprocessor", "TTPlanet_TileGF_Preprocessor", "TTPlanet_TileSimple_Preprocessor", "MediaPipe-FaceMeshPreprocessor", "OneFormer-COCO-SemSegPreprocessor", "OneFormer-ADE20K-SemSegPreprocessor", "DepthAnythingV2Preprocessor", "M-LSDPreprocessor", "HEDPreprocessor", "FakeScribblePreprocessor", "ColorPreprocessor", "PyraCannyPreprocessor", "ScribblePreprocessor", "Scribble_XDoG_Preprocessor", "Scribble_PiDiNet_Preprocessor", "Zoe-DepthMapPreprocessor", "CannyEdgePreprocessor", "BAE-NormalMapPreprocessor", "ShufflePreprocessor", "MiDaS-NormalMapPreprocessor", "MiDaS-DepthMapPreprocessor", "AnimeFace_SemSegPreprocessor", "UniFormer-SemSegPreprocessor", "SemSegPreprocessor", "AnyLineArtPreprocessor_aux", "DSINE-NormalMapPreprocessor", "LineArtPreprocessor", "OpenposePreprocessor", "BinaryPreprocessor", "AnimeLineArtPreprocessor", "DepthAnythingPreprocessor", "Zoe_DepthAnythingPreprocessor", "Manga2Anime_LineArt_Preprocessor", "LineartStandardPreprocessor", "SAMPreprocessor", "ImageLuminanceDetector", "ImageIntensityDetector", "PiDiNetPreprocessor", "DensePosePreprocessor", "Metric3D-DepthMapPreprocessor", "Metric3D-NormalMapPreprocessor", "MeshGraphormer-DepthMapPreprocessor", "LeReS-DepthMapPreprocessor", "TEEDPreprocessor"]]}}, "input_order": {"required": ["preprocessor"]}, "output": [["none", "TilePreprocessor", "TTPlanet_TileGF_Preprocessor", "TTPlanet_TileSimple_Preprocessor", "MediaPipe-FaceMeshPreprocessor", "OneFormer-COCO-SemSegPreprocessor", "OneFormer-ADE20K-SemSegPreprocessor", "DepthAnythingV2Preprocessor", "M-LSDPreprocessor", "HEDPreprocessor", "FakeScribblePreprocessor", "ColorPreprocessor", "PyraCannyPreprocessor", "ScribblePreprocessor", "Scribble_XDoG_Preprocessor", "Scribble_PiDiNet_Preprocessor", "Zoe-DepthMapPreprocessor", "CannyEdgePreprocessor", "BAE-NormalMapPreprocessor", "ShufflePreprocessor", "MiDaS-NormalMapPreprocessor", "MiDaS-DepthMapPreprocessor", "AnimeFace_SemSegPreprocessor", "UniFormer-SemSegPreprocessor", "SemSegPreprocessor", "AnyLineArtPreprocessor_aux", "DSINE-NormalMapPreprocessor", "LineArtPreprocessor", "OpenposePreprocessor", "BinaryPreprocessor", "AnimeLineArtPreprocessor", "DepthAnythingPreprocessor", "Zoe_DepthAnythingPreprocessor", "Manga2Anime_LineArt_Preprocessor", "LineartStandardPreprocessor", "SAMPreprocessor", "ImageLuminanceDetector", "ImageIntensityDetector", "PiDiNetPreprocessor", "DensePosePreprocessor", "Metric3D-DepthMapPreprocessor", "Metric3D-NormalMapPreprocessor", "MeshGraphormer-DepthMapPreprocessor", "LeReS-DepthMapPreprocessor", "TEEDPreprocessor"]], "output_is_list": [false], "output_name": ["preprocessor"], "name": "ControlNetPreprocessorSelector", "display_name": "Preprocessor Selector", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors", "output_node": false}, "PixelPerfectResolution": {"input": {"required": {"original_image": ["IMAGE"], "image_gen_width": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "image_gen_height": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "resize_mode": [["Just Resize", "Crop and Resize", "Resize and Fill"], {"default": "Just Resize"}]}}, "input_order": {"required": ["original_image", "image_gen_width", "image_gen_height", "resize_mode"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["RESOLUTION (INT)"], "name": "PixelPerfectResolution", "display_name": "Pixel Perfect Resolution", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors", "output_node": false}, "ImageGenResolutionFromImage": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["INT", "INT"], "output_is_list": [false, false], "output_name": ["IMAGE_GEN_WIDTH (INT)", "IMAGE_GEN_HEIGHT (INT)"], "name": "ImageGenResolutionFromImage", "display_name": "Generation Resolution From Image", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors", "output_node": false}, "ImageGenResolutionFromLatent": {"input": {"required": {"latent": ["LATENT"]}}, "input_order": {"required": ["latent"]}, "output": ["INT", "INT"], "output_is_list": [false, false], "output_name": ["IMAGE_GEN_WIDTH (INT)", "IMAGE_GEN_HEIGHT (INT)"], "name": "ImageGenResolutionFromLatent", "display_name": "Generation Resolution From Latent", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors", "output_node": false}, "HintImageEnchance": {"input": {"required": {"hint_image": ["IMAGE"], "image_gen_width": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "image_gen_height": ["INT", {"default": 512, "min": 64, "max": 8192, "step": 8}], "resize_mode": [["Just Resize", "Crop and Resize", "Resize and Fill"], {"default": "Just Resize"}]}}, "input_order": {"required": ["hint_image", "image_gen_width", "image_gen_height", "resize_mode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "HintImageEnchance", "display_name": "Enchance And Resize Hint Images", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors", "output_node": false}, "ExecuteAllControlNetPreprocessors": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"resolution": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 64}]}}, "input_order": {"required": ["image"], "optional": ["resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ExecuteAllControlNetPreprocessors", "display_name": "Execute All ControlNet Preprocessors", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors", "output_node": false}, "ControlNetAuxSimpleAddText": {"input": {"required": {"image": ["IMAGE"], "text": ["STRING", {"default": "", "multiline": false}]}}, "input_order": {"required": ["image", "text"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ControlNetAuxSimpleAddText", "display_name": "ControlNetAuxSimpleAddText", "description": "", "python_module": "custom_nodes.comfyui_controlnet_aux", "category": "ControlNet Preprocessors", "output_node": false}, "VHS_VideoCombine": {"input": {"required": {"images": ["IMAGE"], "frame_rate": ["FLOAT", {"default": 8, "min": 1, "step": 1}], "loop_count": ["INT", {"default": 0, "min": 0, "max": 100, "step": 1}], "filename_prefix": ["STRING", {"default": "AnimateDiff"}], "format": [["image/gif", "image/webp", "video/ffmpeg-gif", "video/nvenc_h264-mp4", "video/h265-mp4", "video/h264-mp4", "video/nvenc_hevc-mp4", "video/ProRes", "video/16bit-png", "video/ffv1-mkv", "video/webm", "video/av1-webm", "video/8bit-png", "video/nvenc_av1-mp4"], {"formats": {"video/ffmpeg-gif": [["dither", ["bayer", "heckbert", "floyd_steinberg", "sierra2", "sierra2_4a", "sierra3", "burkes", "atkinson", "none"], {"default": "sierra2_4a"}, "[0:v] split [a][b]; [a] palettegen=reserve_transparent=on:transparency_color=ffffff [p]; [b][p] paletteuse=dither=$val"]], "video/nvenc_h264-mp4": [["pix_fmt", ["yuv420p", "p010le"]], ["bitrate", "INT", {"default": 10, "min": 1, "max": 999, "step": 1}], ["megabit", "BOOLEAN", {"default": true}], ["save_metadata", "BOOLEAN", {"default": true}]], "video/h265-mp4": [["pix_fmt", ["yuv420p10le", "yuv420p"]], ["crf", "INT", {"default": 22, "min": 0, "max": 100, "step": 1}], ["save_metadata", "BOOLEAN", {"default": true}]], "video/h264-mp4": [["pix_fmt", ["yuv420p", "yuv420p10le"]], ["crf", "INT", {"default": 19, "min": 0, "max": 100, "step": 1}], ["save_metadata", "BOOLEAN", {"default": true}], ["trim_to_audio", "BOOLEAN", {"default": false}]], "video/nvenc_hevc-mp4": [["pix_fmt", ["yuv420p", "p010le"]], ["bitrate", "INT", {"default": 10, "min": 1, "max": 999, "step": 1}], ["megabit", "BOOLEAN", {"default": true}], ["save_metadata", "BOOLEAN", {"default": true}]], "video/ProRes": [["profile", ["lt", "standard", "hq", "4444", "4444xq"], {"default": "hq"}]], "video/ffv1-mkv": [["level", ["0", "1", "3"], {"default": "3"}], ["coder", ["0", "1", "2"], {"default": "1"}], ["context", ["0", "1"], {"default": "1"}], ["gop_size", "INT", {"default": 1, "min": 1, "max": 300, "step": 1}], ["slices", ["4", "6", "9", "12", "16", "20", "24", "30"], {"default": "16"}], ["slicecrc", ["0", "1"], {"default": "1"}], ["pix_fmt", ["rgba64le", "bgra", "yuv420p", "yuv422p", "yuv444p", "yuva420p", "yuva422p", "yuva444p", "yuv420p10le", "yuv422p10le", "yuv444p10le", "yuv420p12le", "yuv422p12le", "yuv444p12le", "yuv420p14le", "yuv422p14le", "yuv444p14le", "yuv420p16le", "yuv422p16le", "yuv444p16le", "gray", "gray10le", "gray12le", "gray16le"], {"default": "rgba64le"}], ["save_metadata", "BOOLEAN", {"default": true}], ["trim_to_audio", "BOOLEAN", {"default": false}]], "video/webm": [["pix_fmt", ["yuv420p", "yuva420p"]], ["crf", "INT", {"default": 20, "min": 0, "max": 100, "step": 1}], ["save_metadata", "BOOLEAN", {"default": true}], ["trim_to_audio", "BOOLEAN", {"default": false}]], "video/av1-webm": [["pix_fmt", ["yuv420p10le", "yuv420p"]], ["crf", "INT", {"default": 23, "min": 0, "max": 100, "step": 1}], ["input_color_depth", ["8bit", "16bit"]], ["save_metadata", "BOOLEAN", {"default": true}]], "video/nvenc_av1-mp4": [["pix_fmt", ["yuv420p", "p010le"]], ["bitrate", "INT", {"default": 10, "min": 1, "max": 999, "step": 1}], ["megabit", "BOOLEAN", {"default": true}], ["save_metadata", "BOOLEAN", {"default": true}]], "image/webp": [["lossless", "BOOLEAN", {"default": true}]]}}], "pingpong": ["BOOLEAN", {"default": false}], "save_output": ["BOOLEAN", {"default": true}]}, "optional": {"audio": ["AUDIO"], "meta_batch": ["VHS_BatchManager"], "vae": ["VAE"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["images", "frame_rate", "loop_count", "filename_prefix", "format", "pingpong", "save_output"], "optional": ["audio", "meta_batch", "vae"], "hidden": ["prompt", "extra_pnginfo", "unique_id"]}, "output": ["VHS_FILENAMES"], "output_is_list": [false], "output_name": ["Filenames"], "name": "VHS_VideoCombine", "display_name": "Video Combine \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Video Combine \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Combine an image sequence into a video</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images: The images to be turned into a video</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: (optional) audio to add to the video</div></div><div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long image sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided, the node will take latents as input instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Unlike on Load Video, this isn't always a strict upgrade over using a standalone VAE Decode.</div><div style=\"font-size: 1em\">If you have multiple Video Combine outputs, then the VAE decode will be performed for each output node increasing execution time</div><div style=\"font-size: 1em\">If you make any change to output settings on the Video Combine (such as changing the output format), the VAE decode will be performed again as the decoded result is (by design) not cached</div></div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"frame_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_rate: The frame rate which will be used for the output video. Consider converting this to an input and connecting this to a Load Video with Video Info(Loaded)->fps. When including audio, failure to properly set this will result in audio desync</div></div><div vhs_title=\"loop_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loop_count: The number of additional times the video should repeat. Can cause performance issues when used with long (100+ frames) sequences</div></div><div vhs_title=\"filename_prefix\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filename_prefix: A prefix to add to the name of the output filename. This can include subfolders or format strings.</div></div><div vhs_title=\"format\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">format: The output format to use. Formats starting with, 'image' are saved with PIL, but formats starting with 'video' utilize the video_formats system. 'video' options require ffmpeg and selecting one frequently adds additional options to the node.</div></div><div vhs_title=\"pingpong\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pingpong: Play the video normally, then repeat the video in reverse so that it 'pingpongs' back and forth. This is frequently used to minimize the appearance of skips on very short animations.</div></div><div vhs_title=\"save_output\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">save_output: Specifies if output files should be saved to the output folder, or the temporary output folder</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the processed result. If advanced previews is enabled, the output is always converted to a format viewable from the browser. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div><div vhs_title=\"Common Format Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Common Format Widgets: <div vhs_title=\"crf\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">crf: Determines how much to prioritize quality over filesize. Numbers vary between formats, but on each format that includes it, the default value provides visually loss less output</div></div><div vhs_title=\"pix_fmt\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pix_fmt: The pixel format to use for output. Alternative options will often have higher quality at the cost of increased file size and reduced compatibility with external software.<div style=\"font-size: 1em\"><div vhs_title=\"yuv420p\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">yuv420p: The most common and default format</div></div><div vhs_title=\"yuv420p10le\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">yuv420p10le: Use 10 bit color depth. This can improve color quality when combined with 16bit input color depth</div></div><div vhs_title=\"yuva420p\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">yuva420p: Include transparency in the output video</div></div></div></div></div><div vhs_title=\"input_color_depth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">input_color_depth: VHS supports outputting 16bit images. While this produces higher quality output, the difference usually isn't visible without postprocessing and it significantly increases file size and processing time.</div></div><div vhs_title=\"save_metadata\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">save_metadata: Determines if metadata for the workflow should be included in the output video file</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": true}, "VHS_LoadVideo": {"input": {"required": {"video": [[]], "force_rate": ["FLOAT", {"default": 0, "min": 0, "max": 60, "step": 1, "disable": 0}], "custom_width": ["INT", {"default": 0, "min": 0, "max": 8192, "disable": 0}], "custom_height": ["INT", {"default": 0, "min": 0, "max": 8192, "disable": 0}], "frame_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1, "disable": 0}], "skip_first_frames": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}]}, "optional": {"meta_batch": ["VHS_BatchManager"], "vae": ["VAE"], "format": [["None", "AnimateDiff", "Mochi", "LTXV", "Hunyuan", "Cosmos", "Wan"], {"default": "AnimateDiff", "formats": {"None": {}, "AnimateDiff": {"target_rate": 8, "dim": [8, 0, 512, 512]}, "Mochi": {"target_rate": 24, "dim": [16, 0, 848, 480], "frames": [6, 1]}, "LTXV": {"target_rate": 24, "dim": [32, 0, 768, 512], "frames": [8, 1]}, "Hunyuan": {"target_rate": 24, "dim": [16, 0, 848, 480], "frames": [4, 1]}, "Cosmos": {"target_rate": 24, "dim": [16, 0, 1280, 704], "frames": [8, 1]}, "Wan": {"target_rate": 16, "dim": [8, 0, 832, 480], "frames": [4, 1]}}}]}, "hidden": {"force_size": "STRING", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["video", "force_rate", "custom_width", "custom_height", "frame_load_cap", "skip_first_frames", "select_every_nth"], "optional": ["meta_batch", "vae", "format"], "hidden": ["force_size", "unique_id"]}, "output": ["IMAGE", "INT", "AUDIO", "VHS_VIDEOINFO"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE", "frame_count", "audio", "video_info"], "name": "VHS_LoadVideo", "display_name": "Load Video (Upload) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Video \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a video from the input folder</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Using this is strongly encouraged unless connecting to a node that requires a blue image connection such as Apply Controllnet</div></div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_count: The length of images just returned</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio from the loaded video</div></div><div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: Exposes additional info about the video such as the source frame rate, or the total length</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The loaded images pre-converted to latents. Only available when a vae is connected</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"video\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video: The video file to be loaded. Lists all files with a video extension in the ComfyUI/Input folder</div></div><div vhs_title=\"force_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_rate: Drops or duplicates frames so that the produced output has the target frame rate. Many motion models are trained on videos of a specific frame rate and will give better results if input matches that frame rate. If set to 0, all frames are returned. May give unusual results with inputs that have a variable frame rate like animated gifs. Reducing this value can also greatly reduce the execution time and memory requirements.</div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Previously was used to provide suggested resolutions. Instead, custom_width and custom_height can be disabled by setting to 0.</div></div><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"frame_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_load_cap: The maximum number of frames to load. If 0, all frames are loaded.</div></div><div vhs_title=\"skip_first_frames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_frames: A number of frames which are discarded before producing output.</div></div><div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: Similar to frame rate. Keeps only the first of every n frames and discard the rest. Has better compatibility with variable frame rate inputs such as gifs. When combined with force_rate, select_every_nth_applies after force_rate so the resulting output has a frame rate equivalent to force_rate/select_every_nth. select_every_nth does not apply to skip_first_frames</div></div><div vhs_title=\"format\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">format: Updates other widgets so that only values supported by the given format can be entered and provides recommended defaults.</div></div><div vhs_title=\"choose video to upload\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">choose video to upload: An upload button is provided to upload local files to the input folder</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. If advanced previews is enabled, this preview will reflect the frame_load_cap, force_rate, skip_first_frames, and select_every_nth values chosen. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadVideoPath": {"input": {"required": {"video": ["STRING", {"placeholder": "X://insert/path/here.mp4", "vhs_path_extensions": ["webm", "mp4", "mkv", "gif", "mov"]}], "force_rate": ["FLOAT", {"default": 0, "min": 0, "max": 60, "step": 1, "disable": 0}], "custom_width": ["INT", {"default": 0, "min": 0, "max": 8192, "disable": 0}], "custom_height": ["INT", {"default": 0, "min": 0, "max": 8192, "disable": 0}], "frame_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1, "disable": 0}], "skip_first_frames": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}]}, "optional": {"meta_batch": ["VHS_BatchManager"], "vae": ["VAE"], "format": [["None", "AnimateDiff", "Mochi", "LTXV", "Hunyuan", "Cosmos", "Wan"], {"default": "AnimateDiff", "formats": {"None": {}, "AnimateDiff": {"target_rate": 8, "dim": [8, 0, 512, 512]}, "Mochi": {"target_rate": 24, "dim": [16, 0, 848, 480], "frames": [6, 1]}, "LTXV": {"target_rate": 24, "dim": [32, 0, 768, 512], "frames": [8, 1]}, "Hunyuan": {"target_rate": 24, "dim": [16, 0, 848, 480], "frames": [4, 1]}, "Cosmos": {"target_rate": 24, "dim": [16, 0, 1280, 704], "frames": [8, 1]}, "Wan": {"target_rate": 16, "dim": [8, 0, 832, 480], "frames": [4, 1]}}}]}, "hidden": {"force_size": "STRING", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["video", "force_rate", "custom_width", "custom_height", "frame_load_cap", "skip_first_frames", "select_every_nth"], "optional": ["meta_batch", "vae", "format"], "hidden": ["force_size", "unique_id"]}, "output": ["IMAGE", "INT", "AUDIO", "VHS_VIDEOINFO"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE", "frame_count", "audio", "video_info"], "name": "VHS_LoadVideoPath", "display_name": "Load Video (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Video (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a video from an arbitrary path</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Using this is strongly encouraged unless connecting to a node that requires a blue image connection such as Apply Controllnet</div></div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_count: The length of images just returned</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio from the loaded video</div></div><div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: Exposes additional info about the video such as the source frame rate, or the total length</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The loaded images pre-converted to latents. Only available when a vae is connected</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"video\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video: The video file to be loaded.<div style=\"font-size: 1em\">You can also select an image to load it as a single frame</div><div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"force_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_rate: Drops or duplicates frames so that the produced output has the target frame rate. Many motion models are trained on videos of a specific frame rate and will give better results if input matches that frame rate. If set to 0, all frames are returned. May give unusual results with inputs that have a variable frame rate like animated gifs. Reducing this value can also greatly reduce the execution time and memory requirements.</div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Previously was used to provide suggested resolutions. Instead, custom_width and custom_height can be disabled by setting to 0.</div></div><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"frame_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_load_cap: The maximum number of frames to load. If 0, all frames are loaded.</div></div><div vhs_title=\"skip_first_frames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_frames: A number of frames which are discarded before producing output.</div></div><div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: Similar to frame rate. Keeps only the first of every n frames and discard the rest. Has better compatibility with variable frame rate inputs such as gifs. When combined with force_rate, select_every_nth_applies after force_rate so the resulting output has a frame rate equivalent to force_rate/select_every_nth. select_every_nth does not apply to skip_first_frames</div></div><div vhs_title=\"format\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">format: Updates other widgets so that only values supported by the given format can be entered and provides recommended defaults.</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the frame_load_cap, force_rate, skip_first_frames, and select_every_nth values chosen. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadVideoFFmpeg": {"input": {"required": {"video": [[]], "force_rate": ["FLOAT", {"default": 0, "min": 0, "max": 60, "step": 1, "disable": 0}], "custom_width": ["INT", {"default": 0, "min": 0, "max": 8192, "disable": 0}], "custom_height": ["INT", {"default": 0, "min": 0, "max": 8192, "disable": 0}], "frame_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1, "disable": 0}], "start_time": ["FLOAT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 0.001, "widgetType": "VHSTIMESTAMP"}]}, "optional": {"meta_batch": ["VHS_BatchManager"], "vae": ["VAE"], "format": [["None", "AnimateDiff", "Mochi", "LTXV", "Hunyuan", "Cosmos", "Wan"], {"default": "AnimateDiff", "formats": {"None": {}, "AnimateDiff": {"target_rate": 8, "dim": [8, 0, 512, 512]}, "Mochi": {"target_rate": 24, "dim": [16, 0, 848, 480], "frames": [6, 1]}, "LTXV": {"target_rate": 24, "dim": [32, 0, 768, 512], "frames": [8, 1]}, "Hunyuan": {"target_rate": 24, "dim": [16, 0, 848, 480], "frames": [4, 1]}, "Cosmos": {"target_rate": 24, "dim": [16, 0, 1280, 704], "frames": [8, 1]}, "Wan": {"target_rate": 16, "dim": [8, 0, 832, 480], "frames": [4, 1]}}}]}, "hidden": {"force_size": "STRING", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["video", "force_rate", "custom_width", "custom_height", "frame_load_cap", "start_time"], "optional": ["meta_batch", "vae", "format"], "hidden": ["force_size", "unique_id"]}, "output": ["IMAGE", "MASK", "AUDIO", "VHS_VIDEOINFO"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE", "mask", "audio", "video_info"], "name": "VHS_LoadVideoFFmpeg", "display_name": "Load Video FFmpeg (Upload) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Video FFmpeg \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a video from the input folder using ffmpeg instead of opencv</div></div><div style=\"font-size: 0.8em\">Provides faster execution speed, transparency support, and allows specifying start time in seconds</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Using this is strongly encouraged unless connecting to a node that requires a blue image connection such as Apply Controllnet</div></div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask: Transparency data from the loaded video</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio from the loaded video</div></div><div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: Exposes additional info about the video such as the source frame rate, or the total length</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The loaded images pre-converted to latents. Only available when a vae is connected</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"video\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video: The video file to be loaded. Lists all files with a video extension in the ComfyUI/Input folder</div></div><div vhs_title=\"force_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_rate: Drops or duplicates frames so that the produced output has the target frame rate. Many motion models are trained on videos of a specific frame rate and will give better results if input matches that frame rate. If set to 0, all frames are returned. May give unusual results with inputs that have a variable frame rate like animated gifs. Reducing this value can also greatly reduce the execution time and memory requirements.</div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Previously was used to provide suggested resolutions. Instead, custom_width and custom_height can be disabled by setting to 0.</div></div><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"frame_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_load_cap: The maximum number of frames to load. If 0, all frames are loaded.</div></div><div vhs_title=\"start_time\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">start_time: A timestamp, in seconds from the start of the video, to start loading frames from. </div></div><div vhs_title=\"format\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">format: Updates other widgets so that only values supported by the given format can be entered and provides recommended defaults.</div></div><div vhs_title=\"choose video to upload\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">choose video to upload: An upload button is provided to upload local files to the input folder</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. If advanced previews is enabled, this preview will reflect the frame_load_cap, force_rate, skip_first_frames, and select_every_nth values chosen. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadVideoFFmpegPath": {"input": {"required": {"video": ["STRING", {"placeholder": "X://insert/path/here.mp4", "vhs_path_extensions": ["webm", "mp4", "mkv", "gif", "mov"]}], "force_rate": ["FLOAT", {"default": 0, "min": 0, "max": 60, "step": 1, "disable": 0}], "custom_width": ["INT", {"default": 0, "min": 0, "max": 8192, "disable": 0}], "custom_height": ["INT", {"default": 0, "min": 0, "max": 8192, "disable": 0}], "frame_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1, "disable": 0}], "start_time": ["FLOAT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 0.001, "widgetType": "VHSTIMESTAMP"}]}, "optional": {"meta_batch": ["VHS_BatchManager"], "vae": ["VAE"], "format": [["None", "AnimateDiff", "Mochi", "LTXV", "Hunyuan", "Cosmos", "Wan"], {"default": "AnimateDiff", "formats": {"None": {}, "AnimateDiff": {"target_rate": 8, "dim": [8, 0, 512, 512]}, "Mochi": {"target_rate": 24, "dim": [16, 0, 848, 480], "frames": [6, 1]}, "LTXV": {"target_rate": 24, "dim": [32, 0, 768, 512], "frames": [8, 1]}, "Hunyuan": {"target_rate": 24, "dim": [16, 0, 848, 480], "frames": [4, 1]}, "Cosmos": {"target_rate": 24, "dim": [16, 0, 1280, 704], "frames": [8, 1]}, "Wan": {"target_rate": 16, "dim": [8, 0, 832, 480], "frames": [4, 1]}}}]}, "hidden": {"force_size": "STRING", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["video", "force_rate", "custom_width", "custom_height", "frame_load_cap", "start_time"], "optional": ["meta_batch", "vae", "format"], "hidden": ["force_size", "unique_id"]}, "output": ["IMAGE", "MASK", "AUDIO", "VHS_VIDEOINFO"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE", "mask", "audio", "video_info"], "name": "VHS_LoadVideoFFmpegPath", "display_name": "Load Video FFmpeg (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Video FFmpeg (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a video from an arbitrary path using ffmpeg instead of opencv</div></div><div style=\"font-size: 0.8em\">Provides faster execution speed, transparency support, and allows specifying start time in seconds</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Using this is strongly encouraged unless connecting to a node that requires a blue image connection such as Apply Controllnet</div></div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask: Transparency data from the loaded video</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio from the loaded video</div></div><div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: Exposes additional info about the video such as the source frame rate, or the total length</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The loaded images pre-converted to latents. Only available when a vae is connected</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"video\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video: The video file to be loaded.<div style=\"font-size: 1em\">You can also select an image to load it as a single frame</div><div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"force_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_rate: Drops or duplicates frames so that the produced output has the target frame rate. Many motion models are trained on videos of a specific frame rate and will give better results if input matches that frame rate. If set to 0, all frames are returned. May give unusual results with inputs that have a variable frame rate like animated gifs. Reducing this value can also greatly reduce the execution time and memory requirements.</div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Previously was used to provide suggested resolutions. Instead, custom_width and custom_height can be disabled by setting to 0.</div></div><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"frame_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_load_cap: The maximum number of frames to load. If 0, all frames are loaded.</div></div><div vhs_title=\"skip_first_frames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_frames: A number of frames which are discarded before producing output.</div></div><div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: Similar to frame rate. Keeps only the first of every n frames and discard the rest. Has better compatibility with variable frame rate inputs such as gifs. When combined with force_rate, select_every_nth_applies after force_rate so the resulting output has a frame rate equivalent to force_rate/select_every_nth. select_every_nth does not apply to skip_first_frames</div></div><div vhs_title=\"format\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">format: Updates other widgets so that only values supported by the given format can be entered and provides recommended defaults.</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the frame_load_cap, force_rate, skip_first_frames, and select_every_nth values chosen. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadImagePath": {"input": {"required": {"image": ["STRING", {"placeholder": "X://insert/path/here.png", "vhs_path_extensions": [".ppm", ".jpg", ".pgm", ".tif", ".bmp", ".webp", ".tiff", ".png", ".jpeg"]}], "custom_width": ["INT", {"default": 0, "min": 0, "max": 8192, "step": 8, "disable": 0}], "custom_height": ["INT", {"default": 0, "min": 0, "max": 8192, "step": 8, "disable": 0}]}, "optional": {"vae": ["VAE"]}, "hidden": {"force_size": "STRING"}}, "input_order": {"required": ["image", "custom_width", "custom_height"], "optional": ["vae"], "hidden": ["force_size"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "mask"], "name": "VHS_LoadImagePath", "display_name": "Load Image (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Image (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Load a single image from a given path</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The alpha channel of the loaded images.</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"image\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">image: The image file to be loaded.<div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Allows for conveniently scaling the input without requiring an additional node. Provides options to maintain aspect ratio or conveniently target common training formats for Animate Diff<div style=\"font-size: 1em\"><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div></div></div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the image_load_cap, skip_first_images, and select_every_nth values chosen. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadImages": {"input": {"required": {"directory": [["3d"]]}, "optional": {"image_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "skip_first_images": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}], "meta_batch": ["VHS_BatchManager"]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["directory"], "optional": ["image_load_cap", "skip_first_images", "select_every_nth", "meta_batch"], "hidden": ["unique_id"]}, "output": ["IMAGE", "MASK", "INT"], "output_is_list": [false, false, false], "output_name": ["IMAGE", "MASK", "frame_count"], "name": "VHS_LoadImages", "display_name": "Load Images (Upload) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a sequence of images from a subdirectory of the input folder</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The alpha channel of the loaded images.</div></div><div vhs_title=\"frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_count: The length of images just returned</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"directory\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">directory: The directory images will be loaded from. Filtered to process jpg, png, ppm, bmp, tif, and webp files</div></div><div vhs_title=\"image_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">image_load_cap: The maximum number of images to load. If 0, all images are loaded.</div></div><div vhs_title=\"start_time\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">start_time: A timestamp, in seconds from the start of the video, to start loading frames from. </div></div><div vhs_title=\"choose folder to upload\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">choose folder to upload: An upload button is provided to upload a local folder containing images to the input folder</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the image_load_cap, skip_first_images, and select_every_nth values chosen. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadImagesPath": {"input": {"required": {"directory": ["STRING", {"placeholder": "X://path/to/images", "vhs_path_extensions": []}]}, "optional": {"image_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "skip_first_images": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}], "meta_batch": ["VHS_BatchManager"]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["directory"], "optional": ["image_load_cap", "skip_first_images", "select_every_nth", "meta_batch"], "hidden": ["unique_id"]}, "output": ["IMAGE", "MASK", "INT"], "output_is_list": [false, false, false], "output_name": ["IMAGE", "MASK", "frame_count"], "name": "VHS_LoadImagesPath", "display_name": "Load Images (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Images (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a sequence of images from an arbitrary path</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The alpha channel of the loaded images.</div></div><div vhs_title=\"frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_count: The length of images just returned</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"directory\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">directory: The directory images will be loaded from. Filtered to process jpg, png, ppm, bmp, tif, and webp files<div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"image_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">image_load_cap: The maximum number of images to load. If 0, all images are loaded.</div></div><div vhs_title=\"skip_first_images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_images: A number of images which are discarded before producing output.</div></div><div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: Keeps only the first of every n frames and discard the rest.</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the image_load_cap, skip_first_images, and select_every_nth values chosen. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadAudio": {"input": {"required": {"audio_file": ["STRING", {"default": "input/", "vhs_path_extensions": ["wav", "mp3", "ogg", "m4a", "flac"]}]}, "optional": {"seek_seconds": ["FLOAT", {"default": 0, "min": 0, "widgetType": "VHSTIMESTAMP"}], "duration": ["FLOAT", {"default": 0, "min": 0, "max": 10000000, "step": 0.01, "widgetType": "VHSTIMESTAMP"}]}}, "input_order": {"required": ["audio_file"], "optional": ["seek_seconds", "duration"]}, "output": ["AUDIO", "FLOAT"], "output_is_list": [false, false], "output_name": ["audio", "duration"], "name": "VHS_LoadAudio", "display_name": "Load Audio (Path)\ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Audio (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads an audio file from an arbitrary path</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The loaded audio</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"audio_file\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio_file: The audio file to be loaded.<div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"seek_seconds\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">seek_seconds: An offset from the start of the sound file that the audio should start from</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/audio", "output_node": false}, "VHS_LoadAudioUpload": {"input": {"required": {"audio": [[]]}, "optional": {"start_time": ["FLOAT", {"default": 0, "min": 0, "max": 10000000, "step": 0.01, "widgetType": "VHSTIMESTAMP"}], "duration": ["FLOAT", {"default": 0, "min": 0, "max": 10000000, "step": 0.01, "widgetType": "VHSTIMESTAMP"}]}}, "input_order": {"required": ["audio"], "optional": ["start_time", "duration"]}, "output": ["AUDIO", "FLOAT"], "output_is_list": [false, false], "output_name": ["audio", "duration"], "name": "VHS_LoadAudioUpload", "display_name": "Load Audio (Upload)\ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Audio (Upload) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads an audio file from the input directory</div></div><div style=\"font-size: 0.8em\">Very similar in functionality to the built-in LoadAudio. It was originally added before VHS swapped to use Comfy's internal AUDIO format, but provides the additional options for start time and duration</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The loaded audio</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio file to be loaded.</div></div><div vhs_title=\"start_time\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">start_time: An offset from the start of the sound file that the audio should start from</div></div><div vhs_title=\"duration\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">duration: A maximum limit for the audio. Disabled if 0</div></div><div vhs_title=\"choose audio to upload\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">choose audio to upload: An upload button is provided to upload an audio file to the input folder</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/audio", "output_node": false}, "VHS_AudioToVHSAudio": {"input": {"required": {"audio": ["AUDIO"]}}, "input_order": {"required": ["audio"]}, "output": ["VHS_AUDIO"], "output_is_list": [false], "output_name": ["vhs_audio"], "name": "VHS_AudioToVHSAudio", "display_name": "Audio to legacy VHS_AUDIO\ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Audio to legacy VHS_AUDIO \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>utility function for compatibility with external nodes</div></div><div style=\"font-size: 0.8em\">VHS used to use an internal VHS_AUDIO format for routing audio between inputs and outputs. This format was intended to only be used internally and was designed with a focus on performance over ease of use. Since ComfyUI now has an internal AUDIO format, VHS now uses this format. However, some custom node packs were made that are external to both ComfyUI and VHS that use VHS_AUDIO. This node was added so that those external nodes can still function</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: An input in the standardized AUDIO format</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"vhs_audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vhs_audio: An output in the legacy VHS_AUDIO format for use with external nodes</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/audio", "output_node": false}, "VHS_VHSAudioToAudio": {"input": {"required": {"vhs_audio": ["VHS_AUDIO"]}}, "input_order": {"required": ["vhs_audio"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["audio"], "name": "VHS_VHSAudioToAudio", "display_name": "Legacy VHS_AUDIO to Audio\ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Legacy VHS_AUDIO to Audio \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>utility function for compatibility with external nodes</div></div><div style=\"font-size: 0.8em\">VHS used to use an internal VHS_AUDIO format for routing audio between inputs and outputs. This format was intended to only be used internally and was designed with a focus on performance over ease of use. Since ComfyUI now has an internal AUDIO format, VHS now uses this format. However, some custom node packs were made that are external to both ComfyUI and VHS that use VHS_AUDIO. This node was added so that those external nodes can still function</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"vhs_audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vhs_audio: An input in the legacy VHS_AUDIO format produced by an external node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"vhs_audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vhs_audio: An output in the standardized AUDIO format</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/audio", "output_node": false}, "VHS_PruneOutputs": {"input": {"required": {"filenames": ["VHS_FILENAMES"], "options": [["Intermediate", "Intermediate and Utility"]]}}, "input_order": {"required": ["filenames", "options"]}, "output": [], "output_is_list": [], "output_name": [], "name": "VHS_PruneOutputs", "display_name": "Prune Outputs \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Prune Outputs \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Automates deletion of undesired outputs from a Video Combine node.</div></div><div style=\"font-size: 0.8em\">Video Combine produces a number of file outputs in addition to the final output. Some of these, such as a video file without audio included, are implementation limitations and are not feasible to solve. As an alternative, the Prune Outputs node is added to automate the deletion of these file outputs if they are not desired</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"filenames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filenames: A connection from a Video Combine node to indicate which outputs should be pruned</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"options\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">options: Which files should be deleted<div style=\"font-size: 1em\"><div vhs_title=\"Intermediate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Intermediate: Delete any files that were required for intermediate processing but are not the final output, like the no-audio output file when audio is included</div></div><div vhs_title=\"Intermediate and Utility\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Intermediate and Utility: Delete all produced files that aren't the final output, including the first frame png</div></div></div></div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": true}, "VHS_BatchManager": {"input": {"required": {"frames_per_batch": ["INT", {"default": 16, "min": 1, "max": 9007199254740991, "step": 1}]}, "hidden": {"prompt": "PROMPT", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["frames_per_batch"], "hidden": ["prompt", "unique_id"]}, "output": ["VHS_BatchManager"], "output_is_list": [false], "output_name": ["meta_batch"], "name": "VHS_BatchManager", "display_name": "Meta Batch Manager \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Meta Batch Manager \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Split the processing of a very long video into sets of smaller Meta Batches</div></div><div style=\"font-size: 0.8em\">The Meta Batch Manager allows for extremely long input videos to be processed when all other methods for fitting the content in RAM fail. It does not effect VRAM usage.</div><div style=\"font-size: 0.8em\">It must be connected to at least one Input (a Load Video or Load Images) AND at least one Video Combine</div><div style=\"font-size: 0.8em\"><img src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/7cb3fb7e-59d8-4cb2-a09f-9c6698de8b1f loading=lazy style=\"width: 0px; min-width: 100%\"></div><div style=\"font-size: 0.8em\">It functions by holding both the inputs and ouputs open between executions, and automatically requeue's the workflow until one of the inputs is unable to provide additional images.</div><div style=\"font-size: 0.8em\">Because each sub execution only contains a subset of the total frames, each sub execution creates a hard window which temporal smoothing can not be applied across. This results in jumps in the output.</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: Add all connected nodes to this Meta Batch</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"frames_per_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frames_per_batch: How many frames to process for each sub execution. If loading as image, each frame will use about 50MB of RAM (not VRAM), and this can safely be set in the 100-1000 range, depending on available memory. When loading and combining from latent space (no blue image noodles exist), this value can be much higher, around the 2,000 to 20,000 range</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_VideoInfo": {"input": {"required": {"video_info": ["VHS_VIDEOINFO"]}}, "input_order": {"required": ["video_info"]}, "output": ["FLOAT", "INT", "FLOAT", "INT", "INT", "FLOAT", "INT", "FLOAT", "INT", "INT"], "output_is_list": [false, false, false, false, false, false, false, false, false, false], "output_name": ["source_fps\ud83d\udfe8", "source_frame_count\ud83d\udfe8", "source_duration\ud83d\udfe8", "source_width\ud83d\udfe8", "source_height\ud83d\udfe8", "loaded_fps\ud83d\udfe6", "loaded_frame_count\ud83d\udfe6", "loaded_duration\ud83d\udfe6", "loaded_width\ud83d\udfe6", "loaded_height\ud83d\udfe6"], "name": "VHS_VideoInfo", "display_name": "Video Info \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Video Info \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Splits information on a video into a numerous outputs</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: A connection to a Load Video node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"source_fps\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_fps\ud83d\udfe8: The frame rate of the video</div></div><div vhs_title=\"source_frame_count\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_frame_count\ud83d\udfe8: How many total frames the video contains before accounting for frame rate or select_every_nth</div></div><div vhs_title=\"source_duration\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_duration\ud83d\udfe8: The length of images just returned in seconds</div></div><div vhs_title=\"source_width\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_width\ud83d\udfe8: The width</div></div><div vhs_title=\"source_height\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_height\ud83d\udfe8: The height</div></div><div vhs_title=\"loaded_fps\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_fps\ud83d\udfe6: The frame rate after accounting for force_rate and select_every_nth. This output is of particular use as it can be connected to the converted frame_rate input of a Video Combine node to ensure audio remains synchronized.</div></div><div vhs_title=\"loaded_frame_count\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_frame_count\ud83d\udfe6: The number of frames returned by the current execution. Identical to the frame_count returned by the node itself</div></div><div vhs_title=\"loaded_duration\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_duration\ud83d\udfe6: The duration in seconds of returned images after accounting for frame_load_cap</div></div><div vhs_title=\"loaded_width\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_width\ud83d\udfe6: The width of the video after scaling. These coordinates are in image space even if loading to latent space</div></div><div vhs_title=\"loaded_height\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_height\ud83d\udfe6: The height of the video after scaling. These coordinates are in image space even if loading to latent space</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_VideoInfoSource": {"input": {"required": {"video_info": ["VHS_VIDEOINFO"]}}, "input_order": {"required": ["video_info"]}, "output": ["FLOAT", "INT", "FLOAT", "INT", "INT"], "output_is_list": [false, false, false, false, false], "output_name": ["fps\ud83d\udfe8", "frame_count\ud83d\udfe8", "duration\ud83d\udfe8", "width\ud83d\udfe8", "height\ud83d\udfe8"], "name": "VHS_VideoInfoSource", "display_name": "Video Info (Source) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Video Info Source \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Splits information on a video into a numerous outputs describing the file itself without accounting for load options</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: A connection to a Load Video node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"source_fps\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_fps\ud83d\udfe8: The frame rate of the video</div></div><div vhs_title=\"source_frame_count\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_frame_count\ud83d\udfe8: How many total frames the video contains before accounting for frame rate or select_every_nth</div></div><div vhs_title=\"source_duration\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_duration\ud83d\udfe8: The length of images just returned in seconds</div></div><div vhs_title=\"source_width\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_width\ud83d\udfe8: The original width</div></div><div vhs_title=\"source_height\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_height\ud83d\udfe8: The original height</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_VideoInfoLoaded": {"input": {"required": {"video_info": ["VHS_VIDEOINFO"]}}, "input_order": {"required": ["video_info"]}, "output": ["FLOAT", "INT", "FLOAT", "INT", "INT"], "output_is_list": [false, false, false, false, false], "output_name": ["fps\ud83d\udfe6", "frame_count\ud83d\udfe6", "duration\ud83d\udfe6", "width\ud83d\udfe6", "height\ud83d\udfe6"], "name": "VHS_VideoInfoLoaded", "display_name": "Video Info (Loaded) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Video Info Loaded \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Splits information on a video into a numerous outputs describing the file itself after accounting for load options</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: A connection to a Load Video node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"loaded_fps\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_fps\ud83d\udfe6: The frame rate after accounting for force_rate and select_every_nth. This output is of particular use as it can be connected to the converted frame_rate input of a Video Combine node to ensure audio remains synchronized.</div></div><div vhs_title=\"loaded_frame_count\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_frame_count\ud83d\udfe6: The number of frames returned by the current execution. Identical to the frame_count returned by the node itself</div></div><div vhs_title=\"loaded_duration\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_duration\ud83d\udfe6: The duration in seconds of returned images after accounting for frame_load_cap</div></div><div vhs_title=\"loaded_width\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_width\ud83d\udfe6: The width of the video after scaling. This is the dimension of the corresponding image even if loading as a latent directly</div></div><div vhs_title=\"loaded_height\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_height\ud83d\udfe6: The height of the video after scaling. This is the dimension of the corresponding image even if loading as a latent directly</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_SelectFilename": {"input": {"required": {"filenames": ["VHS_FILENAMES"], "index": ["INT", {"default": -1, "step": 1, "min": -1}]}}, "input_order": {"required": ["filenames", "index"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["Filename"], "name": "VHS_SelectFilename", "display_name": "Select Filename \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "VAE Select Filename \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Select a single filename from the VHS_FILENAMES output by a Video Combine and return it as a string</div></div><div style=\"font-size: 0.8em\">Take care when combining this node with Prune Outputs. The VHS_FILENAMES object is immutable and will always contain the full list of output files, but execution order is undefined behavior (currently, Prune Outputs will generally execute first) and SelectFilename may return a path to a file that no longer exists.</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"filenames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filenames: A VHS_FILENAMES from a Video Combine node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"filename\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filename: A string representation of the full output path for the chosen file</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"index\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">index: The index of which file should be selected. The default, -1, chooses the most complete output</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_VAEEncodeBatched": {"input": {"required": {"pixels": ["IMAGE"], "vae": ["VAE"], "per_batch": ["INT", {"default": 16, "min": 1}]}}, "input_order": {"required": ["pixels", "vae", "per_batch"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VHS_VAEEncodeBatched", "display_name": "VAE Encode Batched \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "VAE Encode Batched \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Encode images as latents with a manually specified batch size.</div></div><div style=\"font-size: 0.8em\">Some people have ran into VRAM issues when encoding or decoding large batches of images. As a workaround, this node lets you manually set a batch size when encoding images.</div><div style=\"font-size: 0.8em\">Unless these issues have been encountered, it is simpler to use the native VAE Encode or to encode directly from a Load Video</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"pixels\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pixels: The images to be encoded.</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: The VAE to use when encoding.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The encoded latents.</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"per_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">per_batch: The maximum number of images to encode in each batch.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/batched nodes", "output_node": false}, "VHS_VAEDecodeBatched": {"input": {"required": {"samples": ["LATENT"], "vae": ["VAE"], "per_batch": ["INT", {"default": 16, "min": 1}]}}, "input_order": {"required": ["samples", "vae", "per_batch"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "VHS_VAEDecodeBatched", "display_name": "VAE Decode Batched \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "VAE Decode Batched \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Decode latents to images with a manually specified batch size</div></div><div style=\"font-size: 0.8em\">Some people have ran into VRAM issues when encoding or decoding large batches of images. As a workaround, this node lets you manually set a batch size when decoding latents.</div><div style=\"font-size: 0.8em\">Unless these issues have been encountered, it is simpler to use the native VAE Decode or to decode from a Video Combine directly</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"samples\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">samples: The latents to be decoded.</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: The VAE to use when decoding.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The decoded images.</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"per_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">per_batch: The maximum number of images to decode in each batch.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/batched nodes", "output_node": false}, "VHS_SplitLatents": {"input": {"required": {"latents": ["LATENT"], "split_index": ["INT", {"default": 0, "step": 1, "min": -9007199254740991, "max": 9007199254740991}]}}, "input_order": {"required": ["latents", "split_index"]}, "output": ["LATENT", "INT", "LATENT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["LATENT_A", "A_count", "LATENT_B", "B_count"], "name": "VHS_SplitLatents", "display_name": "Split Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Split Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Split a set of latents into two groups</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents: The latents to be split.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT_A: The first group of latents</div></div><div vhs_title=\"A_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">A_count: The number of latents in group A. This will be equal to split_index unless the latents input has length less than split_index</div></div><div vhs_title=\"LATENT_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT_B: The second group of latents</div></div><div vhs_title=\"B_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">B_count: The number of latents in group B</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"split_index\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">split_index: The index of the first latent that will be in the second output groups.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_SplitImages": {"input": {"required": {"images": ["IMAGE"], "split_index": ["INT", {"default": 0, "step": 1, "min": -9007199254740991, "max": 9007199254740991}]}}, "input_order": {"required": ["images", "split_index"]}, "output": ["IMAGE", "INT", "IMAGE", "INT"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE_A", "A_count", "IMAGE_B", "B_count"], "name": "VHS_SplitImages", "display_name": "Split Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Split Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Split a set of images into two groups</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images: The images to be split.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE_A: The first group of images</div></div><div vhs_title=\"A_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">A_count: The number of images in group A. This will be equal to split_index unless the images input has length less than split_index</div></div><div vhs_title=\"IMAGE_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE_B: The second group of images</div></div><div vhs_title=\"B_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">B_count: The number of images in group B</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"split_index\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">split_index: The index of the first latent that will be in the second output groups.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_SplitMasks": {"input": {"required": {"mask": ["MASK"], "split_index": ["INT", {"default": 0, "step": 1, "min": -9007199254740991, "max": 9007199254740991}]}}, "input_order": {"required": ["mask", "split_index"]}, "output": ["MASK", "INT", "MASK", "INT"], "output_is_list": [false, false, false, false], "output_name": ["MASK_A", "A_count", "MASK_B", "B_count"], "name": "VHS_SplitMasks", "display_name": "Split Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Split Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Split a set of masks into two groups</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask: The masks to be split.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"MASK_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK_A: The first group of masks</div></div><div vhs_title=\"A_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">A_count: The number of masks in group A. This will be equal to split_index unless the mask input has length less than split_index</div></div><div vhs_title=\"MASK_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK_B: The second group of masks</div></div><div vhs_title=\"B_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">B_count: The number of masks in group B</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"split_index\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">split_index: The index of the first latent that will be in the second output groups.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_MergeLatents": {"input": {"required": {"latents_A": ["LATENT"], "latents_B": ["LATENT"], "merge_strategy": [["match A", "match B", "match smaller", "match larger"]], "scale_method": [["nearest-exact", "bilinear", "area", "bicubic", "bislerp"]], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["latents_A", "latents_B", "merge_strategy", "scale_method", "crop"]}, "output": ["LATENT", "INT"], "output_is_list": [false, false], "output_name": ["LATENT", "count"], "name": "VHS_MergeLatents", "display_name": "Merge Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Merge Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Combine two groups of latents into a single group of latents</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents_A: The first group of latents</div></div><div vhs_title=\"latents_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents_B: The first group of latents</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The combined group of latents</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The length of the combined group</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"merge_strategy\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">merge_strategy: Determines what the output resolution will be if input resolutions don't match<div style=\"font-size: 1em\"><div vhs_title=\"match A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match A: Always use the resolution for A</div></div><div vhs_title=\"match B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match B: Always use the resolution for B</div></div><div vhs_title=\"match smaller\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match smaller: Pick the smaller resolution by area</div></div><div vhs_title=\"match larger\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match larger: Pick the larger resolution by area</div></div></div></div></div><div vhs_title=\"scale_method\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">scale_method: Determines what method to use if scaling is required</div></div><div vhs_title=\"crop\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">crop: When sizes don't match, should the resized image have it's aspect ratio changed, or be cropped to maintain aspect ratio</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_MergeImages": {"input": {"required": {"images_A": ["IMAGE"], "images_B": ["IMAGE"], "merge_strategy": [["match A", "match B", "match smaller", "match larger"]], "scale_method": [["nearest-exact", "bilinear", "area", "bicubic", "bislerp"]], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["images_A", "images_B", "merge_strategy", "scale_method", "crop"]}, "output": ["IMAGE", "INT"], "output_is_list": [false, false], "output_name": ["IMAGE", "count"], "name": "VHS_MergeImages", "display_name": "Merge Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Merge Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Combine two groups of images into a single group of images</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images_A: The first group of images</div></div><div vhs_title=\"images_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images_B: The first group of images</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The combined group of images</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The length of the combined group</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"merge_strategy\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">merge_strategy: Determines what the output resolution will be if input resolutions don't match<div style=\"font-size: 1em\"><div vhs_title=\"match A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match A: Always use the resolution for A</div></div><div vhs_title=\"match B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match B: Always use the resolution for B</div></div><div vhs_title=\"match smaller\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match smaller: Pick the smaller resolution by area</div></div><div vhs_title=\"match larger\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match larger: Pick the larger resolution by area</div></div></div></div></div><div vhs_title=\"scale_method\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">scale_method: Determines what method to use if scaling is required</div></div><div vhs_title=\"crop\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">crop: When sizes don't match, should the resized image have it's aspect ratio changed, or be cropped to maintain aspect ratio</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_MergeMasks": {"input": {"required": {"mask_A": ["MASK"], "mask_B": ["MASK"], "merge_strategy": [["match A", "match B", "match smaller", "match larger"]], "scale_method": [["nearest-exact", "bilinear", "area", "bicubic", "bislerp"]], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["mask_A", "mask_B", "merge_strategy", "scale_method", "crop"]}, "output": ["MASK", "INT"], "output_is_list": [false, false], "output_name": ["MASK", "count"], "name": "VHS_MergeMasks", "display_name": "Merge Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Merge Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Combine two groups of masks into a single group of masks</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"mask_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask_A: The first group of masks</div></div><div vhs_title=\"mask_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask_B: The first group of masks</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The combined group of masks</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The length of the combined group</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"merge_strategy\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">merge_strategy: Determines what the output resolution will be if input resolutions don't match<div style=\"font-size: 1em\"><div vhs_title=\"match A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match A: Always use the resolution for A</div></div><div vhs_title=\"match B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match B: Always use the resolution for B</div></div><div vhs_title=\"match smaller\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match smaller: Pick the smaller resolution by area</div></div><div vhs_title=\"match larger\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match larger: Pick the larger resolution by area</div></div></div></div></div><div vhs_title=\"scale_method\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">scale_method: Determines what method to use if scaling is required</div></div><div vhs_title=\"crop\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">crop: When sizes don't match, should the resized image have it's aspect ratio changed, or be cropped to maintain aspect ratio</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_GetLatentCount": {"input": {"required": {"latents": ["LATENT"]}}, "input_order": {"required": ["latents"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["count"], "name": "VHS_GetLatentCount", "display_name": "Get Latent Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Get Latent Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Return the number of latents in an input as an INT</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents: The input latent</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of latents in the input</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_GetImageCount": {"input": {"required": {"images": ["IMAGE"]}}, "input_order": {"required": ["images"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["count"], "name": "VHS_GetImageCount", "display_name": "Get Image Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Get Image Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Return the number of images in an input as an INT</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images: The input image</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of images in the input</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_GetMaskCount": {"input": {"required": {"mask": ["MASK"]}}, "input_order": {"required": ["mask"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["count"], "name": "VHS_GetMaskCount", "display_name": "Get Mask Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Get Mask Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Return the number of masks in an input as an INT</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"masks\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">masks: The input mask</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of masks in the input</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_DuplicateLatents": {"input": {"required": {"latents": ["LATENT"], "multiply_by": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["latents", "multiply_by"]}, "output": ["LATENT", "INT"], "output_is_list": [false, false], "output_name": ["LATENT", "count"], "name": "VHS_DuplicateLatents", "display_name": "Repeat Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Repeat Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Append copies of a latent to itself so it repeats</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents: The latents to be repeated</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The latent with repeats</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of latents in the output. Equal to the length of the input latent * multiply_by</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"multiply_by\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">multiply_by: Controls the number of times the latent should repeat. 1, the default, means no change.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_DuplicateImages": {"input": {"required": {"images": ["IMAGE"], "multiply_by": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["images", "multiply_by"]}, "output": ["IMAGE", "INT"], "output_is_list": [false, false], "output_name": ["IMAGE", "count"], "name": "VHS_DuplicateImages", "display_name": "Repeat Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Repeat Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Append copies of a image to itself so it repeats</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"IMAGES\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGES: The image to be repeated</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The image with repeats</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of image in the output. Equal to the length of the input image * multiply_by</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"multiply_by\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">multiply_by: Controls the number of times the mask should repeat. 1, the default, means no change.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_DuplicateMasks": {"input": {"required": {"mask": ["MASK"], "multiply_by": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["mask", "multiply_by"]}, "output": ["MASK", "INT"], "output_is_list": [false, false], "output_name": ["MASK", "count"], "name": "VHS_DuplicateMasks", "display_name": "Repeat Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Repeat Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Append copies of a mask to itself so it repeats</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"masks\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">masks: The masks to be repeated</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The mask with repeats</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of mask in the output. Equal to the length of the input mask * multiply_by</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"multiply_by\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">multiply_by: Controls the number of times the mask should repeat. 1, the default, means no change.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_SelectEveryNthLatent": {"input": {"required": {"latents": ["LATENT"], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}], "skip_first_latents": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["latents", "select_every_nth", "skip_first_latents"]}, "output": ["LATENT", "INT"], "output_is_list": [false, false], "output_name": ["LATENT", "count"], "name": "VHS_SelectEveryNthLatent", "display_name": "Select Every Nth Latent \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Select Every Nth Latent \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Keep only 1 latent for every interval</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents: The input latent</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The output latents</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of latents in the input</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: The interval from which one frame is kept. 1 means no frames are skipped.</div></div><div vhs_title=\"skip_first_latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_latents: A number of frames which that is skipped from the start. This applies before select_every_nth. As a result, multiple copies of the node can each have a different skip_first_frames to divide the latent into groups</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_SelectEveryNthImage": {"input": {"required": {"images": ["IMAGE"], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}], "skip_first_images": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["images", "select_every_nth", "skip_first_images"]}, "output": ["IMAGE", "INT"], "output_is_list": [false, false], "output_name": ["IMAGE", "count"], "name": "VHS_SelectEveryNthImage", "display_name": "Select Every Nth Image \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Select Every Nth Image \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Keep only 1 image for every interval</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images: The input image</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The output images</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of images in the input</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: The interval from which one frame is kept. 1 means no frames are skipped.</div></div><div vhs_title=\"skip_first_images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_images: A number of frames which that is skipped from the start. This applies before select_every_nth. As a result, multiple copies of the node can each have a different skip_first_frames to divide the image into groups</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_SelectEveryNthMask": {"input": {"required": {"mask": ["MASK"], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}], "skip_first_masks": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["mask", "select_every_nth", "skip_first_masks"]}, "output": ["MASK", "INT"], "output_is_list": [false, false], "output_name": ["MASK", "count"], "name": "VHS_SelectEveryNthMask", "display_name": "Select Every Nth Mask \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Select Every Nth Mask \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Keep only 1 mask for every interval</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask: The input mask</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The output mask</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of mask in the input</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: The interval from which one frame is kept. 1 means no frames are skipped.</div></div><div vhs_title=\"skip_first_mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_mask: A number of frames which that is skipped from the start. This applies before select_every_nth. As a result, multiple copies of the node can each have a different skip_first_frames to divide the mask into groups</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_SelectLatents": {"input": {"required": {"latent": ["LATENT"], "indexes": ["STRING", {"default": "0"}], "err_if_missing": ["BOOLEAN", {"default": true}], "err_if_empty": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["latent", "indexes", "err_if_missing", "err_if_empty"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VHS_SelectLatents", "display_name": "Select Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Use comma-separated indexes to select items in the given order.\nSupports negative indexes, python-style ranges (end index excluded),\nas well as range step.\n\nAcceptable entries (assuming 16 items provided, so idxs 0 to 15 exist):\n0         -> Returns [0]\n-1        -> Returns [15]\n0, 1, 13  -> Returns [0, 1, 13]\n0:5, 13   -> Returns [0, 1, 2, 3, 4, 13]\n0:-1      -> Returns [0, 1, 2, ..., 13, 14]\n0:5:-1    -> Returns [4, 3, 2, 1, 0]\n0:5:2     -> Returns [0, 2, 4]\n::-1     -> Returns [15, 14, 13, ..., 2, 1, 0]\n", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_SelectImages": {"input": {"required": {"image": ["IMAGE"], "indexes": ["STRING", {"default": "0"}], "err_if_missing": ["BOOLEAN", {"default": true}], "err_if_empty": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["image", "indexes", "err_if_missing", "err_if_empty"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "VHS_SelectImages", "display_name": "Select Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Use comma-separated indexes to select items in the given order.\nSupports negative indexes, python-style ranges (end index excluded),\nas well as range step.\n\nAcceptable entries (assuming 16 items provided, so idxs 0 to 15 exist):\n0         -> Returns [0]\n-1        -> Returns [15]\n0, 1, 13  -> Returns [0, 1, 13]\n0:5, 13   -> Returns [0, 1, 2, 3, 4, 13]\n0:-1      -> Returns [0, 1, 2, ..., 13, 14]\n0:5:-1    -> Returns [4, 3, 2, 1, 0]\n0:5:2     -> Returns [0, 2, 4]\n::-1     -> Returns [15, 14, 13, ..., 2, 1, 0]\n", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_SelectMasks": {"input": {"required": {"mask": ["MASK"], "indexes": ["STRING", {"default": "0"}], "err_if_missing": ["BOOLEAN", {"default": true}], "err_if_empty": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["mask", "indexes", "err_if_missing", "err_if_empty"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "VHS_SelectMasks", "display_name": "Select Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Use comma-separated indexes to select items in the given order.\nSupports negative indexes, python-style ranges (end index excluded),\nas well as range step.\n\nAcceptable entries (assuming 16 items provided, so idxs 0 to 15 exist):\n0         -> Returns [0]\n-1        -> Returns [15]\n0, 1, 13  -> Returns [0, 1, 13]\n0:5, 13   -> Returns [0, 1, 2, 3, 4, 13]\n0:-1      -> Returns [0, 1, 2, ..., 13, 14]\n0:5:-1    -> Returns [4, 3, 2, 1, 0]\n0:5:2     -> Returns [0, 2, 4]\n::-1     -> Returns [15, 14, 13, ..., 2, 1, 0]\n", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_Unbatch": {"input": {"required": {"batched": ["*"]}}, "input_order": {"required": ["batched"]}, "output": ["*"], "output_is_list": [false], "output_name": ["unbatched"], "name": "VHS_Unbatch", "display_name": "Unbatch \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Unbatch \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Unbatch a list of items into a single concatenated item</div></div><div style=\"font-size: 0.8em\">Useful for when you want a single video output from a complex workflow</div><div style=\"font-size: 0.8em\">Has no relation to the Meta Batch system of VHS</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"batched\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">batched: Any input which may or may not be batched</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"unbatched\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">unbatched: A single output element. Torch tensors are concatenated across dim 0, all other types are added which functions as concatenation for strings and arrays, but may give undesired results for other types</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_SelectLatest": {"input": {"required": {"filename_prefix": ["STRING", {"default": "output/AnimateDiff", "vhs_path_extensions": []}], "filename_postfix": ["STRING", {"placeholder": ".webm"}]}}, "input_order": {"required": ["filename_prefix", "filename_postfix"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["Filename"], "name": "VHS_SelectLatest", "display_name": "Select Latest \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Select Latest \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Experimental virtual node to select the most recently modified file from a given folder</div></div><div style=\"font-size: 0.8em\">Assists in the creation of workflows where outputs from one execution are used elsewhere in subsequent executions.</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"filename_prefix\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filename_prefix: A path which can consist of a combination of folders and a prefix which candidate files must match</div></div><div vhs_title=\"filename_postfix\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filename_postfix: A string which chich the selected file must end with. Useful for limiting to a target extension.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"Filename\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Filename: A string representing a file path to the most recently modified file.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false, "experimental": true}, "BOOLConstant": {"input": {"required": {"value": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["value"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["value"], "name": "BOOLConstant", "display_name": "BOOL Constant", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/constants", "output_node": false}, "INTConstant": {"input": {"required": {"value": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}]}}, "input_order": {"required": ["value"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["value"], "name": "INTConstant", "display_name": "INT Constant", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/constants", "output_node": false}, "FloatConstant": {"input": {"required": {"value": ["FLOAT", {"default": 0.0, "min": -18446744073709551615, "max": 18446744073709551615, "step": 1e-05}]}}, "input_order": {"required": ["value"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["value"], "name": "FloatConstant", "display_name": "Float Constant", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/constants", "output_node": false}, "StringConstant": {"input": {"required": {"string": ["STRING", {"default": "", "multiline": false}]}}, "input_order": {"required": ["string"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "StringConstant", "display_name": "String Constant", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/constants", "output_node": false}, "StringConstantMultiline": {"input": {"required": {"string": ["STRING", {"default": "", "multiline": true}], "strip_newlines": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["string", "strip_newlines"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "StringConstantMultiline", "display_name": "String Constant Multiline", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/constants", "output_node": false}, "ConditioningMultiCombine": {"input": {"required": {"inputcount": ["INT", {"default": 2, "min": 2, "max": 20, "step": 1}], "operation": [["combine", "concat"], {"default": "combine"}], "conditioning_1": ["CONDITIONING"], "conditioning_2": ["CONDITIONING"]}}, "input_order": {"required": ["inputcount", "operation", "conditioning_1", "conditioning_2"]}, "output": ["CONDITIONING", "INT"], "output_is_list": [false, false], "output_name": ["combined", "inputcount"], "name": "ConditioningMultiCombine", "display_name": "Conditioning Multi Combine", "description": "\nCombines multiple conditioning nodes into one\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/conditioning", "output_node": false}, "ConditioningSetMaskAndCombine": {"input": {"required": {"positive_1": ["CONDITIONING"], "negative_1": ["CONDITIONING"], "positive_2": ["CONDITIONING"], "negative_2": ["CONDITIONING"], "mask_1": ["MASK"], "mask_2": ["MASK"], "mask_1_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_2_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}}, "input_order": {"required": ["positive_1", "negative_1", "positive_2", "negative_2", "mask_1", "mask_2", "mask_1_strength", "mask_2_strength", "set_cond_area"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["combined_positive", "combined_negative"], "name": "ConditioningSetMaskAndCombine", "display_name": "ConditioningSetMaskAndCombine", "description": "\nBundles multiple conditioning mask and combine nodes into one,functionality is identical to ComfyUI native nodes\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/conditioning", "output_node": false}, "ConditioningSetMaskAndCombine3": {"input": {"required": {"positive_1": ["CONDITIONING"], "negative_1": ["CONDITIONING"], "positive_2": ["CONDITIONING"], "negative_2": ["CONDITIONING"], "positive_3": ["CONDITIONING"], "negative_3": ["CONDITIONING"], "mask_1": ["MASK"], "mask_2": ["MASK"], "mask_3": ["MASK"], "mask_1_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_2_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_3_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}}, "input_order": {"required": ["positive_1", "negative_1", "positive_2", "negative_2", "positive_3", "negative_3", "mask_1", "mask_2", "mask_3", "mask_1_strength", "mask_2_strength", "mask_3_strength", "set_cond_area"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["combined_positive", "combined_negative"], "name": "ConditioningSetMaskAndCombine3", "display_name": "ConditioningSetMaskAndCombine3", "description": "\nBundles multiple conditioning mask and combine nodes into one,functionality is identical to ComfyUI native nodes\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/conditioning", "output_node": false}, "ConditioningSetMaskAndCombine4": {"input": {"required": {"positive_1": ["CONDITIONING"], "negative_1": ["CONDITIONING"], "positive_2": ["CONDITIONING"], "negative_2": ["CONDITIONING"], "positive_3": ["CONDITIONING"], "negative_3": ["CONDITIONING"], "positive_4": ["CONDITIONING"], "negative_4": ["CONDITIONING"], "mask_1": ["MASK"], "mask_2": ["MASK"], "mask_3": ["MASK"], "mask_4": ["MASK"], "mask_1_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_2_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_3_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_4_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}}, "input_order": {"required": ["positive_1", "negative_1", "positive_2", "negative_2", "positive_3", "negative_3", "positive_4", "negative_4", "mask_1", "mask_2", "mask_3", "mask_4", "mask_1_strength", "mask_2_strength", "mask_3_strength", "mask_4_strength", "set_cond_area"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["combined_positive", "combined_negative"], "name": "ConditioningSetMaskAndCombine4", "display_name": "ConditioningSetMaskAndCombine4", "description": "\nBundles multiple conditioning mask and combine nodes into one,functionality is identical to ComfyUI native nodes\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/conditioning", "output_node": false}, "ConditioningSetMaskAndCombine5": {"input": {"required": {"positive_1": ["CONDITIONING"], "negative_1": ["CONDITIONING"], "positive_2": ["CONDITIONING"], "negative_2": ["CONDITIONING"], "positive_3": ["CONDITIONING"], "negative_3": ["CONDITIONING"], "positive_4": ["CONDITIONING"], "negative_4": ["CONDITIONING"], "positive_5": ["CONDITIONING"], "negative_5": ["CONDITIONING"], "mask_1": ["MASK"], "mask_2": ["MASK"], "mask_3": ["MASK"], "mask_4": ["MASK"], "mask_5": ["MASK"], "mask_1_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_2_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_3_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_4_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "mask_5_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}}, "input_order": {"required": ["positive_1", "negative_1", "positive_2", "negative_2", "positive_3", "negative_3", "positive_4", "negative_4", "positive_5", "negative_5", "mask_1", "mask_2", "mask_3", "mask_4", "mask_5", "mask_1_strength", "mask_2_strength", "mask_3_strength", "mask_4_strength", "mask_5_strength", "set_cond_area"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["combined_positive", "combined_negative"], "name": "ConditioningSetMaskAndCombine5", "display_name": "ConditioningSetMaskAndCombine5", "description": "\nBundles multiple conditioning mask and combine nodes into one,functionality is identical to ComfyUI native nodes\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/conditioning", "output_node": false}, "CondPassThrough": {"input": {"required": {}, "optional": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"]}}, "input_order": {"required": [], "optional": ["positive", "negative"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "CondPassThrough", "display_name": "CondPassThrough", "description": "\n    Simply passes through the positive and negative conditioning,\n    workaround for Set node not allowing bypassed inputs.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": false}, "DownloadAndLoadCLIPSeg": {"input": {"required": {"model": [["Kijai/clipseg-rd64-refined-fp16", "CIDAS/clipseg-rd64-refined"]]}}, "input_order": {"required": ["model"]}, "output": ["CLIPSEGMODEL"], "output_is_list": [false], "output_name": ["clipseg_model"], "name": "DownloadAndLoadCLIPSeg", "display_name": "(Down)load CLIPSeg", "description": "\nDownloads and loads CLIPSeg model with huggingface_hub,  \nto ComfyUI/models/clip_seg\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "BatchCLIPSeg": {"input": {"required": {"images": ["IMAGE"], "text": ["STRING", {"multiline": false}], "threshold": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 10.0, "step": 0.001}], "binary_mask": ["BOOLEAN", {"default": true}], "combine_mask": ["BOOLEAN", {"default": false}], "use_cuda": ["BOOLEAN", {"default": true}]}, "optional": {"blur_sigma": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.1}], "opt_model": ["CLIPSEGMODEL"], "prev_mask": ["MASK", {"default": null}], "image_bg_level": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "invert": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["images", "text", "threshold", "binary_mask", "combine_mask", "use_cuda"], "optional": ["blur_sigma", "opt_model", "prev_mask", "image_bg_level", "invert"]}, "output": ["MASK", "IMAGE"], "output_is_list": [false, false], "output_name": ["Mask", "Image"], "name": "BatchCLIPSeg", "display_name": "Batch CLIPSeg", "description": "\nSegments an image or batch of images using CLIPSeg.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "ColorToMask": {"input": {"required": {"images": ["IMAGE"], "invert": ["BOOLEAN", {"default": false}], "red": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "green": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "blue": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "threshold": ["INT", {"default": 10, "min": 0, "max": 255, "step": 1}], "per_batch": ["INT", {"default": 16, "min": 1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["images", "invert", "red", "green", "blue", "threshold", "per_batch"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ColorToMask", "display_name": "Color To Mask", "description": "\nConverts chosen RGB value to a mask.  \nWith batch inputs, the **per_batch**  \ncontrols the number of images processed at once.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "CreateGradientMask": {"input": {"required": {"invert": ["BOOLEAN", {"default": false}], "frames": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "width": ["INT", {"default": 256, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 256, "min": 16, "max": 4096, "step": 1}]}}, "input_order": {"required": ["invert", "frames", "width", "height"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "CreateGradientMask", "display_name": "Create Gradient Mask", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "CreateTextMask": {"input": {"required": {"invert": ["BOOLEAN", {"default": false}], "frames": ["INT", {"default": 1, "min": 1, "max": 4096, "step": 1}], "text_x": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}], "text_y": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}], "font_size": ["INT", {"default": 32, "min": 8, "max": 4096, "step": 1}], "font_color": ["STRING", {"default": "white"}], "text": ["STRING", {"default": "HELLO!", "multiline": true}], "font": [["FreeMono.ttf", "FreeMonoBoldOblique.otf", "TTNorms-Black.otf"]], "width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "start_rotation": ["INT", {"default": 0, "min": 0, "max": 359, "step": 1}], "end_rotation": ["INT", {"default": 0, "min": -359, "max": 359, "step": 1}]}}, "input_order": {"required": ["invert", "frames", "text_x", "text_y", "font_size", "font_color", "text", "font", "width", "height", "start_rotation", "end_rotation"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "CreateTextMask", "display_name": "Create Text Mask", "description": "\nCreates a text image and mask.  \nLooks for fonts from this folder:  \nComfyUI/custom_nodes/ComfyUI-KJNodes/fonts\n  \nIf start_rotation and/or end_rotation are different values,  \ncreates animation between them.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "CreateAudioMask": {"input": {"required": {"invert": ["BOOLEAN", {"default": false}], "frames": ["INT", {"default": 16, "min": 1, "max": 255, "step": 1}], "scale": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 2.0, "step": 0.01}], "audio_path": ["STRING", {"default": "audio.wav"}], "width": ["INT", {"default": 256, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 256, "min": 16, "max": 4096, "step": 1}]}}, "input_order": {"required": ["invert", "frames", "scale", "audio_path", "width", "height"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "CreateAudioMask", "display_name": "Create Audio Mask", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/deprecated", "output_node": false}, "CreateFadeMask": {"input": {"required": {"invert": ["BOOLEAN", {"default": false}], "frames": ["INT", {"default": 2, "min": 2, "max": 10000, "step": 1}], "width": ["INT", {"default": 256, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 256, "min": 16, "max": 4096, "step": 1}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "start_level": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "midpoint_level": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "end_level": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "midpoint_frame": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}]}}, "input_order": {"required": ["invert", "frames", "width", "height", "interpolation", "start_level", "midpoint_level", "end_level", "midpoint_frame"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "CreateFadeMask", "display_name": "Create Fade Mask", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/deprecated", "output_node": false}, "CreateFadeMaskAdvanced": {"input": {"required": {"points_string": ["STRING", {"default": "0:(0.0),\n7:(1.0),\n15:(0.0)\n", "multiline": true}], "invert": ["BOOLEAN", {"default": false}], "frames": ["INT", {"default": 16, "min": 2, "max": 10000, "step": 1}], "width": ["INT", {"default": 512, "min": 1, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 1, "max": 4096, "step": 1}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out", "none", "default_to_black"]]}}, "input_order": {"required": ["points_string", "invert", "frames", "width", "height", "interpolation"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "CreateFadeMaskAdvanced", "display_name": "Create Fade Mask Advanced", "description": "\nCreate a batch of masks interpolated between given frames and values. \nUses same syntax as Fizz' BatchValueSchedule.\nFirst value is the frame index (not that this starts from 0, not 1) \nand the second value inside the brackets is the float value of the mask in range 0.0 - 1.0  \n\nFor example the default values:  \n0:(0.0)  \n7:(1.0)  \n15:(0.0)  \n  \nWould create a mask batch fo 16 frames, starting from black, \ninterpolating with the chosen curve to fully white at the 8th frame, \nand interpolating from that to fully black at the 16th frame.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "CreateFluidMask": {"input": {"required": {"invert": ["BOOLEAN", {"default": false}], "frames": ["INT", {"default": 1, "min": 1, "max": 4096, "step": 1}], "width": ["INT", {"default": 256, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 256, "min": 16, "max": 4096, "step": 1}], "inflow_count": ["INT", {"default": 3, "min": 0, "max": 255, "step": 1}], "inflow_velocity": ["INT", {"default": 1, "min": 0, "max": 255, "step": 1}], "inflow_radius": ["INT", {"default": 8, "min": 0, "max": 255, "step": 1}], "inflow_padding": ["INT", {"default": 50, "min": 0, "max": 255, "step": 1}], "inflow_duration": ["INT", {"default": 60, "min": 0, "max": 255, "step": 1}]}}, "input_order": {"required": ["invert", "frames", "width", "height", "inflow_count", "inflow_velocity", "inflow_radius", "inflow_padding", "inflow_duration"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "CreateFluidMask", "display_name": "Create Fluid Mask", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "CreateShapeMask": {"input": {"required": {"shape": [["circle", "square", "triangle"], {"default": "circle"}], "frames": ["INT", {"default": 1, "min": 1, "max": 4096, "step": 1}], "location_x": ["INT", {"default": 256, "min": 0, "max": 4096, "step": 1}], "location_y": ["INT", {"default": 256, "min": 0, "max": 4096, "step": 1}], "grow": ["INT", {"default": 0, "min": -512, "max": 512, "step": 1}], "frame_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "shape_width": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 1}], "shape_height": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 1}]}}, "input_order": {"required": ["shape", "frames", "location_x", "location_y", "grow", "frame_width", "frame_height", "shape_width", "shape_height"]}, "output": ["MASK", "MASK"], "output_is_list": [false, false], "output_name": ["mask", "mask_inverted"], "name": "CreateShapeMask", "display_name": "Create Shape Mask", "description": "\nCreates a mask or batch of masks with the specified shape.  \nLocations are center locations.  \nGrow value is the amount to grow the shape on each frame, creating animated masks.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "CreateVoronoiMask": {"input": {"required": {"frames": ["INT", {"default": 16, "min": 2, "max": 4096, "step": 1}], "num_points": ["INT", {"default": 15, "min": 1, "max": 4096, "step": 1}], "line_width": ["INT", {"default": 4, "min": 1, "max": 4096, "step": 1}], "speed": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "frame_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}]}}, "input_order": {"required": ["frames", "num_points", "line_width", "speed", "frame_width", "frame_height"]}, "output": ["MASK", "MASK"], "output_is_list": [false, false], "output_name": ["mask", "mask_inverted"], "name": "CreateVoronoiMask", "display_name": "Create Voronoi Mask", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "CreateMagicMask": {"input": {"required": {"frames": ["INT", {"default": 16, "min": 2, "max": 4096, "step": 1}], "depth": ["INT", {"default": 12, "min": 1, "max": 500, "step": 1}], "distortion": ["FLOAT", {"default": 1.5, "min": 0.0, "max": 100.0, "step": 0.01}], "seed": ["INT", {"default": 123, "min": 0, "max": 99999999, "step": 1}], "transitions": ["INT", {"default": 1, "min": 1, "max": 20, "step": 1}], "frame_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}]}}, "input_order": {"required": ["frames", "depth", "distortion", "seed", "transitions", "frame_width", "frame_height"]}, "output": ["MASK", "MASK"], "output_is_list": [false, false], "output_name": ["mask", "mask_inverted"], "name": "CreateMagicMask", "display_name": "Create Magic Mask", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "GetMaskSizeAndCount": {"input": {"required": {"mask": ["MASK"]}}, "input_order": {"required": ["mask"]}, "output": ["MASK", "INT", "INT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["mask", "width", "height", "count"], "name": "GetMaskSizeAndCount", "display_name": "Get Mask Size & Count", "description": "\nReturns the width, height and batch size of the mask,  \nand passes it through unchanged.  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "GrowMaskWithBlur": {"input": {"required": {"mask": ["MASK"], "expand": ["INT", {"default": 0, "min": -16384, "max": 16384, "step": 1}], "incremental_expandrate": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.1}], "tapered_corners": ["BOOLEAN", {"default": true}], "flip_input": ["BOOLEAN", {"default": false}], "blur_radius": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100, "step": 0.1}], "lerp_alpha": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "decay_factor": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"fill_holes": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["mask", "expand", "incremental_expandrate", "tapered_corners", "flip_input", "blur_radius", "lerp_alpha", "decay_factor"], "optional": ["fill_holes"]}, "output": ["MASK", "MASK"], "output_is_list": [false, false], "output_name": ["mask", "mask_inverted"], "name": "GrowMaskWithBlur", "display_name": "Grow Mask With Blur", "description": "\n# GrowMaskWithBlur\n- mask: Input mask or mask batch\n- expand: Expand or contract mask or mask batch by a given amount\n- incremental_expandrate: increase expand rate by a given amount per frame\n- tapered_corners: use tapered corners\n- flip_input: flip input mask\n- blur_radius: value higher than 0 will blur the mask\n- lerp_alpha: alpha value for interpolation between frames\n- decay_factor: decay value for interpolation between frames\n- fill_holes: fill holes in the mask (slow)", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "MaskBatchMulti": {"input": {"required": {"inputcount": ["INT", {"default": 2, "min": 2, "max": 1000, "step": 1}], "mask_1": ["MASK"], "mask_2": ["MASK"]}}, "input_order": {"required": ["inputcount", "mask_1", "mask_2"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["masks"], "name": "MaskBatchMulti", "display_name": "Mask Batch Multi", "description": "\nCreates an image batch from multiple masks.  \nYou can set how many inputs the node has,  \nwith the **inputcount** and clicking update.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "OffsetMask": {"input": {"required": {"mask": ["MASK"], "x": ["INT", {"default": 0, "min": -4096, "max": 16384, "step": 1, "display": "number"}], "y": ["INT", {"default": 0, "min": -4096, "max": 16384, "step": 1, "display": "number"}], "angle": ["INT", {"default": 0, "min": -360, "max": 360, "step": 1, "display": "number"}], "duplication_factor": ["INT", {"default": 1, "min": 1, "max": 1000, "step": 1, "display": "number"}], "roll": ["BOOLEAN", {"default": false}], "incremental": ["BOOLEAN", {"default": false}], "padding_mode": [["empty", "border", "reflection"], {"default": "empty"}]}}, "input_order": {"required": ["mask", "x", "y", "angle", "duplication_factor", "roll", "incremental", "padding_mode"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["mask"], "name": "OffsetMask", "display_name": "Offset Mask", "description": "\nOffsets the mask by the specified amount.  \n - mask: Input mask or mask batch\n - x: Horizontal offset\n - y: Vertical offset\n - angle: Angle in degrees\n - roll: roll edge wrapping\n - duplication_factor: Number of times to duplicate the mask to form a batch\n - border padding_mode: Padding mode for the mask\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "RemapMaskRange": {"input": {"required": {"mask": ["MASK"], "min": ["FLOAT", {"default": 0.0, "min": -10.0, "max": 1.0, "step": 0.01}], "max": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["mask", "min", "max"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["mask"], "name": "RemapMaskRange", "display_name": "Remap Mask Range", "description": "\nSets new min and max values for the mask.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "ResizeMask": {"input": {"required": {"mask": ["MASK"], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1, "display": "number"}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1, "display": "number"}], "keep_proportions": ["BOOLEAN", {"default": false}], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["mask", "width", "height", "keep_proportions", "upscale_method", "crop"]}, "output": ["MASK", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["mask", "width", "height"], "name": "ResizeMask", "display_name": "Resize Mask", "description": "\nResizes the mask or batch of masks to the specified width and height.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "RoundMask": {"input": {"required": {"mask": ["MASK"]}}, "input_order": {"required": ["mask"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "RoundMask", "display_name": "Round Mask", "description": "\nRounds the mask or batch of masks to a binary mask.  \n<img src=\"https://github.com/kijai/ComfyUI-KJNodes/assets/40791699/52c85202-f74e-4b96-9dac-c8bda5ddcc40\" width=\"300\" height=\"250\" alt=\"RoundMask example\">\n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "SeparateMasks": {"input": {"required": {"mask": ["MASK"], "size_threshold_width": ["INT", {"default": 256, "min": 0.0, "max": 4096, "step": 1}], "size_threshold_height": ["INT", {"default": 256, "min": 0.0, "max": 4096, "step": 1}], "mode": [["convex_polygons", "area"]], "max_poly_points": ["INT", {"default": 8, "min": 3, "max": 32, "step": 1}]}}, "input_order": {"required": ["mask", "size_threshold_width", "size_threshold_height", "mode", "max_poly_points"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["mask"], "name": "SeparateMasks", "display_name": "Separate Masks", "description": "Separates a mask into multiple masks based on the size of the connected components.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": true}, "AddLabel": {"input": {"required": {"image": ["IMAGE"], "text_x": ["INT", {"default": 10, "min": 0, "max": 4096, "step": 1}], "text_y": ["INT", {"default": 2, "min": 0, "max": 4096, "step": 1}], "height": ["INT", {"default": 48, "min": -1, "max": 4096, "step": 1}], "font_size": ["INT", {"default": 32, "min": 0, "max": 4096, "step": 1}], "font_color": ["STRING", {"default": "white"}], "label_color": ["STRING", {"default": "black"}], "font": [["FreeMono.ttf", "FreeMonoBoldOblique.otf", "TTNorms-Black.otf"]], "text": ["STRING", {"default": "Text"}], "direction": [["up", "down", "left", "right", "overlay"], {"default": "up"}]}, "optional": {"caption": ["STRING", {"default": "", "forceInput": true}]}}, "input_order": {"required": ["image", "text_x", "text_y", "height", "font_size", "font_color", "label_color", "font", "text", "direction"], "optional": ["caption"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "AddLabel", "display_name": "Add Label", "description": "\nCreates a new with the given text, and concatenates it to  \neither above or below the input image.  \nNote that this changes the input image's height!  \nFonts are loaded from this folder:  \nComfyUI/custom_nodes/ComfyUI-KJNodes/fonts\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "ColorMatch": {"input": {"required": {"image_ref": ["IMAGE"], "image_target": ["IMAGE"], "method": [["mkl", "hm", "reinhard", "mvgd", "hm-mvgd-hm", "hm-mkl-hm"], {"default": "mkl"}]}, "optional": {"strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["image_ref", "image_target", "method"], "optional": ["strength"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "ColorMatch", "display_name": "Color Match", "description": "\ncolor-matcher enables color transfer across images which comes in handy for automatic  \ncolor-grading of photographs, paintings and film sequences as well as light-field  \nand stopmotion corrections.  \n\nThe methods behind the mappings are based on the approach from Reinhard et al.,  \nthe Monge-Kantorovich Linearization (MKL) as proposed by Pitie et al. and our analytical solution  \nto a Multi-Variate Gaussian Distribution (MVGD) transfer in conjunction with classical histogram   \nmatching. As shown below our HM-MVGD-HM compound outperforms existing methods.   \nhttps://github.com/hahnec/color-matcher/\n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageTensorList": {"input": {"required": {"image1": ["IMAGE"], "image2": ["IMAGE"]}}, "input_order": {"required": ["image1", "image2"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageTensorList", "display_name": "Image Tensor List", "description": "\nCreates an image list from the input images.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "CrossFadeImages": {"input": {"required": {"images_1": ["IMAGE"], "images_2": ["IMAGE"], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out", "bounce", "elastic", "glitchy", "exponential_ease_out"]], "transition_start_index": ["INT", {"default": 1, "min": 0, "max": 4096, "step": 1}], "transitioning_frames": ["INT", {"default": 1, "min": 0, "max": 4096, "step": 1}], "start_level": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "end_level": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["images_1", "images_2", "interpolation", "transition_start_index", "transitioning_frames", "start_level", "end_level"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "CrossFadeImages", "display_name": "Cross Fade Images", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "CrossFadeImagesMulti": {"input": {"required": {"inputcount": ["INT", {"default": 2, "min": 2, "max": 1000, "step": 1}], "image_1": ["IMAGE"], "image_2": ["IMAGE"], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out", "bounce", "elastic", "glitchy", "exponential_ease_out"]], "transitioning_frames": ["INT", {"default": 1, "min": 0, "max": 4096, "step": 1}]}}, "input_order": {"required": ["inputcount", "image_1", "image_2", "interpolation", "transitioning_frames"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "CrossFadeImagesMulti", "display_name": "Cross Fade Images Multi", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "GetImagesFromBatchIndexed": {"input": {"required": {"images": ["IMAGE"], "indexes": ["STRING", {"default": "0, 1, 2", "multiline": true}]}}, "input_order": {"required": ["images", "indexes"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "GetImagesFromBatchIndexed", "display_name": "Get Images From Batch Indexed", "description": "\nSelects and returns the images at the specified indices as an image batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "GetImageRangeFromBatch": {"input": {"required": {"start_index": ["INT", {"default": 0, "min": -1, "max": 4096, "step": 1}], "num_frames": ["INT", {"default": 1, "min": 1, "max": 4096, "step": 1}]}, "optional": {"images": ["IMAGE"], "masks": ["MASK"]}}, "input_order": {"required": ["start_index", "num_frames"], "optional": ["images", "masks"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "GetImageRangeFromBatch", "display_name": "Get Image or Mask Range From Batch", "description": "\nReturns a range of images from a batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "GetLatentRangeFromBatch": {"input": {"required": {"latents": ["LATENT"], "start_index": ["INT", {"default": 0, "min": -1, "max": 4096, "step": 1}], "num_frames": ["INT", {"default": 1, "min": -1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["latents", "start_index", "num_frames"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "GetLatentRangeFromBatch", "display_name": "Get Latent Range From Batch", "description": "\nReturns a range of latents from a batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/latents", "output_node": false}, "GetImageSizeAndCount": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "INT", "INT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["image", "width", "height", "count"], "name": "GetImageSizeAndCount", "display_name": "Get Image Size & Count", "description": "\nReturns width, height and batch size of the image,  \nand passes it through unchanged.  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "FastPreview": {"input": {"required": {"image": ["IMAGE"], "format": [["JPEG", "PNG", "WEBP"], {"default": "JPEG"}], "quality": ["INT", {"default": 75, "min": 1, "max": 100, "step": 1}]}}, "input_order": {"required": ["image", "format", "quality"]}, "output": [], "output_is_list": [], "output_name": [], "name": "FastPreview", "display_name": "Fast Preview", "description": "Experimental node for faster image previews by displaying through base64 it without saving to disk.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": true}, "ImageBatchFilter": {"input": {"required": {"images": ["IMAGE"], "empty_color": ["STRING", {"default": "0, 0, 0"}], "empty_threshold": ["FLOAT", {"default": 0.01, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"replacement_image": ["IMAGE"]}}, "input_order": {"required": ["images", "empty_color", "empty_threshold"], "optional": ["replacement_image"]}, "output": ["IMAGE", "STRING"], "output_is_list": [false, false], "output_name": ["images", "removed_indices"], "name": "ImageBatchFilter", "display_name": "Image Batch Filter", "description": "Removes empty images from a batch", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageAndMaskPreview": {"input": {"required": {"mask_opacity": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "mask_color": ["STRING", {"default": "255, 255, 255"}], "pass_through": ["BOOLEAN", {"default": false}]}, "optional": {"image": ["IMAGE"], "mask": ["MASK"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["mask_opacity", "mask_color", "pass_through"], "optional": ["image", "mask"], "hidden": ["prompt", "extra_pnginfo"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["composite"], "name": "ImageAndMaskPreview", "display_name": "ImageAndMaskPreview", "description": "\nPreview an image or a mask, when both inputs are used  \ncomposites the mask on top of the image.\nwith pass_through on the preview is disabled and the  \ncomposite is returned from the composite slot instead,  \nthis allows for the preview to be passed for video combine  \nnodes for example.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": true}, "ImageAddMulti": {"input": {"required": {"inputcount": ["INT", {"default": 2, "min": 2, "max": 1000, "step": 1}], "image_1": ["IMAGE"], "image_2": ["IMAGE"], "blending": [["add", "subtract", "multiply", "difference"], {"default": "add"}], "blend_amount": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 0.01}]}}, "input_order": {"required": ["inputcount", "image_1", "image_2", "blending", "blend_amount"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "ImageAddMulti", "display_name": "Image Add Multi", "description": "\nAdd blends multiple images together.    \nYou can set how many inputs the node has,  \nwith the **inputcount** and clicking update.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageBatchMulti": {"input": {"required": {"inputcount": ["INT", {"default": 2, "min": 2, "max": 1000, "step": 1}], "image_1": ["IMAGE"], "image_2": ["IMAGE"]}}, "input_order": {"required": ["inputcount", "image_1", "image_2"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "ImageBatchMulti", "display_name": "Image Batch Multi", "description": "\nCreates an image batch from multiple images.  \nYou can set how many inputs the node has,  \nwith the **inputcount** and clicking update.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageBatchRepeatInterleaving": {"input": {"required": {"images": ["IMAGE"], "repeats": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"mask": ["MASK"]}}, "input_order": {"required": ["images", "repeats"], "optional": ["mask"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "ImageBatchRepeatInterleaving", "display_name": "ImageBatchRepeatInterleaving", "description": "\nRepeats each image in a batch by the specified number of times.  \nExample batch of 5 images: 0, 1 ,2, 3, 4  \nwith repeats 2 becomes batch of 10 images: 0, 0, 1, 1, 2, 2, 3, 3, 4, 4  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageBatchTestPattern": {"input": {"required": {"batch_size": ["INT", {"default": 1, "min": 1, "max": 255, "step": 1}], "start_from": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "text_x": ["INT", {"default": 256, "min": 0, "max": 4096, "step": 1}], "text_y": ["INT", {"default": 256, "min": 0, "max": 4096, "step": 1}], "width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "font": [["FreeMono.ttf", "FreeMonoBoldOblique.otf", "TTNorms-Black.otf"]], "font_size": ["INT", {"default": 255, "min": 8, "max": 4096, "step": 1}]}}, "input_order": {"required": ["batch_size", "start_from", "text_x", "text_y", "width", "height", "font", "font_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageBatchTestPattern", "display_name": "Image Batch Test Pattern", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "ImageConcanate": {"input": {"required": {"image1": ["IMAGE"], "image2": ["IMAGE"], "direction": [["right", "down", "left", "up"], {"default": "right"}], "match_image_size": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["image1", "image2", "direction", "match_image_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageConcanate", "display_name": "Image Concatenate", "description": "\nConcatenates the image2 to image1 in the specified direction.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageConcatFromBatch": {"input": {"required": {"images": ["IMAGE"], "num_columns": ["INT", {"default": 3, "min": 1, "max": 255, "step": 1}], "match_image_size": ["BOOLEAN", {"default": false}], "max_resolution": ["INT", {"default": 4096}]}}, "input_order": {"required": ["images", "num_columns", "match_image_size", "max_resolution"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageConcatFromBatch", "display_name": "Image Concatenate From Batch", "description": "\n    Concatenates images from a batch into a grid with a specified number of columns.\n    ", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageConcatMulti": {"input": {"required": {"inputcount": ["INT", {"default": 2, "min": 2, "max": 1000, "step": 1}], "image_1": ["IMAGE"], "image_2": ["IMAGE"], "direction": [["right", "down", "left", "up"], {"default": "right"}], "match_image_size": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["inputcount", "image_1", "image_2", "direction", "match_image_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "ImageConcatMulti", "display_name": "Image Concatenate Multi", "description": "\nCreates an image from multiple images.  \nYou can set how many inputs the node has,  \nwith the **inputcount** and clicking update.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageCropByMask": {"input": {"required": {"image": ["IMAGE"], "mask": ["MASK"]}}, "input_order": {"required": ["image", "mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "ImageCropByMask", "display_name": "Image Crop By Mask", "description": "Crops the input images based on the provided mask.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageCropByMaskAndResize": {"input": {"required": {"image": ["IMAGE"], "mask": ["MASK"], "base_resolution": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}], "padding": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "min_crop_resolution": ["INT", {"default": 128, "min": 0, "max": 16384, "step": 8}], "max_crop_resolution": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}]}}, "input_order": {"required": ["image", "mask", "base_resolution", "padding", "min_crop_resolution", "max_crop_resolution"]}, "output": ["IMAGE", "MASK", "BBOX"], "output_is_list": [false, false, false], "output_name": ["images", "masks", "bbox"], "name": "ImageCropByMaskAndResize", "display_name": "Image Crop By Mask And Resize", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageCropByMaskBatch": {"input": {"required": {"image": ["IMAGE"], "masks": ["MASK"], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}], "padding": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}], "preserve_size": ["BOOLEAN", {"default": false}], "bg_color": ["STRING", {"default": "0, 0, 0", "tooltip": "Color as RGB values in range 0-255, separated by commas."}]}}, "input_order": {"required": ["image", "masks", "width", "height", "padding", "preserve_size", "bg_color"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["images", "masks"], "name": "ImageCropByMaskBatch", "display_name": "Image Crop By Mask Batch", "description": "Crops the input images based on the provided masks.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageUncropByMask": {"input": {"required": {"destination": ["IMAGE"], "source": ["IMAGE"], "mask": ["MASK"], "bbox": ["BBOX"]}}, "input_order": {"required": ["destination", "source", "mask", "bbox"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "ImageUncropByMask", "display_name": "Image Uncrop By Mask", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageGrabPIL": {"input": {"required": {"x": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}], "width": ["INT", {"default": 512, "min": 0, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 0, "max": 4096, "step": 1}], "num_frames": ["INT", {"default": 1, "min": 1, "max": 255, "step": 1}], "delay": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["x", "y", "width", "height", "num_frames", "delay"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "ImageGrabPIL", "display_name": "Image Grab PIL", "description": "\nCaptures an area specified by screen coordinates.  \nCan be used for realtime diffusion with autoqueue.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageGridComposite2x2": {"input": {"required": {"image1": ["IMAGE"], "image2": ["IMAGE"], "image3": ["IMAGE"], "image4": ["IMAGE"]}}, "input_order": {"required": ["image1", "image2", "image3", "image4"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageGridComposite2x2", "display_name": "Image Grid Composite 2x2", "description": "\nConcatenates the 4 input images into a 2x2 grid. \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageGridComposite3x3": {"input": {"required": {"image1": ["IMAGE"], "image2": ["IMAGE"], "image3": ["IMAGE"], "image4": ["IMAGE"], "image5": ["IMAGE"], "image6": ["IMAGE"], "image7": ["IMAGE"], "image8": ["IMAGE"], "image9": ["IMAGE"]}}, "input_order": {"required": ["image1", "image2", "image3", "image4", "image5", "image6", "image7", "image8", "image9"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageGridComposite3x3", "display_name": "Image Grid Composite 3x3", "description": "\nConcatenates the 9 input images into a 3x3 grid. \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageGridtoBatch": {"input": {"required": {"image": ["IMAGE"], "columns": ["INT", {"default": 3, "min": 1, "max": 8, "tooltip": "The number of columns in the grid."}], "rows": ["INT", {"default": 0, "min": 1, "max": 8, "tooltip": "The number of rows in the grid. Set to 0 for automatic calculation."}]}}, "input_order": {"required": ["image", "columns", "rows"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageGridtoBatch", "display_name": "Image Grid To Batch", "description": "Converts a grid of images to a batch of images.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageNoiseAugmentation": {"input": {"required": {"image": ["IMAGE"], "noise_aug_strength": ["FLOAT", {"default": null, "min": 0.0, "max": 100.0, "step": 0.001}], "seed": ["INT", {"default": 123, "min": 0, "max": 18446744073709551615, "step": 1}]}}, "input_order": {"required": ["image", "noise_aug_strength", "seed"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageNoiseAugmentation", "display_name": "Image Noise Augmentation", "description": "\n    Add noise to an image.  \n    ", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageNormalize_Neg1_To_1": {"input": {"required": {"images": ["IMAGE"]}}, "input_order": {"required": ["images"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageNormalize_Neg1_To_1", "display_name": "Image Normalize -1 to 1", "description": "\nNormalize the images to be in the range [-1, 1]  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImagePass": {"input": {"required": {}, "optional": {"image": ["IMAGE"]}}, "input_order": {"required": [], "optional": ["image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImagePass", "display_name": "ImagePass", "description": "\nPasses the image through without modifying it.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImagePadKJ": {"input": {"required": {"image": ["IMAGE"], "left": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "right": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "top": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "bottom": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "extra_padding": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "pad_mode": [["edge", "color"]], "color": ["STRING", {"default": "0, 0, 0", "tooltip": "Color as RGB values in range 0-255, separated by commas."}]}, "optional": {"mask": ["MASK"], "target_width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1, "forceInput": true}], "target_height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1, "forceInput": true}]}}, "input_order": {"required": ["image", "left", "right", "top", "bottom", "extra_padding", "pad_mode", "color"], "optional": ["mask", "target_width", "target_height"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["images", "masks"], "name": "ImagePadKJ", "display_name": "ImagePad KJ", "description": "Pad the input image and optionally mask with the specified padding.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImagePadForOutpaintMasked": {"input": {"required": {"image": ["IMAGE"], "left": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "top": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "right": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "bottom": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "feathering": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}]}, "optional": {"mask": ["MASK"]}}, "input_order": {"required": ["image", "left", "top", "right", "bottom", "feathering"], "optional": ["mask"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "ImagePadForOutpaintMasked", "display_name": "Image Pad For Outpaint Masked", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "image", "output_node": false}, "ImagePadForOutpaintTargetSize": {"input": {"required": {"image": ["IMAGE"], "target_width": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "target_height": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "feathering": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]]}, "optional": {"mask": ["MASK"]}}, "input_order": {"required": ["image", "target_width", "target_height", "feathering", "upscale_method"], "optional": ["mask"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "ImagePadForOutpaintTargetSize", "display_name": "Image Pad For Outpaint Target Size", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "image", "output_node": false}, "ImagePrepForICLora": {"input": {"required": {"reference_image": ["IMAGE"], "output_width": ["INT", {"default": 1024, "min": 1, "max": 4096, "step": 1}], "output_height": ["INT", {"default": 1024, "min": 1, "max": 4096, "step": 1}], "border_width": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}]}, "optional": {"latent_image": ["IMAGE"], "latent_mask": ["MASK"], "reference_mask": ["MASK"]}}, "input_order": {"required": ["reference_image", "output_width", "output_height", "border_width"], "optional": ["latent_image", "latent_mask", "reference_mask"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "ImagePrepForICLora", "display_name": "Image Prep For ICLora", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "image", "output_node": false}, "ImageResizeKJ": {"input": {"required": {"image": ["IMAGE"], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]], "keep_proportion": ["BOOLEAN", {"default": false}], "divisible_by": ["INT", {"default": 2, "min": 0, "max": 512, "step": 1}]}, "optional": {"get_image_size": ["IMAGE"], "crop": [["disabled", "center", 0], {"tooltip": "0 will do the default center crop, this is a workaround for the widget order changing with the new frontend, as in old workflows the value of this widget becomes 0 automatically"}]}}, "input_order": {"required": ["image", "width", "height", "upscale_method", "keep_proportion", "divisible_by"], "optional": ["get_image_size", "crop"]}, "output": ["IMAGE", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["IMAGE", "width", "height"], "name": "ImageResizeKJ", "display_name": "Resize Image (deprecated)", "description": "\nDEPRECATED!\n\nDue to ComfyUI frontend changes, this node should no longer be used, please check the   \nv2 of the node. This node is only kept to not completely break older workflows.  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false, "deprecated": true}, "ImageResizeKJv2": {"input": {"required": {"image": ["IMAGE"], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]], "keep_proportion": [["stretch", "resize", "pad", "pad_edge", "crop"], {"default": false}], "pad_color": ["STRING", {"default": "0, 0, 0", "tooltip": "Color to use for padding."}], "crop_position": [["center", "top", "bottom", "left", "right"], {"default": "center"}], "divisible_by": ["INT", {"default": 2, "min": 0, "max": 512, "step": 1}]}, "optional": {"device": [["cpu", "gpu"]]}}, "input_order": {"required": ["image", "width", "height", "upscale_method", "keep_proportion", "pad_color", "crop_position", "divisible_by"], "optional": ["device"]}, "output": ["IMAGE", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["IMAGE", "width", "height"], "name": "ImageResizeKJv2", "display_name": "Resize Image v2", "description": "\nResizes the image to the specified width and height.  \nSize can be retrieved from the input.\n\nKeep proportions keeps the aspect ratio of the image, by  \nhighest dimension.  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ImageUpscaleWithModelBatched": {"input": {"required": {"upscale_model": ["UPSCALE_MODEL"], "images": ["IMAGE"], "per_batch": ["INT", {"default": 16, "min": 1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["upscale_model", "images", "per_batch"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageUpscaleWithModelBatched", "display_name": "Image Upscale With Model Batched", "description": "\nSame as ComfyUI native model upscaling node,  \nbut allows setting sub-batches for reduced VRAM usage.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "InsertImagesToBatchIndexed": {"input": {"required": {"original_images": ["IMAGE"], "images_to_insert": ["IMAGE"], "indexes": ["STRING", {"default": "0, 1, 2", "multiline": true}]}, "optional": {"mode": [["replace", "insert"]]}}, "input_order": {"required": ["original_images", "images_to_insert", "indexes"], "optional": ["mode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "InsertImagesToBatchIndexed", "display_name": "Insert Images To Batch Indexed", "description": "\nInserts images at the specified indices into the original image batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "InsertLatentToIndexed": {"input": {"required": {"source": ["LATENT"], "destination": ["LATENT"], "index": ["INT", {"default": 0, "min": -1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["source", "destination", "index"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "InsertLatentToIndexed", "display_name": "Insert Latent To Index", "description": "\nInserts a latent at the specified index into the original latent batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/latents", "output_node": false}, "LoadAndResizeImage": {"input": {"required": {"image": [["chicken-Shine-sxs.png", "chicken-shine-head-white-bg-1.4kx1.4k.png", "chicken-shine-head.png", "chicken_shine_16-9.png", "chicken_shine_big_banner_alt-Recovered.png", "example.png", "feedback_5bf4a783.png", "feedback_9e877b73.png", "feedback_d5b0860e.png", "feedback_f2885aca.png", "rs=w_1280,h_960 (1).webp"], {"image_upload": true}], "resize": ["BOOLEAN", {"default": false}], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}], "repeat": ["INT", {"default": 1, "min": 1, "max": 4096, "step": 1}], "keep_proportion": ["BOOLEAN", {"default": false}], "divisible_by": ["INT", {"default": 2, "min": 0, "max": 512, "step": 1}], "mask_channel": [["alpha", "red", "green", "blue"], {"tooltip": "Channel to use for the mask output"}], "background_color": ["STRING", {"default": "", "tooltip": "Fills the alpha channel with the specified color."}]}}, "input_order": {"required": ["image", "resize", "width", "height", "repeat", "keep_proportion", "divisible_by", "mask_channel", "background_color"]}, "output": ["IMAGE", "MASK", "INT", "INT", "STRING"], "output_is_list": [false, false, false, false, false], "output_name": ["image", "mask", "width", "height", "image_path"], "name": "LoadAndResizeImage", "display_name": "Load & Resize Image", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "LoadImagesFromFolderKJ": {"input": {"required": {"folder": ["STRING", {"default": ""}], "width": ["INT", {"default": 1024, "min": 64, "step": 1}], "height": ["INT", {"default": 1024, "min": 64, "step": 1}], "keep_aspect_ratio": [["crop", "pad", "stretch"]]}, "optional": {"image_load_cap": ["INT", {"default": 0, "min": 0, "step": 1}], "start_index": ["INT", {"default": 0, "min": 0, "step": 1}], "include_subfolders": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["folder", "width", "height", "keep_aspect_ratio"], "optional": ["image_load_cap", "start_index", "include_subfolders"]}, "output": ["IMAGE", "MASK", "INT", "STRING"], "output_is_list": [false, false, false, false], "output_name": ["image", "mask", "count", "image_path"], "name": "LoadImagesFromFolderKJ", "display_name": "Load Images From Folder (KJ)", "description": "Loads images from a folder into a batch, images are resized and loaded into a batch.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "MergeImageChannels": {"input": {"required": {"red": ["IMAGE"], "green": ["IMAGE"], "blue": ["IMAGE"]}, "optional": {"alpha": ["MASK", {"default": null}]}}, "input_order": {"required": ["red", "green", "blue"], "optional": ["alpha"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "MergeImageChannels", "display_name": "Merge Image Channels", "description": "\nMerges channel data into an image.  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "PadImageBatchInterleaved": {"input": {"required": {"images": ["IMAGE"], "empty_frames_per_image": ["INT", {"default": 1, "min": 0, "max": 4096, "step": 1}], "pad_frame_value": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "add_after_last": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["images", "empty_frames_per_image", "pad_frame_value", "add_after_last"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["images", "masks"], "name": "PadImageBatchInterleaved", "display_name": "Pad Image Batch Interleaved", "description": "\nInserts empty frames between the images in a batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "PreviewAnimation": {"input": {"required": {"fps": ["FLOAT", {"default": 8.0, "min": 0.01, "max": 1000.0, "step": 0.01}]}, "optional": {"images": ["IMAGE"], "masks": ["MASK"]}}, "input_order": {"required": ["fps"], "optional": ["images", "masks"]}, "output": [], "output_is_list": [], "output_name": [], "name": "PreviewAnimation", "display_name": "Preview Animation", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": true}, "RemapImageRange": {"input": {"required": {"image": ["IMAGE"], "min": ["FLOAT", {"default": 0.0, "min": -10.0, "max": 1.0, "step": 0.01}], "max": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "clamp": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["image", "min", "max", "clamp"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "RemapImageRange", "display_name": "Remap Image Range", "description": "\nRemaps the image values to the specified range. \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ReverseImageBatch": {"input": {"required": {"images": ["IMAGE"]}}, "input_order": {"required": ["images"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ReverseImageBatch", "display_name": "Reverse Image Batch", "description": "\nReverses the order of the images in a batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "ReplaceImagesInBatch": {"input": {"required": {"original_images": ["IMAGE"], "replacement_images": ["IMAGE"], "start_index": ["INT", {"default": 1, "min": 0, "max": 4096, "step": 1}]}, "optional": {"original_masks": ["MASK"], "replacement_masks": ["MASK"]}}, "input_order": {"required": ["original_images", "replacement_images", "start_index"], "optional": ["original_masks", "replacement_masks"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "ReplaceImagesInBatch", "display_name": "Replace Images In Batch", "description": "\nReplaces the images in a batch, starting from the specified start index,  \nwith the replacement images.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "SaveImageWithAlpha": {"input": {"required": {"images": ["IMAGE"], "mask": ["MASK"], "filename_prefix": ["STRING", {"default": "ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "mask", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveImageWithAlpha", "display_name": "Save Image With Alpha", "description": "\nSaves an image and mask as .PNG with the mask as the alpha channel. \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": true}, "SaveImageKJ": {"input": {"required": {"images": ["IMAGE", {"tooltip": "The images to save."}], "filename_prefix": ["STRING", {"default": "ComfyUI", "tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes."}], "output_folder": ["STRING", {"default": "output", "tooltip": "The folder to save the images to."}]}, "optional": {"caption_file_extension": ["STRING", {"default": ".txt", "tooltip": "The extension for the caption file."}], "caption": ["STRING", {"forceInput": true, "tooltip": "string to save as .txt file"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "filename_prefix", "output_folder"], "optional": ["caption_file_extension", "caption"], "hidden": ["prompt", "extra_pnginfo"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["filename"], "name": "SaveImageKJ", "display_name": "Save Image KJ", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": true}, "ShuffleImageBatch": {"input": {"required": {"images": ["IMAGE"], "seed": ["INT", {"default": 123, "min": 0, "max": 18446744073709551615, "step": 1}]}}, "input_order": {"required": ["images", "seed"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ShuffleImageBatch", "display_name": "Shuffle Image Batch", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "SplitImageChannels": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "IMAGE", "IMAGE", "MASK"], "output_is_list": [false, false, false, false], "output_name": ["red", "green", "blue", "mask"], "name": "SplitImageChannels", "display_name": "Split Image Channels", "description": "\nSplits image channels into images where the selected channel  \nis repeated for all channels, and the alpha as a mask. \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "TransitionImagesMulti": {"input": {"required": {"inputcount": ["INT", {"default": 2, "min": 2, "max": 1000, "step": 1}], "image_1": ["IMAGE"], "image_2": ["IMAGE"], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out", "bounce", "elastic", "glitchy", "exponential_ease_out"]], "transition_type": [["horizontal slide", "vertical slide", "box", "circle", "horizontal door", "vertical door", "fade"]], "transitioning_frames": ["INT", {"default": 1, "min": 0, "max": 4096, "step": 1}], "blur_radius": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.1}], "reverse": ["BOOLEAN", {"default": false}], "device": [["CPU", "GPU"], {"default": "CPU"}]}}, "input_order": {"required": ["inputcount", "image_1", "image_2", "interpolation", "transition_type", "transitioning_frames", "blur_radius", "reverse", "device"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "TransitionImagesMulti", "display_name": "Transition Images Multi", "description": "\nCreates transitions between images.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "TransitionImagesInBatch": {"input": {"required": {"images": ["IMAGE"], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out", "bounce", "elastic", "glitchy", "exponential_ease_out"]], "transition_type": [["horizontal slide", "vertical slide", "box", "circle", "horizontal door", "vertical door", "fade"]], "transitioning_frames": ["INT", {"default": 1, "min": 0, "max": 4096, "step": 1}], "blur_radius": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.1}], "reverse": ["BOOLEAN", {"default": false}], "device": [["CPU", "GPU"], {"default": "CPU"}]}}, "input_order": {"required": ["images", "interpolation", "transition_type", "transitioning_frames", "blur_radius", "reverse", "device"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "TransitionImagesInBatch", "display_name": "Transition Images In Batch", "description": "\nCreates transitions between images in a batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "BatchCropFromMask": {"input": {"required": {"original_images": ["IMAGE"], "masks": ["MASK"], "crop_size_mult": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "bbox_smooth_alpha": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["original_images", "masks", "crop_size_mult", "bbox_smooth_alpha"]}, "output": ["IMAGE", "IMAGE", "BBOX", "INT", "INT"], "output_is_list": [false, false, false, false, false], "output_name": ["original_images", "cropped_images", "bboxes", "width", "height"], "name": "BatchCropFromMask", "display_name": "Batch Crop From Mask", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "BatchCropFromMaskAdvanced": {"input": {"required": {"original_images": ["IMAGE"], "masks": ["MASK"], "crop_size_mult": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "bbox_smooth_alpha": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["original_images", "masks", "crop_size_mult", "bbox_smooth_alpha"]}, "output": ["IMAGE", "IMAGE", "MASK", "IMAGE", "MASK", "BBOX", "BBOX", "INT", "INT"], "output_is_list": [false, false, false, false, false, false, false, false, false], "output_name": ["original_images", "cropped_images", "cropped_masks", "combined_crop_image", "combined_crop_masks", "bboxes", "combined_bounding_box", "bbox_width", "bbox_height"], "name": "BatchCropFromMaskAdvanced", "display_name": "Batch Crop From Mask Advanced", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "FilterZeroMasksAndCorrespondingImages": {"input": {"required": {"masks": ["MASK"]}, "optional": {"original_images": ["IMAGE"]}}, "input_order": {"required": ["masks"], "optional": ["original_images"]}, "output": ["MASK", "IMAGE", "IMAGE", "INDEXES"], "output_is_list": [false, false, false, false], "output_name": ["non_zero_masks_out", "non_zero_mask_images_out", "zero_mask_images_out", "zero_mask_images_out_indexes"], "name": "FilterZeroMasksAndCorrespondingImages", "display_name": "FilterZeroMasksAndCorrespondingImages", "description": "\nFilter out all the empty (i.e. all zero) mask in masks  \nAlso filter out all the corresponding images in original_images by indexes if provide  \n  \noriginal_images (optional): If provided, need have same length as masks.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "InsertImageBatchByIndexes": {"input": {"required": {"images": ["IMAGE"], "images_to_insert": ["IMAGE"], "insert_indexes": ["INDEXES"]}}, "input_order": {"required": ["images", "images_to_insert", "insert_indexes"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images_after_insert"], "name": "InsertImageBatchByIndexes", "display_name": "Insert Image Batch By Indexes", "description": "\nThis node is designed to be use with node FilterZeroMasksAndCorrespondingImages\nIt inserts the images_to_insert into images according to insert_indexes\n\nReturns:\n    images_after_insert: updated original images with origonal sequence order\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "BatchUncrop": {"input": {"required": {"original_images": ["IMAGE"], "cropped_images": ["IMAGE"], "bboxes": ["BBOX"], "border_blending": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 1.0, "step": 0.01}], "crop_rescale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "border_top": ["BOOLEAN", {"default": true}], "border_bottom": ["BOOLEAN", {"default": true}], "border_left": ["BOOLEAN", {"default": true}], "border_right": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["original_images", "cropped_images", "bboxes", "border_blending", "crop_rescale", "border_top", "border_bottom", "border_left", "border_right"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "BatchUncrop", "display_name": "Batch Uncrop", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "BatchUncropAdvanced": {"input": {"required": {"original_images": ["IMAGE"], "cropped_images": ["IMAGE"], "cropped_masks": ["MASK"], "combined_crop_mask": ["MASK"], "bboxes": ["BBOX"], "border_blending": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 1.0, "step": 0.01}], "crop_rescale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "use_combined_mask": ["BOOLEAN", {"default": false}], "use_square_mask": ["BOOLEAN", {"default": true}]}, "optional": {"combined_bounding_box": ["BBOX", {"default": null}]}}, "input_order": {"required": ["original_images", "cropped_images", "cropped_masks", "combined_crop_mask", "bboxes", "border_blending", "crop_rescale", "use_combined_mask", "use_square_mask"], "optional": ["combined_bounding_box"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "BatchUncropAdvanced", "display_name": "Batch Uncrop Advanced", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "SplitBboxes": {"input": {"required": {"bboxes": ["BBOX"], "index": ["INT", {"default": 0, "min": 0, "max": 99999999, "step": 1}]}}, "input_order": {"required": ["bboxes", "index"]}, "output": ["BBOX", "BBOX"], "output_is_list": [false, false], "output_name": ["bboxes_a", "bboxes_b"], "name": "SplitBboxes", "display_name": "Split Bboxes", "description": "\nSplits the specified bbox list at the given index into two lists.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "BboxToInt": {"input": {"required": {"bboxes": ["BBOX"], "index": ["INT", {"default": 0, "min": 0, "max": 99999999, "step": 1}]}}, "input_order": {"required": ["bboxes", "index"]}, "output": ["INT", "INT", "INT", "INT", "INT", "INT"], "output_is_list": [false, false, false, false, false, false], "output_name": ["x_min", "y_min", "width", "height", "center_x", "center_y"], "name": "BboxToInt", "display_name": "Bbox To Int", "description": "\nReturns selected index from bounding box list as integers.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "BboxVisualize": {"input": {"required": {"images": ["IMAGE"], "bboxes": ["BBOX"], "line_width": ["INT", {"default": 1, "min": 1, "max": 10, "step": 1}]}}, "input_order": {"required": ["images", "bboxes", "line_width"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "BboxVisualize", "display_name": "Bbox Visualize", "description": "\nVisualizes the specified bbox on the image.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking", "output_node": false}, "GenerateNoise": {"input": {"required": {"width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "seed": ["INT", {"default": 123, "min": 0, "max": 18446744073709551615, "step": 1}], "multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 4096, "step": 0.01}], "constant_batch_noise": ["BOOLEAN", {"default": false}], "normalize": ["BOOLEAN", {"default": false}]}, "optional": {"model": ["MODEL"], "sigmas": ["SIGMAS"], "latent_channels": [["4", "16"]], "shape": [["BCHW", "BCTHW", "BTCHW"]]}}, "input_order": {"required": ["width", "height", "batch_size", "seed", "multiplier", "constant_batch_noise", "normalize"], "optional": ["model", "sigmas", "latent_channels", "shape"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "GenerateNoise", "display_name": "Generate Noise", "description": "\nGenerates noise for injection or to be used as empty latents on samplers with add_noise off.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/noise", "output_node": false}, "FlipSigmasAdjusted": {"input": {"required": {"sigmas": ["SIGMAS"], "divide_by_last_sigma": ["BOOLEAN", {"default": false}], "divide_by": ["FLOAT", {"default": 1, "min": 1, "max": 255, "step": 0.01}], "offset_by": ["INT", {"default": 1, "min": -100, "max": 100, "step": 1}]}}, "input_order": {"required": ["sigmas", "divide_by_last_sigma", "divide_by", "offset_by"]}, "output": ["SIGMAS", "STRING"], "output_is_list": [false, false], "output_name": ["SIGMAS", "sigmas_string"], "name": "FlipSigmasAdjusted", "display_name": "Flip Sigmas Adjusted", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/noise", "output_node": false}, "InjectNoiseToLatent": {"input": {"required": {"latents": ["LATENT"], "strength": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 200.0, "step": 0.0001}], "noise": ["LATENT"], "normalize": ["BOOLEAN", {"default": false}], "average": ["BOOLEAN", {"default": false}]}, "optional": {"mask": ["MASK"], "mix_randn_amount": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.001}], "seed": ["INT", {"default": 123, "min": 0, "max": 18446744073709551615, "step": 1}]}}, "input_order": {"required": ["latents", "strength", "noise", "normalize", "average"], "optional": ["mask", "mix_randn_amount", "seed"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "InjectNoiseToLatent", "display_name": "Inject Noise To Latent", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/noise", "output_node": false}, "CustomSigmas": {"input": {"required": {"sigmas_string": ["STRING", {"default": "14.615, 6.475, 3.861, 2.697, 1.886, 1.396, 0.963, 0.652, 0.399, 0.152, 0.029", "multiline": true}], "interpolate_to_steps": ["INT", {"default": 10, "min": 0, "max": 255, "step": 1}]}}, "input_order": {"required": ["sigmas_string", "interpolate_to_steps"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "CustomSigmas", "display_name": "Custom Sigmas", "description": "\nCreates a sigmas tensor from a string of comma separated values.  \nExamples: \n   \nNvidia's optimized AYS 10 step schedule for SD 1.5:  \n14.615, 6.475, 3.861, 2.697, 1.886, 1.396, 0.963, 0.652, 0.399, 0.152, 0.029  \nSDXL:   \n14.615, 6.315, 3.771, 2.181, 1.342, 0.862, 0.555, 0.380, 0.234, 0.113, 0.029  \nSVD:  \n700.00, 54.5, 15.886, 7.977, 4.248, 1.789, 0.981, 0.403, 0.173, 0.034, 0.002  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/noise", "output_node": false}, "StringToFloatList": {"input": {"required": {"string": ["STRING", {"default": "1, 2, 3", "multiline": true}]}}, "input_order": {"required": ["string"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "StringToFloatList", "display_name": "String to Float List", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": false}, "WidgetToString": {"input": {"required": {"id": ["INT", {"default": 0}], "widget_name": ["STRING", {"multiline": false}], "return_all": ["BOOLEAN", {"default": false}]}, "optional": {"any_input": ["*", {}], "node_title": ["STRING", {"multiline": false}], "allowed_float_decimals": ["INT", {"default": 2, "min": 0, "max": 10, "tooltip": "Number of decimal places to display for float values"}]}, "hidden": {"extra_pnginfo": "EXTRA_PNGINFO", "prompt": "PROMPT", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["id", "widget_name", "return_all"], "optional": ["any_input", "node_title", "allowed_float_decimals"], "hidden": ["extra_pnginfo", "prompt", "unique_id"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "WidgetToString", "display_name": "Widget To String", "description": "\nSelects a node and it's specified widget and outputs the value as a string.  \nIf no node id or title is provided it will use the 'any_input' link and use that node.  \nTo see node id's, enable node id display from Manager badge menu.  \nAlternatively you can search with the node title. Node titles ONLY exist if they  \nare manually edited!  \nThe 'any_input' is required for making sure the node you want the value from exists in the workflow.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "SaveStringKJ": {"input": {"required": {"string": ["STRING", {"forceInput": true, "tooltip": "string to save as .txt file"}], "filename_prefix": ["STRING", {"default": "text", "tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes."}], "output_folder": ["STRING", {"default": "output", "tooltip": "The folder to save the images to."}]}, "optional": {"file_extension": ["STRING", {"default": ".txt", "tooltip": "The extension for the caption file."}]}}, "input_order": {"required": ["string", "filename_prefix", "output_folder"], "optional": ["file_extension"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["filename"], "name": "SaveStringKJ", "display_name": "Save String KJ", "description": "Saves the input string to your ComfyUI output directory.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": true}, "DummyOut": {"input": {"required": {"any_input": ["*", {}]}}, "input_order": {"required": ["any_input"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "DummyOut", "display_name": "Dummy Out", "description": "\nDoes nothing, used to trigger generic workflow output.    \nA way to get previews in the UI without saving anything to disk.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": true}, "GetLatentsFromBatchIndexed": {"input": {"required": {"latents": ["LATENT"], "indexes": ["STRING", {"default": "0, 1, 2", "multiline": true}], "latent_format": [["BCHW", "BTCHW", "BCTHW"], {"default": "BCHW"}]}}, "input_order": {"required": ["latents", "indexes", "latent_format"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "GetLatentsFromBatchIndexed", "display_name": "Get Latents From Batch Indexed", "description": "\nSelects and returns the latents at the specified indices as an latent batch.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/latents", "output_node": false}, "ScaleBatchPromptSchedule": {"input": {"required": {"input_str": ["STRING", {"forceInput": true, "default": "0:(0.0),\n7:(1.0),\n15:(0.0)\n"}], "old_frame_count": ["INT", {"forceInput": true, "default": 1, "min": 1, "max": 4096, "step": 1}], "new_frame_count": ["INT", {"forceInput": true, "default": 1, "min": 1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["input_str", "old_frame_count", "new_frame_count"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "ScaleBatchPromptSchedule", "display_name": "Scale Batch Prompt Schedule", "description": "\nScales a batch schedule from Fizz' nodes BatchPromptSchedule\nto a different frame count.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": false}, "CameraPoseVisualizer": {"input": {"required": {"pose_file_path": ["STRING", {"default": "", "multiline": false}], "base_xval": ["FLOAT", {"default": 0.2, "min": 0, "max": 100, "step": 0.01}], "zval": ["FLOAT", {"default": 0.3, "min": 0, "max": 100, "step": 0.01}], "scale": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 10.0, "step": 0.01}], "use_exact_fx": ["BOOLEAN", {"default": false}], "relative_c2w": ["BOOLEAN", {"default": true}], "use_viewer": ["BOOLEAN", {"default": false}]}, "optional": {"cameractrl_poses": ["CAMERACTRL_POSES", {"default": null}]}}, "input_order": {"required": ["pose_file_path", "base_xval", "zval", "scale", "use_exact_fx", "relative_c2w", "use_viewer"], "optional": ["cameractrl_poses"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "CameraPoseVisualizer", "display_name": "Camera Pose Visualizer", "description": "\nVisualizes the camera poses, from Animatediff-Evolved CameraCtrl Pose  \nor a .txt file with RealEstate camera intrinsics and coordinates, in a 3D plot. \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": false}, "AppendStringsToList": {"input": {"required": {"string1": ["STRING", {"default": "", "forceInput": true}], "string2": ["STRING", {"default": "", "forceInput": true}]}}, "input_order": {"required": ["string1", "string2"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "AppendStringsToList", "display_name": "Append Strings To List", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "JoinStrings": {"input": {"required": {"string1": ["STRING", {"default": "", "forceInput": true}], "string2": ["STRING", {"default": "", "forceInput": true}], "delimiter": ["STRING", {"default": " ", "multiline": false}]}}, "input_order": {"required": ["string1", "string2", "delimiter"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "JoinStrings", "display_name": "Join Strings", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "JoinStringMulti": {"input": {"required": {"inputcount": ["INT", {"default": 2, "min": 2, "max": 1000, "step": 1}], "string_1": ["STRING", {"default": "", "forceInput": true}], "string_2": ["STRING", {"default": "", "forceInput": true}], "delimiter": ["STRING", {"default": " ", "multiline": false}], "return_list": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["inputcount", "string_1", "string_2", "delimiter", "return_list"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["string"], "name": "JoinStringMulti", "display_name": "Join String Multi", "description": "\nCreates single string, or a list of strings, from  \nmultiple input strings.  \nYou can set how many inputs the node has,  \nwith the **inputcount** and clicking update.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "SomethingToString": {"input": {"required": {"input": ["*", {}]}, "optional": {"prefix": ["STRING", {"default": ""}], "suffix": ["STRING", {"default": ""}]}}, "input_order": {"required": ["input"], "optional": ["prefix", "suffix"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "SomethingToString", "display_name": "Something To String", "description": "\nConverts any type to a string.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "Sleep": {"input": {"required": {"input": ["*", {}], "minutes": ["INT", {"default": 0, "min": 0, "max": 1439}], "seconds": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 59.99, "step": 0.01}]}}, "input_order": {"required": ["input", "minutes", "seconds"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "Sleep", "display_name": "Sleep", "description": "\nDelays the execution for the input amount of time.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": false}, "VRAM_Debug": {"input": {"required": {"empty_cache": ["BOOLEAN", {"default": true}], "gc_collect": ["BOOLEAN", {"default": true}], "unload_all_models": ["BOOLEAN", {"default": false}]}, "optional": {"any_input": ["*", {}], "image_pass": ["IMAGE"], "model_pass": ["MODEL"]}}, "input_order": {"required": ["empty_cache", "gc_collect", "unload_all_models"], "optional": ["any_input", "image_pass", "model_pass"]}, "output": ["*", "IMAGE", "MODEL", "INT", "INT"], "output_is_list": [false, false, false, false, false], "output_name": ["any_output", "image_pass", "model_pass", "freemem_before", "freemem_after"], "name": "VRAM_Debug", "display_name": "VRAM Debug", "description": "\nReturns the inputs unchanged, they are only used as triggers,  \nand performs comfy model management functions and garbage collection,  \nreports free VRAM before and after the operations.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": false}, "EmptyLatentImagePresets": {"input": {"required": {"dimensions": [["512 x 512 (1:1)", "768 x 512 (1.5:1)", "960 x 512 (1.875:1)", "1024 x 512 (2:1)", "1024 x 576 (1.778:1)", "1536 x 640 (2.4:1)", "1344 x 768 (1.75:1)", "1216 x 832 (1.46:1)", "1152 x 896 (1.286:1)", "1024 x 1024 (1:1)"], {"default": "512 x 512 (1:1)"}], "invert": ["BOOLEAN", {"default": false}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["dimensions", "invert", "batch_size"]}, "output": ["LATENT", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["Latent", "Width", "Height"], "name": "EmptyLatentImagePresets", "display_name": "Empty Latent Image Presets", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/latents", "output_node": false}, "EmptyLatentImageCustomPresets": {"input": {"required": {"dimensions": [[]], "invert": ["BOOLEAN", {"default": false}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["dimensions", "invert", "batch_size"]}, "output": ["LATENT", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["Latent", "Width", "Height"], "name": "EmptyLatentImageCustomPresets", "display_name": "Empty Latent Image Custom Presets", "description": "\nGenerates an empty latent image with the specified dimensions.  \nThe choices are loaded from 'custom_dimensions.json' in the nodes folder.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/latents", "output_node": false}, "ModelPassThrough": {"input": {"required": {}, "optional": {"model": ["MODEL"]}}, "input_order": {"required": [], "optional": ["model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["model"], "name": "ModelPassThrough", "display_name": "ModelPass", "description": "\n    Simply passes through the model,\n    workaround for Set node not allowing bypassed inputs.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": false}, "ModelSaveKJ": {"input": {"required": {"model": ["MODEL"], "filename_prefix": ["STRING", {"default": "diffusion_models/ComfyUI"}], "model_key_prefix": ["STRING", {"default": "model.diffusion_model."}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["model", "filename_prefix", "model_key_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "ModelSaveKJ", "display_name": "Model Save KJ", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "advanced/model_merging", "output_node": true}, "SetShakkerLabsUnionControlNetType": {"input": {"required": {"control_net": ["CONTROL_NET"], "type": [["auto", "canny", "tile", "depth", "blur", "pose", "gray", "low quality"]]}}, "input_order": {"required": ["control_net", "type"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "SetShakkerLabsUnionControlNetType", "display_name": "Set Shakker Labs Union ControlNet Type", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "conditioning/controlnet", "output_node": false}, "StyleModelApplyAdvanced": {"input": {"required": {"conditioning": ["CONDITIONING"], "style_model": ["STYLE_MODEL"], "clip_vision_output": ["CLIP_VISION_OUTPUT"], "strength": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.001}]}}, "input_order": {"required": ["conditioning", "style_model", "clip_vision_output", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "StyleModelApplyAdvanced", "display_name": "Style Model Apply Advanced", "description": "StyleModelApply but with strength parameter", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "NormalizedAmplitudeToMask": {"input": {"required": {"normalized_amp": ["NORMALIZED_AMPLITUDE"], "width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_offset": ["INT", {"default": 0, "min": -255, "max": 255, "step": 1}], "location_x": ["INT", {"default": 256, "min": 0, "max": 4096, "step": 1}], "location_y": ["INT", {"default": 256, "min": 0, "max": 4096, "step": 1}], "size": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 1}], "shape": [["none", "circle", "square", "triangle"], {"default": "none"}], "color": [["white", "amplitude"], {"default": "amplitude"}]}}, "input_order": {"required": ["normalized_amp", "width", "height", "frame_offset", "location_x", "location_y", "size", "shape", "color"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "NormalizedAmplitudeToMask", "display_name": "NormalizedAmplitudeToMask", "description": "\nWorks as a bridge to the AudioScheduler -nodes:  \nhttps://github.com/a1lazydog/ComfyUI-AudioScheduler  \nCreates masks based on the normalized amplitude.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/audio", "output_node": false}, "NormalizedAmplitudeToFloatList": {"input": {"required": {"normalized_amp": ["NORMALIZED_AMPLITUDE"]}}, "input_order": {"required": ["normalized_amp"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "NormalizedAmplitudeToFloatList", "display_name": "NormalizedAmplitudeToFloatList", "description": "\nWorks as a bridge to the AudioScheduler -nodes:  \nhttps://github.com/a1lazydog/ComfyUI-AudioScheduler  \nCreates a list of floats from the normalized amplitude.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/audio", "output_node": false}, "OffsetMaskByNormalizedAmplitude": {"input": {"required": {"normalized_amp": ["NORMALIZED_AMPLITUDE"], "mask": ["MASK"], "x": ["INT", {"default": 0, "min": -4096, "max": 16384, "step": 1, "display": "number"}], "y": ["INT", {"default": 0, "min": -4096, "max": 16384, "step": 1, "display": "number"}], "rotate": ["BOOLEAN", {"default": false}], "angle_multiplier": ["FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.001, "display": "number"}]}}, "input_order": {"required": ["normalized_amp", "mask", "x", "y", "rotate", "angle_multiplier"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["mask"], "name": "OffsetMaskByNormalizedAmplitude", "display_name": "OffsetMaskByNormalizedAmplitude", "description": "\nWorks as a bridge to the AudioScheduler -nodes:  \nhttps://github.com/a1lazydog/ComfyUI-AudioScheduler  \nOffsets masks based on the normalized amplitude.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/audio", "output_node": false}, "ImageTransformByNormalizedAmplitude": {"input": {"required": {"normalized_amp": ["NORMALIZED_AMPLITUDE"], "zoom_scale": ["FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.001, "display": "number"}], "x_offset": ["INT", {"default": 0, "min": -16383, "max": 16384, "step": 1, "display": "number"}], "y_offset": ["INT", {"default": 0, "min": -16383, "max": 16384, "step": 1, "display": "number"}], "cumulative": ["BOOLEAN", {"default": false}], "image": ["IMAGE"]}}, "input_order": {"required": ["normalized_amp", "zoom_scale", "x_offset", "y_offset", "cumulative", "image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageTransformByNormalizedAmplitude", "display_name": "ImageTransformByNormalizedAmplitude", "description": "\nWorks as a bridge to the AudioScheduler -nodes:  \nhttps://github.com/a1lazydog/ComfyUI-AudioScheduler  \nTransforms image based on the normalized amplitude.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/audio", "output_node": false}, "AudioConcatenate": {"input": {"required": {"audio1": ["AUDIO"], "audio2": ["AUDIO"], "direction": [["right", "left"], {"default": "right"}]}}, "input_order": {"required": ["audio1", "audio2", "direction"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "AudioConcatenate", "display_name": "AudioConcatenate", "description": "\nConcatenates the audio1 to audio2 in the specified direction.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/audio", "output_node": false}, "SplineEditor": {"input": {"required": {"points_store": ["STRING", {"multiline": false}], "coordinates": ["STRING", {"multiline": false}], "mask_width": ["INT", {"default": 512, "min": 8, "max": 4096, "step": 8}], "mask_height": ["INT", {"default": 512, "min": 8, "max": 4096, "step": 8}], "points_to_sample": ["INT", {"default": 16, "min": 2, "max": 1000, "step": 1}], "sampling_method": [["path", "time", "controlpoints"], {"default": "time"}], "interpolation": [["cardinal", "monotone", "basis", "linear", "step-before", "step-after", "polar", "polar-reverse"], {"default": "cardinal"}], "tension": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "repeat_output": ["INT", {"default": 1, "min": 1, "max": 4096, "step": 1}], "float_output_type": [["list", "pandas series", "tensor"], {"default": "list"}]}, "optional": {"min_value": ["FLOAT", {"default": 0.0, "min": -10000.0, "max": 10000.0, "step": 0.01}], "max_value": ["FLOAT", {"default": 1.0, "min": -10000.0, "max": 10000.0, "step": 0.01}], "bg_image": ["IMAGE"]}}, "input_order": {"required": ["points_store", "coordinates", "mask_width", "mask_height", "points_to_sample", "sampling_method", "interpolation", "tension", "repeat_output", "float_output_type"], "optional": ["min_value", "max_value", "bg_image"]}, "output": ["MASK", "STRING", "FLOAT", "INT", "STRING"], "output_is_list": [false, false, false, false, false], "output_name": ["mask", "coord_str", "float", "count", "normalized_str"], "name": "SplineEditor", "display_name": "Spline Editor", "description": "\n# WORK IN PROGRESS  \nDo not count on this as part of your workflow yet,  \nprobably contains lots of bugs and stability is not  \nguaranteed!!  \n  \n## Graphical editor to create values for various   \n## schedules and/or mask batches.  \n\n**Shift + click** to add control point at end.\n**Ctrl + click** to add control point (subdivide) between two points.  \n**Right click on a point** to delete it.    \nNote that you can't delete from start/end.  \n  \nRight click on canvas for context menu:  \nThese are purely visual options, doesn't affect the output:  \n - Toggle handles visibility\n - Display sample points: display the points to be returned.  \n\n**points_to_sample** value sets the number of samples  \nreturned from the **drawn spline itself**, this is independent from the  \nactual control points, so the interpolation type matters.  \nsampling_method: \n - time: samples along the time axis, used for schedules  \n - path: samples along the path itself, useful for coordinates  \n\noutput types:\n - mask batch  \n        example compatible nodes: anything that takes masks  \n - list of floats\n        example compatible nodes: IPAdapter weights  \n - pandas series\n        example compatible nodes: anything that takes Fizz'  \n        nodes Batch Value Schedule  \n - torch tensor  \n        example compatible nodes: unknown\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/weights", "output_node": false}, "CreateShapeImageOnPath": {"input": {"required": {"shape": [["circle", "square", "triangle"], {"default": "circle"}], "coordinates": ["STRING", {"forceInput": true}], "frame_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "shape_width": ["INT", {"default": 128, "min": 2, "max": 4096, "step": 1}], "shape_height": ["INT", {"default": 128, "min": 2, "max": 4096, "step": 1}], "shape_color": ["STRING", {"default": "white"}], "bg_color": ["STRING", {"default": "black"}], "blur_radius": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100, "step": 0.1}], "intensity": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 100.0, "step": 0.01}]}, "optional": {"size_multiplier": ["FLOAT", {"default": [1.0], "forceInput": true}], "trailing": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "border_width": ["INT", {"default": 0, "min": 0, "max": 100, "step": 1}], "border_color": ["STRING", {"default": "black"}]}}, "input_order": {"required": ["shape", "coordinates", "frame_width", "frame_height", "shape_width", "shape_height", "shape_color", "bg_color", "blur_radius", "intensity"], "optional": ["size_multiplier", "trailing", "border_width", "border_color"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["image", "mask"], "name": "CreateShapeImageOnPath", "display_name": "Create Shape Image On Path", "description": "\nCreates an image or batch of images with the specified shape.  \nLocations are center locations.  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "CreateShapeMaskOnPath": {"input": {"required": {"shape": [["circle", "square", "triangle"], {"default": "circle"}], "coordinates": ["STRING", {"forceInput": true}], "frame_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "shape_width": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 1}], "shape_height": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 1}]}, "optional": {"size_multiplier": ["FLOAT", {"default": [1.0], "forceInput": true}]}}, "input_order": {"required": ["shape", "coordinates", "frame_width", "frame_height", "shape_width", "shape_height"], "optional": ["size_multiplier"]}, "output": ["MASK", "MASK"], "output_is_list": [false, false], "output_name": ["mask", "mask_inverted"], "name": "CreateShapeMaskOnPath", "display_name": "Create Shape Mask On Path", "description": "\nCreates a mask or batch of masks with the specified shape.  \nLocations are center locations.  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "CreateTextOnPath": {"input": {"required": {"coordinates": ["STRING", {"forceInput": true}], "text": ["STRING", {"default": "text", "multiline": true}], "frame_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "font": [["FreeMono.ttf", "FreeMonoBoldOblique.otf", "TTNorms-Black.otf"]], "font_size": ["INT", {"default": 42}], "alignment": [["left", "center", "right"], {"default": "center"}], "text_color": ["STRING", {"default": "white"}]}, "optional": {"size_multiplier": ["FLOAT", {"default": [1.0], "forceInput": true}]}}, "input_order": {"required": ["coordinates", "text", "frame_width", "frame_height", "font", "font_size", "alignment", "text_color"], "optional": ["size_multiplier"]}, "output": ["IMAGE", "MASK", "MASK"], "output_is_list": [false, false, false], "output_name": ["image", "mask", "mask_inverted"], "name": "CreateTextOnPath", "display_name": "Create Text On Path", "description": "\nCreates a mask or batch of masks with the specified text.  \nLocations are center locations.  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "CreateGradientFromCoords": {"input": {"required": {"coordinates": ["STRING", {"forceInput": true}], "frame_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "start_color": ["STRING", {"default": "white"}], "end_color": ["STRING", {"default": "black"}], "multiplier": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["coordinates", "frame_width", "frame_height", "start_color", "end_color", "multiplier"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "CreateGradientFromCoords", "display_name": "Create Gradient From Coords", "description": "\nCreates a gradient image from coordinates.    \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "CutAndDragOnPath": {"input": {"required": {"image": ["IMAGE"], "coordinates": ["STRING", {"forceInput": true}], "mask": ["MASK"], "frame_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "frame_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "inpaint": ["BOOLEAN", {"default": true}]}, "optional": {"bg_image": ["IMAGE"]}}, "input_order": {"required": ["image", "coordinates", "mask", "frame_width", "frame_height", "inpaint"], "optional": ["bg_image"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["image", "mask"], "name": "CutAndDragOnPath", "display_name": "Cut And Drag On Path", "description": "\nCuts the masked area from the image, and drags it along the path. If inpaint is enabled, and no bg_image is provided, the cut area is filled using cv2 TELEA algorithm.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "GradientToFloat": {"input": {"required": {"image": ["IMAGE"], "steps": ["INT", {"default": 10, "min": 2, "max": 10000, "step": 1}]}}, "input_order": {"required": ["image", "steps"]}, "output": ["FLOAT", "FLOAT"], "output_is_list": [false, false], "output_name": ["float_x", "float_y"], "name": "GradientToFloat", "display_name": "Gradient To Float", "description": "\nCalculates list of floats from image.    \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "WeightScheduleExtend": {"input": {"required": {"input_values_1": ["FLOAT", {"default": 0.0, "forceInput": true}], "input_values_2": ["FLOAT", {"default": 0.0, "forceInput": true}], "output_type": [["match_input", "list", "pandas series", "tensor"], {"default": "match_input"}]}}, "input_order": {"required": ["input_values_1", "input_values_2", "output_type"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "WeightScheduleExtend", "display_name": "Weight Schedule Extend", "description": "\nExtends, and converts if needed, different value lists/series  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/weights", "output_node": false}, "MaskOrImageToWeight": {"input": {"required": {"output_type": [["list", "pandas series", "tensor", "string"], {"default": "list"}]}, "optional": {"images": ["IMAGE"], "masks": ["MASK"]}}, "input_order": {"required": ["output_type"], "optional": ["images", "masks"]}, "output": ["FLOAT", "STRING"], "output_is_list": [false, false], "output_name": ["FLOAT", "STRING"], "name": "MaskOrImageToWeight", "display_name": "Mask Or Image To Weight", "description": "\nGets the mean values from mask or image batch  \nand returns that as the selected output type.   \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/weights", "output_node": false}, "WeightScheduleConvert": {"input": {"required": {"input_values": ["FLOAT", {"default": 0.0, "forceInput": true}], "output_type": [["match_input", "list", "pandas series", "tensor"], {"default": "list"}], "invert": ["BOOLEAN", {"default": false}], "repeat": ["INT", {"default": 1, "min": 1, "max": 255, "step": 1}]}, "optional": {"remap_to_frames": ["INT", {"default": 0}], "interpolation_curve": ["FLOAT", {"forceInput": true}], "remap_values": ["BOOLEAN", {"default": false}], "remap_min": ["FLOAT", {"default": 0.0, "min": -100000, "max": 100000.0, "step": 0.01}], "remap_max": ["FLOAT", {"default": 1.0, "min": -100000, "max": 100000.0, "step": 0.01}]}}, "input_order": {"required": ["input_values", "output_type", "invert", "repeat"], "optional": ["remap_to_frames", "interpolation_curve", "remap_values", "remap_min", "remap_max"]}, "output": ["FLOAT", "STRING", "INT"], "output_is_list": [false, false, false], "output_name": ["FLOAT", "STRING", "INT"], "name": "WeightScheduleConvert", "display_name": "Weight Schedule Convert", "description": "\nConverts different value lists/series to another type.  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/weights", "output_node": false}, "FloatToMask": {"input": {"required": {"input_values": ["FLOAT", {"forceInput": true, "default": 0}], "width": ["INT", {"default": 100, "min": 1}], "height": ["INT", {"default": 100, "min": 1}]}}, "input_order": {"required": ["input_values", "width", "height"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "FloatToMask", "display_name": "Float To Mask", "description": "\nGenerates a batch of masks based on the input float values.\nThe batch size is determined by the length of the input float values.\nEach mask is generated with the specified width and height.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/masking/generate", "output_node": false}, "FloatToSigmas": {"input": {"required": {"float_list": ["FLOAT", {"default": 0.0, "forceInput": true}]}}, "input_order": {"required": ["float_list"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "FloatToSigmas", "display_name": "Float To Sigmas", "description": "\nCreates a sigmas tensor from list of float values.  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/noise", "output_node": false}, "SigmasToFloat": {"input": {"required": {"sigmas": ["SIGMAS"]}}, "input_order": {"required": ["sigmas"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["float"], "name": "SigmasToFloat", "display_name": "Sigmas To Float", "description": "\nCreates a float list from sigmas tensors.  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/noise", "output_node": false}, "PlotCoordinates": {"input": {"required": {"coordinates": ["STRING", {"forceInput": true}], "text": ["STRING", {"default": "title", "multiline": false}], "width": ["INT", {"default": 512, "min": 8, "max": 4096, "step": 8}], "height": ["INT", {"default": 512, "min": 8, "max": 4096, "step": 8}], "bbox_width": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 8}], "bbox_height": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 8}]}, "optional": {"size_multiplier": ["FLOAT", {"default": [1.0], "forceInput": true}]}}, "input_order": {"required": ["coordinates", "text", "width", "height", "bbox_width", "bbox_height"], "optional": ["size_multiplier"]}, "output": ["IMAGE", "INT", "INT", "INT", "INT"], "output_is_list": [false, false, false, false, false], "output_name": ["images", "width", "height", "bbox_width", "bbox_height"], "name": "PlotCoordinates", "display_name": "Plot Coordinates", "description": "\nPlots coordinates to sequence of images using Matplotlib.  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "InterpolateCoords": {"input": {"required": {"coordinates": ["STRING", {"forceInput": true}], "interpolation_curve": ["FLOAT", {"forceInput": true}]}}, "input_order": {"required": ["coordinates", "interpolation_curve"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["coordinates"], "name": "InterpolateCoords", "display_name": "Interpolate Coords", "description": "\nInterpolates coordinates based on a curve.   \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "PointsEditor": {"input": {"required": {"points_store": ["STRING", {"multiline": false}], "coordinates": ["STRING", {"multiline": false}], "neg_coordinates": ["STRING", {"multiline": false}], "bbox_store": ["STRING", {"multiline": false}], "bboxes": ["STRING", {"multiline": false}], "bbox_format": [["xyxy", "xywh"]], "width": ["INT", {"default": 512, "min": 8, "max": 4096, "step": 8}], "height": ["INT", {"default": 512, "min": 8, "max": 4096, "step": 8}], "normalize": ["BOOLEAN", {"default": false}]}, "optional": {"bg_image": ["IMAGE"]}}, "input_order": {"required": ["points_store", "coordinates", "neg_coordinates", "bbox_store", "bboxes", "bbox_format", "width", "height", "normalize"], "optional": ["bg_image"]}, "output": ["STRING", "STRING", "BBOX", "MASK", "IMAGE"], "output_is_list": [false, false, false, false, false], "output_name": ["positive_coords", "negative_coords", "bbox", "bbox_mask", "cropped_image"], "name": "PointsEditor", "display_name": "Points Editor", "description": "\n# WORK IN PROGRESS  \nDo not count on this as part of your workflow yet,  \nprobably contains lots of bugs and stability is not  \nguaranteed!!  \n  \n## Graphical editor to create coordinates\n\n**Shift + click** to add a positive (green) point.\n**Shift + right click** to add a negative (red) point.\n**Ctrl + click** to draw a box.  \n**Right click on a point** to delete it.    \nNote that you can't delete from start/end of the points array.  \n  \nTo add an image select the node and copy/paste or drag in the image.  \nOr from the bg_image input on queue (first frame of the batch).  \n\n**THE IMAGE IS SAVED TO THE NODE AND WORKFLOW METADATA**  \nyou can clear the image from the context menu by right clicking on the canvas  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "StabilityAPI_SD3": {"input": {"required": {"prompt": ["STRING", {"multiline": true}], "n_prompt": ["STRING", {"multiline": true}], "seed": ["INT", {"default": 123, "min": 0, "max": 4294967294, "step": 1}], "model": [["sd3", "sd3-turbo"], {"default": "sd3"}], "aspect_ratio": [["1:1", "16:9", "21:9", "2:3", "3:2", "4:5", "5:4", "9:16", "9:21"], {"default": "1:1"}], "output_format": [["png", "jpeg"], {"default": "jpeg"}]}, "optional": {"api_key": ["STRING", {"multiline": true}], "image": ["IMAGE"], "img2img_strength": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "disable_metadata": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["prompt", "n_prompt", "seed", "model", "aspect_ratio", "output_format"], "optional": ["api_key", "image", "img2img_strength", "disable_metadata"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "StabilityAPI_SD3", "display_name": "Stability API SD3", "description": "\n## Calls StabilityAI API\n   \nAlthough you may have multiple keys in your account,  \nyou should use the same key for all requests to this API.  \n\nGet your API key here: https://platform.stability.ai/account/keys  \nRecommended to set the key in the config.json -file under this  \nnode packs folder.  \n# WARNING:  \nOtherwise the API key may get saved in the image metadata even  \nwith \"disable_metadata\" on if the workflow includes save nodes  \nseparate from this node.  \n   \nsd3 requires 6.5 credits per generation  \nsd3-turbo requires 4 credits per generation  \n\nIf no image is provided, mode is set to text-to-image  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "SoundReactive": {"input": {"required": {"sound_level": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 99999, "step": 0.01}], "start_range_hz": ["INT", {"default": 150, "min": 0, "max": 9999, "step": 1}], "end_range_hz": ["INT", {"default": 2000, "min": 0, "max": 9999, "step": 1}], "multiplier": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 99999, "step": 0.01}], "smoothing_factor": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "normalize": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["sound_level", "start_range_hz", "end_range_hz", "multiplier", "smoothing_factor", "normalize"]}, "output": ["FLOAT", "INT"], "output_is_list": [false, false], "output_name": ["sound_level", "sound_level_int"], "name": "SoundReactive", "display_name": "Sound Reactive", "description": "\nReacts to the sound level of the input.  \nUses your browsers sound input options and requires.  \nMeant to be used with realtime diffusion with autoqueue.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/audio", "output_node": false}, "StableZero123_BatchSchedule": {"input": {"required": {"clip_vision": ["CLIP_VISION"], "init_image": ["IMAGE"], "vae": ["VAE"], "width": ["INT", {"default": 256, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 256, "min": 16, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "azimuth_points_string": ["STRING", {"default": "0:(0.0),\n7:(1.0),\n15:(0.0)\n", "multiline": true}], "elevation_points_string": ["STRING", {"default": "0:(0.0),\n7:(0.0),\n15:(0.0)\n", "multiline": true}]}}, "input_order": {"required": ["clip_vision", "init_image", "vae", "width", "height", "batch_size", "interpolation", "azimuth_points_string", "elevation_points_string"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "StableZero123_BatchSchedule", "display_name": "Stable Zero123 Batch Schedule", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "SV3D_BatchSchedule": {"input": {"required": {"clip_vision": ["CLIP_VISION"], "init_image": ["IMAGE"], "vae": ["VAE"], "width": ["INT", {"default": 576, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 576, "min": 16, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 21, "min": 1, "max": 4096}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "azimuth_points_string": ["STRING", {"default": "0:(0.0),\n9:(180.0),\n20:(360.0)\n", "multiline": true}], "elevation_points_string": ["STRING", {"default": "0:(0.0),\n9:(0.0),\n20:(0.0)\n", "multiline": true}]}}, "input_order": {"required": ["clip_vision", "init_image", "vae", "width", "height", "batch_size", "interpolation", "azimuth_points_string", "elevation_points_string"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "SV3D_BatchSchedule", "display_name": "SV3D Batch Schedule", "description": "\nAllow scheduling of the azimuth and elevation conditions for SV3D.  \nNote that SV3D is still a video model and the schedule needs to always go forward  \nhttps://huggingface.co/stabilityai/sv3d\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "LoadResAdapterNormalization": {"input": {"required": {"model": ["MODEL"], "resadapter_path": [["Artfusion Surreal XL.safetensors", "Flux_dev_turbo_krea_mix.safetensors", "Flux_dev_v1.safetensors", "XLbluePencilXL_v700.safetensors", "XLrealbluejuggernautmi_v10.safetensors", "animagineXLRealistic_v5.safetensors", "animeIllustDiffusion_v08.safetensors", "artfusionXL_v11Lightning.safetensors", "cyberrealisticXL_v5.safetensors", "dreamshaperXL_v21TurboDPMSDE.safetensors", "electricDreams_electricDreamsV04.safetensors", "epicrealismXL_vxvAnewstoryRealism.safetensors", "illustrationStyleIV.nR7A.safetensors", "illustrationXL_v10.safetensors", "jibMixRealisticXL_v170SmokeSheen.safetensors", "jruTheJourneyRemains_v20XL.safetensors", "midgardPonyTHLSDXL_v32.safetensors", "pixniteXL_v10.safetensors", "reymixXL_v20.safetensors", "sd_xl_base_1.0.safetensors", "sd_xl_refiner_1.0.safetensors", "sdxlFaetastic_v10.safetensors", "sdxlInkpunkstyle_v01.safetensors", "v1-5-pruned-emaonly.safetensors", "xl6HEPHAISTOSSD10XLSFW_v331BF16Experimental.safetensors"]]}}, "input_order": {"required": ["model", "resadapter_path"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "LoadResAdapterNormalization", "display_name": "LoadResAdapterNormalization", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "Superprompt": {"input": {"required": {"instruction_prompt": ["STRING", {"default": "Expand the following prompt to add more detail", "multiline": true}], "prompt": ["STRING", {"default": "", "multiline": true, "forceInput": true}], "max_new_tokens": ["INT", {"default": 128, "min": 1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["instruction_prompt", "prompt", "max_new_tokens"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Superprompt", "display_name": "Superprompt", "description": "\n# SuperPrompt\nA T5 model fine-tuned on the SuperPrompt dataset for  \nupsampling text prompts to more detailed descriptions.  \nMeant to be used as a pre-generation step for text-to-image  \nmodels that benefit from more detailed prompts.  \nhttps://huggingface.co/roborovski/superprompt-v1\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/text", "output_node": false}, "GLIGENTextBoxApplyBatchCoords": {"input": {"required": {"conditioning_to": ["CONDITIONING"], "latents": ["LATENT"], "clip": ["CLIP"], "gligen_textbox_model": ["GLIGEN"], "coordinates": ["STRING", {"forceInput": true}], "text": ["STRING", {"multiline": true}], "width": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 8}], "height": ["INT", {"default": 128, "min": 8, "max": 4096, "step": 8}]}, "optional": {"size_multiplier": ["FLOAT", {"default": [1.0], "forceInput": true}]}}, "input_order": {"required": ["conditioning_to", "latents", "clip", "gligen_textbox_model", "coordinates", "text", "width", "height"], "optional": ["size_multiplier"]}, "output": ["CONDITIONING", "IMAGE"], "output_is_list": [false, false], "output_name": ["conditioning", "coord_preview"], "name": "GLIGENTextBoxApplyBatchCoords", "display_name": "GLIGENTextBoxApplyBatchCoords", "description": "\nThis node allows scheduling GLIGEN text box positions in a batch,  \nto be used with AnimateDiff-Evolved. Intended to pair with the  \nSpline Editor -node.  \n\nGLIGEN model can be downloaded through the Manage's \"Install Models\" menu.  \nOr directly from here:  \nhttps://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/tree/main  \n  \nInputs:  \n- **latents** input is used to calculate batch size  \n- **clip** is your standard text encoder, use same as for the main prompt  \n- **gligen_textbox_model** connects to GLIGEN Loader  \n- **coordinates** takes a json string of points, directly compatible  \nwith the spline editor node.\n- **text** is the part of the prompt to set position for  \n- **width** and **height** are the size of the GLIGEN bounding box  \n  \nOutputs:\n- **conditioning** goes between to clip text encode and the sampler  \n- **coord_preview** is an optional preview of the coordinates and  \nbounding boxes.\n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "Intrinsic_lora_sampling": {"input": {"required": {"model": ["MODEL"], "lora_name": [["intrinsic_lora_sd15_albedo.safetensors", "intrinsic_lora_sd15_depth.safetensors", "intrinsic_lora_sd15_normal.safetensors", "intrinsic_lora_sd15_shading.safetensors", "intrinsic_loras.txt"]], "task": [["depth map", "surface normals", "albedo", "shading"], {"default": "depth map"}], "text": ["STRING", {"multiline": true, "default": ""}], "clip": ["CLIP"], "vae": ["VAE"], "per_batch": ["INT", {"default": 16, "min": 1, "max": 4096, "step": 1}]}, "optional": {"image": ["IMAGE"], "optional_latent": ["LATENT"]}}, "input_order": {"required": ["model", "lora_name", "task", "text", "clip", "vae", "per_batch"], "optional": ["image", "optional_latent"]}, "output": ["IMAGE", "LATENT"], "output_is_list": [false, false], "output_name": ["IMAGE", "LATENT"], "name": "Intrinsic_lora_sampling", "display_name": "Intrinsic Lora Sampling", "description": "\nSampler to use the intrinsic loras:  \nhttps://github.com/duxiaodan/intrinsic-lora  \nThese LoRAs are tiny and thus included  \nwith this node pack.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes", "output_node": false}, "CheckpointPerturbWeights": {"input": {"required": {"model": ["MODEL"], "joint_blocks": ["FLOAT", {"default": 0.02, "min": 0.001, "max": 10.0, "step": 0.001}], "final_layer": ["FLOAT", {"default": 0.02, "min": 0.001, "max": 10.0, "step": 0.001}], "rest_of_the_blocks": ["FLOAT", {"default": 0.02, "min": 0.001, "max": 10.0, "step": 0.001}], "seed": ["INT", {"default": 123, "min": 0, "max": 18446744073709551615, "step": 1}]}}, "input_order": {"required": ["model", "joint_blocks", "final_layer", "rest_of_the_blocks", "seed"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "CheckpointPerturbWeights", "display_name": "CheckpointPerturbWeights", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": true}, "Screencap_mss": {"input": {"required": {"x": ["INT", {"default": 0, "min": 0, "max": 10000, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 10000, "step": 1}], "width": ["INT", {"default": 512, "min": 0, "max": 10000, "step": 1}], "height": ["INT", {"default": 512, "min": 0, "max": 10000, "step": 1}], "num_frames": ["INT", {"default": 1, "min": 1, "max": 255, "step": 1}], "delay": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["x", "y", "width", "height", "num_frames", "delay"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "Screencap_mss", "display_name": "Screencap mss", "description": "\nCaptures an area specified by screen coordinates.  \nCan be used for realtime diffusion with autoqueue.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/image", "output_node": false}, "WebcamCaptureCV2": {"input": {"required": {"x": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 4096, "step": 1}], "width": ["INT", {"default": 512, "min": 0, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 0, "max": 4096, "step": 1}], "cam_index": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "release": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["x", "y", "width", "height", "cam_index", "release"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "WebcamCaptureCV2", "display_name": "Webcam Capture CV2", "description": "\nCaptures a frame from a webcam using CV2.  \nCan be used for realtime diffusion with autoqueue.\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "DifferentialDiffusionAdvanced": {"input": {"required": {"model": ["MODEL"], "samples": ["LATENT"], "mask": ["MASK"], "multiplier": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.001}]}}, "input_order": {"required": ["model", "samples", "mask", "multiplier"]}, "output": ["MODEL", "LATENT"], "output_is_list": [false, false], "output_name": ["MODEL", "LATENT"], "name": "DifferentialDiffusionAdvanced", "display_name": "Differential Diffusion Advanced", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "_for_testing", "output_node": false}, "FluxBlockLoraLoader": {"input": {"required": {"model": ["MODEL", {"tooltip": "The diffusion model the LoRA will be applied to."}], "strength_model": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01, "tooltip": "How strongly to modify the diffusion model. This value can be negative."}]}, "optional": {"lora_name": [["BiFangBird.safetensors", "DrugPony.safetensors", "Harrlogos_v2.0.safetensors", "Inquisition_v1.safetensors", "Iridescence.safetensors", "Luxury_Houses_V1-000009.safetensors", "MJ52_v2.0.safetensors", "Textimprover-FLUX-V0.4.safetensors", "animemix_v3_offset.safetensors", "ff7r_style_ned_offset.safetensors", "first_stage-10.safetensors", "fractalized.safetensors", "hyvideo_FastVideo_LoRA-fp8.safetensors", "neoclassical villa - PHK.safetensors", "pokemon_v3_offset.safetensors", "polyhedron_new_skin_v1.1.safetensors", "poms-funtime-mlora-emporium/LiquidAF-0-1.safetensors", "poms-funtime-mlora-emporium/Smoooth-0-1.safetensors", "poms-funtime-mlora-emporium/WAS26.safetensors", "psychedelic_portrait.safetensors", "sd_xl_offset_example-lora_1.0.safetensors"], {"tooltip": "The name of the LoRA."}], "opt_lora_path": ["STRING", {"forceInput": true, "tooltip": "Absolute path of the LoRA."}], "blocks": ["SELECTEDBLOCKS"]}}, "input_order": {"required": ["model", "strength_model"], "optional": ["lora_name", "opt_lora_path", "blocks"]}, "output": ["MODEL", "STRING"], "output_is_list": [false, false], "output_name": ["model", "rank"], "name": "FluxBlockLoraLoader", "display_name": "Flux Block Lora Loader", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "output_tooltips": ["The modified diffusion model.", "possible rank of the LoRA."]}, "FluxBlockLoraSelect": {"input": {"required": {"double_blocks.0.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.1.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.2.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.3.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.4.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.5.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.6.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.7.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.8.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.9.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.10.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.11.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.12.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.13.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.14.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.15.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.16.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.17.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.18.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.0.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.1.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.2.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.3.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.4.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.5.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.6.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.7.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.8.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.9.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.10.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.11.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.12.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.13.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.14.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.15.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.16.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.17.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.18.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.19.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.20.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.21.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.22.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.23.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.24.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.25.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.26.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.27.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.28.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.29.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.30.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.31.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.32.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.33.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.34.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.35.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.36.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.37.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}]}}, "input_order": {"required": ["double_blocks.0.", "double_blocks.1.", "double_blocks.2.", "double_blocks.3.", "double_blocks.4.", "double_blocks.5.", "double_blocks.6.", "double_blocks.7.", "double_blocks.8.", "double_blocks.9.", "double_blocks.10.", "double_blocks.11.", "double_blocks.12.", "double_blocks.13.", "double_blocks.14.", "double_blocks.15.", "double_blocks.16.", "double_blocks.17.", "double_blocks.18.", "single_blocks.0.", "single_blocks.1.", "single_blocks.2.", "single_blocks.3.", "single_blocks.4.", "single_blocks.5.", "single_blocks.6.", "single_blocks.7.", "single_blocks.8.", "single_blocks.9.", "single_blocks.10.", "single_blocks.11.", "single_blocks.12.", "single_blocks.13.", "single_blocks.14.", "single_blocks.15.", "single_blocks.16.", "single_blocks.17.", "single_blocks.18.", "single_blocks.19.", "single_blocks.20.", "single_blocks.21.", "single_blocks.22.", "single_blocks.23.", "single_blocks.24.", "single_blocks.25.", "single_blocks.26.", "single_blocks.27.", "single_blocks.28.", "single_blocks.29.", "single_blocks.30.", "single_blocks.31.", "single_blocks.32.", "single_blocks.33.", "single_blocks.34.", "single_blocks.35.", "single_blocks.36.", "single_blocks.37."]}, "output": ["SELECTEDBLOCKS"], "output_is_list": [false], "output_name": ["blocks"], "name": "FluxBlockLoraSelect", "display_name": "Flux Block Lora Select", "description": "Select individual block alpha values, value of 0 removes the block altogether", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "output_tooltips": ["The modified diffusion model."]}, "HunyuanVideoBlockLoraSelect": {"input": {"required": {"double_blocks.0.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.1.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.2.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.3.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.4.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.5.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.6.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.7.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.8.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.9.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.10.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.11.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.12.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.13.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.14.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.15.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.16.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.17.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.18.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "double_blocks.19.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.0.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.1.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.2.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.3.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.4.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.5.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.6.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.7.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.8.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.9.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.10.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.11.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.12.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.13.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.14.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.15.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.16.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.17.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.18.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.19.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.20.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.21.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.22.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.23.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.24.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.25.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.26.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.27.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.28.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.29.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.30.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.31.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.32.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.33.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.34.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.35.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.36.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.37.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.38.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "single_blocks.39.": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.01}]}}, "input_order": {"required": ["double_blocks.0.", "double_blocks.1.", "double_blocks.2.", "double_blocks.3.", "double_blocks.4.", "double_blocks.5.", "double_blocks.6.", "double_blocks.7.", "double_blocks.8.", "double_blocks.9.", "double_blocks.10.", "double_blocks.11.", "double_blocks.12.", "double_blocks.13.", "double_blocks.14.", "double_blocks.15.", "double_blocks.16.", "double_blocks.17.", "double_blocks.18.", "double_blocks.19.", "single_blocks.0.", "single_blocks.1.", "single_blocks.2.", "single_blocks.3.", "single_blocks.4.", "single_blocks.5.", "single_blocks.6.", "single_blocks.7.", "single_blocks.8.", "single_blocks.9.", "single_blocks.10.", "single_blocks.11.", "single_blocks.12.", "single_blocks.13.", "single_blocks.14.", "single_blocks.15.", "single_blocks.16.", "single_blocks.17.", "single_blocks.18.", "single_blocks.19.", "single_blocks.20.", "single_blocks.21.", "single_blocks.22.", "single_blocks.23.", "single_blocks.24.", "single_blocks.25.", "single_blocks.26.", "single_blocks.27.", "single_blocks.28.", "single_blocks.29.", "single_blocks.30.", "single_blocks.31.", "single_blocks.32.", "single_blocks.33.", "single_blocks.34.", "single_blocks.35.", "single_blocks.36.", "single_blocks.37.", "single_blocks.38.", "single_blocks.39."]}, "output": ["SELECTEDBLOCKS"], "output_is_list": [false], "output_name": ["blocks"], "name": "HunyuanVideoBlockLoraSelect", "display_name": "Hunyuan Video Block Lora Select", "description": "Select individual block alpha values, value of 0 removes the block altogether", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "output_tooltips": ["The modified diffusion model."]}, "CustomControlNetWeightsFluxFromList": {"input": {"required": {"list_of_floats": ["FLOAT", {"forceInput": true}]}, "optional": {"uncond_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cn_extras": ["CN_WEIGHTS_EXTRAS"], "autosize": ["ACNAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["list_of_floats"], "optional": ["uncond_multiplier", "cn_extras", "autosize"]}, "output": ["CONTROL_NET_WEIGHTS", "TIMESTEP_KEYFRAME"], "output_is_list": [false, false], "output_name": ["CN_WEIGHTS", "TK_SHORTCUT"], "name": "CustomControlNetWeightsFluxFromList", "display_name": "Custom ControlNet Weights Flux From List", "description": "Creates controlnet weights from a list of floats for Advanced-ControlNet", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/controlnet", "output_node": false}, "CheckpointLoaderKJ": {"input": {"required": {"ckpt_name": [["Artfusion Surreal XL.safetensors", "Flux_dev_turbo_krea_mix.safetensors", "Flux_dev_v1.safetensors", "XLbluePencilXL_v700.safetensors", "XLrealbluejuggernautmi_v10.safetensors", "animagineXLRealistic_v5.safetensors", "animeIllustDiffusion_v08.safetensors", "artfusionXL_v11Lightning.safetensors", "cyberrealisticXL_v5.safetensors", "dreamshaperXL_v21TurboDPMSDE.safetensors", "electricDreams_electricDreamsV04.safetensors", "epicrealismXL_vxvAnewstoryRealism.safetensors", "illustrationStyleIV.nR7A.safetensors", "illustrationXL_v10.safetensors", "jibMixRealisticXL_v170SmokeSheen.safetensors", "jruTheJourneyRemains_v20XL.safetensors", "midgardPonyTHLSDXL_v32.safetensors", "pixniteXL_v10.safetensors", "reymixXL_v20.safetensors", "sd_xl_base_1.0.safetensors", "sd_xl_refiner_1.0.safetensors", "sdxlFaetastic_v10.safetensors", "sdxlInkpunkstyle_v01.safetensors", "v1-5-pruned-emaonly.safetensors", "xl6HEPHAISTOSSD10XLSFW_v331BF16Experimental.safetensors"], {"tooltip": "The name of the checkpoint (model) to load."}], "weight_dtype": [["default", "fp8_e4m3fn", "fp8_e4m3fn_fast", "fp8_e5m2", "fp16", "bf16", "fp32"]], "compute_dtype": [["default", "fp16", "bf16", "fp32"], {"default": "default", "tooltip": "The compute dtype to use for the model."}], "patch_cublaslinear": ["BOOLEAN", {"default": false, "tooltip": "Enable or disable the patching, won't take effect on already loaded models!"}], "sage_attention": [["disabled", "auto", "sageattn_qk_int8_pv_fp16_cuda", "sageattn_qk_int8_pv_fp16_triton", "sageattn_qk_int8_pv_fp8_cuda"], {"default": false, "tooltip": "Patch comfy attention to use sageattn."}], "enable_fp16_accumulation": ["BOOLEAN", {"default": false, "tooltip": "Enable torch.backends.cuda.matmul.allow_fp16_accumulation, requires pytorch 2.7.0 nightly."}]}}, "input_order": {"required": ["ckpt_name", "weight_dtype", "compute_dtype", "patch_cublaslinear", "sage_attention", "enable_fp16_accumulation"]}, "output": ["MODEL", "CLIP", "VAE"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "VAE"], "name": "CheckpointLoaderKJ", "display_name": "CheckpointLoaderKJ", "description": "Experimental node for patching torch.nn.Linear with CublasLinear.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": true, "experimental": true}, "DiffusionModelLoaderKJ": {"input": {"required": {"model_name": [["wan2.2_ti2v_5B_fp16.safetensors"], {"tooltip": "The name of the checkpoint (model) to load."}], "weight_dtype": [["default", "fp8_e4m3fn", "fp8_e4m3fn_fast", "fp8_e5m2", "fp16", "bf16", "fp32"]], "compute_dtype": [["default", "fp16", "bf16", "fp32"], {"default": "default", "tooltip": "The compute dtype to use for the model."}], "patch_cublaslinear": ["BOOLEAN", {"default": false, "tooltip": "Enable or disable the patching, won't take effect on already loaded models!"}], "sage_attention": [["disabled", "auto", "sageattn_qk_int8_pv_fp16_cuda", "sageattn_qk_int8_pv_fp16_triton", "sageattn_qk_int8_pv_fp8_cuda"], {"default": false, "tooltip": "Patch comfy attention to use sageattn."}], "enable_fp16_accumulation": ["BOOLEAN", {"default": false, "tooltip": "Enable torch.backends.cuda.matmul.allow_fp16_accumulation, requires pytorch 2.7.0 nightly."}]}}, "input_order": {"required": ["model_name", "weight_dtype", "compute_dtype", "patch_cublaslinear", "sage_attention", "enable_fp16_accumulation"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "DiffusionModelLoaderKJ", "display_name": "Diffusion Model Loader KJ", "description": "Node for patching torch.nn.Linear with CublasLinear.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": true, "experimental": true}, "TorchCompileModelFluxAdvanced": {"input": {"required": {"model": ["MODEL"], "backend": [["inductor", "cudagraphs"]], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}], "double_blocks": ["STRING", {"default": "0-18", "multiline": true}], "single_blocks": ["STRING", {"default": "0-37", "multiline": true}], "dynamic": ["BOOLEAN", {"default": false, "tooltip": "Enable dynamic mode"}]}, "optional": {"dynamo_cache_size_limit": ["INT", {"default": 64, "min": 0, "max": 1024, "step": 1, "tooltip": "torch._dynamo.config.cache_size_limit"}]}}, "input_order": {"required": ["model", "backend", "fullgraph", "mode", "double_blocks", "single_blocks", "dynamic"], "optional": ["dynamo_cache_size_limit"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "TorchCompileModelFluxAdvanced", "display_name": "TorchCompileModelFluxAdvanced", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/torchcompile", "output_node": false, "experimental": true}, "TorchCompileModelFluxAdvancedV2": {"input": {"required": {"model": ["MODEL"], "backend": [["inductor", "cudagraphs"]], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}], "double_blocks": ["BOOLEAN", {"default": true, "tooltip": "Compile double blocks"}], "single_blocks": ["BOOLEAN", {"default": true, "tooltip": "Compile single blocks"}], "dynamic": ["BOOLEAN", {"default": false, "tooltip": "Enable dynamic mode"}]}, "optional": {"dynamo_cache_size_limit": ["INT", {"default": 64, "min": 0, "max": 1024, "step": 1, "tooltip": "torch._dynamo.config.cache_size_limit"}]}}, "input_order": {"required": ["model", "backend", "fullgraph", "mode", "double_blocks", "single_blocks", "dynamic"], "optional": ["dynamo_cache_size_limit"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "TorchCompileModelFluxAdvancedV2", "display_name": "TorchCompileModelFluxAdvancedV2", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/torchcompile", "output_node": false, "experimental": true}, "TorchCompileModelHyVideo": {"input": {"required": {"model": ["MODEL"], "backend": [["inductor", "cudagraphs"], {"default": "inductor"}], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}], "dynamic": ["BOOLEAN", {"default": false, "tooltip": "Enable dynamic mode"}], "dynamo_cache_size_limit": ["INT", {"default": 64, "min": 0, "max": 1024, "step": 1, "tooltip": "torch._dynamo.config.cache_size_limit"}], "compile_single_blocks": ["BOOLEAN", {"default": true, "tooltip": "Compile single blocks"}], "compile_double_blocks": ["BOOLEAN", {"default": true, "tooltip": "Compile double blocks"}], "compile_txt_in": ["BOOLEAN", {"default": false, "tooltip": "Compile txt_in layers"}], "compile_vector_in": ["BOOLEAN", {"default": false, "tooltip": "Compile vector_in layers"}], "compile_final_layer": ["BOOLEAN", {"default": false, "tooltip": "Compile final layer"}]}}, "input_order": {"required": ["model", "backend", "fullgraph", "mode", "dynamic", "dynamo_cache_size_limit", "compile_single_blocks", "compile_double_blocks", "compile_txt_in", "compile_vector_in", "compile_final_layer"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "TorchCompileModelHyVideo", "display_name": "TorchCompileModelHyVideo", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/torchcompile", "output_node": false, "experimental": true}, "TorchCompileVAE": {"input": {"required": {"vae": ["VAE"], "backend": [["inductor", "cudagraphs"]], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}], "compile_encoder": ["BOOLEAN", {"default": true, "tooltip": "Compile encoder"}], "compile_decoder": ["BOOLEAN", {"default": true, "tooltip": "Compile decoder"}]}}, "input_order": {"required": ["vae", "backend", "fullgraph", "mode", "compile_encoder", "compile_decoder"]}, "output": ["VAE"], "output_is_list": [false], "output_name": ["VAE"], "name": "TorchCompileVAE", "display_name": "TorchCompileVAE", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/torchcompile", "output_node": false, "experimental": true}, "TorchCompileControlNet": {"input": {"required": {"controlnet": ["CONTROL_NET"], "backend": [["inductor", "cudagraphs"]], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}]}}, "input_order": {"required": ["controlnet", "backend", "fullgraph", "mode"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "TorchCompileControlNet", "display_name": "TorchCompileControlNet", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/torchcompile", "output_node": false, "experimental": true}, "PatchModelPatcherOrder": {"input": {"required": {"model": ["MODEL"], "patch_order": [["object_patch_first", "weight_patch_first"], {"default": "weight_patch_first", "tooltip": "Patch the comfy patch_model function to load weight patches (LoRAs) before compiling the model"}], "full_load": [["enabled", "disabled", "auto"], {"default": "auto", "tooltip": "Disabling may help with memory issues when loading large models, when changing this you should probably force model reload to avoid issues!"}]}}, "input_order": {"required": ["model", "patch_order", "full_load"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "PatchModelPatcherOrder", "display_name": "Patch Model Patcher Order", "description": "Patch the comfy patch_model function patching order, useful for torch.compile (used as object_patch) as it should come last if you want to use LoRAs with compile", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "experimental": true}, "TorchCompileLTXModel": {"input": {"required": {"model": ["MODEL"], "backend": [["inductor", "cudagraphs"]], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}], "dynamic": ["BOOLEAN", {"default": false, "tooltip": "Enable dynamic mode"}]}}, "input_order": {"required": ["model", "backend", "fullgraph", "mode", "dynamic"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "TorchCompileLTXModel", "display_name": "TorchCompileLTXModel", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/torchcompile", "output_node": false, "experimental": true}, "TorchCompileCosmosModel": {"input": {"required": {"model": ["MODEL"], "backend": [["inductor", "cudagraphs"]], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}], "dynamic": ["BOOLEAN", {"default": false, "tooltip": "Enable dynamic mode"}], "dynamo_cache_size_limit": ["INT", {"default": 64, "tooltip": "Set the dynamo cache size limit"}]}}, "input_order": {"required": ["model", "backend", "fullgraph", "mode", "dynamic", "dynamo_cache_size_limit"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "TorchCompileCosmosModel", "display_name": "TorchCompileCosmosModel", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/torchcompile", "output_node": false, "experimental": true}, "TorchCompileModelWanVideo": {"input": {"required": {"model": ["MODEL"], "backend": [["inductor", "cudagraphs"], {"default": "inductor"}], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}], "dynamic": ["BOOLEAN", {"default": false, "tooltip": "Enable dynamic mode"}], "dynamo_cache_size_limit": ["INT", {"default": 64, "min": 0, "max": 1024, "step": 1, "tooltip": "torch._dynamo.config.cache_size_limit"}], "compile_transformer_blocks_only": ["BOOLEAN", {"default": false, "tooltip": "Compile only transformer blocks"}]}}, "input_order": {"required": ["model", "backend", "fullgraph", "mode", "dynamic", "dynamo_cache_size_limit", "compile_transformer_blocks_only"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "TorchCompileModelWanVideo", "display_name": "TorchCompileModelWanVideo", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/torchcompile", "output_node": false, "experimental": true}, "TorchCompileModelWanVideoV2": {"input": {"required": {"model": ["MODEL"], "backend": [["inductor", "cudagraphs"], {"default": "inductor"}], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}], "dynamic": ["BOOLEAN", {"default": false, "tooltip": "Enable dynamic mode"}], "compile_transformer_blocks_only": ["BOOLEAN", {"default": true, "tooltip": "Compile only transformer blocks, faster compile and less error prone"}], "dynamo_cache_size_limit": ["INT", {"default": 64, "min": 0, "max": 1024, "step": 1, "tooltip": "torch._dynamo.config.cache_size_limit"}]}}, "input_order": {"required": ["model", "backend", "fullgraph", "mode", "dynamic", "compile_transformer_blocks_only", "dynamo_cache_size_limit"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "TorchCompileModelWanVideoV2", "display_name": "TorchCompileModelWanVideoV2", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/torchcompile", "output_node": false, "experimental": true}, "PathchSageAttentionKJ": {"input": {"required": {"model": ["MODEL"], "sage_attention": [["disabled", "auto", "sageattn_qk_int8_pv_fp16_cuda", "sageattn_qk_int8_pv_fp16_triton", "sageattn_qk_int8_pv_fp8_cuda"], {"default": false, "tooltip": "Global patch comfy attention to use sageattn, once patched to revert back to normal you would need to run this node again with disabled option."}]}}, "input_order": {"required": ["model", "sage_attention"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "PathchSageAttentionKJ", "display_name": "Patch Sage Attention KJ", "description": "Experimental node for patching attention mode. This doesn't use the model patching system and thus can't be disabled without running the node again with 'disabled' option.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "experimental": true}, "LeapfusionHunyuanI2VPatcher": {"input": {"required": {"model": ["MODEL"], "latent": ["LATENT"], "index": ["INT", {"default": 0, "min": -1, "max": 1000, "step": 1, "tooltip": "The index of the latent to be replaced. 0 for first frame and -1 for last"}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The start percentage of steps to apply"}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The end percentage of steps to apply"}], "strength": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.001}]}}, "input_order": {"required": ["model", "latent", "index", "start_percent", "end_percent", "strength"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "LeapfusionHunyuanI2VPatcher", "display_name": "Leapfusion Hunyuan I2V Patcher", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "VAELoaderKJ": {"input": {"required": {"vae_name": [["diffusion_pytorch_model.safetensors", "flux_vae.safetensors", "mochi_vae.safetensors", "sdxl_vae.safetensors", "vae-ft-ema-560000-ema.vae.pt", "wan2.2_vae.safetensors"]], "device": [["main_device", "cpu"]], "weight_dtype": [["bf16", "fp16", "fp32"]]}}, "input_order": {"required": ["vae_name", "device", "weight_dtype"]}, "output": ["VAE"], "output_is_list": [false], "output_name": ["VAE"], "name": "VAELoaderKJ", "display_name": "VAELoader KJ", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/vae", "output_node": false}, "ScheduledCFGGuidance": {"input": {"required": {"model": ["MODEL"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "cfg": ["FLOAT", {"default": 6.0, "min": 0.0, "max": 100.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "positive", "negative", "cfg", "start_percent", "end_percent"]}, "output": ["GUIDER"], "output_is_list": [false], "output_name": ["GUIDER"], "name": "ScheduledCFGGuidance", "display_name": "Scheduled CFG Guidance", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false}, "ApplyRifleXRoPE_HunuyanVideo": {"input": {"required": {"model": ["MODEL"], "latent": ["LATENT", {"tooltip": "Only used to get the latent count"}], "k": ["INT", {"default": 4, "min": 1, "max": 100, "step": 1, "tooltip": "Index of intrinsic frequency"}]}}, "input_order": {"required": ["model", "latent", "k"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ApplyRifleXRoPE_HunuyanVideo", "display_name": "Apply RifleXRoPE HunuyanVideo", "description": "Extends the potential frame count of HunyuanVideo using this method: https://github.com/thu-ml/RIFLEx", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "experimental": true}, "ApplyRifleXRoPE_WanVideo": {"input": {"required": {"model": ["MODEL"], "latent": ["LATENT", {"tooltip": "Only used to get the latent count"}], "k": ["INT", {"default": 6, "min": 1, "max": 100, "step": 1, "tooltip": "Index of intrinsic frequency"}]}}, "input_order": {"required": ["model", "latent", "k"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ApplyRifleXRoPE_WanVideo", "display_name": "Apply RifleXRoPE WanVideo", "description": "Extends the potential frame count of HunyuanVideo using this method: https://github.com/thu-ml/RIFLEx", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "experimental": true}, "WanVideoTeaCacheKJ": {"input": {"required": {"model": ["MODEL"], "rel_l1_thresh": ["FLOAT", {"default": 0.275, "min": 0.0, "max": 10.0, "step": 0.001, "tooltip": "Threshold for to determine when to apply the cache, compromise between speed and accuracy. When using coefficients a good value range is something between 0.2-0.4 for all but 1.3B model, which should be about 10 times smaller, same as when not using coefficients."}], "start_percent": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The start percentage of the steps to use with TeaCache."}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The end percentage of the steps to use with TeaCache."}], "cache_device": [["main_device", "offload_device"], {"default": "offload_device", "tooltip": "Device to cache to"}], "coefficients": [["disabled", "1.3B", "14B", "i2v_480", "i2v_720"], {"default": "i2v_480", "tooltip": "Coefficients for rescaling the relative l1 distance, if disabled the threshold value should be about 10 times smaller than the value used with coefficients."}]}}, "input_order": {"required": ["model", "rel_l1_thresh", "start_percent", "end_percent", "cache_device", "coefficients"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["model"], "name": "WanVideoTeaCacheKJ", "display_name": "WanVideo Tea Cache (native)", "description": "\nPatch WanVideo model to use TeaCache. Speeds up inference by caching the output and  \napplying it instead of doing the step.  Best results are achieved by choosing the  \nappropriate coefficients for the model. Early steps should never be skipped, with too  \naggressive values this can happen and the motion suffers. Starting later can help with that too.   \nWhen NOT using coefficients, the threshold value should be  \nabout 10 times smaller than the value used with coefficients.  \n\nOfficial recommended values https://github.com/ali-vilab/TeaCache/tree/main/TeaCache4Wan2.1:\n\n\n<pre style='font-family:monospace'>\n+-------------------+--------+---------+--------+\n|       Model       |  Low   | Medium  |  High  |\n+-------------------+--------+---------+--------+\n| Wan2.1 t2v 1.3B  |  0.05  |  0.07   |  0.08  |\n| Wan2.1 t2v 14B   |  0.14  |  0.15   |  0.20  |\n| Wan2.1 i2v 480P  |  0.13  |  0.19   |  0.26  |\n| Wan2.1 i2v 720P  |  0.18  |  0.20   |  0.30  |\n+-------------------+--------+---------+--------+\n</pre> \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/teacache", "output_node": false, "experimental": true}, "WanVideoEnhanceAVideoKJ": {"input": {"required": {"model": ["MODEL"], "latent": ["LATENT", {"tooltip": "Only used to get the latent count"}], "weight": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 10.0, "step": 0.001, "tooltip": "Strength of the enhance effect"}]}}, "input_order": {"required": ["model", "latent", "weight"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["model"], "name": "WanVideoEnhanceAVideoKJ", "display_name": "WanVideo Enhance A Video (native)", "description": "https://github.com/NUS-HPC-AI-Lab/Enhance-A-Video", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "experimental": true}, "SkipLayerGuidanceWanVideo": {"input": {"required": {"model": ["MODEL"], "blocks": ["STRING", {"default": "10", "multiline": false}], "start_percent": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["model", "blocks", "start_percent", "end_percent"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "SkipLayerGuidanceWanVideo", "display_name": "Skip Layer Guidance WanVideo", "description": "Simplified skip layer guidance that only skips the uncond on selected blocks", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "advanced/guidance", "output_node": false, "experimental": true}, "TimerNodeKJ": {"input": {"required": {"any_input": ["*", {}], "mode": [["start", "stop"]], "name": ["STRING", {"default": "Timer"}]}, "optional": {"timer": ["TIMER"]}}, "input_order": {"required": ["any_input", "mode", "name"], "optional": ["timer"]}, "output": ["*", "TIMER", "INT"], "output_is_list": [false, false, false], "output_name": ["any_output", "timer", "time"], "name": "TimerNodeKJ", "display_name": "Timer Node KJ", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/misc", "output_node": false}, "HunyuanVideoEncodeKeyframesToCond": {"input": {"required": {"model": ["MODEL"], "positive": ["CONDITIONING"], "vae": ["VAE"], "start_frame": ["IMAGE"], "end_frame": ["IMAGE"], "num_frames": ["INT", {"default": 33, "min": 2, "max": 4096, "step": 1}], "tile_size": ["INT", {"default": 512, "min": 64, "max": 4096, "step": 64}], "overlap": ["INT", {"default": 64, "min": 0, "max": 4096, "step": 32}], "temporal_size": ["INT", {"default": 64, "min": 8, "max": 4096, "step": 4, "tooltip": "Only used for video VAEs: Amount of frames to encode at a time."}], "temporal_overlap": ["INT", {"default": 8, "min": 4, "max": 4096, "step": 4, "tooltip": "Only used for video VAEs: Amount of frames to overlap."}]}, "optional": {"negative": ["CONDITIONING"]}}, "input_order": {"required": ["model", "positive", "vae", "start_frame", "end_frame", "num_frames", "tile_size", "overlap", "temporal_size", "temporal_overlap"], "optional": ["negative"]}, "output": ["MODEL", "CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false, false], "output_name": ["model", "positive", "negative", "latent"], "name": "HunyuanVideoEncodeKeyframesToCond", "display_name": "HunyuanVideo Encode Keyframes To Cond", "description": "", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/videomodels", "output_node": false}, "CFGZeroStarAndInit": {"input": {"required": {"model": ["MODEL"], "use_zero_init": ["BOOLEAN", {"default": true}], "zero_init_steps": ["INT", {"default": 0, "min": 0, "tooltip": "for zero init, starts from 0 so first step is always zeroed out if use_zero_init enabled"}]}}, "input_order": {"required": ["model", "use_zero_init", "zero_init_steps"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "CFGZeroStarAndInit", "display_name": "CFG Zero Star/Init", "description": "https://github.com/WeichenFan/CFG-Zero-star", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": false, "experimental": true}, "ModelPatchTorchSettings": {"input": {"required": {"model": ["MODEL"], "enable_fp16_accumulation": ["BOOLEAN", {"default": false, "tooltip": "Enable torch.backends.cuda.matmul.allow_fp16_accumulation, requires pytorch 2.7.0 nightly."}]}}, "input_order": {"required": ["model", "enable_fp16_accumulation"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelPatchTorchSettings", "display_name": "Model Patch Torch Settings", "description": "Adds callbacks to model to set torch settings before and after running the model.", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/experimental", "output_node": true, "experimental": true}, "CreateInstanceDiffusionTracking": {"input": {"required": {"coordinates": ["STRING", {"forceInput": true}], "width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "bbox_width": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "bbox_height": ["INT", {"default": 512, "min": 16, "max": 4096, "step": 1}], "class_name": ["STRING", {"default": "class_name"}], "class_id": ["INT", {"default": 0, "min": 0, "max": 255, "step": 1}], "prompt": ["STRING", {"default": "prompt", "multiline": true}]}, "optional": {"size_multiplier": ["FLOAT", {"default": [1.0], "forceInput": true}], "fit_in_frame": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["coordinates", "width", "height", "bbox_width", "bbox_height", "class_name", "class_id", "prompt"], "optional": ["size_multiplier", "fit_in_frame"]}, "output": ["TRACKING", "STRING", "INT", "INT", "INT", "INT"], "output_is_list": [false, false, false, false, false, false], "output_name": ["tracking", "prompt", "width", "height", "bbox_width", "bbox_height"], "name": "CreateInstanceDiffusionTracking", "display_name": "CreateInstanceDiffusionTracking", "description": "\nCreates tracking data to be used with InstanceDiffusion:  \nhttps://github.com/logtd/ComfyUI-InstanceDiffusion  \n  \nInstanceDiffusion prompt format:  \n\"class_id.class_name\": \"prompt\",  \nfor example:  \n\"1.head\": \"((head))\",  \n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/InstanceDiffusion", "output_node": false}, "AppendInstanceDiffusionTracking": {"input": {"required": {"tracking_1": ["TRACKING", {"forceInput": true}], "tracking_2": ["TRACKING", {"forceInput": true}]}, "optional": {"prompt_1": ["STRING", {"default": "", "forceInput": true}], "prompt_2": ["STRING", {"default": "", "forceInput": true}]}}, "input_order": {"required": ["tracking_1", "tracking_2"], "optional": ["prompt_1", "prompt_2"]}, "output": ["TRACKING", "STRING"], "output_is_list": [false, false], "output_name": ["tracking", "prompt"], "name": "AppendInstanceDiffusionTracking", "display_name": "AppendInstanceDiffusionTracking", "description": "\nAppends tracking data to be used with InstanceDiffusion:  \nhttps://github.com/logtd/ComfyUI-InstanceDiffusion  \n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/InstanceDiffusion", "output_node": false}, "DrawInstanceDiffusionTracking": {"input": {"required": {"image": ["IMAGE"], "tracking": ["TRACKING", {"forceInput": true}], "box_line_width": ["INT", {"default": 2, "min": 1, "max": 10, "step": 1}], "draw_text": ["BOOLEAN", {"default": true}], "font": [["FreeMono.ttf", "FreeMonoBoldOblique.otf", "TTNorms-Black.otf"]], "font_size": ["INT", {"default": 20}]}}, "input_order": {"required": ["image", "tracking", "box_line_width", "draw_text", "font", "font_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["image"], "name": "DrawInstanceDiffusionTracking", "display_name": "DrawInstanceDiffusionTracking", "description": "\nDraws the tracking data from  \nCreateInstanceDiffusionTracking -node.\n\n", "python_module": "custom_nodes.ComfyUI-KJNodes", "category": "KJNodes/InstanceDiffusion", "output_node": false}, "Context Big (rgthree)": {"input": {"required": {}, "optional": {"base_ctx": ["RGTHREE_CONTEXT"], "model": ["MODEL"], "clip": ["CLIP"], "vae": ["VAE"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "latent": ["LATENT"], "images": ["IMAGE"], "seed": ["INT", {"forceInput": true}], "steps": ["INT", {"forceInput": true}], "step_refiner": ["INT", {"forceInput": true}], "cfg": ["FLOAT", {"forceInput": true}], "ckpt_name": [["Artfusion Surreal XL.safetensors", "Flux_dev_turbo_krea_mix.safetensors", "Flux_dev_v1.safetensors", "XLbluePencilXL_v700.safetensors", "XLrealbluejuggernautmi_v10.safetensors", "animagineXLRealistic_v5.safetensors", "animeIllustDiffusion_v08.safetensors", "artfusionXL_v11Lightning.safetensors", "cyberrealisticXL_v5.safetensors", "dreamshaperXL_v21TurboDPMSDE.safetensors", "electricDreams_electricDreamsV04.safetensors", "epicrealismXL_vxvAnewstoryRealism.safetensors", "illustrationStyleIV.nR7A.safetensors", "illustrationXL_v10.safetensors", "jibMixRealisticXL_v170SmokeSheen.safetensors", "jruTheJourneyRemains_v20XL.safetensors", "midgardPonyTHLSDXL_v32.safetensors", "pixniteXL_v10.safetensors", "reymixXL_v20.safetensors", "sd_xl_base_1.0.safetensors", "sd_xl_refiner_1.0.safetensors", "sdxlFaetastic_v10.safetensors", "sdxlInkpunkstyle_v01.safetensors", "v1-5-pruned-emaonly.safetensors", "xl6HEPHAISTOSSD10XLSFW_v331BF16Experimental.safetensors"], {"forceInput": true}], "sampler": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"], {"forceInput": true}], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"], {"forceInput": true}], "clip_width": ["INT", {"forceInput": true}], "clip_height": ["INT", {"forceInput": true}], "text_pos_g": ["STRING", {"forceInput": true}], "text_pos_l": ["STRING", {"forceInput": true}], "text_neg_g": ["STRING", {"forceInput": true}], "text_neg_l": ["STRING", {"forceInput": true}], "mask": ["MASK"], "control_net": ["CONTROL_NET"]}, "hidden": {}}, "input_order": {"required": [], "optional": ["base_ctx", "model", "clip", "vae", "positive", "negative", "latent", "images", "seed", "steps", "step_refiner", "cfg", "ckpt_name", "sampler", "scheduler", "clip_width", "clip_height", "text_pos_g", "text_pos_l", "text_neg_g", "text_neg_l", "mask", "control_net"], "hidden": []}, "output": ["RGTHREE_CONTEXT", "MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING", "LATENT", "IMAGE", "INT", "INT", "INT", "FLOAT", ["Artfusion Surreal XL.safetensors", "Flux_dev_turbo_krea_mix.safetensors", "Flux_dev_v1.safetensors", "XLbluePencilXL_v700.safetensors", "XLrealbluejuggernautmi_v10.safetensors", "animagineXLRealistic_v5.safetensors", "animeIllustDiffusion_v08.safetensors", "artfusionXL_v11Lightning.safetensors", "cyberrealisticXL_v5.safetensors", "dreamshaperXL_v21TurboDPMSDE.safetensors", "electricDreams_electricDreamsV04.safetensors", "epicrealismXL_vxvAnewstoryRealism.safetensors", "illustrationStyleIV.nR7A.safetensors", "illustrationXL_v10.safetensors", "jibMixRealisticXL_v170SmokeSheen.safetensors", "jruTheJourneyRemains_v20XL.safetensors", "midgardPonyTHLSDXL_v32.safetensors", "pixniteXL_v10.safetensors", "reymixXL_v20.safetensors", "sd_xl_base_1.0.safetensors", "sd_xl_refiner_1.0.safetensors", "sdxlFaetastic_v10.safetensors", "sdxlInkpunkstyle_v01.safetensors", "v1-5-pruned-emaonly.safetensors", "xl6HEPHAISTOSSD10XLSFW_v331BF16Experimental.safetensors"], ["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"], ["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"], "INT", "INT", "STRING", "STRING", "STRING", "STRING", "MASK", "CONTROL_NET"], "output_is_list": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "output_name": ["CONTEXT", "MODEL", "CLIP", "VAE", "POSITIVE", "NEGATIVE", "LATENT", "IMAGE", "SEED", "STEPS", "STEP_REFINER", "CFG", "CKPT_NAME", "SAMPLER", "SCHEDULER", "CLIP_WIDTH", "CLIP_HEIGHT", "TEXT_POS_G", "TEXT_POS_L", "TEXT_NEG_G", "TEXT_NEG_L", "MASK", "CONTROL_NET"], "name": "Context Big (rgthree)", "display_name": "Context Big (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Context (rgthree)": {"input": {"required": {}, "optional": {"base_ctx": ["RGTHREE_CONTEXT"], "model": ["MODEL"], "clip": ["CLIP"], "vae": ["VAE"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "latent": ["LATENT"], "images": ["IMAGE"], "seed": ["INT", {"forceInput": true}]}, "hidden": {"version": "FLOAT"}}, "input_order": {"required": [], "optional": ["base_ctx", "model", "clip", "vae", "positive", "negative", "latent", "images", "seed"], "hidden": ["version"]}, "output": ["RGTHREE_CONTEXT", "MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING", "LATENT", "IMAGE", "INT"], "output_is_list": [false, false, false, false, false, false, false, false, false], "output_name": ["CONTEXT", "MODEL", "CLIP", "VAE", "POSITIVE", "NEGATIVE", "LATENT", "IMAGE", "SEED"], "name": "Context (rgthree)", "display_name": "Context (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Context Switch (rgthree)": {"input": {"required": {}, "optional": {}}, "input_order": {"required": [], "optional": []}, "output": ["RGTHREE_CONTEXT", "MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING", "LATENT", "IMAGE", "INT"], "output_is_list": [false, false, false, false, false, false, false, false, false], "output_name": ["CONTEXT", "MODEL", "CLIP", "VAE", "POSITIVE", "NEGATIVE", "LATENT", "IMAGE", "SEED"], "name": "Context Switch (rgthree)", "display_name": "Context Switch (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Context Switch Big (rgthree)": {"input": {"required": {}, "optional": {}}, "input_order": {"required": [], "optional": []}, "output": ["RGTHREE_CONTEXT", "MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING", "LATENT", "IMAGE", "INT", "INT", "INT", "FLOAT", ["Artfusion Surreal XL.safetensors", "Flux_dev_turbo_krea_mix.safetensors", "Flux_dev_v1.safetensors", "XLbluePencilXL_v700.safetensors", "XLrealbluejuggernautmi_v10.safetensors", "animagineXLRealistic_v5.safetensors", "animeIllustDiffusion_v08.safetensors", "artfusionXL_v11Lightning.safetensors", "cyberrealisticXL_v5.safetensors", "dreamshaperXL_v21TurboDPMSDE.safetensors", "electricDreams_electricDreamsV04.safetensors", "epicrealismXL_vxvAnewstoryRealism.safetensors", "illustrationStyleIV.nR7A.safetensors", "illustrationXL_v10.safetensors", "jibMixRealisticXL_v170SmokeSheen.safetensors", "jruTheJourneyRemains_v20XL.safetensors", "midgardPonyTHLSDXL_v32.safetensors", "pixniteXL_v10.safetensors", "reymixXL_v20.safetensors", "sd_xl_base_1.0.safetensors", "sd_xl_refiner_1.0.safetensors", "sdxlFaetastic_v10.safetensors", "sdxlInkpunkstyle_v01.safetensors", "v1-5-pruned-emaonly.safetensors", "xl6HEPHAISTOSSD10XLSFW_v331BF16Experimental.safetensors"], ["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"], ["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"], "INT", "INT", "STRING", "STRING", "STRING", "STRING", "MASK", "CONTROL_NET"], "output_is_list": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "output_name": ["CONTEXT", "MODEL", "CLIP", "VAE", "POSITIVE", "NEGATIVE", "LATENT", "IMAGE", "SEED", "STEPS", "STEP_REFINER", "CFG", "CKPT_NAME", "SAMPLER", "SCHEDULER", "CLIP_WIDTH", "CLIP_HEIGHT", "TEXT_POS_G", "TEXT_POS_L", "TEXT_NEG_G", "TEXT_NEG_L", "MASK", "CONTROL_NET"], "name": "Context Switch Big (rgthree)", "display_name": "Context Switch Big (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Context Merge (rgthree)": {"input": {"required": {}, "optional": {}}, "input_order": {"required": [], "optional": []}, "output": ["RGTHREE_CONTEXT", "MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING", "LATENT", "IMAGE", "INT"], "output_is_list": [false, false, false, false, false, false, false, false, false], "output_name": ["CONTEXT", "MODEL", "CLIP", "VAE", "POSITIVE", "NEGATIVE", "LATENT", "IMAGE", "SEED"], "name": "Context Merge (rgthree)", "display_name": "Context Merge (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Context Merge Big (rgthree)": {"input": {"required": {}, "optional": {}}, "input_order": {"required": [], "optional": []}, "output": ["RGTHREE_CONTEXT", "MODEL", "CLIP", "VAE", "CONDITIONING", "CONDITIONING", "LATENT", "IMAGE", "INT", "INT", "INT", "FLOAT", ["Artfusion Surreal XL.safetensors", "Flux_dev_turbo_krea_mix.safetensors", "Flux_dev_v1.safetensors", "XLbluePencilXL_v700.safetensors", "XLrealbluejuggernautmi_v10.safetensors", "animagineXLRealistic_v5.safetensors", "animeIllustDiffusion_v08.safetensors", "artfusionXL_v11Lightning.safetensors", "cyberrealisticXL_v5.safetensors", "dreamshaperXL_v21TurboDPMSDE.safetensors", "electricDreams_electricDreamsV04.safetensors", "epicrealismXL_vxvAnewstoryRealism.safetensors", "illustrationStyleIV.nR7A.safetensors", "illustrationXL_v10.safetensors", "jibMixRealisticXL_v170SmokeSheen.safetensors", "jruTheJourneyRemains_v20XL.safetensors", "midgardPonyTHLSDXL_v32.safetensors", "pixniteXL_v10.safetensors", "reymixXL_v20.safetensors", "sd_xl_base_1.0.safetensors", "sd_xl_refiner_1.0.safetensors", "sdxlFaetastic_v10.safetensors", "sdxlInkpunkstyle_v01.safetensors", "v1-5-pruned-emaonly.safetensors", "xl6HEPHAISTOSSD10XLSFW_v331BF16Experimental.safetensors"], ["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"], ["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"], "INT", "INT", "STRING", "STRING", "STRING", "STRING", "MASK", "CONTROL_NET"], "output_is_list": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "output_name": ["CONTEXT", "MODEL", "CLIP", "VAE", "POSITIVE", "NEGATIVE", "LATENT", "IMAGE", "SEED", "STEPS", "STEP_REFINER", "CFG", "CKPT_NAME", "SAMPLER", "SCHEDULER", "CLIP_WIDTH", "CLIP_HEIGHT", "TEXT_POS_G", "TEXT_POS_L", "TEXT_NEG_G", "TEXT_NEG_L", "MASK", "CONTROL_NET"], "name": "Context Merge Big (rgthree)", "display_name": "Context Merge Big (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Display Int (rgthree)": {"input": {"required": {"input": ["INT", {"forceInput": true}]}}, "input_order": {"required": ["input"]}, "output": [], "output_is_list": [], "output_name": [], "name": "Display Int (rgthree)", "display_name": "Display Int (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": true}, "Display Any (rgthree)": {"input": {"required": {"source": ["*", {}]}, "hidden": {"unique_id": "UNIQUE_ID", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["source"], "hidden": ["unique_id", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "Display Any (rgthree)", "display_name": "Display Any (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": true}, "Lora Loader Stack (rgthree)": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "lora_01": [["None", "BiFangBird.safetensors", "DrugPony.safetensors", "Harrlogos_v2.0.safetensors", "Inquisition_v1.safetensors", "Iridescence.safetensors", "Luxury_Houses_V1-000009.safetensors", "MJ52_v2.0.safetensors", "Textimprover-FLUX-V0.4.safetensors", "animemix_v3_offset.safetensors", "ff7r_style_ned_offset.safetensors", "first_stage-10.safetensors", "fractalized.safetensors", "hyvideo_FastVideo_LoRA-fp8.safetensors", "neoclassical villa - PHK.safetensors", "pokemon_v3_offset.safetensors", "polyhedron_new_skin_v1.1.safetensors", "poms-funtime-mlora-emporium/LiquidAF-0-1.safetensors", "poms-funtime-mlora-emporium/Smoooth-0-1.safetensors", "poms-funtime-mlora-emporium/WAS26.safetensors", "psychedelic_portrait.safetensors", "sd_xl_offset_example-lora_1.0.safetensors"]], "strength_01": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "lora_02": [["None", "BiFangBird.safetensors", "DrugPony.safetensors", "Harrlogos_v2.0.safetensors", "Inquisition_v1.safetensors", "Iridescence.safetensors", "Luxury_Houses_V1-000009.safetensors", "MJ52_v2.0.safetensors", "Textimprover-FLUX-V0.4.safetensors", "animemix_v3_offset.safetensors", "ff7r_style_ned_offset.safetensors", "first_stage-10.safetensors", "fractalized.safetensors", "hyvideo_FastVideo_LoRA-fp8.safetensors", "neoclassical villa - PHK.safetensors", "pokemon_v3_offset.safetensors", "polyhedron_new_skin_v1.1.safetensors", "poms-funtime-mlora-emporium/LiquidAF-0-1.safetensors", "poms-funtime-mlora-emporium/Smoooth-0-1.safetensors", "poms-funtime-mlora-emporium/WAS26.safetensors", "psychedelic_portrait.safetensors", "sd_xl_offset_example-lora_1.0.safetensors"]], "strength_02": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "lora_03": [["None", "BiFangBird.safetensors", "DrugPony.safetensors", "Harrlogos_v2.0.safetensors", "Inquisition_v1.safetensors", "Iridescence.safetensors", "Luxury_Houses_V1-000009.safetensors", "MJ52_v2.0.safetensors", "Textimprover-FLUX-V0.4.safetensors", "animemix_v3_offset.safetensors", "ff7r_style_ned_offset.safetensors", "first_stage-10.safetensors", "fractalized.safetensors", "hyvideo_FastVideo_LoRA-fp8.safetensors", "neoclassical villa - PHK.safetensors", "pokemon_v3_offset.safetensors", "polyhedron_new_skin_v1.1.safetensors", "poms-funtime-mlora-emporium/LiquidAF-0-1.safetensors", "poms-funtime-mlora-emporium/Smoooth-0-1.safetensors", "poms-funtime-mlora-emporium/WAS26.safetensors", "psychedelic_portrait.safetensors", "sd_xl_offset_example-lora_1.0.safetensors"]], "strength_03": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "lora_04": [["None", "BiFangBird.safetensors", "DrugPony.safetensors", "Harrlogos_v2.0.safetensors", "Inquisition_v1.safetensors", "Iridescence.safetensors", "Luxury_Houses_V1-000009.safetensors", "MJ52_v2.0.safetensors", "Textimprover-FLUX-V0.4.safetensors", "animemix_v3_offset.safetensors", "ff7r_style_ned_offset.safetensors", "first_stage-10.safetensors", "fractalized.safetensors", "hyvideo_FastVideo_LoRA-fp8.safetensors", "neoclassical villa - PHK.safetensors", "pokemon_v3_offset.safetensors", "polyhedron_new_skin_v1.1.safetensors", "poms-funtime-mlora-emporium/LiquidAF-0-1.safetensors", "poms-funtime-mlora-emporium/Smoooth-0-1.safetensors", "poms-funtime-mlora-emporium/WAS26.safetensors", "psychedelic_portrait.safetensors", "sd_xl_offset_example-lora_1.0.safetensors"]], "strength_04": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "clip", "lora_01", "strength_01", "lora_02", "strength_02", "lora_03", "strength_03", "lora_04", "strength_04"]}, "output": ["MODEL", "CLIP"], "output_is_list": [false, false], "output_name": ["MODEL", "CLIP"], "name": "Lora Loader Stack (rgthree)", "display_name": "Lora Loader Stack (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Seed (rgthree)": {"input": {"required": {"seed": ["INT", {"default": 0, "min": -1125899906842624, "max": 1125899906842624}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["seed"], "hidden": ["prompt", "extra_pnginfo", "unique_id"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["SEED"], "name": "Seed (rgthree)", "display_name": "Seed (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Image Inset Crop (rgthree)": {"input": {"required": {"image": ["IMAGE"], "measurement": [["Pixels", "Percentage"]], "left": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "right": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "top": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "bottom": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}]}}, "input_order": {"required": ["image", "measurement", "left", "right", "top", "bottom"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Image Inset Crop (rgthree)", "display_name": "Image Inset Crop (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Power Prompt (rgthree)": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "dynamicPrompts": true}]}, "optional": {"opt_model": ["MODEL"], "opt_clip": ["CLIP"], "insert_lora": [["CHOOSE", "DISABLE LORAS", "BiFangBird", "DrugPony", "Harrlogos_v2.0", "Inquisition_v1", "Iridescence", "Luxury_Houses_V1-000009", "MJ52_v2.0", "Textimprover-FLUX-V0.4", "animemix_v3_offset", "ff7r_style_ned_offset", "first_stage-10", "fractalized", "hyvideo_FastVideo_LoRA-fp8", "neoclassical villa - PHK", "pokemon_v3_offset", "polyhedron_new_skin_v1.1", "poms-funtime-mlora-emporium/LiquidAF-0-1", "poms-funtime-mlora-emporium/Smoooth-0-1", "poms-funtime-mlora-emporium/WAS26", "psychedelic_portrait", "sd_xl_offset_example-lora_1.0"]], "insert_embedding": [["CHOOSE"]], "insert_saved": [["CHOOSE"]]}, "hidden": {"values_insert_saved": [["CHOOSE"]]}}, "input_order": {"required": ["prompt"], "optional": ["opt_model", "opt_clip", "insert_lora", "insert_embedding", "insert_saved"], "hidden": ["values_insert_saved"]}, "output": ["CONDITIONING", "MODEL", "CLIP", "STRING"], "output_is_list": [false, false, false, false], "output_name": ["CONDITIONING", "MODEL", "CLIP", "TEXT"], "name": "Power Prompt (rgthree)", "display_name": "Power Prompt (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Power Prompt - Simple (rgthree)": {"input": {"required": {"prompt": ["STRING", {"multiline": true, "dynamicPrompts": true}]}, "optional": {"opt_clip": ["CLIP"], "insert_embedding": [["CHOOSE"]], "insert_saved": [["CHOOSE"]]}, "hidden": {"values_insert_saved": [["CHOOSE"]]}}, "input_order": {"required": ["prompt"], "optional": ["opt_clip", "insert_embedding", "insert_saved"], "hidden": ["values_insert_saved"]}, "output": ["CONDITIONING", "STRING"], "output_is_list": [false, false], "output_name": ["CONDITIONING", "TEXT"], "name": "Power Prompt - Simple (rgthree)", "display_name": "Power Prompt - Simple (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "KSampler Config (rgthree)": {"input": {"required": {"steps_total": ["INT", {"default": 30, "min": 1, "max": 16384, "step": 1}], "refiner_step": ["INT", {"default": 24, "min": 1, "max": 16384, "step": 1}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.5}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"]]}}, "input_order": {"required": ["steps_total", "refiner_step", "cfg", "sampler_name", "scheduler"]}, "output": ["INT", "INT", "FLOAT", ["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"], ["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"]], "output_is_list": [false, false, false, false, false], "output_name": ["STEPS", "REFINER_STEP", "CFG", "SAMPLER", "SCHEDULER"], "name": "KSampler Config (rgthree)", "display_name": "KSampler Config (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "SDXL Empty Latent Image (rgthree)": {"input": {"required": {"dimensions": [["1536 x 640   (landscape)", "1344 x 768   (landscape)", "1216 x 832   (landscape)", "1152 x 896   (landscape)", "1024 x 1024  (square)", " 896 x 1152  (portrait)", " 832 x 1216  (portrait)", " 768 x 1344  (portrait)", " 640 x 1536  (portrait)"], {"default": "1024 x 1024  (square)"}], "clip_scale": ["FLOAT", {"default": 2.0, "min": 1.0, "max": 10.0, "step": 0.5}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 64}]}}, "input_order": {"required": ["dimensions", "clip_scale", "batch_size"]}, "output": ["LATENT", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["LATENT", "CLIP_WIDTH", "CLIP_HEIGHT"], "name": "SDXL Empty Latent Image (rgthree)", "display_name": "SDXL Empty Latent Image (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "SDXL Power Prompt - Positive (rgthree)": {"input": {"required": {"prompt_g": ["STRING", {"multiline": true, "dynamicPrompts": true}], "prompt_l": ["STRING", {"multiline": true, "dynamicPrompts": true}]}, "optional": {"opt_model": ["MODEL"], "opt_clip": ["CLIP"], "opt_clip_width": ["INT", {"forceInput": true, "default": 1024.0, "min": 0, "max": 16384}], "opt_clip_height": ["INT", {"forceInput": true, "default": 1024.0, "min": 0, "max": 16384}], "insert_lora": [["CHOOSE", "DISABLE LORAS", "BiFangBird", "DrugPony", "Harrlogos_v2.0", "Inquisition_v1", "Iridescence", "Luxury_Houses_V1-000009", "MJ52_v2.0", "Textimprover-FLUX-V0.4", "animemix_v3_offset", "ff7r_style_ned_offset", "first_stage-10", "fractalized", "hyvideo_FastVideo_LoRA-fp8", "neoclassical villa - PHK", "pokemon_v3_offset", "polyhedron_new_skin_v1.1", "poms-funtime-mlora-emporium/LiquidAF-0-1", "poms-funtime-mlora-emporium/Smoooth-0-1", "poms-funtime-mlora-emporium/WAS26", "psychedelic_portrait", "sd_xl_offset_example-lora_1.0"]], "insert_embedding": [["CHOOSE"]], "insert_saved": [["CHOOSE"]], "target_width": ["INT", {"default": -1, "min": -1, "max": 16384}], "target_height": ["INT", {"default": -1, "min": -1, "max": 16384}], "crop_width": ["INT", {"default": -1, "min": -1, "max": 16384}], "crop_height": ["INT", {"default": -1, "min": -1, "max": 16384}]}, "hidden": {"values_insert_saved": [["CHOOSE"]]}}, "input_order": {"required": ["prompt_g", "prompt_l"], "optional": ["opt_model", "opt_clip", "opt_clip_width", "opt_clip_height", "insert_lora", "insert_embedding", "insert_saved", "target_width", "target_height", "crop_width", "crop_height"], "hidden": ["values_insert_saved"]}, "output": ["CONDITIONING", "MODEL", "CLIP", "STRING", "STRING"], "output_is_list": [false, false, false, false, false], "output_name": ["CONDITIONING", "MODEL", "CLIP", "TEXT_G", "TEXT_L"], "name": "SDXL Power Prompt - Positive (rgthree)", "display_name": "SDXL Power Prompt - Positive (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "SDXL Power Prompt - Simple / Negative (rgthree)": {"input": {"required": {"prompt_g": ["STRING", {"multiline": true, "dynamicPrompts": true}], "prompt_l": ["STRING", {"multiline": true, "dynamicPrompts": true}]}, "optional": {"opt_clip": ["CLIP"], "opt_clip_width": ["INT", {"forceInput": true, "default": 1024.0, "min": 0, "max": 16384}], "opt_clip_height": ["INT", {"forceInput": true, "default": 1024.0, "min": 0, "max": 16384}], "insert_embedding": [["CHOOSE"]], "insert_saved": [["CHOOSE"]], "target_width": ["INT", {"default": -1, "min": -1, "max": 16384}], "target_height": ["INT", {"default": -1, "min": -1, "max": 16384}], "crop_width": ["INT", {"default": -1, "min": -1, "max": 16384}], "crop_height": ["INT", {"default": -1, "min": -1, "max": 16384}]}, "hidden": {"values_insert_saved": [["CHOOSE"]]}}, "input_order": {"required": ["prompt_g", "prompt_l"], "optional": ["opt_clip", "opt_clip_width", "opt_clip_height", "insert_embedding", "insert_saved", "target_width", "target_height", "crop_width", "crop_height"], "hidden": ["values_insert_saved"]}, "output": ["CONDITIONING", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["CONDITIONING", "TEXT_G", "TEXT_L"], "name": "SDXL Power Prompt - Simple / Negative (rgthree)", "display_name": "SDXL Power Prompt - Simple / Negative (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Any Switch (rgthree)": {"input": {"required": {}, "optional": {}}, "input_order": {"required": [], "optional": []}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "Any Switch (rgthree)", "display_name": "Any Switch (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Image Comparer (rgthree)": {"input": {"required": {}, "optional": {"image_a": ["IMAGE"], "image_b": ["IMAGE"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": [], "optional": ["image_a", "image_b"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "Image Comparer (rgthree)", "display_name": "Image Comparer (rgthree)", "description": "Compares two images with a hover slider, or click from properties.", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": true}, "Power Lora Loader (rgthree)": {"input": {"required": {}, "optional": {"model": ["MODEL"], "clip": ["CLIP"]}, "hidden": {}}, "input_order": {"required": [], "optional": ["model", "clip"], "hidden": []}, "output": ["MODEL", "CLIP"], "output_is_list": [false, false], "output_name": ["MODEL", "CLIP"], "name": "Power Lora Loader (rgthree)", "display_name": "Power Lora Loader (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Power Primitive (rgthree)": {"input": {"required": {}, "optional": {}}, "input_order": {"required": [], "optional": []}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "Power Primitive (rgthree)", "display_name": "Power Primitive (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Image or Latent Size (rgthree)": {"input": {"required": {}, "optional": {}}, "input_order": {"required": [], "optional": []}, "output": ["INT", "INT"], "output_is_list": [false, false], "output_name": ["WIDTH", "HEIGHT"], "name": "Image or Latent Size (rgthree)", "display_name": "Image or Latent Size (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Image Resize (rgthree)": {"input": {"required": {"image": ["IMAGE"], "measurement": [["pixels", "percentage"]], "width": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1, "tooltip": "The width of the desired resize. A pixel value if measurement is 'pixels' or a 100% scale percentage value if measurement is 'percentage'. Passing '0' will calculate the dimension based on the height."}], "height": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "fit": [["crop", "pad", "contain"], {"tooltip": "'crop' resizes so the image covers the desired width and height, and center-crops the excess, returning exactly the desired width and height.\n'pad' resizes so the image fits inside the desired width and height, and fills the empty space returning exactly the desired width and height.\n'contain' resizes so the image fits inside the desired width and height, and returns the image with it's new size, with one side liekly smaller than the desired.\n\nNote, if either width or height is '0', the effective fit is 'contain'."}], "method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]]}}, "input_order": {"required": ["image", "measurement", "width", "height", "fit", "method"]}, "output": ["IMAGE", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["IMAGE", "WIDTH", "HEIGHT"], "name": "Image Resize (rgthree)", "display_name": "Image Resize (rgthree)", "description": "Resize the image.", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "Power Puter (rgthree)": {"input": {"required": {}, "optional": {}, "hidden": {"unique_id": "UNIQUE_ID", "extra_pnginfo": "EXTRA_PNGINFO", "prompt": "PROMPT"}}, "input_order": {"required": [], "optional": [], "hidden": ["unique_id", "extra_pnginfo", "prompt"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "Power Puter (rgthree)", "display_name": "Power Puter (rgthree)", "description": "", "python_module": "custom_nodes.rgthree-comfy", "category": "rgthree", "output_node": false}, "SaveImageWebsocket": {"input": {"required": {"images": ["IMAGE"]}}, "input_order": {"required": ["images"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveImageWebsocket", "display_name": "SaveImageWebsocket", "description": "", "python_module": "custom_nodes.websocket_image_save", "category": "api/image", "output_node": true}, "ADE_AnimateDiffLoRALoader": {"input": {"required": {"name": [[]], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}]}, "optional": {"prev_motion_lora": ["MOTION_LORA"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 30}]}}, "input_order": {"required": ["name", "strength"], "optional": ["prev_motion_lora"], "hidden": ["autosize"]}, "output": ["MOTION_LORA"], "output_is_list": [false], "output_name": ["MOTION_LORA"], "name": "ADE_AnimateDiffLoRALoader", "display_name": "Load AnimateDiff LoRA \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53", "output_node": false}, "ADE_AnimateDiffSamplingSettings": {"input": {"required": {"batch_offset": ["INT", {"default": 0, "min": 0, "max": 9007199254740991}], "noise_type": [["default", "constant", "empty", "repeated_context", "FreeNoise"]], "seed_gen": [["comfy", "comfy [gpu]", "auto1111", "auto1111 [gpu]"]], "seed_offset": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991}]}, "optional": {"noise_layers": ["NOISE_LAYERS"], "iteration_opts": ["ITERATION_OPTS"], "seed_override": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "forceInput": true}], "adapt_denoise_steps": ["BOOLEAN", {"default": false}], "custom_cfg": ["CUSTOM_CFG"], "sigma_schedule": ["SIGMA_SCHEDULE"], "image_inject": ["IMAGE_INJECT"], "ancestral_opts": ["ANCESTRAL_OPTS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["batch_offset", "noise_type", "seed_gen", "seed_offset"], "optional": ["noise_layers", "iteration_opts", "seed_override", "adapt_denoise_steps", "custom_cfg", "sigma_schedule", "image_inject", "ancestral_opts"], "hidden": ["autosize"]}, "output": ["SAMPLE_SETTINGS"], "output_is_list": [false], "output_name": ["settings"], "name": "ADE_AnimateDiffSamplingSettings", "display_name": "Sample Settings \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53", "output_node": false}, "ADE_AnimateDiffKeyframe": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"prev_ad_keyframes": ["AD_KEYFRAMES"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "per_block_replace": ["PER_BLOCK"], "inherit_missing": ["BOOLEAN", {"default": true}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent"], "optional": ["prev_ad_keyframes", "scale_multival", "effect_multival", "per_block_replace", "inherit_missing", "guarantee_steps"], "hidden": ["autosize"]}, "output": ["AD_KEYFRAMES"], "output_is_list": [false], "output_name": ["AD_KEYFRAMES"], "name": "ADE_AnimateDiffKeyframe", "display_name": "AnimateDiff Keyframe \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53", "output_node": false}, "ADE_MultivalDynamic": {"input": {"required": {"float_val": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}]}, "optional": {"mask_optional": ["MASK"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["float_val"], "optional": ["mask_optional"], "hidden": ["autosize"]}, "output": ["MULTIVAL"], "output_is_list": [false], "output_name": ["MULTIVAL"], "name": "ADE_MultivalDynamic", "display_name": "Multival \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/multival", "output_node": false}, "ADE_MultivalDynamicFloatInput": {"input": {"required": {"float_val": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001, "forceInput": true}]}, "optional": {"mask_optional": ["MASK"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["float_val"], "optional": ["mask_optional"], "hidden": ["autosize"]}, "output": ["MULTIVAL"], "output_is_list": [false], "output_name": ["MULTIVAL"], "name": "ADE_MultivalDynamicFloatInput", "display_name": "Multival [Float List] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/multival", "output_node": false}, "ADE_MultivalDynamicFloats": {"input": {"required": {"floats": ["FLOATS", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}]}, "optional": {"mask_optional": ["MASK"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["floats"], "optional": ["mask_optional"], "hidden": ["autosize"]}, "output": ["MULTIVAL"], "output_is_list": [false], "output_name": ["MULTIVAL"], "name": "ADE_MultivalDynamicFloats", "display_name": "Multival [Floats] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/multival", "output_node": false}, "ADE_MultivalScaledMask": {"input": {"required": {"min_float_val": ["FLOAT", {"default": 0.0, "min": 0.0, "step": 0.001}], "max_float_val": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "mask": ["MASK"]}, "optional": {"scaling": [["absolute", "relative"]]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["min_float_val", "max_float_val", "mask"], "optional": ["scaling"], "hidden": ["autosize"]}, "output": ["MULTIVAL"], "output_is_list": [false], "output_name": ["MULTIVAL"], "name": "ADE_MultivalScaledMask", "display_name": "Multival Scaled Mask \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/multival", "output_node": false}, "ADE_MultivalConvertToMask": {"input": {"required": {"multival": ["MULTIVAL"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["multival"], "hidden": ["autosize"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ADE_MultivalConvertToMask", "display_name": "Multival to Mask \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/multival", "output_node": false}, "ADE_StandardStaticContextOptions": {"input": {"required": {"context_length": ["INT", {"default": 16, "min": 1, "max": 128}], "context_overlap": ["INT", {"default": 4, "min": 0, "max": 128}]}, "optional": {"fuse_method": [["pyramid", "relative", "flat", "overlap-linear", "\ud83d\udd2cdelayed reverse sawtooth", "\ud83d\udd2cpyramid-sigma", "\ud83d\udd2cpyramid-sigma inverse", "\ud83d\udd2cgauss-sigma", "\ud83d\udd2cgauss-sigma inverse", "\ud83d\udd2crandom"]], "use_on_equal_length": ["BOOLEAN", {"default": false}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "prev_context": ["CONTEXT_OPTIONS"], "view_opts": ["VIEW_OPTS"]}}, "input_order": {"required": ["context_length", "context_overlap"], "optional": ["fuse_method", "use_on_equal_length", "start_percent", "guarantee_steps", "prev_context", "view_opts"]}, "output": ["CONTEXT_OPTIONS"], "output_is_list": [false], "output_name": ["CONTEXT_OPTS"], "name": "ADE_StandardStaticContextOptions", "display_name": "Context Options\u25c6Standard Static \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts", "output_node": false}, "ADE_StandardUniformContextOptions": {"input": {"required": {"context_length": ["INT", {"default": 16, "min": 1, "max": 128}], "context_stride": ["INT", {"default": 1, "min": 1, "max": 32}], "context_overlap": ["INT", {"default": 4, "min": 0, "max": 128}]}, "optional": {"fuse_method": [["pyramid", "flat", "overlap-linear", "\ud83d\udd2cdelayed reverse sawtooth", "\ud83d\udd2cpyramid-sigma", "\ud83d\udd2cpyramid-sigma inverse", "\ud83d\udd2cgauss-sigma", "\ud83d\udd2cgauss-sigma inverse", "\ud83d\udd2crandom"]], "use_on_equal_length": ["BOOLEAN", {"default": false}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "prev_context": ["CONTEXT_OPTIONS"], "view_opts": ["VIEW_OPTS"]}}, "input_order": {"required": ["context_length", "context_stride", "context_overlap"], "optional": ["fuse_method", "use_on_equal_length", "start_percent", "guarantee_steps", "prev_context", "view_opts"]}, "output": ["CONTEXT_OPTIONS"], "output_is_list": [false], "output_name": ["CONTEXT_OPTS"], "name": "ADE_StandardUniformContextOptions", "display_name": "Context Options\u25c6Standard Uniform \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts", "output_node": false}, "ADE_LoopedUniformContextOptions": {"input": {"required": {"context_length": ["INT", {"default": 16, "min": 1, "max": 128}], "context_stride": ["INT", {"default": 1, "min": 1, "max": 32}], "context_overlap": ["INT", {"default": 4, "min": 0, "max": 128}], "closed_loop": ["BOOLEAN", {"default": false}]}, "optional": {"fuse_method": [["pyramid", "flat", "overlap-linear", "\ud83d\udd2cdelayed reverse sawtooth", "\ud83d\udd2cpyramid-sigma", "\ud83d\udd2cpyramid-sigma inverse", "\ud83d\udd2cgauss-sigma", "\ud83d\udd2cgauss-sigma inverse", "\ud83d\udd2crandom"]], "use_on_equal_length": ["BOOLEAN", {"default": false}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "prev_context": ["CONTEXT_OPTIONS"], "view_opts": ["VIEW_OPTS"]}}, "input_order": {"required": ["context_length", "context_stride", "context_overlap", "closed_loop"], "optional": ["fuse_method", "use_on_equal_length", "start_percent", "guarantee_steps", "prev_context", "view_opts"]}, "output": ["CONTEXT_OPTIONS"], "output_is_list": [false], "output_name": ["CONTEXT_OPTS"], "name": "ADE_LoopedUniformContextOptions", "display_name": "Context Options\u25c6Looped Uniform \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts", "output_node": false}, "ADE_ViewsOnlyContextOptions": {"input": {"required": {"view_opts_req": ["VIEW_OPTS"]}, "optional": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "prev_context": ["CONTEXT_OPTIONS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["view_opts_req"], "optional": ["start_percent", "guarantee_steps", "prev_context"], "hidden": ["autosize"]}, "output": ["CONTEXT_OPTIONS"], "output_is_list": [false], "output_name": ["CONTEXT_OPTS"], "name": "ADE_ViewsOnlyContextOptions", "display_name": "Context Options\u25c6Views Only [VRAM\u21c8] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts", "output_node": false}, "ADE_BatchedContextOptions": {"input": {"required": {"context_length": ["INT", {"default": 16, "min": 1, "max": 128}]}, "optional": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "prev_context": ["CONTEXT_OPTIONS"]}}, "input_order": {"required": ["context_length"], "optional": ["start_percent", "guarantee_steps", "prev_context"]}, "output": ["CONTEXT_OPTIONS"], "output_is_list": [false], "output_name": ["CONTEXT_OPTS"], "name": "ADE_BatchedContextOptions", "display_name": "Context Options\u25c6Batched [Non-AD] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts", "output_node": false}, "ADE_AnimateDiffUniformContextOptions": {"input": {"required": {"context_length": ["INT", {"default": 16, "min": 1, "max": 128}], "context_stride": ["INT", {"default": 1, "min": 1, "max": 32}], "context_overlap": ["INT", {"default": 4, "min": 0, "max": 128}], "context_schedule": [["uniform"]], "closed_loop": ["BOOLEAN", {"default": false}]}, "optional": {"fuse_method": [["pyramid", "flat", "overlap-linear", "\ud83d\udd2cdelayed reverse sawtooth", "\ud83d\udd2cpyramid-sigma", "\ud83d\udd2cpyramid-sigma inverse", "\ud83d\udd2cgauss-sigma", "\ud83d\udd2cgauss-sigma inverse", "\ud83d\udd2crandom"], {"default": "flat"}], "use_on_equal_length": ["BOOLEAN", {"default": false}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "prev_context": ["CONTEXT_OPTIONS"], "view_opts": ["VIEW_OPTS"], "deprecation_warning": ["ADEWARN", {"text": ""}]}}, "input_order": {"required": ["context_length", "context_stride", "context_overlap", "context_schedule", "closed_loop"], "optional": ["fuse_method", "use_on_equal_length", "start_percent", "guarantee_steps", "prev_context", "view_opts", "deprecation_warning"]}, "output": ["CONTEXT_OPTIONS"], "output_is_list": [false], "output_name": ["CONTEXT_OPTS"], "name": "ADE_AnimateDiffUniformContextOptions", "display_name": "Context Options\u25c6Looped Uniform \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "", "output_node": false}, "ADE_VisualizeContextOptionsK": {"input": {"required": {"model": ["MODEL"], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"]]}, "optional": {"context_opts": ["CONTEXT_OPTIONS"], "visual_width": ["INT", {"min": 32, "max": 16384, "default": 1440}], "latents_length": ["INT", {"min": 1, "max": 9007199254740991, "default": 32}], "steps": ["INT", {"min": 0, "max": 9007199254740991, "default": 20}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "sampler_name", "scheduler"], "optional": ["context_opts", "visual_width", "latents_length", "steps", "denoise"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ADE_VisualizeContextOptionsK", "display_name": "Visualize Context Options (K.) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/visualize", "output_node": false}, "ADE_VisualizeContextOptionsKAdv": {"input": {"required": {"model": ["MODEL"], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"]]}, "optional": {"context_opts": ["CONTEXT_OPTIONS"], "visual_width": ["INT", {"min": 32, "max": 16384, "default": 1440}], "latents_length": ["INT", {"min": 1, "max": 9007199254740991, "default": 32}], "steps": ["INT", {"min": 0, "max": 9007199254740991, "default": 20}], "start_step": ["INT", {"min": 0, "max": 9007199254740991, "default": 0}], "end_step": ["INT", {"min": 1, "max": 9007199254740991, "default": 20}]}}, "input_order": {"required": ["model", "sampler_name", "scheduler"], "optional": ["context_opts", "visual_width", "latents_length", "steps", "start_step", "end_step"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ADE_VisualizeContextOptionsKAdv", "display_name": "Visualize Context Options (K.Adv.) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/visualize", "output_node": false}, "ADE_VisualizeContextOptionsSCustom": {"input": {"required": {"model": ["MODEL"], "sigmas": ["SIGMAS"]}, "optional": {"context_opts": ["CONTEXT_OPTIONS"], "visual_width": ["INT", {"min": 32, "max": 16384, "default": 1440}], "latents_length": ["INT", {"min": 1, "max": 9007199254740991, "default": 32}]}}, "input_order": {"required": ["model", "sigmas"], "optional": ["context_opts", "visual_width", "latents_length"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ADE_VisualizeContextOptionsSCustom", "display_name": "Visualize Context Options (S.Cus.) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/visualize", "output_node": false}, "ADE_StandardStaticViewOptions": {"input": {"required": {"view_length": ["INT", {"default": 16, "min": 1, "max": 128}], "view_overlap": ["INT", {"default": 4, "min": 0, "max": 128}]}, "optional": {"fuse_method": [["pyramid", "flat", "overlap-linear", "\ud83d\udd2cdelayed reverse sawtooth", "\ud83d\udd2cpyramid-sigma", "\ud83d\udd2cpyramid-sigma inverse", "\ud83d\udd2cgauss-sigma", "\ud83d\udd2cgauss-sigma inverse", "\ud83d\udd2crandom"]]}}, "input_order": {"required": ["view_length", "view_overlap"], "optional": ["fuse_method"]}, "output": ["VIEW_OPTS"], "output_is_list": [false], "output_name": ["VIEW_OPTS"], "name": "ADE_StandardStaticViewOptions", "display_name": "View Options\u25c6Standard Static \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/view opts", "output_node": false}, "ADE_StandardUniformViewOptions": {"input": {"required": {"view_length": ["INT", {"default": 16, "min": 1, "max": 128}], "view_stride": ["INT", {"default": 1, "min": 1, "max": 32}], "view_overlap": ["INT", {"default": 4, "min": 0, "max": 128}]}, "optional": {"fuse_method": [["pyramid", "flat", "overlap-linear", "\ud83d\udd2cdelayed reverse sawtooth", "\ud83d\udd2cpyramid-sigma", "\ud83d\udd2cpyramid-sigma inverse", "\ud83d\udd2cgauss-sigma", "\ud83d\udd2cgauss-sigma inverse", "\ud83d\udd2crandom"]]}}, "input_order": {"required": ["view_length", "view_stride", "view_overlap"], "optional": ["fuse_method"]}, "output": ["VIEW_OPTS"], "output_is_list": [false], "output_name": ["VIEW_OPTS"], "name": "ADE_StandardUniformViewOptions", "display_name": "View Options\u25c6Standard Uniform \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/view opts", "output_node": false}, "ADE_LoopedUniformViewOptions": {"input": {"required": {"view_length": ["INT", {"default": 16, "min": 1, "max": 128}], "view_stride": ["INT", {"default": 1, "min": 1, "max": 32}], "view_overlap": ["INT", {"default": 4, "min": 0, "max": 128}], "closed_loop": ["BOOLEAN", {"default": false}]}, "optional": {"fuse_method": [["pyramid", "flat", "overlap-linear", "\ud83d\udd2cdelayed reverse sawtooth", "\ud83d\udd2cpyramid-sigma", "\ud83d\udd2cpyramid-sigma inverse", "\ud83d\udd2cgauss-sigma", "\ud83d\udd2cgauss-sigma inverse", "\ud83d\udd2crandom"]], "use_on_equal_length": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["view_length", "view_stride", "view_overlap", "closed_loop"], "optional": ["fuse_method", "use_on_equal_length"]}, "output": ["VIEW_OPTS"], "output_is_list": [false], "output_name": ["VIEW_OPTS"], "name": "ADE_LoopedUniformViewOptions", "display_name": "View Options\u25c6Looped Uniform \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/view opts", "output_node": false}, "ADE_ContextExtras_Set": {"input": {"required": {"context_opts": ["CONTEXT_OPTIONS"]}, "optional": {"context_extras": ["CONTEXT_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["context_opts"], "optional": ["context_extras"], "hidden": ["autosize"]}, "output": ["CONTEXT_OPTIONS"], "output_is_list": [false], "output_name": ["CONTEXT_OPTS"], "name": "ADE_ContextExtras_Set", "display_name": "Set Context Extras \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras", "output_node": false}, "ADE_ContextExtras_ContextRef": {"input": {"required": {}, "optional": {"prev_extras": ["CONTEXT_EXTRAS"], "strength_multival": ["MULTIVAL"], "contextref_mode": ["CONTEXTREF_MODE"], "contextref_tune": ["CONTEXTREF_TUNE"], "contextref_kf": ["CONTEXTREF_KEYFRAME"], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 1.0, "step": 0.001}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["prev_extras", "strength_multival", "contextref_mode", "contextref_tune", "contextref_kf", "start_percent", "end_percent"], "hidden": ["autosize"]}, "output": ["CONTEXT_EXTRAS"], "output_is_list": [false], "output_name": ["CONTEXT_EXTRAS"], "name": "ADE_ContextExtras_ContextRef", "display_name": "Context Extras\u25c6ContextRef \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras", "output_node": false}, "ADE_ContextExtras_ContextRef_ModeFirst": {"input": {"required": {}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "hidden": ["autosize"]}, "output": ["CONTEXTREF_MODE"], "output_is_list": [false], "output_name": ["CONTEXTREF_MODE"], "name": "ADE_ContextExtras_ContextRef_ModeFirst", "display_name": "ContextRef Mode\u25c6First \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/contextref", "output_node": false}, "ADE_ContextExtras_ContextRef_ModeSliding": {"input": {"required": {}, "optional": {"sliding_width": ["INT", {"default": 2, "min": 2, "max": 9007199254740991, "step": 1}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["sliding_width"], "hidden": ["autosize"]}, "output": ["CONTEXTREF_MODE"], "output_is_list": [false], "output_name": ["CONTEXTREF_MODE"], "name": "ADE_ContextExtras_ContextRef_ModeSliding", "display_name": "ContextRef Mode\u25c6Sliding \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/contextref", "output_node": false}, "ADE_ContextExtras_ContextRef_ModeIndexes": {"input": {"required": {}, "optional": {"switch_on_idxs": ["STRING", {"default": ""}], "always_include_0": ["BOOLEAN", {"default": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["switch_on_idxs", "always_include_0"], "hidden": ["autosize"]}, "output": ["CONTEXTREF_MODE"], "output_is_list": [false], "output_name": ["CONTEXTREF_MODE"], "name": "ADE_ContextExtras_ContextRef_ModeIndexes", "display_name": "ContextRef Mode\u25c6Indexes \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/contextref", "output_node": false}, "ADE_ContextExtras_ContextRef_TuneAttn": {"input": {"required": {}, "optional": {"attn_style_fidelity": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "attn_ref_weight": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "attn_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["attn_style_fidelity", "attn_ref_weight", "attn_strength"], "hidden": ["autosize"]}, "output": ["CONTEXTREF_TUNE"], "output_is_list": [false], "output_name": ["CONTEXTREF_TUNE"], "name": "ADE_ContextExtras_ContextRef_TuneAttn", "display_name": "ContextRef Tune\u25c6Attn \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/contextref", "output_node": false}, "ADE_ContextExtras_ContextRef_TuneAttnAdain": {"input": {"required": {}, "optional": {"attn_style_fidelity": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "attn_ref_weight": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "attn_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "adain_style_fidelity": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "adain_ref_weight": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "adain_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["attn_style_fidelity", "attn_ref_weight", "attn_strength", "adain_style_fidelity", "adain_ref_weight", "adain_strength"], "hidden": ["autosize"]}, "output": ["CONTEXTREF_TUNE"], "output_is_list": [false], "output_name": ["CONTEXTREF_TUNE"], "name": "ADE_ContextExtras_ContextRef_TuneAttnAdain", "display_name": "ContextRef Tune\u25c6Attn+Adain \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/contextref", "output_node": false}, "ADE_ContextExtras_ContextRef_Keyframe": {"input": {"required": {}, "optional": {"prev_kf": ["CONTEXTREF_KEYFRAME"], "mult_multival": ["MULTIVAL"], "mode_replace": ["CONTEXTREF_MODE"], "tune_replace": ["CONTEXTREF_TUNE"], "mult": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "inherit_missing": ["BOOLEAN", {"default": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["prev_kf", "mult_multival", "mode_replace", "tune_replace", "mult", "start_percent", "guarantee_steps", "inherit_missing"], "hidden": ["autosize"]}, "output": ["CONTEXTREF_KEYFRAME"], "output_is_list": [false], "output_name": ["CONTEXTREF_KF"], "name": "ADE_ContextExtras_ContextRef_Keyframe", "display_name": "ContextRef Keyframe \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/contextref", "output_node": false}, "ADE_ContextExtras_ContextRef_KeyframeInterpolation": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "mult_start": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "mult_end": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "intervals": ["INT", {"default": 50, "min": 2, "max": 100, "step": 1}], "inherit_missing": ["BOOLEAN", {"default": true}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_kf": ["CONTEXTREF_KEYFRAME"], "mult_multival": ["MULTIVAL"], "mode_replace": ["CONTEXTREF_MODE"], "tune_replace": ["CONTEXTREF_TUNE"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent", "end_percent", "mult_start", "mult_end", "interpolation", "intervals", "inherit_missing", "print_keyframes"], "optional": ["prev_kf", "mult_multival", "mode_replace", "tune_replace"], "hidden": ["autosize"]}, "output": ["CONTEXTREF_KEYFRAME"], "output_is_list": [false], "output_name": ["CONTEXTREF_KF"], "name": "ADE_ContextExtras_ContextRef_KeyframeInterpolation", "display_name": "ContextRef Keyframes Interp. \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/contextref", "output_node": false}, "ADE_ContextExtras_ContextRef_KeyframeFromList": {"input": {"required": {"mults_float": ["FLOAT", {"default": -1, "min": -1, "step": 0.001, "forceInput": true}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "inherit_missing": ["BOOLEAN", {"default": true}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_kf": ["CONTEXTREF_KEYFRAME"], "mult_multival": ["MULTIVAL"], "mode_replace": ["CONTEXTREF_MODE"], "tune_replace": ["CONTEXTREF_TUNE"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["mults_float", "start_percent", "end_percent", "inherit_missing", "print_keyframes"], "optional": ["prev_kf", "mult_multival", "mode_replace", "tune_replace"], "hidden": ["autosize"]}, "output": ["CONTEXTREF_KEYFRAME"], "output_is_list": [false], "output_name": ["CONTEXTREF_KF"], "name": "ADE_ContextExtras_ContextRef_KeyframeFromList", "display_name": "ContextRef Keyframes From List \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/contextref", "output_node": false}, "ADE_ContextExtras_NaiveReuse": {"input": {"required": {}, "optional": {"prev_extras": ["CONTEXT_EXTRAS"], "strength_multival": ["MULTIVAL"], "naivereuse_kf": ["NAIVEREUSE_KEYFRAME"], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 0.15, "min": 0.0, "max": 1.0, "step": 0.001}], "weighted_mean": ["FLOAT", {"default": 0.95, "min": 0.0, "max": 1.0, "step": 0.001}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["prev_extras", "strength_multival", "naivereuse_kf", "start_percent", "end_percent", "weighted_mean"], "hidden": ["autosize"]}, "output": ["CONTEXT_EXTRAS"], "output_is_list": [false], "output_name": ["CONTEXT_EXTRAS"], "name": "ADE_ContextExtras_NaiveReuse", "display_name": "Context Extras\u25c6NaiveReuse \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras", "output_node": false}, "ADE_ContextExtras_NaiveReuse_Keyframe": {"input": {"required": {}, "optional": {"prev_kf": ["NAIVEREUSE_KEYFRAME"], "mult_multival": ["MULTIVAL"], "mult": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "inherit_missing": ["BOOLEAN", {"default": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["prev_kf", "mult_multival", "mult", "start_percent", "guarantee_steps", "inherit_missing"], "hidden": ["autosize"]}, "output": ["NAIVEREUSE_KEYFRAME"], "output_is_list": [false], "output_name": ["NAIVEREUSE_KF"], "name": "ADE_ContextExtras_NaiveReuse_Keyframe", "display_name": "NaiveReuse Keyframe \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/naivereuse", "output_node": false}, "ADE_ContextExtras_NaiveReuse_KeyframeInterpolation": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "mult_start": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "mult_end": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "intervals": ["INT", {"default": 50, "min": 2, "max": 100, "step": 1}], "inherit_missing": ["BOOLEAN", {"default": true}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_kf": ["NAIVEREUSE_KEYFRAME"], "mult_multival": ["MULTIVAL"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent", "end_percent", "mult_start", "mult_end", "interpolation", "intervals", "inherit_missing", "print_keyframes"], "optional": ["prev_kf", "mult_multival"], "hidden": ["autosize"]}, "output": ["NAIVEREUSE_KEYFRAME"], "output_is_list": [false], "output_name": ["NAIVEREUSE_KF"], "name": "ADE_ContextExtras_NaiveReuse_KeyframeInterpolation", "display_name": "NaiveReuse Keyframes Interp. \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/naivereuse", "output_node": false}, "ADE_ContextExtras_NaiveReuse_KeyframeFromList": {"input": {"required": {"mults_float": ["FLOAT", {"default": -1, "min": -1, "step": 0.001, "forceInput": true}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "inherit_missing": ["BOOLEAN", {"default": true}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_kf": ["NAIVEREUSE_KEYFRAME"], "mult_multival": ["MULTIVAL"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["mults_float", "start_percent", "end_percent", "inherit_missing", "print_keyframes"], "optional": ["prev_kf", "mult_multival"], "hidden": ["autosize"]}, "output": ["NAIVEREUSE_KEYFRAME"], "output_is_list": [false], "output_name": ["NAIVEREUSE_KF"], "name": "ADE_ContextExtras_NaiveReuse_KeyframeFromList", "display_name": "NaiveReuse Keyframes From List \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/naivereuse", "output_node": false}, "ADE_IterationOptsDefault": {"input": {"required": {"iterations": ["INT", {"default": 1, "min": 1}]}, "optional": {"iter_batch_offset": ["INT", {"default": 0, "min": 0, "max": 9007199254740991}], "iter_seed_offset": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991}]}}, "input_order": {"required": ["iterations"], "optional": ["iter_batch_offset", "iter_seed_offset"]}, "output": ["ITERATION_OPTS"], "output_is_list": [false], "output_name": ["ITERATION_OPTS"], "name": "ADE_IterationOptsDefault", "display_name": "Default Iteration Options \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/iteration opts", "output_node": false}, "ADE_IterationOptsFreeInit": {"input": {"required": {"iterations": ["INT", {"default": 2, "min": 1}], "filter": [["gaussian", "butterworth", "ideal", "box"]], "d_s": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 1.0, "step": 0.001}], "d_t": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 1.0, "step": 0.001}], "n_butterworth": ["INT", {"default": 4, "min": 1, "max": 100}], "sigma_step": ["INT", {"default": 999, "min": 1, "max": 999}], "apply_to_1st_iter": ["BOOLEAN", {"default": false}], "init_type": [["FreeInit [sampler sigma]", "FreeInit [model sigma]", "DinkInit_v1"]]}, "optional": {"iter_batch_offset": ["INT", {"default": 0, "min": 0, "max": 9007199254740991}], "iter_seed_offset": ["INT", {"default": 1, "min": -9007199254740991, "max": 9007199254740991}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["iterations", "filter", "d_s", "d_t", "n_butterworth", "sigma_step", "apply_to_1st_iter", "init_type"], "optional": ["iter_batch_offset", "iter_seed_offset"], "hidden": ["autosize"]}, "output": ["ITERATION_OPTS"], "output_is_list": [false], "output_name": ["ITERATION_OPTS"], "name": "ADE_IterationOptsFreeInit", "display_name": "FreeInit Iteration Options \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/iteration opts", "output_node": false}, "ADE_RegisterLoraHook": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "lora_name": [["BiFangBird.safetensors", "DrugPony.safetensors", "Harrlogos_v2.0.safetensors", "Inquisition_v1.safetensors", "Iridescence.safetensors", "Luxury_Houses_V1-000009.safetensors", "MJ52_v2.0.safetensors", "Textimprover-FLUX-V0.4.safetensors", "animemix_v3_offset.safetensors", "ff7r_style_ned_offset.safetensors", "first_stage-10.safetensors", "fractalized.safetensors", "hyvideo_FastVideo_LoRA-fp8.safetensors", "neoclassical villa - PHK.safetensors", "pokemon_v3_offset.safetensors", "polyhedron_new_skin_v1.1.safetensors", "poms-funtime-mlora-emporium/LiquidAF-0-1.safetensors", "poms-funtime-mlora-emporium/Smoooth-0-1.safetensors", "poms-funtime-mlora-emporium/WAS26.safetensors", "psychedelic_portrait.safetensors", "sd_xl_offset_example-lora_1.0.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}}, "input_order": {"required": ["model", "clip", "lora_name", "strength_model", "strength_clip"], "optional": ["deprecation_warning"]}, "output": ["MODEL", "CLIP", "HOOKS"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "HOOKS"], "name": "ADE_RegisterLoraHook", "display_name": "Register LoRA Hook \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/register lora hooks", "output_node": false, "deprecated": true}, "ADE_RegisterLoraHookModelOnly": {"input": {"required": {"model": ["MODEL"], "lora_name": [["BiFangBird.safetensors", "DrugPony.safetensors", "Harrlogos_v2.0.safetensors", "Inquisition_v1.safetensors", "Iridescence.safetensors", "Luxury_Houses_V1-000009.safetensors", "MJ52_v2.0.safetensors", "Textimprover-FLUX-V0.4.safetensors", "animemix_v3_offset.safetensors", "ff7r_style_ned_offset.safetensors", "first_stage-10.safetensors", "fractalized.safetensors", "hyvideo_FastVideo_LoRA-fp8.safetensors", "neoclassical villa - PHK.safetensors", "pokemon_v3_offset.safetensors", "polyhedron_new_skin_v1.1.safetensors", "poms-funtime-mlora-emporium/LiquidAF-0-1.safetensors", "poms-funtime-mlora-emporium/Smoooth-0-1.safetensors", "poms-funtime-mlora-emporium/WAS26.safetensors", "psychedelic_portrait.safetensors", "sd_xl_offset_example-lora_1.0.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}}, "input_order": {"required": ["model", "lora_name", "strength_model"], "optional": ["deprecation_warning"]}, "output": ["MODEL", "HOOKS"], "output_is_list": [false, false], "output_name": ["MODEL", "HOOKS"], "name": "ADE_RegisterLoraHookModelOnly", "display_name": "Register LoRA Hook (Model Only) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/register lora hooks", "output_node": false, "deprecated": true}, "ADE_RegisterModelAsLoraHook": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "ckpt_name": [["Artfusion Surreal XL.safetensors", "Flux_dev_turbo_krea_mix.safetensors", "Flux_dev_v1.safetensors", "XLbluePencilXL_v700.safetensors", "XLrealbluejuggernautmi_v10.safetensors", "animagineXLRealistic_v5.safetensors", "animeIllustDiffusion_v08.safetensors", "artfusionXL_v11Lightning.safetensors", "cyberrealisticXL_v5.safetensors", "dreamshaperXL_v21TurboDPMSDE.safetensors", "electricDreams_electricDreamsV04.safetensors", "epicrealismXL_vxvAnewstoryRealism.safetensors", "illustrationStyleIV.nR7A.safetensors", "illustrationXL_v10.safetensors", "jibMixRealisticXL_v170SmokeSheen.safetensors", "jruTheJourneyRemains_v20XL.safetensors", "midgardPonyTHLSDXL_v32.safetensors", "pixniteXL_v10.safetensors", "reymixXL_v20.safetensors", "sd_xl_base_1.0.safetensors", "sd_xl_refiner_1.0.safetensors", "sdxlFaetastic_v10.safetensors", "sdxlInkpunkstyle_v01.safetensors", "v1-5-pruned-emaonly.safetensors", "xl6HEPHAISTOSSD10XLSFW_v331BF16Experimental.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}}, "input_order": {"required": ["model", "clip", "ckpt_name", "strength_model", "strength_clip"], "optional": ["deprecation_warning"]}, "output": ["MODEL", "CLIP", "HOOKS"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "HOOKS"], "name": "ADE_RegisterModelAsLoraHook", "display_name": "Register Model as LoRA Hook \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/register lora hooks", "output_node": false, "deprecated": true, "experimental": true}, "ADE_RegisterModelAsLoraHookModelOnly": {"input": {"required": {"model": ["MODEL"], "ckpt_name": [["Artfusion Surreal XL.safetensors", "Flux_dev_turbo_krea_mix.safetensors", "Flux_dev_v1.safetensors", "XLbluePencilXL_v700.safetensors", "XLrealbluejuggernautmi_v10.safetensors", "animagineXLRealistic_v5.safetensors", "animeIllustDiffusion_v08.safetensors", "artfusionXL_v11Lightning.safetensors", "cyberrealisticXL_v5.safetensors", "dreamshaperXL_v21TurboDPMSDE.safetensors", "electricDreams_electricDreamsV04.safetensors", "epicrealismXL_vxvAnewstoryRealism.safetensors", "illustrationStyleIV.nR7A.safetensors", "illustrationXL_v10.safetensors", "jibMixRealisticXL_v170SmokeSheen.safetensors", "jruTheJourneyRemains_v20XL.safetensors", "midgardPonyTHLSDXL_v32.safetensors", "pixniteXL_v10.safetensors", "reymixXL_v20.safetensors", "sd_xl_base_1.0.safetensors", "sd_xl_refiner_1.0.safetensors", "sdxlFaetastic_v10.safetensors", "sdxlInkpunkstyle_v01.safetensors", "v1-5-pruned-emaonly.safetensors", "xl6HEPHAISTOSSD10XLSFW_v331BF16Experimental.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}}, "input_order": {"required": ["model", "ckpt_name", "strength_model"], "optional": ["deprecation_warning"]}, "output": ["MODEL", "HOOKS"], "output_is_list": [false, false], "output_name": ["MODEL", "HOOKS"], "name": "ADE_RegisterModelAsLoraHookModelOnly", "display_name": "Register Model as LoRA Hook (MO) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/register lora hooks", "output_node": false, "deprecated": true, "experimental": true}, "ADE_CombineLoraHooks": {"input": {"required": {}, "optional": {"lora_hook_A": ["HOOKS"], "lora_hook_B": ["HOOKS"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["lora_hook_A", "lora_hook_B", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "ADE_CombineLoraHooks", "display_name": "Combine LoRA Hooks [2] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/combine lora hooks", "output_node": false, "deprecated": true}, "ADE_CombineLoraHooksFour": {"input": {"required": {}, "optional": {"lora_hook_A": ["HOOKS"], "lora_hook_B": ["HOOKS"], "lora_hook_C": ["HOOKS"], "lora_hook_D": ["HOOKS"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["lora_hook_A", "lora_hook_B", "lora_hook_C", "lora_hook_D", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "ADE_CombineLoraHooksFour", "display_name": "Combine LoRA Hooks [4] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/combine lora hooks", "output_node": false, "deprecated": true}, "ADE_CombineLoraHooksEight": {"input": {"required": {}, "optional": {"lora_hook_A": ["HOOKS"], "lora_hook_B": ["HOOKS"], "lora_hook_C": ["HOOKS"], "lora_hook_D": ["HOOKS"], "lora_hook_E": ["HOOKS"], "lora_hook_F": ["HOOKS"], "lora_hook_G": ["HOOKS"], "lora_hook_H": ["HOOKS"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["lora_hook_A", "lora_hook_B", "lora_hook_C", "lora_hook_D", "lora_hook_E", "lora_hook_F", "lora_hook_G", "lora_hook_H", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "ADE_CombineLoraHooksEight", "display_name": "Combine LoRA Hooks [8] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/combine lora hooks", "output_node": false, "deprecated": true}, "ADE_SetLoraHookKeyframe": {"input": {"required": {"lora_hook": ["HOOKS"], "hook_kf": ["HOOK_KEYFRAMES"]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["lora_hook", "hook_kf"], "optional": ["deprecation_warning"], "hidden": ["autosize"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "ADE_SetLoraHookKeyframe", "display_name": "Set LoRA Hook Keyframes \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning", "output_node": false, "deprecated": true}, "ADE_AttachLoraHookToCLIP": {"input": {"required": {"clip": ["CLIP"], "lora_hook": ["HOOKS"]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["clip", "lora_hook"], "optional": ["deprecation_warning"], "hidden": ["autosize"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["hook_CLIP"], "name": "ADE_AttachLoraHookToCLIP", "display_name": "Set CLIP LoRA Hook \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning", "output_node": false, "deprecated": true}, "ADE_LoraHookKeyframe": {"input": {"required": {"strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}]}, "optional": {"prev_hook_kf": ["HOOK_KEYFRAMES"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["strength_model", "start_percent", "guarantee_steps"], "optional": ["prev_hook_kf", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["HOOK_KEYFRAMES"], "output_is_list": [false], "output_name": ["HOOK_KF"], "name": "ADE_LoraHookKeyframe", "display_name": "LoRA Hook Keyframe \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/schedule lora hooks", "output_node": false, "deprecated": true}, "ADE_LoraHookKeyframeInterpolation": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "strength_start": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "strength_end": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "intervals": ["INT", {"default": 5, "min": 2, "max": 100, "step": 1}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_hook_kf": ["HOOK_KEYFRAMES"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent", "end_percent", "strength_start", "strength_end", "interpolation", "intervals", "print_keyframes"], "optional": ["prev_hook_kf", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["HOOK_KEYFRAMES"], "output_is_list": [false], "output_name": ["HOOK_KF"], "name": "ADE_LoraHookKeyframeInterpolation", "display_name": "LoRA Hook Keyframes Interp. \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/schedule lora hooks", "output_node": false, "deprecated": true}, "ADE_LoraHookKeyframeFromStrengthList": {"input": {"required": {"strengths_float": ["FLOAT", {"default": -1, "min": -1, "step": 0.001, "forceInput": true}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_hook_kf": ["HOOK_KEYFRAMES"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}}, "input_order": {"required": ["strengths_float", "start_percent", "end_percent", "print_keyframes"], "optional": ["prev_hook_kf", "deprecation_warning"]}, "output": ["HOOK_KEYFRAMES"], "output_is_list": [false], "output_name": ["HOOK_KF"], "name": "ADE_LoraHookKeyframeFromStrengthList", "display_name": "LoRA Hook Keyframes From List \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/schedule lora hooks", "output_node": false, "deprecated": true}, "ADE_AttachLoraHookToConditioning": {"input": {"required": {"conditioning": ["CONDITIONING"], "lora_hook": ["HOOKS"]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["conditioning", "lora_hook"], "optional": ["deprecation_warning"], "hidden": ["autosize"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ADE_AttachLoraHookToConditioning", "display_name": "Set Model LoRA Hook \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/single cond ops", "output_node": false, "deprecated": true}, "ADE_PairedConditioningSetMask": {"input": {"required": {"positive_ADD": ["CONDITIONING"], "negative_ADD": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"opt_mask": ["MASK"], "opt_lora_hook": ["HOOKS"], "opt_timesteps": ["TIMESTEPS_RANGE"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["positive_ADD", "negative_ADD", "strength", "set_cond_area"], "optional": ["opt_mask", "opt_lora_hook", "opt_timesteps", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ADE_PairedConditioningSetMask", "display_name": "Set Props on Conds \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning", "output_node": false, "deprecated": true}, "ADE_ConditioningSetMask": {"input": {"required": {"cond_ADD": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"opt_mask": ["MASK"], "opt_lora_hook": ["HOOKS"], "opt_timesteps": ["TIMESTEPS_RANGE"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["cond_ADD", "strength", "set_cond_area"], "optional": ["opt_mask", "opt_lora_hook", "opt_timesteps", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ADE_ConditioningSetMask", "display_name": "Set Props on Cond \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/single cond ops", "output_node": false, "deprecated": true}, "ADE_PairedConditioningSetMaskAndCombine": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "positive_ADD": ["CONDITIONING"], "negative_ADD": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"opt_mask": ["MASK"], "opt_lora_hook": ["HOOKS"], "opt_timesteps": ["TIMESTEPS_RANGE"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["positive", "negative", "positive_ADD", "negative_ADD", "strength", "set_cond_area"], "optional": ["opt_mask", "opt_lora_hook", "opt_timesteps", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ADE_PairedConditioningSetMaskAndCombine", "display_name": "Set Props and Combine Conds \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning", "output_node": false, "deprecated": true}, "ADE_ConditioningSetMaskAndCombine": {"input": {"required": {"cond": ["CONDITIONING"], "cond_ADD": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"opt_mask": ["MASK"], "opt_lora_hook": ["HOOKS"], "opt_timesteps": ["TIMESTEPS_RANGE"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["cond", "cond_ADD", "strength", "set_cond_area"], "optional": ["opt_mask", "opt_lora_hook", "opt_timesteps", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ADE_ConditioningSetMaskAndCombine", "display_name": "Set Props and Combine Cond \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/single cond ops", "output_node": false, "deprecated": true}, "ADE_PairedConditioningSetUnmaskedAndCombine": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "positive_DEFAULT": ["CONDITIONING"], "negative_DEFAULT": ["CONDITIONING"]}, "optional": {"opt_lora_hook": ["HOOKS"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["positive", "negative", "positive_DEFAULT", "negative_DEFAULT"], "optional": ["opt_lora_hook", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ADE_PairedConditioningSetUnmaskedAndCombine", "display_name": "Set Unmasked Conds \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning", "output_node": false, "deprecated": true}, "ADE_ConditioningSetUnmaskedAndCombine": {"input": {"required": {"cond": ["CONDITIONING"], "cond_DEFAULT": ["CONDITIONING"]}, "optional": {"opt_lora_hook": ["HOOKS"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["cond", "cond_DEFAULT"], "optional": ["opt_lora_hook", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ADE_ConditioningSetUnmaskedAndCombine", "display_name": "Set Unmasked Cond \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/single cond ops", "output_node": false, "deprecated": true}, "ADE_PairedConditioningCombine": {"input": {"required": {"positive_A": ["CONDITIONING"], "negative_A": ["CONDITIONING"], "positive_B": ["CONDITIONING"], "negative_B": ["CONDITIONING"]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}}, "input_order": {"required": ["positive_A", "negative_A", "positive_B", "negative_B"], "optional": ["deprecation_warning"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ADE_PairedConditioningCombine", "display_name": "Manual Combine Conds \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning", "output_node": false, "deprecated": true}, "ADE_ConditioningCombine": {"input": {"required": {"cond_A": ["CONDITIONING"], "cond_B": ["CONDITIONING"]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}}, "input_order": {"required": ["cond_A", "cond_B"], "optional": ["deprecation_warning"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ADE_ConditioningCombine", "display_name": "Manual Combine Cond \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/single cond ops", "output_node": false, "deprecated": true}, "ADE_TimestepsConditioning": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent", "end_percent"], "optional": ["deprecation_warning"], "hidden": ["autosize"]}, "output": ["TIMESTEPS_RANGE"], "output_is_list": [false], "output_name": ["TIMESTEPS_RANGE"], "name": "ADE_TimestepsConditioning", "display_name": "Timesteps Conditioning \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning", "output_node": false, "deprecated": true}, "ADE_NoiseLayerAdd": {"input": {"required": {"batch_offset": ["INT", {"default": 0, "min": 0, "max": 9007199254740991}], "noise_type": [["default", "constant", "empty", "repeated_context", "FreeNoise"]], "seed_gen_override": [["use existing", "comfy", "comfy [gpu]", "auto1111", "auto1111 [gpu]"]], "seed_offset": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991}], "noise_weight": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 10.0, "step": 0.001}]}, "optional": {"prev_noise_layers": ["NOISE_LAYERS"], "mask_optional": ["MASK"], "seed_override": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "forceInput": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["batch_offset", "noise_type", "seed_gen_override", "seed_offset", "noise_weight"], "optional": ["prev_noise_layers", "mask_optional", "seed_override"], "hidden": ["autosize"]}, "output": ["NOISE_LAYERS"], "output_is_list": [false], "output_name": ["NOISE_LAYERS"], "name": "ADE_NoiseLayerAdd", "display_name": "Noise Layer [Add] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/noise layers", "output_node": false}, "ADE_NoiseLayerAddWeighted": {"input": {"required": {"batch_offset": ["INT", {"default": 0, "min": 0, "max": 9007199254740991}], "noise_type": [["default", "constant", "empty", "repeated_context", "FreeNoise"]], "seed_gen_override": [["use existing", "comfy", "comfy [gpu]", "auto1111", "auto1111 [gpu]"]], "seed_offset": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991}], "noise_weight": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 10.0, "step": 0.001}], "balance_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}]}, "optional": {"prev_noise_layers": ["NOISE_LAYERS"], "mask_optional": ["MASK"], "seed_override": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "forceInput": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["batch_offset", "noise_type", "seed_gen_override", "seed_offset", "noise_weight", "balance_multiplier"], "optional": ["prev_noise_layers", "mask_optional", "seed_override"], "hidden": ["autosize"]}, "output": ["NOISE_LAYERS"], "output_is_list": [false], "output_name": ["NOISE_LAYERS"], "name": "ADE_NoiseLayerAddWeighted", "display_name": "Noise Layer [Add Weighted] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/noise layers", "output_node": false}, "ADE_NoiseLayerNormalizedSum": {"input": {"required": {"batch_offset": ["INT", {"default": 0, "min": 0, "max": 9007199254740991}], "noise_type": [["default", "constant", "empty", "repeated_context", "FreeNoise"]], "seed_gen_override": [["use existing", "comfy", "comfy [gpu]", "auto1111", "auto1111 [gpu]"]], "seed_offset": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991}], "noise_weight": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"prev_noise_layers": ["NOISE_LAYERS"], "mask_optional": ["MASK"], "seed_override": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "forceInput": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["batch_offset", "noise_type", "seed_gen_override", "seed_offset", "noise_weight"], "optional": ["prev_noise_layers", "mask_optional", "seed_override"], "hidden": ["autosize"]}, "output": ["NOISE_LAYERS"], "output_is_list": [false], "output_name": ["NOISE_LAYERS"], "name": "ADE_NoiseLayerNormalizedSum", "display_name": "Noise Layer [Normalized Sum] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/noise layers", "output_node": false}, "ADE_NoiseLayerReplace": {"input": {"required": {"batch_offset": ["INT", {"default": 0, "min": 0, "max": 9007199254740991}], "noise_type": [["default", "constant", "empty", "repeated_context", "FreeNoise"]], "seed_gen_override": [["use existing", "comfy", "comfy [gpu]", "auto1111", "auto1111 [gpu]"]], "seed_offset": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991}]}, "optional": {"prev_noise_layers": ["NOISE_LAYERS"], "mask_optional": ["MASK"], "seed_override": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "forceInput": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["batch_offset", "noise_type", "seed_gen_override", "seed_offset"], "optional": ["prev_noise_layers", "mask_optional", "seed_override"], "hidden": ["autosize"]}, "output": ["NOISE_LAYERS"], "output_is_list": [false], "output_name": ["NOISE_LAYERS"], "name": "ADE_NoiseLayerReplace", "display_name": "Noise Layer [Replace] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/noise layers", "output_node": false}, "ADE_AnimateDiffSettings": {"input": {"optional": {"pe_adjust": ["PE_ADJUST"], "weight_adjust": ["WEIGHT_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"optional": ["pe_adjust", "weight_adjust"], "hidden": ["autosize"]}, "output": ["AD_SETTINGS"], "output_is_list": [false], "output_name": ["AD_SETTINGS"], "name": "ADE_AnimateDiffSettings", "display_name": "AnimateDiff Settings \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings", "output_node": false}, "ADE_AdjustPESweetspotStretch": {"input": {"required": {"sweetspot": ["INT", {"default": 16, "min": 0, "max": 9007199254740991}], "new_sweetspot": ["INT", {"default": 16, "min": 0, "max": 9007199254740991}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_pe_adjust": ["PE_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["sweetspot", "new_sweetspot", "print_adjustment"], "optional": ["prev_pe_adjust"], "hidden": ["autosize"]}, "output": ["PE_ADJUST"], "output_is_list": [false], "output_name": ["PE_ADJUST"], "name": "ADE_AdjustPESweetspotStretch", "display_name": "Adjust PE [Sweetspot] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/pe adjust", "output_node": false}, "ADE_AdjustPEFullStretch": {"input": {"required": {"pe_stretch": ["INT", {"default": 0, "min": 0, "max": 9007199254740991}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_pe_adjust": ["PE_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["pe_stretch", "print_adjustment"], "optional": ["prev_pe_adjust"], "hidden": ["autosize"]}, "output": ["PE_ADJUST"], "output_is_list": [false], "output_name": ["PE_ADJUST"], "name": "ADE_AdjustPEFullStretch", "display_name": "Adjust PE [Full Stretch] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/pe adjust", "output_node": false}, "ADE_AdjustPEManual": {"input": {"required": {"cap_initial_pe_length": ["INT", {"default": 0, "min": 0, "step": 1}], "interpolate_pe_to_length": ["INT", {"default": 0, "min": 0, "step": 1}], "initial_pe_idx_offset": ["INT", {"default": 0, "min": 0, "step": 1}], "final_pe_idx_offset": ["INT", {"default": 0, "min": 0, "step": 1}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_pe_adjust": ["PE_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["cap_initial_pe_length", "interpolate_pe_to_length", "initial_pe_idx_offset", "final_pe_idx_offset", "print_adjustment"], "optional": ["prev_pe_adjust"], "hidden": ["autosize"]}, "output": ["PE_ADJUST"], "output_is_list": [false], "output_name": ["PE_ADJUST"], "name": "ADE_AdjustPEManual", "display_name": "Adjust PE [Manual] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/pe adjust", "output_node": false}, "ADE_AdjustWeightAllAdd": {"input": {"required": {"all_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_weight_adjust": ["WEIGHT_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["all_ADD", "print_adjustment"], "optional": ["prev_weight_adjust"], "hidden": ["autosize"]}, "output": ["WEIGHT_ADJUST"], "output_is_list": [false], "output_name": ["WEIGHT_ADJUST"], "name": "ADE_AdjustWeightAllAdd", "display_name": "Adjust Weight [All\u25c6Add] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/weight adjust", "output_node": false}, "ADE_AdjustWeightAllMult": {"input": {"required": {"all_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_weight_adjust": ["WEIGHT_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["all_MULT", "print_adjustment"], "optional": ["prev_weight_adjust"], "hidden": ["autosize"]}, "output": ["WEIGHT_ADJUST"], "output_is_list": [false], "output_name": ["WEIGHT_ADJUST"], "name": "ADE_AdjustWeightAllMult", "display_name": "Adjust Weight [All\u25c6Mult] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/weight adjust", "output_node": false}, "ADE_AdjustWeightIndivAdd": {"input": {"required": {"pe_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "attn_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "other_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_weight_adjust": ["WEIGHT_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["pe_ADD", "attn_ADD", "other_ADD", "print_adjustment"], "optional": ["prev_weight_adjust"], "hidden": ["autosize"]}, "output": ["WEIGHT_ADJUST"], "output_is_list": [false], "output_name": ["WEIGHT_ADJUST"], "name": "ADE_AdjustWeightIndivAdd", "display_name": "Adjust Weight [Indiv\u25c6Add] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/weight adjust", "output_node": false}, "ADE_AdjustWeightIndivMult": {"input": {"required": {"pe_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "attn_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "other_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_weight_adjust": ["WEIGHT_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["pe_MULT", "attn_MULT", "other_MULT", "print_adjustment"], "optional": ["prev_weight_adjust"], "hidden": ["autosize"]}, "output": ["WEIGHT_ADJUST"], "output_is_list": [false], "output_name": ["WEIGHT_ADJUST"], "name": "ADE_AdjustWeightIndivMult", "display_name": "Adjust Weight [Indiv\u25c6Mult] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/weight adjust", "output_node": false}, "ADE_AdjustWeightIndivAttnAdd": {"input": {"required": {"pe_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "attn_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "attn_q_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "attn_k_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "attn_v_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "attn_out_weight_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "attn_out_bias_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "other_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_weight_adjust": ["WEIGHT_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["pe_ADD", "attn_ADD", "attn_q_ADD", "attn_k_ADD", "attn_v_ADD", "attn_out_weight_ADD", "attn_out_bias_ADD", "other_ADD", "print_adjustment"], "optional": ["prev_weight_adjust"], "hidden": ["autosize"]}, "output": ["WEIGHT_ADJUST"], "output_is_list": [false], "output_name": ["WEIGHT_ADJUST"], "name": "ADE_AdjustWeightIndivAttnAdd", "display_name": "Adjust Weight [Indiv-Attn\u25c6Add] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/weight adjust", "output_node": false}, "ADE_AdjustWeightIndivAttnMult": {"input": {"required": {"pe_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "attn_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "attn_q_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "attn_k_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "attn_v_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "attn_out_weight_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "attn_out_bias_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "other_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_weight_adjust": ["WEIGHT_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["pe_MULT", "attn_MULT", "attn_q_MULT", "attn_k_MULT", "attn_v_MULT", "attn_out_weight_MULT", "attn_out_bias_MULT", "other_MULT", "print_adjustment"], "optional": ["prev_weight_adjust"], "hidden": ["autosize"]}, "output": ["WEIGHT_ADJUST"], "output_is_list": [false], "output_name": ["WEIGHT_ADJUST"], "name": "ADE_AdjustWeightIndivAttnMult", "display_name": "Adjust Weight [Indiv-Attn\u25c6Mult] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/weight adjust", "output_node": false}, "ADE_CustomCFGSimple": {"input": {"required": {"cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1}]}, "optional": {"cfg_extras": ["CFG_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["cfg"], "optional": ["cfg_extras"], "hidden": ["autosize"]}, "output": ["CUSTOM_CFG"], "output_is_list": [false], "output_name": ["CUSTOM_CFG"], "name": "ADE_CustomCFGSimple", "display_name": "Custom CFG \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/custom cfg", "output_node": false}, "ADE_CustomCFG": {"input": {"required": {"cfg_multival": ["MULTIVAL"]}, "optional": {"cfg_extras": ["CFG_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["cfg_multival"], "optional": ["cfg_extras"], "hidden": ["autosize"]}, "output": ["CUSTOM_CFG"], "output_is_list": [false], "output_name": ["CUSTOM_CFG"], "name": "ADE_CustomCFG", "display_name": "Custom CFG [Multival] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/custom cfg", "output_node": false}, "ADE_CustomCFGKeyframeSimple": {"input": {"required": {"cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}]}, "optional": {"prev_custom_cfg": ["CUSTOM_CFG"], "cfg_extras": ["CFG_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 10}]}}, "input_order": {"required": ["cfg", "start_percent", "guarantee_steps"], "optional": ["prev_custom_cfg", "cfg_extras"], "hidden": ["autosize"]}, "output": ["CUSTOM_CFG"], "output_is_list": [false], "output_name": ["CUSTOM_CFG"], "name": "ADE_CustomCFGKeyframeSimple", "display_name": "Custom CFG Keyframe \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/custom cfg", "output_node": false}, "ADE_CustomCFGKeyframe": {"input": {"required": {"cfg_multival": ["MULTIVAL"], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}]}, "optional": {"prev_custom_cfg": ["CUSTOM_CFG"], "cfg_extras": ["CFG_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["cfg_multival", "start_percent", "guarantee_steps"], "optional": ["prev_custom_cfg", "cfg_extras"], "hidden": ["autosize"]}, "output": ["CUSTOM_CFG"], "output_is_list": [false], "output_name": ["CUSTOM_CFG"], "name": "ADE_CustomCFGKeyframe", "display_name": "Custom CFG Keyframe [Multival] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/custom cfg", "output_node": false}, "ADE_CustomCFGKeyframeInterpolation": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "cfg_start": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1}], "cfg_end": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "intervals": ["INT", {"default": 50, "min": 2, "max": 100, "step": 1}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_custom_cfg": ["CUSTOM_CFG"], "cfg_extras": ["CFG_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent", "end_percent", "cfg_start", "cfg_end", "interpolation", "intervals", "print_keyframes"], "optional": ["prev_custom_cfg", "cfg_extras"], "hidden": ["autosize"]}, "output": ["CUSTOM_CFG"], "output_is_list": [false], "output_name": ["CUSTOM_CFG"], "name": "ADE_CustomCFGKeyframeInterpolation", "display_name": "Custom CFG Keyframes Interp. \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/custom cfg", "output_node": false}, "ADE_CustomCFGKeyframeFromList": {"input": {"required": {"cfgs_float": ["FLOAT", {"default": -1, "min": -1, "step": 0.001, "forceInput": true}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_custom_cfg": ["CUSTOM_CFG"], "cfg_extras": ["CFG_EXTRAS"]}}, "input_order": {"required": ["cfgs_float", "start_percent", "end_percent", "print_keyframes"], "optional": ["prev_custom_cfg", "cfg_extras"]}, "output": ["CUSTOM_CFG"], "output_is_list": [false], "output_name": ["CUSTOM_CFG"], "name": "ADE_CustomCFGKeyframeFromList", "display_name": "Custom CFG Keyframes From List \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/custom cfg", "output_node": false}, "ADE_CFGExtrasPAGSimple": {"input": {"required": {"scale": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}]}, "optional": {"prev_extras": ["CFG_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["scale"], "optional": ["prev_extras"], "hidden": ["autosize"]}, "output": ["CFG_EXTRAS"], "output_is_list": [false], "output_name": ["CFG_EXTRAS"], "name": "ADE_CFGExtrasPAGSimple", "display_name": "CFG Extras\u25c6PAG \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/cfg extras", "output_node": false}, "ADE_CFGExtrasPAG": {"input": {"required": {"scale_multival": ["MULTIVAL"]}, "optional": {"prev_extras": ["CFG_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["scale_multival"], "optional": ["prev_extras"], "hidden": ["autosize"]}, "output": ["CFG_EXTRAS"], "output_is_list": [false], "output_name": ["CFG_EXTRAS"], "name": "ADE_CFGExtrasPAG", "display_name": "CFG Extras\u25c6PAG [Multival] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/cfg extras", "output_node": false}, "ADE_CFGExtrasRescaleCFGSimple": {"input": {"required": {"multiplier": ["FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"prev_extras": ["CFG_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 10}]}}, "input_order": {"required": ["multiplier"], "optional": ["prev_extras"], "hidden": ["autosize"]}, "output": ["CFG_EXTRAS"], "output_is_list": [false], "output_name": ["CFG_EXTRAS"], "name": "ADE_CFGExtrasRescaleCFGSimple", "display_name": "CFG Extras\u25c6RescaleCFG \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/cfg extras", "output_node": false}, "ADE_CFGExtrasRescaleCFG": {"input": {"required": {"mult_multival": ["MULTIVAL"]}, "optional": {"prev_extras": ["CFG_EXTRAS"]}}, "input_order": {"required": ["mult_multival"], "optional": ["prev_extras"]}, "output": ["CFG_EXTRAS"], "output_is_list": [false], "output_name": ["CFG_EXTRAS"], "name": "ADE_CFGExtrasRescaleCFG", "display_name": "CFG Extras\u25c6RescaleCFG [Multival] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/cfg extras", "output_node": false}, "ADE_SigmaSchedule": {"input": {"required": {"beta_schedule": [["sqrt_linear (AnimateDiff)", "linear (AnimateDiff-SDXL)", "linear (HotshotXL/default)", "avg(sqrt_linear,linear)", "lcm avg(sqrt_linear,linear)", "lcm", "lcm[100_ots]", "lcm >> sqrt_linear", "sqrt", "cosine", "squaredcos_cap_v2"]]}}, "input_order": {"required": ["beta_schedule"]}, "output": ["SIGMA_SCHEDULE"], "output_is_list": [false], "output_name": ["SIGMA_SCHEDULE"], "name": "ADE_SigmaSchedule", "display_name": "Create Sigma Schedule \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/sigma schedule", "output_node": false}, "ADE_RawSigmaSchedule": {"input": {"required": {"raw_beta_schedule": [["linear", "sqrt_linear", "sqrt", "cosine", "squaredcos_cap_v2"]], "linear_start": ["FLOAT", {"default": 0.00085, "min": 0.0, "max": 1.0, "step": 1e-06}], "linear_end": ["FLOAT", {"default": 0.012, "min": 0.0, "max": 1.0, "step": 1e-06}], "sampling": [["eps", "v_prediction", "lcm"]], "lcm_original_timesteps": ["INT", {"default": 50, "min": 1, "max": 1000}], "zsnr": ["BOOLEAN", {"default": false}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["raw_beta_schedule", "linear_start", "linear_end", "sampling", "lcm_original_timesteps", "zsnr"], "hidden": ["autosize"]}, "output": ["SIGMA_SCHEDULE"], "output_is_list": [false], "output_name": ["SIGMA_SCHEDULE"], "name": "ADE_RawSigmaSchedule", "display_name": "Create Raw Sigma Schedule \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/sigma schedule", "output_node": false}, "ADE_SigmaScheduleWeightedAverage": {"input": {"required": {"schedule_A": ["SIGMA_SCHEDULE"], "schedule_B": ["SIGMA_SCHEDULE"], "weight_A": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.001}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["schedule_A", "schedule_B", "weight_A"], "hidden": ["autosize"]}, "output": ["SIGMA_SCHEDULE"], "output_is_list": [false], "output_name": ["SIGMA_SCHEDULE"], "name": "ADE_SigmaScheduleWeightedAverage", "display_name": "Sigma Schedule Weighted Mean \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/sigma schedule", "output_node": false}, "ADE_SigmaScheduleWeightedAverageInterp": {"input": {"required": {"schedule_A": ["SIGMA_SCHEDULE"], "schedule_B": ["SIGMA_SCHEDULE"], "weight_A_Start": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.001}], "weight_A_End": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.001}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["schedule_A", "schedule_B", "weight_A_Start", "weight_A_End", "interpolation"], "hidden": ["autosize"]}, "output": ["SIGMA_SCHEDULE"], "output_is_list": [false], "output_name": ["SIGMA_SCHEDULE"], "name": "ADE_SigmaScheduleWeightedAverageInterp", "display_name": "Sigma Schedule Interp. Mean \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/sigma schedule", "output_node": false}, "ADE_SigmaScheduleSplitAndCombine": {"input": {"required": {"schedule_Start": ["SIGMA_SCHEDULE"], "schedule_End": ["SIGMA_SCHEDULE"], "idx_split_percent": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.001}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["schedule_Start", "schedule_End", "idx_split_percent"], "hidden": ["autosize"]}, "output": ["SIGMA_SCHEDULE"], "output_is_list": [false], "output_name": ["SIGMA_SCHEDULE"], "name": "ADE_SigmaScheduleSplitAndCombine", "display_name": "Sigma Schedule Split Combine \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/sigma schedule", "output_node": false}, "ADE_SigmaScheduleToSigmas": {"input": {"required": {"sigma_schedule": ["SIGMA_SCHEDULE"], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"]], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["sigma_schedule", "scheduler", "steps", "denoise"], "hidden": ["autosize"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "ADE_SigmaScheduleToSigmas", "display_name": "Sigma Schedule To Sigmas \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/sigma schedule", "output_node": false}, "ADE_NoisedImageInjection": {"input": {"required": {"image": ["IMAGE"], "vae": ["VAE"]}, "optional": {"mask_opt": ["MASK"], "invert_mask": ["BOOLEAN", {"default": false}], "resize_image": ["BOOLEAN", {"default": true}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 1, "max": 9007199254740991}], "img_inject_opts": ["IMAGE_INJECT_OPTIONS"], "strength_multival": ["MULTIVAL"], "prev_image_inject": ["IMAGE_INJECT"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["image", "vae"], "optional": ["mask_opt", "invert_mask", "resize_image", "start_percent", "guarantee_steps", "img_inject_opts", "strength_multival", "prev_image_inject"], "hidden": ["autosize"]}, "output": ["IMAGE_INJECT"], "output_is_list": [false], "output_name": ["IMAGE_INJECT"], "name": "ADE_NoisedImageInjection", "display_name": "Image Injection \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/image inject", "output_node": false}, "ADE_NoisedImageInjectOptions": {"input": {"required": {}, "optional": {"composite_x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "composite_y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["composite_x", "composite_y"], "hidden": ["autosize"]}, "output": ["IMAGE_INJECT_OPTIONS"], "output_is_list": [false], "output_name": ["IMG_INJECT_OPTS"], "name": "ADE_NoisedImageInjectOptions", "display_name": "Image Injection Options \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/image inject", "output_node": false}, "ADE_AncestralOptions": {"input": {"required": {"noise_type": [["default", "constant"]], "seed_offset": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991}]}, "optional": {"seed_override": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "forceInput": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["noise_type", "seed_offset"], "optional": ["seed_override"], "hidden": ["autosize"]}, "output": ["ANCESTRAL_OPTS"], "output_is_list": [false], "output_name": ["ANCESTRAL_OPTS"], "name": "ADE_AncestralOptions", "display_name": "Ancestral Options \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings", "output_node": false}, "ADE_PromptScheduling": {"input": {"required": {"prompts": ["STRING", {"multiline": true, "default": ""}], "clip": ["CLIP"]}, "optional": {"prepend_text": ["STRING", {"multiline": true, "default": "", "forceInput": true}], "append_text": ["STRING", {"multiline": true, "default": "", "forceInput": true}], "values_replace": ["VALUES_REPLACE"], "print_schedule": ["BOOLEAN", {"default": false}], "max_length": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "tensor_interp": [["lerp", "slerp"]]}}, "input_order": {"required": ["prompts", "clip"], "optional": ["prepend_text", "append_text", "values_replace", "print_schedule", "max_length", "tensor_interp"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ADE_PromptScheduling", "display_name": "Prompt Scheduling \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "<div><div id=VHS_shortdesc style=\"font-size: .8em\">Encode a schedule of prompts with automatic interpolation.</div></div><div><div vhs_title=\"Format\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Format: <div>Scheduling supports two formats: JSON and pythonic.</div><div><div vhs_title=\"JSON\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">JSON: <div>\"idx\": \"your prompt here\", ...</div></div></div><div vhs_title=\"pythonic\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pythonic: <div>idx = \"your prompt here\", ...</div></div></div></div><div>The idx is the index of the frame - first frame is 0, last frame is max_frames-1. An idx may be the following:</div><div><div vhs_title=\"allowed idxs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">allowed idxs: <div vhs_title=\"single\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">single: A positive integer (e.g. 0, 2) schedules value for frame. A negative integer (e.g. -1, -5) schedules value for frame from the end (-1 would be the last frame). A decimal (e.g. 0.5, 1.0) selects frame based relative location in whole schedule (0.5 would be halfway, 1.0 would be last frame).</div></div><div vhs_title=\"range\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">range: Using rules above, single:single chooses uninterpolated prompts from start idx (included) to end idx (excluded). Examples -> 0:12, 0:-5, 2:0.5</div></div><div vhs_title=\"hold\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">hold: Putting a colon after a single idx stops interpolation until the next provided index. Examples -> 0:, 0.5:, 16: </div></div></div></div></div><div>The prompts themselves should be surrounded by double quotes (\"your prompt here\"). Portions of prompts can use value schedules provided values_replace.</div><div><div vhs_title=\"JSON\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">JSON: <div>\"0\": \"blue rock on mountain\",</div><div>\"16\": \"green rock in lake\"</div></div></div><div vhs_title=\"pythonic\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pythonic: <div>0 = \"blue rock on mountain\",</div><div>16 = \"green rock in lake\"</div></div></div></div></div></div></div><div><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"prompts\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">prompts: Write your prompts here.</div></div><div vhs_title=\"clip\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">clip: CLIP to use for encoding prompts.</div></div><div vhs_title=\"values_replace\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">values_replace: OPTIONAL, replaces keys from value_replace keys with provided value schedules. Keys in the prompt are written as `some_key`, surrounded by the ` characters.</div></div><div vhs_title=\"prepend_text\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">prepend_text: OPTIONAL, adds text before all prompts.</div></div><div vhs_title=\"append_text\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">append_text: OPTIONAL, adds text after all prompts.</div></div><div vhs_title=\"max_length\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">max_length: Used to select the intended length of schedule. If set to 0, will use the largest index in the schedule as max_length, but will disable relative indexes (negative and decimal).</div></div><div vhs_title=\"tensor_interp\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">tensor_interp: Selects method of interpolating prompt conds - defaults to lerp.</div></div><div vhs_title=\"print_schedule\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">print_schedule: When True, prints output values for each frame.</div></div></div></div></div><div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"CONDITIONING\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">CONDITIONING: Encoded prompts.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/scheduling", "output_node": false}, "ADE_PromptSchedulingLatents": {"input": {"required": {"prompts": ["STRING", {"multiline": true, "default": ""}], "clip": ["CLIP"], "latent": ["LATENT"]}, "optional": {"prepend_text": ["STRING", {"multiline": true, "default": "", "forceInput": true}], "append_text": ["STRING", {"multiline": true, "default": "", "forceInput": true}], "values_replace": ["VALUES_REPLACE"], "print_schedule": ["BOOLEAN", {"default": false}], "tensor_interp": [["lerp", "slerp"]]}}, "input_order": {"required": ["prompts", "clip", "latent"], "optional": ["prepend_text", "append_text", "values_replace", "print_schedule", "tensor_interp"]}, "output": ["CONDITIONING", "LATENT"], "output_is_list": [false, false], "output_name": ["CONDITIONING", "LATENT"], "name": "ADE_PromptSchedulingLatents", "display_name": "Prompt Scheduling [Latents] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "<div><div id=VHS_shortdesc style=\"font-size: .8em\">Encode a schedule of prompts with automatic interpolation, its length matching passed-in latent count.</div></div><div><div vhs_title=\"Format\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Format: <div>Scheduling supports two formats: JSON and pythonic.</div><div><div vhs_title=\"JSON\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">JSON: <div>\"idx\": \"your prompt here\", ...</div></div></div><div vhs_title=\"pythonic\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pythonic: <div>idx = \"your prompt here\", ...</div></div></div></div><div>The idx is the index of the frame - first frame is 0, last frame is max_frames-1. An idx may be the following:</div><div><div vhs_title=\"allowed idxs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">allowed idxs: <div vhs_title=\"single\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">single: A positive integer (e.g. 0, 2) schedules value for frame. A negative integer (e.g. -1, -5) schedules value for frame from the end (-1 would be the last frame). A decimal (e.g. 0.5, 1.0) selects frame based relative location in whole schedule (0.5 would be halfway, 1.0 would be last frame).</div></div><div vhs_title=\"range\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">range: Using rules above, single:single chooses uninterpolated prompts from start idx (included) to end idx (excluded). Examples -> 0:12, 0:-5, 2:0.5</div></div><div vhs_title=\"hold\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">hold: Putting a colon after a single idx stops interpolation until the next provided index. Examples -> 0:, 0.5:, 16: </div></div></div></div></div><div>The prompts themselves should be surrounded by double quotes (\"your prompt here\"). Portions of prompts can use value schedules provided values_replace.</div><div><div vhs_title=\"JSON\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">JSON: <div>\"0\": \"blue rock on mountain\",</div><div>\"16\": \"green rock in lake\"</div></div></div><div vhs_title=\"pythonic\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pythonic: <div>0 = \"blue rock on mountain\",</div><div>16 = \"green rock in lake\"</div></div></div></div></div></div></div><div><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"prompts\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">prompts: Write your prompts here.</div></div><div vhs_title=\"clip\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">clip: CLIP to use for encoding prompts.</div></div><div vhs_title=\"latent\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latent: Used to get the amount of frames (max_length) to use for scheduling.</div></div><div vhs_title=\"values_replace\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">values_replace: OPTIONAL, replaces keys from value_replace keys with provided value schedules. Keys in the prompt are written as `some_key`, surrounded by the ` characters.</div></div><div vhs_title=\"prepend_text\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">prepend_text: OPTIONAL, adds text before all prompts.</div></div><div vhs_title=\"append_text\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">append_text: OPTIONAL, adds text after all prompts.</div></div><div vhs_title=\"tensor_interp\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">tensor_interp: Selects method of interpolating prompt conds - defaults to lerp.</div></div><div vhs_title=\"print_schedule\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">print_schedule: When True, prints output values for each frame.</div></div></div></div></div><div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"CONDITIONING\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">CONDITIONING: Encoded prompts.</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: Unmodified input latents; can be used as pipe, or can be ignored.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/scheduling", "output_node": false}, "ADE_ValueScheduling": {"input": {"required": {"values": ["STRING", {"multiline": true, "default": ""}]}, "optional": {"print_schedule": ["BOOLEAN", {"default": false}], "max_length": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["values"], "optional": ["print_schedule", "max_length"], "hidden": ["autosize"]}, "output": ["FLOAT", "FLOATS", "INT", "INTS"], "output_is_list": [false, false, false, false], "output_name": ["FLOAT", "FLOATS", "INT", "INTS"], "name": "ADE_ValueScheduling", "display_name": "Value Scheduling \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "<div><div id=VHS_shortdesc style=\"font-size: .8em\">Create a list of values with automatic interpolation.</div></div><div><div vhs_title=\"Format\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Format: <div>Scheduling supports two formats: JSON and pythonic.</div><div><div vhs_title=\"JSON\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">JSON: <div>\"idx\": float/int_value, ...</div></div></div><div vhs_title=\"pythonic\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pythonic: <div>idx = float/int_value, ...</div></div></div></div><div>The idx is the index of the frame - first frame is 0, last frame is max_frames-1. An idx may be the following:</div><div><div vhs_title=\"allowed idxs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">allowed idxs: <div vhs_title=\"single\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">single: A positive integer (e.g. 0, 2) schedules value for frame. A negative integer (e.g. -1, -5) schedules value for frame from the end (-1 would be the last frame). A decimal (e.g. 0.5, 1.0) selects frame based relative location in whole schedule (0.5 would be halfway, 1.0 would be last frame).</div></div><div vhs_title=\"range\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">range: Using rules above, single:single chooses uninterpolated prompts from start idx (included) to end idx (excluded). Examples -> 0:12, 0:-5, 2:0.5</div></div><div vhs_title=\"hold\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">hold: Putting a colon after a single idx stops interpolation until the next provided index. Examples -> 0:, 0.5:, 16: </div></div></div></div></div><div>The values can be written without any special formatting.</div><div><div vhs_title=\"JSON\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">JSON: <div>\"0\": 1.0,</div><div>\"16\": 1.3</div></div></div><div vhs_title=\"pythonic\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pythonic: <div>0 = 1.0,</div><div>16 = 1.3</div></div></div></div></div></div></div><div><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"values\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">values: Write your values here.</div></div><div vhs_title=\"max_length\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">max_length: Used to select the intended length of schedule. If set to 0, will use the largest index in the schedule as max_length, but will disable relative indexes (negative and decimal).</div></div><div vhs_title=\"print_schedule\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">print_schedule: When True, prints output values for each frame.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/scheduling", "output_node": false}, "ADE_ValueSchedulingLatents": {"input": {"required": {"values": ["STRING", {"multiline": true, "default": ""}], "latent": ["LATENT"]}, "optional": {"print_schedule": ["BOOLEAN", {"default": false}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["values", "latent"], "optional": ["print_schedule"], "hidden": ["autosize"]}, "output": ["FLOAT", "FLOATS", "INT", "INTS"], "output_is_list": [false, false, false, false], "output_name": ["FLOAT", "FLOATS", "INT", "INTS"], "name": "ADE_ValueSchedulingLatents", "display_name": "Value Scheduling [Latents] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "<div><div id=VHS_shortdesc style=\"font-size: .8em\">Create a list of values with automatic interpolation, its length matching passed-in latent count.</div></div><div><div vhs_title=\"Format\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Format: <div>Scheduling supports two formats: JSON and pythonic.</div><div><div vhs_title=\"JSON\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">JSON: <div>\"idx\": float/int_value, ...</div></div></div><div vhs_title=\"pythonic\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pythonic: <div>idx = float/int_value, ...</div></div></div></div><div>The idx is the index of the frame - first frame is 0, last frame is max_frames-1. An idx may be the following:</div><div><div vhs_title=\"allowed idxs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">allowed idxs: <div vhs_title=\"single\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">single: A positive integer (e.g. 0, 2) schedules value for frame. A negative integer (e.g. -1, -5) schedules value for frame from the end (-1 would be the last frame). A decimal (e.g. 0.5, 1.0) selects frame based relative location in whole schedule (0.5 would be halfway, 1.0 would be last frame).</div></div><div vhs_title=\"range\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">range: Using rules above, single:single chooses uninterpolated prompts from start idx (included) to end idx (excluded). Examples -> 0:12, 0:-5, 2:0.5</div></div><div vhs_title=\"hold\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">hold: Putting a colon after a single idx stops interpolation until the next provided index. Examples -> 0:, 0.5:, 16: </div></div></div></div></div><div>The values can be written without any special formatting.</div><div><div vhs_title=\"JSON\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">JSON: <div>\"0\": 1.0,</div><div>\"16\": 1.3</div></div></div><div vhs_title=\"pythonic\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pythonic: <div>0 = 1.0,</div><div>16 = 1.3</div></div></div></div></div></div></div><div><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"values\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">values: Write your values here.</div></div><div vhs_title=\"latent\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latent: Used to get the amount of frames (max_length) to use for scheduling.</div></div><div vhs_title=\"print_schedule\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">print_schedule: When True, prints output values for each frame.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/scheduling", "output_node": false}, "ADE_ValuesReplace": {"input": {"required": {"value_key": ["STRING", {"default": ""}], "floats": ["FLOATS"]}, "optional": {"prev_replace": ["VALUES_REPLACE"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["value_key", "floats"], "optional": ["prev_replace"], "hidden": ["autosize"]}, "output": ["VALUES_REPLACE"], "output_is_list": [false], "output_name": ["VALUES_REPLACE"], "name": "ADE_ValuesReplace", "display_name": "Add Values Replace \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "<div><div id=VHS_shortdesc style=\"font-size: .8em\">Add a values schedule bound to a key to be used in Prompt Scheduling node.</div></div><div><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"value_key\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">value_key: Key to use for value schedule in Prompt Scheduling node. Can only contain a-z, A-Z, 0-9, and _ characters. In Prompt Scheduling, keys can be referred to as `some_key`, where the key is surrounded by ` characters.</div></div><div vhs_title=\"floats\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">floats: List of floats, likely outputted by a Value Scheduling node.</div></div><div vhs_title=\"prev_replace\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">prev_replace: OPTIONAL, other values_replace can be chained.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/scheduling", "output_node": false}, "ADE_FloatToFloats": {"input": {"required": {"FLOAT": ["FLOAT", {"default": 39, "forceInput": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["FLOAT"], "hidden": ["autosize"]}, "output": ["FLOATS"], "output_is_list": [false], "output_name": ["FLOATS"], "name": "ADE_FloatToFloats", "display_name": "Float to Floats \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/scheduling", "output_node": false}, "ADE_ADBlockCombo": {"input": {"required": {}, "optional": {"effect": ["MULTIVAL"], "scale": ["MULTIVAL"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["effect", "scale"], "hidden": ["autosize"]}, "output": ["AD_BLOCK"], "output_is_list": [false], "output_name": ["AD_BLOCK"], "name": "ADE_ADBlockCombo", "display_name": "AD Block \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_ADBlockIndiv": {"input": {"required": {}, "optional": {"effect": ["MULTIVAL"], "scale_0": ["MULTIVAL"], "scale_1": ["MULTIVAL"], "autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["effect", "scale_0", "scale_1", "autosize"]}, "output": ["AD_BLOCK"], "output_is_list": [false], "output_name": ["AD_BLOCK"], "name": "ADE_ADBlockIndiv", "display_name": "AD Block+ \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_PerBlockHighLevel": {"input": {"required": {}, "optional": {"down": ["AD_BLOCK"], "mid": ["AD_BLOCK"], "up": ["AD_BLOCK"], "autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["down", "mid", "up", "autosize"]}, "output": ["PER_BLOCK"], "output_is_list": [false], "output_name": ["PER_BLOCK"], "name": "ADE_PerBlockHighLevel", "display_name": "AD Per Block \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_PerBlock_SD15_MidLevel": {"input": {"required": {}, "optional": {"down_0": ["AD_BLOCK"], "down_1": ["AD_BLOCK"], "down_2": ["AD_BLOCK"], "down_3": ["AD_BLOCK"], "mid": ["AD_BLOCK"], "up_0": ["AD_BLOCK"], "up_1": ["AD_BLOCK"], "up_2": ["AD_BLOCK"], "up_3": ["AD_BLOCK"], "autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["down_0", "down_1", "down_2", "down_3", "mid", "up_0", "up_1", "up_2", "up_3", "autosize"]}, "output": ["PER_BLOCK"], "output_is_list": [false], "output_name": ["PER_BLOCK"], "name": "ADE_PerBlock_SD15_MidLevel", "display_name": "AD Per Block+ (SD1.5) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_PerBlock_SD15_LowLevel": {"input": {"required": {}, "optional": {"down_0__0": ["AD_BLOCK"], "down_0__1": ["AD_BLOCK"], "down_1__0": ["AD_BLOCK"], "down_1__1": ["AD_BLOCK"], "down_2__0": ["AD_BLOCK"], "down_2__1": ["AD_BLOCK"], "down_3__0": ["AD_BLOCK"], "down_3__1": ["AD_BLOCK"], "mid": ["AD_BLOCK"], "up_0__0": ["AD_BLOCK"], "up_0__1": ["AD_BLOCK"], "up_0__2": ["AD_BLOCK"], "up_1__0": ["AD_BLOCK"], "up_1__1": ["AD_BLOCK"], "up_1__2": ["AD_BLOCK"], "up_2__0": ["AD_BLOCK"], "up_2__1": ["AD_BLOCK"], "up_2__2": ["AD_BLOCK"], "up_3__0": ["AD_BLOCK"], "up_3__1": ["AD_BLOCK"], "up_3__2": ["AD_BLOCK"], "autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["down_0__0", "down_0__1", "down_1__0", "down_1__1", "down_2__0", "down_2__1", "down_3__0", "down_3__1", "mid", "up_0__0", "up_0__1", "up_0__2", "up_1__0", "up_1__1", "up_1__2", "up_2__0", "up_2__1", "up_2__2", "up_3__0", "up_3__1", "up_3__2", "autosize"]}, "output": ["PER_BLOCK"], "output_is_list": [false], "output_name": ["PER_BLOCK"], "name": "ADE_PerBlock_SD15_LowLevel", "display_name": "AD Per Block++ (SD1.5) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_PerBlock_SD15_FromFloats": {"input": {"required": {}, "optional": {"effect_21_floats": ["FLOATS"], "scale_21_floats": ["FLOATS"], "autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["effect_21_floats", "scale_21_floats", "autosize"]}, "output": ["PER_BLOCK"], "output_is_list": [false], "output_name": ["PER_BLOCK"], "name": "ADE_PerBlock_SD15_FromFloats", "display_name": "AD Per Block Floats (SD1.5) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "<div><div id=VHS_shortdesc style=\"font-size: .8em\">Use Floats from Value Schedules to select SD1.5 effect/scale values for blocks.</div></div><div>SD1.5 Motion Modules contain 21 blocks:</div><div>idx 0 - start of down blocks (down_0__0)</div><div>idx 7 - end of down blocks   (down_3__1)</div><div>idx 8 - mid block            (mid)</div><div>idx 9 - start of up blocks   (up_0__0)</div><div>idx 20 - end of up blocks    (up_3__2)</div>", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_PerBlock_SDXL_MidLevel": {"input": {"required": {}, "optional": {"down_0": ["AD_BLOCK"], "down_1": ["AD_BLOCK"], "down_2": ["AD_BLOCK"], "mid": ["AD_BLOCK"], "up_0": ["AD_BLOCK"], "up_1": ["AD_BLOCK"], "up_2": ["AD_BLOCK"], "autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["down_0", "down_1", "down_2", "mid", "up_0", "up_1", "up_2", "autosize"]}, "output": ["PER_BLOCK"], "output_is_list": [false], "output_name": ["PER_BLOCK"], "name": "ADE_PerBlock_SDXL_MidLevel", "display_name": "AD Per Block+ (SDXL) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_PerBlock_SDXL_LowLevel": {"input": {"required": {}, "optional": {"down_0__0": ["AD_BLOCK"], "down_0__1": ["AD_BLOCK"], "down_1__0": ["AD_BLOCK"], "down_1__1": ["AD_BLOCK"], "down_2__0": ["AD_BLOCK"], "down_2__1": ["AD_BLOCK"], "mid": ["AD_BLOCK"], "up_0__0": ["AD_BLOCK"], "up_0__1": ["AD_BLOCK"], "up_0__2": ["AD_BLOCK"], "up_1__0": ["AD_BLOCK"], "up_1__1": ["AD_BLOCK"], "up_1__2": ["AD_BLOCK"], "up_2__0": ["AD_BLOCK"], "up_2__1": ["AD_BLOCK"], "up_2__2": ["AD_BLOCK"], "autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["down_0__0", "down_0__1", "down_1__0", "down_1__1", "down_2__0", "down_2__1", "mid", "up_0__0", "up_0__1", "up_0__2", "up_1__0", "up_1__1", "up_1__2", "up_2__0", "up_2__1", "up_2__2", "autosize"]}, "output": ["PER_BLOCK"], "output_is_list": [false], "output_name": ["PER_BLOCK"], "name": "ADE_PerBlock_SDXL_LowLevel", "display_name": "AD Per Block++ (SDXL) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_PerBlock_SDXL_FromFloats": {"input": {"required": {}, "optional": {"effect_16_floats": ["FLOATS"], "scale_16_floats": ["FLOATS"], "autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["effect_16_floats", "scale_16_floats", "autosize"]}, "output": ["PER_BLOCK"], "output_is_list": [false], "output_name": ["PER_BLOCK"], "name": "ADE_PerBlock_SDXL_FromFloats", "display_name": "AD Per Block Floats (SDXL) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "<div><div id=VHS_shortdesc style=\"font-size: .8em\">Use Floats from Value Schedules to select SDXL effect/scale values for blocks.</div></div><div>SDXL Motion Modules contain 16 blocks:</div><div>idx 0 - start of down blocks (down_0__0)</div><div>idx 5 - end of down blocks   (down_2__1)</div><div>idx 6 - mid block            (mid)</div><div>idx 7 - start of up blocks   (up_0__0)</div><div>idx 15 - end of up blocks    (up_2__2)</div>", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_AnimateDiffUnload": {"input": {"required": {"model": ["MODEL"]}}, "input_order": {"required": ["model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ADE_AnimateDiffUnload", "display_name": "AnimateDiff Unload \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/extras", "output_node": false}, "ADE_EmptyLatentImageLarge": {"input": {"required": {"width": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "height": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 262144}]}}, "input_order": {"required": ["width", "height", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "ADE_EmptyLatentImageLarge", "display_name": "Empty Latent Image (Big Batch) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/extras", "output_node": false}, "CheckpointLoaderSimpleWithNoiseSelect": {"input": {"required": {"ckpt_name": [["Artfusion Surreal XL.safetensors", "Flux_dev_turbo_krea_mix.safetensors", "Flux_dev_v1.safetensors", "XLbluePencilXL_v700.safetensors", "XLrealbluejuggernautmi_v10.safetensors", "animagineXLRealistic_v5.safetensors", "animeIllustDiffusion_v08.safetensors", "artfusionXL_v11Lightning.safetensors", "cyberrealisticXL_v5.safetensors", "dreamshaperXL_v21TurboDPMSDE.safetensors", "electricDreams_electricDreamsV04.safetensors", "epicrealismXL_vxvAnewstoryRealism.safetensors", "illustrationStyleIV.nR7A.safetensors", "illustrationXL_v10.safetensors", "jibMixRealisticXL_v170SmokeSheen.safetensors", "jruTheJourneyRemains_v20XL.safetensors", "midgardPonyTHLSDXL_v32.safetensors", "pixniteXL_v10.safetensors", "reymixXL_v20.safetensors", "sd_xl_base_1.0.safetensors", "sd_xl_refiner_1.0.safetensors", "sdxlFaetastic_v10.safetensors", "sdxlInkpunkstyle_v01.safetensors", "v1-5-pruned-emaonly.safetensors", "xl6HEPHAISTOSSD10XLSFW_v331BF16Experimental.safetensors"]], "beta_schedule": [["autoselect", "use existing", "sqrt_linear (AnimateDiff)", "linear (AnimateDiff-SDXL)", "linear (HotshotXL/default)", "avg(sqrt_linear,linear)", "lcm avg(sqrt_linear,linear)", "lcm", "lcm[100_ots]", "lcm >> sqrt_linear", "sqrt", "cosine", "squaredcos_cap_v2"], {"default": "use existing"}]}, "optional": {"use_custom_scale_factor": ["BOOLEAN", {"default": false}], "scale_factor": ["FLOAT", {"default": 0.18215, "min": 0.0, "max": 1.0, "step": 1e-05}]}}, "input_order": {"required": ["ckpt_name", "beta_schedule"], "optional": ["use_custom_scale_factor", "scale_factor"]}, "output": ["MODEL", "CLIP", "VAE"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "VAE"], "name": "CheckpointLoaderSimpleWithNoiseSelect", "display_name": "Load Checkpoint w/ Noise Select \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/extras", "output_node": false}, "ADE_PerturbedAttentionGuidanceMultival": {"input": {"required": {"model": ["MODEL"], "scale_multival": ["MULTIVAL"]}}, "input_order": {"required": ["model", "scale_multival"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ADE_PerturbedAttentionGuidanceMultival", "display_name": "PerturbedAttnGuide [Multival] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/extras", "output_node": false}, "ADE_RescaleCFGMultival": {"input": {"required": {"model": ["MODEL"], "mult_multival": ["MULTIVAL"]}}, "input_order": {"required": ["model", "mult_multival"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ADE_RescaleCFGMultival", "display_name": "RescaleCFG [Multival] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/extras", "output_node": false}, "ADE_AnimateDiffLoaderGen1": {"input": {"required": {"model": ["MODEL"], "model_name": [[]], "beta_schedule": [["autoselect", "use existing", "sqrt_linear (AnimateDiff)", "linear (AnimateDiff-SDXL)", "linear (HotshotXL/default)", "avg(sqrt_linear,linear)", "lcm avg(sqrt_linear,linear)", "lcm", "lcm[100_ots]", "lcm >> sqrt_linear", "sqrt", "cosine", "squaredcos_cap_v2"], {"default": "autoselect"}]}, "optional": {"context_options": ["CONTEXT_OPTIONS"], "motion_lora": ["MOTION_LORA"], "ad_settings": ["AD_SETTINGS"], "ad_keyframes": ["AD_KEYFRAMES"], "sample_settings": ["SAMPLE_SETTINGS"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "per_block": ["PER_BLOCK"]}}, "input_order": {"required": ["model", "model_name", "beta_schedule"], "optional": ["context_options", "motion_lora", "ad_settings", "ad_keyframes", "sample_settings", "scale_multival", "effect_multival", "per_block"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ADE_AnimateDiffLoaderGen1", "display_name": "AnimateDiff Loader \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2460", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2460 Gen1 nodes \u2460", "output_node": false}, "ADE_UseEvolvedSampling": {"input": {"required": {"model": ["MODEL"], "beta_schedule": [["autoselect", "use existing", "sqrt_linear (AnimateDiff)", "linear (AnimateDiff-SDXL)", "linear (HotshotXL/default)", "avg(sqrt_linear,linear)", "lcm avg(sqrt_linear,linear)", "lcm", "lcm[100_ots]", "lcm >> sqrt_linear", "sqrt", "cosine", "squaredcos_cap_v2"], {"default": "autoselect"}]}, "optional": {"m_models": ["M_MODELS"], "context_options": ["CONTEXT_OPTIONS"], "sample_settings": ["SAMPLE_SETTINGS"]}}, "input_order": {"required": ["model", "beta_schedule"], "optional": ["m_models", "context_options", "sample_settings"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ADE_UseEvolvedSampling", "display_name": "Use Evolved Sampling \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461", "output_node": false}, "ADE_ApplyAnimateDiffModelSimple": {"input": {"required": {"motion_model": ["MOTION_MODEL_ADE"]}, "optional": {"motion_lora": ["MOTION_LORA"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "ad_keyframes": ["AD_KEYFRAMES"], "per_block": ["PER_BLOCK"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["motion_model"], "optional": ["motion_lora", "scale_multival", "effect_multival", "ad_keyframes", "per_block"], "hidden": ["autosize"]}, "output": ["M_MODELS"], "output_is_list": [false], "output_name": ["M_MODELS"], "name": "ADE_ApplyAnimateDiffModelSimple", "display_name": "Apply AnimateDiff Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461", "output_node": false}, "ADE_ApplyAnimateDiffModel": {"input": {"required": {"motion_model": ["MOTION_MODEL_ADE"], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"motion_lora": ["MOTION_LORA"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "ad_keyframes": ["AD_KEYFRAMES"], "prev_m_models": ["M_MODELS"], "per_block": ["PER_BLOCK"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["motion_model", "start_percent", "end_percent"], "optional": ["motion_lora", "scale_multival", "effect_multival", "ad_keyframes", "prev_m_models", "per_block"], "hidden": ["autosize"]}, "output": ["M_MODELS"], "output_is_list": [false], "output_name": ["M_MODELS"], "name": "ADE_ApplyAnimateDiffModel", "display_name": "Apply AnimateDiff Model (Adv.) \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461", "output_node": false}, "ADE_LoadAnimateDiffModel": {"input": {"required": {"model_name": [[]]}, "optional": {"ad_settings": ["AD_SETTINGS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 50}]}}, "input_order": {"required": ["model_name"], "optional": ["ad_settings"], "hidden": ["autosize"]}, "output": ["MOTION_MODEL_ADE"], "output_is_list": [false], "output_name": ["MOTION_MODEL"], "name": "ADE_LoadAnimateDiffModel", "display_name": "Load AnimateDiff Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461", "output_node": false}, "ADE_ApplyAnimateLCMI2VModel": {"input": {"required": {"motion_model": ["MOTION_MODEL_ADE"], "ref_latent": ["LATENT"], "ref_drift": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 10.0, "step": 0.001}], "apply_ref_when_disabled": ["BOOLEAN", {"default": false}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"motion_lora": ["MOTION_LORA"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "ad_keyframes": ["AD_KEYFRAMES"], "prev_m_models": ["M_MODELS"], "per_block": ["PER_BLOCK"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["motion_model", "ref_latent", "ref_drift", "apply_ref_when_disabled", "start_percent", "end_percent"], "optional": ["motion_lora", "scale_multival", "effect_multival", "ad_keyframes", "prev_m_models", "per_block"], "hidden": ["autosize"]}, "output": ["M_MODELS"], "output_is_list": [false], "output_name": ["M_MODELS"], "name": "ADE_ApplyAnimateLCMI2VModel", "display_name": "Apply AnimateLCM-I2V Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/AnimateLCM-I2V", "output_node": false}, "ADE_LoadAnimateLCMI2VModel": {"input": {"required": {"model_name": [[]]}, "optional": {"ad_settings": ["AD_SETTINGS"]}}, "input_order": {"required": ["model_name"], "optional": ["ad_settings"]}, "output": ["MOTION_MODEL_ADE", "MOTION_MODEL_ADE"], "output_is_list": [false, false], "output_name": ["MOTION_MODEL", "encoder_only"], "name": "ADE_LoadAnimateLCMI2VModel", "display_name": "Load AnimateLCM-I2V Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/AnimateLCM-I2V", "output_node": false}, "ADE_UpscaleAndVAEEncode": {"input": {"required": {"image": ["IMAGE"], "vae": ["VAE"], "latent_size": ["LATENT"], "scale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]], "crop": [["disabled", "center"], {"default": "center"}]}}, "input_order": {"required": ["image", "vae", "latent_size", "scale_method", "crop"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "ADE_UpscaleAndVAEEncode", "display_name": "Scale Ref Image and VAE Encode \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/AnimateLCM-I2V", "output_node": false}, "ADE_InjectI2VIntoAnimateDiffModel": {"input": {"required": {"model_name": [[]], "motion_model": ["MOTION_MODEL_ADE"]}, "optional": {"ad_settings": ["AD_SETTINGS"], "deprecation_warning": ["ADEWARN", {"text": "Experimental. Don't expect to work.", "warn_type": "experimental", "color": "#CFC"}]}}, "input_order": {"required": ["model_name", "motion_model"], "optional": ["ad_settings", "deprecation_warning"]}, "output": ["MOTION_MODEL_ADE"], "output_is_list": [false], "output_name": ["MOTION_MODEL"], "name": "ADE_InjectI2VIntoAnimateDiffModel", "display_name": "\ud83e\uddeaInject I2V into AnimateDiff Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/AnimateLCM-I2V/\ud83e\uddeaexperimental", "output_node": false}, "ADE_ApplyAnimateDiffModelWithCameraCtrl": {"input": {"required": {"motion_model": ["MOTION_MODEL_ADE"], "cameractrl_poses": ["CAMERACTRL_POSES"], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"motion_lora": ["MOTION_LORA"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "cameractrl_multival": ["MULTIVAL"], "ad_keyframes": ["AD_KEYFRAMES"], "prev_m_models": ["M_MODELS"], "per_block": ["PER_BLOCK"]}}, "input_order": {"required": ["motion_model", "cameractrl_poses", "start_percent", "end_percent"], "optional": ["motion_lora", "scale_multival", "effect_multival", "cameractrl_multival", "ad_keyframes", "prev_m_models", "per_block"]}, "output": ["M_MODELS"], "output_is_list": [false], "output_name": ["M_MODELS"], "name": "ADE_ApplyAnimateDiffModelWithCameraCtrl", "display_name": "Apply AnimateDiff+CameraCtrl Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl", "output_node": false}, "ADE_LoadAnimateDiffModelWithCameraCtrl": {"input": {"required": {"model_name": [[]], "camera_ctrl": [[]]}, "optional": {"ad_settings": ["AD_SETTINGS"]}}, "input_order": {"required": ["model_name", "camera_ctrl"], "optional": ["ad_settings"]}, "output": ["MOTION_MODEL_ADE"], "output_is_list": [false], "output_name": ["MOTION_MODEL"], "name": "ADE_LoadAnimateDiffModelWithCameraCtrl", "display_name": "Load AnimateDiff+CameraCtrl Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl", "output_node": false}, "ADE_CameraCtrlAnimateDiffKeyframe": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"prev_ad_keyframes": ["AD_KEYFRAMES"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "cameractrl_multival": ["MULTIVAL"], "inherit_missing": ["BOOLEAN", {"default": true}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent"], "optional": ["prev_ad_keyframes", "scale_multival", "effect_multival", "cameractrl_multival", "inherit_missing", "guarantee_steps"], "hidden": ["autosize"]}, "output": ["AD_KEYFRAMES"], "output_is_list": [false], "output_name": ["AD_KEYFRAMES"], "name": "ADE_CameraCtrlAnimateDiffKeyframe", "display_name": "AnimateDiff+CameraCtrl Keyframe \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl", "output_node": false}, "ADE_LoadCameraPoses": {"input": {"required": {"pose_filename": [[]]}}, "input_order": {"required": ["pose_filename"]}, "output": ["CAMERACTRL_POSES"], "output_is_list": [false], "output_name": ["CAMERACTRL_POSES"], "name": "ADE_LoadCameraPoses", "display_name": "Load CameraCtrl Poses (File) \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl/poses", "output_node": false}, "ADE_LoadCameraPosesFromPath": {"input": {"optional": {"file_path": ["STRING", {"default": "X://path/to/pose_file.txt"}]}}, "input_order": {"optional": ["file_path"]}, "output": ["CAMERACTRL_POSES"], "output_is_list": [false], "output_name": ["CAMERACTRL_POSES"], "name": "ADE_LoadCameraPosesFromPath", "display_name": "Load CameraCtrl Poses (Path) \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl/poses", "output_node": false}, "ADE_CameraPoseBasic": {"input": {"required": {"motion_type": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "speed": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01}], "frame_length": ["INT", {"default": 16}]}, "optional": {"prev_poses": ["CAMERACTRL_POSES"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["motion_type", "speed", "frame_length"], "optional": ["prev_poses"], "hidden": ["autosize"]}, "output": ["CAMERACTRL_POSES"], "output_is_list": [false], "output_name": ["CAMERACTRL_POSES"], "name": "ADE_CameraPoseBasic", "display_name": "Create CameraCtrl Poses \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl/poses", "output_node": false}, "ADE_CameraPoseCombo": {"input": {"required": {"motion_type1": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "motion_type2": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "motion_type3": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "motion_type4": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "motion_type5": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "motion_type6": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "speed": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01}], "frame_length": ["INT", {"default": 16}]}, "optional": {"prev_poses": ["CAMERACTRL_POSES"]}}, "input_order": {"required": ["motion_type1", "motion_type2", "motion_type3", "motion_type4", "motion_type5", "motion_type6", "speed", "frame_length"], "optional": ["prev_poses"]}, "output": ["CAMERACTRL_POSES"], "output_is_list": [false], "output_name": ["CAMERACTRL_POSES"], "name": "ADE_CameraPoseCombo", "display_name": "Create CameraCtrl Poses (Combo) \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl/poses", "output_node": false}, "ADE_CameraPoseAdvanced": {"input": {"required": {"motion_type1": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "strength1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "motion_type2": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "strength2": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "motion_type3": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "strength3": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "motion_type4": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "strength4": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "motion_type5": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "strength5": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "motion_type6": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "strength6": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "speed": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01}], "frame_length": ["INT", {"default": 16}]}, "optional": {"prev_poses": ["CAMERACTRL_POSES"]}}, "input_order": {"required": ["motion_type1", "strength1", "motion_type2", "strength2", "motion_type3", "strength3", "motion_type4", "strength4", "motion_type5", "strength5", "motion_type6", "strength6", "speed", "frame_length"], "optional": ["prev_poses"]}, "output": ["CAMERACTRL_POSES"], "output_is_list": [false], "output_name": ["CAMERACTRL_POSES"], "name": "ADE_CameraPoseAdvanced", "display_name": "Create CameraCtrl Poses (Adv.) \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl/poses", "output_node": false}, "ADE_CameraManualPoseAppend": {"input": {"required": {"poses_first": ["CAMERACTRL_POSES"], "poses_last": ["CAMERACTRL_POSES"]}}, "input_order": {"required": ["poses_first", "poses_last"]}, "output": ["CAMERACTRL_POSES"], "output_is_list": [false], "output_name": ["CAMERACTRL_POSES"], "name": "ADE_CameraManualPoseAppend", "display_name": "Manual Append CameraCtrl Poses \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl/poses", "output_node": false}, "ADE_ReplaceCameraParameters": {"input": {"required": {"poses": ["CAMERACTRL_POSES"], "fx": ["FLOAT", {"default": 0.474812461, "min": 0, "max": 1, "step": 1e-09}], "fy": ["FLOAT", {"default": 0.844111024, "min": 0, "max": 1, "step": 1e-09}], "cx": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 0.01}], "cy": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 0.01}]}}, "input_order": {"required": ["poses", "fx", "fy", "cx", "cy"]}, "output": ["CAMERACTRL_POSES"], "output_is_list": [false], "output_name": ["CAMERACTRL_POSES"], "name": "ADE_ReplaceCameraParameters", "display_name": "Replace Camera Parameters \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl/poses", "output_node": false}, "ADE_ReplaceOriginalPoseAspectRatio": {"input": {"required": {"poses": ["CAMERACTRL_POSES"], "orig_pose_width": ["INT", {"default": 1280, "min": 1, "max": 9007199254740991}], "orig_pose_height": ["INT", {"default": 720, "min": 1, "max": 9007199254740991}]}}, "input_order": {"required": ["poses", "orig_pose_width", "orig_pose_height"]}, "output": ["CAMERACTRL_POSES"], "output_is_list": [false], "output_name": ["CAMERACTRL_POSES"], "name": "ADE_ReplaceOriginalPoseAspectRatio", "display_name": "Replace Orig. Pose Aspect Ratio \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl/poses", "output_node": false}, "ADE_ApplyAnimateDiffModelWithPIA": {"input": {"required": {"motion_model": ["MOTION_MODEL_ADE"], "image": ["IMAGE"], "vae": ["VAE"], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"pia_input": ["PIA_INPUT"], "motion_lora": ["MOTION_LORA"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "ad_keyframes": ["AD_KEYFRAMES"], "prev_m_models": ["M_MODELS"], "per_block": ["PER_BLOCK"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["motion_model", "image", "vae", "start_percent", "end_percent"], "optional": ["pia_input", "motion_lora", "scale_multival", "effect_multival", "ad_keyframes", "prev_m_models", "per_block"], "hidden": ["autosize"]}, "output": ["M_MODELS"], "output_is_list": [false], "output_name": ["M_MODELS"], "name": "ADE_ApplyAnimateDiffModelWithPIA", "display_name": "Apply AnimateDiff-PIA Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/PIA", "output_node": false}, "ADE_InputPIA_Multival": {"input": {"required": {"multival": ["MULTIVAL"]}}, "input_order": {"required": ["multival"]}, "output": ["PIA_INPUT"], "output_is_list": [false], "output_name": ["PIA_INPUT"], "name": "ADE_InputPIA_Multival", "display_name": "PIA Input [Multival] \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/PIA", "output_node": false}, "ADE_InputPIA_PaperPresets": {"input": {"required": {"preset": [["Animation (Small Motion)", "Animation (Medium Motion)", "Animation (Large Motion)", "Loop (Small Motion)", "Loop (Medium Motion)", "Loop (Large Motion)", "Style Transfer (Small Motion)", "Style Transfer (Medium Motion)", "Style Transfer (Large Motion)"]], "batch_index": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991, "step": 1}]}, "optional": {"mult_multival": ["MULTIVAL"], "print_values": ["BOOLEAN", {"default": false}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["preset", "batch_index"], "optional": ["mult_multival", "print_values"], "hidden": ["autosize"]}, "output": ["PIA_INPUT"], "output_is_list": [false], "output_name": ["PIA_INPUT"], "name": "ADE_InputPIA_PaperPresets", "display_name": "PIA Input [Paper Presets] \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/PIA", "output_node": false}, "ADE_PIA_AnimateDiffKeyframe": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"prev_ad_keyframes": ["AD_KEYFRAMES"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "pia_input": ["PIA_INPUT"], "inherit_missing": ["BOOLEAN", {"default": true}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent"], "optional": ["prev_ad_keyframes", "scale_multival", "effect_multival", "pia_input", "inherit_missing", "guarantee_steps"], "hidden": ["autosize"]}, "output": ["AD_KEYFRAMES"], "output_is_list": [false], "output_name": ["AD_KEYFRAMES"], "name": "ADE_PIA_AnimateDiffKeyframe", "display_name": "AnimateDiff-PIA Keyframe \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/PIA", "output_node": false}, "ADE_InjectPIAIntoAnimateDiffModel": {"input": {"required": {"model_name": [[]], "motion_model": ["MOTION_MODEL_ADE"]}, "optional": {"ad_settings": ["AD_SETTINGS"], "deprecation_warning": ["ADEWARN", {"text": "Experimental. Don't expect to work.", "warn_type": "experimental", "color": "#CFC"}]}}, "input_order": {"required": ["model_name", "motion_model"], "optional": ["ad_settings", "deprecation_warning"]}, "output": ["MOTION_MODEL_ADE"], "output_is_list": [false], "output_name": ["MOTION_MODEL"], "name": "ADE_InjectPIAIntoAnimateDiffModel", "display_name": "\ud83e\uddeaInject PIA into AnimateDiff Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/PIA/\ud83e\uddeaexperimental", "output_node": false}, "ADE_AnimateDiffLoaderWithContext": {"input": {"required": {"model": ["MODEL"], "model_name": [[]], "beta_schedule": [["autoselect", "use existing", "sqrt_linear (AnimateDiff)", "linear (AnimateDiff-SDXL)", "linear (HotshotXL/default)", "avg(sqrt_linear,linear)", "lcm avg(sqrt_linear,linear)", "lcm", "lcm[100_ots]", "lcm >> sqrt_linear", "sqrt", "cosine", "squaredcos_cap_v2"], {"default": "autoselect"}]}, "optional": {"context_options": ["CONTEXT_OPTIONS"], "motion_lora": ["MOTION_LORA"], "ad_settings": ["AD_SETTINGS"], "sample_settings": ["SAMPLE_SETTINGS"], "motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "apply_v2_models_properly": ["BOOLEAN", {"default": true}], "ad_keyframes": ["AD_KEYFRAMES"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated; use AnimateDiff Loader instead."}]}}, "input_order": {"required": ["model", "model_name", "beta_schedule"], "optional": ["context_options", "motion_lora", "ad_settings", "sample_settings", "motion_scale", "apply_v2_models_properly", "ad_keyframes", "deprecation_warning"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ADE_AnimateDiffLoaderWithContext", "display_name": "AnimateDiff Loader [Legacy] \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2460", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2460 Gen1 nodes \u2460", "output_node": false, "deprecated": true}, "AnimateDiffLoaderV1": {"input": {"required": {"model": ["MODEL"], "latents": ["LATENT"], "model_name": [[]], "unlimited_area_hack": ["BOOLEAN", {"default": false}], "beta_schedule": [["sqrt_linear (AnimateDiff)", "use existing", "autoselect", "linear (AnimateDiff-SDXL)", "linear (HotshotXL/default)", "avg(sqrt_linear,linear)", "lcm avg(sqrt_linear,linear)", "lcm", "lcm[100_ots]", "lcm >> sqrt_linear", "sqrt", "cosine", "squaredcos_cap_v2"]]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated"}]}}, "input_order": {"required": ["model", "latents", "model_name", "unlimited_area_hack", "beta_schedule"], "optional": ["deprecation_warning"]}, "output": ["MODEL", "LATENT"], "output_is_list": [false, false], "output_name": ["MODEL", "LATENT"], "name": "AnimateDiffLoaderV1", "display_name": "\ud83d\udeabAnimateDiff Loader [DEPRECATED] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "", "output_node": false, "deprecated": true}, "ADE_AnimateDiffLoaderV1Advanced": {"input": {"required": {"model": ["MODEL"], "latents": ["LATENT"], "model_name": [[]], "unlimited_area_hack": ["BOOLEAN", {"default": false}], "context_length": ["INT", {"default": 16, "min": 0, "max": 1000}], "context_stride": ["INT", {"default": 1, "min": 1, "max": 1000}], "context_overlap": ["INT", {"default": 4, "min": 0, "max": 1000}], "context_schedule": [["uniform"]], "closed_loop": ["BOOLEAN", {"default": false}], "beta_schedule": [["sqrt_linear (AnimateDiff)", "use existing", "autoselect", "linear (AnimateDiff-SDXL)", "linear (HotshotXL/default)", "avg(sqrt_linear,linear)", "lcm avg(sqrt_linear,linear)", "lcm", "lcm[100_ots]", "lcm >> sqrt_linear", "sqrt", "cosine", "squaredcos_cap_v2"]]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated"}]}}, "input_order": {"required": ["model", "latents", "model_name", "unlimited_area_hack", "context_length", "context_stride", "context_overlap", "context_schedule", "closed_loop", "beta_schedule"], "optional": ["deprecation_warning"]}, "output": ["MODEL", "LATENT"], "output_is_list": [false, false], "output_name": ["MODEL", "LATENT"], "name": "ADE_AnimateDiffLoaderV1Advanced", "display_name": "\ud83d\udeabAnimateDiff Loader (Advanced) [DEPRECATED] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "", "output_node": false, "deprecated": true}, "ADE_AnimateDiffCombine": {"input": {"required": {"images": ["IMAGE"], "frame_rate": ["INT", {"default": 8, "min": 1, "max": 24, "step": 1}], "loop_count": ["INT", {"default": 0, "min": 0, "max": 100, "step": 1}], "filename_prefix": ["STRING", {"default": "AnimateDiff"}], "format": [["image/gif", "image/webp", "video/av1-webm", "video/h264-mp4", "video/h265-mp4", "video/webm"]], "pingpong": ["BOOLEAN", {"default": false}], "save_image": ["BOOLEAN", {"default": true}]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated. Use VHS Video Combine"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "frame_rate", "loop_count", "filename_prefix", "format", "pingpong", "save_image"], "optional": ["deprecation_warning"], "hidden": ["prompt", "extra_pnginfo"]}, "output": ["GIF"], "output_is_list": [false], "output_name": ["GIF"], "name": "ADE_AnimateDiffCombine", "display_name": "\ud83d\udeabAnimateDiff Combine [DEPRECATED, Use Video Combine (VHS) Instead!] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "", "output_node": true, "deprecated": true}, "ADE_AnimateDiffModelSettings_Release": {"input": {"required": {"min_motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "max_motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}]}, "optional": {"mask_motion_scale": ["MASK"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated"}]}}, "input_order": {"required": ["min_motion_scale", "max_motion_scale"], "optional": ["mask_motion_scale", "deprecation_warning"]}, "output": ["AD_SETTINGS"], "output_is_list": [false], "output_name": ["AD_SETTINGS"], "name": "ADE_AnimateDiffModelSettings_Release", "display_name": "\ud83d\udeab[DEPR] Motion Model Settings \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2460", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "", "output_node": false, "deprecated": true}, "ADE_AnimateDiffModelSettingsSimple": {"input": {"required": {"motion_pe_stretch": ["INT", {"default": 0, "min": 0, "step": 1}]}, "optional": {"mask_motion_scale": ["MASK"], "min_motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "max_motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "deprecation_warning": ["ADEWARN", {"text": "Deprecated"}]}}, "input_order": {"required": ["motion_pe_stretch"], "optional": ["mask_motion_scale", "min_motion_scale", "max_motion_scale", "deprecation_warning"]}, "output": ["AD_SETTINGS"], "output_is_list": [false], "output_name": ["AD_SETTINGS"], "name": "ADE_AnimateDiffModelSettingsSimple", "display_name": "\ud83d\udeab[DEPR] Motion Model Settings (Simple) \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2460", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "", "output_node": false, "deprecated": true}, "ADE_AnimateDiffModelSettings": {"input": {"required": {"pe_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "attn_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "other_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "motion_pe_stretch": ["INT", {"default": 0, "min": 0, "step": 1}], "cap_initial_pe_length": ["INT", {"default": 0, "min": 0, "step": 1}], "interpolate_pe_to_length": ["INT", {"default": 0, "min": 0, "step": 1}], "initial_pe_idx_offset": ["INT", {"default": 0, "min": 0, "step": 1}], "final_pe_idx_offset": ["INT", {"default": 0, "min": 0, "step": 1}]}, "optional": {"mask_motion_scale": ["MASK"], "min_motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "max_motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "deprecation_warning": ["ADEWARN", {"text": "Deprecated"}]}}, "input_order": {"required": ["pe_strength", "attn_strength", "other_strength", "motion_pe_stretch", "cap_initial_pe_length", "interpolate_pe_to_length", "initial_pe_idx_offset", "final_pe_idx_offset"], "optional": ["mask_motion_scale", "min_motion_scale", "max_motion_scale", "deprecation_warning"]}, "output": ["AD_SETTINGS"], "output_is_list": [false], "output_name": ["AD_SETTINGS"], "name": "ADE_AnimateDiffModelSettings", "display_name": "\ud83d\udeab[DEPR] Motion Model Settings (Advanced) \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2460", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "", "output_node": false, "deprecated": true}, "ADE_AnimateDiffModelSettingsAdvancedAttnStrengths": {"input": {"required": {"pe_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "attn_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "attn_q_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "attn_k_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "attn_v_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "attn_out_weight_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "attn_out_bias_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "other_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "motion_pe_stretch": ["INT", {"default": 0, "min": 0, "step": 1}], "cap_initial_pe_length": ["INT", {"default": 0, "min": 0, "step": 1}], "interpolate_pe_to_length": ["INT", {"default": 0, "min": 0, "step": 1}], "initial_pe_idx_offset": ["INT", {"default": 0, "min": 0, "step": 1}], "final_pe_idx_offset": ["INT", {"default": 0, "min": 0, "step": 1}]}, "optional": {"mask_motion_scale": ["MASK"], "min_motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "max_motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "deprecation_warning": ["ADEWARN", {"text": "Deprecated"}]}}, "input_order": {"required": ["pe_strength", "attn_strength", "attn_q_strength", "attn_k_strength", "attn_v_strength", "attn_out_weight_strength", "attn_out_bias_strength", "other_strength", "motion_pe_stretch", "cap_initial_pe_length", "interpolate_pe_to_length", "initial_pe_idx_offset", "final_pe_idx_offset"], "optional": ["mask_motion_scale", "min_motion_scale", "max_motion_scale", "deprecation_warning"]}, "output": ["AD_SETTINGS"], "output_is_list": [false], "output_name": ["AD_SETTINGS"], "name": "ADE_AnimateDiffModelSettingsAdvancedAttnStrengths", "display_name": "\ud83d\udeab[DEPR] Motion Model Settings (Adv. Attn) \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2460", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "", "output_node": false, "deprecated": true}, "GetBooleanFromImage": {"input": {"required": {"image": ["IMAGE"], "query": ["STRING", {"default": ""}], "boolean": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["image", "query", "boolean"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "GetBooleanFromImage", "display_name": "Get Boolean from Image", "description": "", "python_module": "custom_nodes.comfyui-get-meta", "category": "image", "output_node": false}, "GetIntFromImage": {"input": {"required": {"image": ["IMAGE"], "query": ["STRING", {"default": ""}], "int": ["INT", {"default": 0}]}}, "input_order": {"required": ["image", "query", "int"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "GetIntFromImage", "display_name": "Get Int from Image", "description": "", "python_module": "custom_nodes.comfyui-get-meta", "category": "image", "output_node": false}, "GetFloatFromImage": {"input": {"required": {"image": ["IMAGE"], "query": ["STRING", {"default": ""}], "float": ["FLOAT", {"default": 0.0}]}}, "input_order": {"required": ["image", "query", "float"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "GetFloatFromImage", "display_name": "Get Float from Image", "description": "", "python_module": "custom_nodes.comfyui-get-meta", "category": "image", "output_node": false}, "GetStringFromImage": {"input": {"required": {"image": ["IMAGE"], "query": ["STRING", {"default": ""}], "string": ["STRING", {"default": "", "multiline": true}]}}, "input_order": {"required": ["image", "query", "string"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "GetStringFromImage", "display_name": "Get String from Image", "description": "", "python_module": "custom_nodes.comfyui-get-meta", "category": "image", "output_node": false}, "GetComboFromImage": {"input": {"required": {"image": ["IMAGE"], "query": ["STRING", {"default": ""}], "combo": ["STRING", {"default": ""}]}}, "input_order": {"required": ["image", "query", "combo"]}, "output": ["*"], "output_is_list": [false], "output_name": ["COMBO"], "name": "GetComboFromImage", "display_name": "Get Combo from Image", "description": "", "python_module": "custom_nodes.comfyui-get-meta", "category": "image", "output_node": false}, "GetNodesFromImage": {"input": {"required": {"image": ["IMAGE"], "nodes": ["STRING", {"default": "", "multiline": true}]}}, "input_order": {"required": ["image", "nodes"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "GetNodesFromImage", "display_name": "Get Nodes from Image", "description": "", "python_module": "custom_nodes.comfyui-get-meta", "category": "image", "output_node": false}, "GetWorkflowFromImage": {"input": {"required": {"image": ["IMAGE"], "workflow": ["STRING", {"default": "", "multiline": true}]}}, "input_order": {"required": ["image", "workflow"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "GetWorkflowFromImage", "display_name": "Get Workflow from Image", "description": "", "python_module": "custom_nodes.comfyui-get-meta", "category": "image", "output_node": false}, "GetPromptFromImage": {"input": {"required": {"image": ["IMAGE"], "prompt": ["STRING", {"default": "", "multiline": true}]}}, "input_order": {"required": ["image", "prompt"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "GetPromptFromImage", "display_name": "Get Prompt from Image", "description": "", "python_module": "custom_nodes.comfyui-get-meta", "category": "image", "output_node": false}, "TTSWebUI_OpenAI_TTS": {"input": {"required": {"text": ["STRING", {"multiline": true, "default": "Hello from ComfyUI"}], "api_base": ["STRING", {"default": "http://127.0.0.1:7778"}], "model": ["STRING", {"default": "kokoro"}], "voice": ["STRING", {"default": "random"}], "speed": ["FLOAT", {"default": 1.0, "min": 0.25, "max": 4.0, "step": 0.05}], "params_json": ["STRING", {"multiline": true, "default": "{}", "placeholder": "{\"temperature\":0.7,\"rvc_params\":{...}}"}]}, "optional": {"api_key": ["STRING", {"default": "", "password": true}], "timeout_sec": ["INT", {"default": 120, "min": 1, "max": 600}], "channels_first": ["BOOLEAN", {"default": true}], "also_save_wav": ["BOOLEAN", {"default": false}], "save_prefix": ["STRING", {"default": "tts"}], "return_metadata": ["BOOLEAN", {"default": true}], "advanced_request_json": ["STRING", {"multiline": true, "default": "", "placeholder": "{\"model\":\"kokoro\",\"input\":\"...\",\"voice\":\"random\",\"speed\":1.0,\"response_format\":\"wav\",\"params\":{...}}"}]}}, "input_order": {"required": ["text", "api_base", "model", "voice", "speed", "params_json"], "optional": ["api_key", "timeout_sec", "channels_first", "also_save_wav", "save_prefix", "return_metadata", "advanced_request_json"]}, "output": ["AUDIO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["audio", "wav_path", "metadata_json"], "name": "TTSWebUI_OpenAI_TTS", "display_name": "TTS WebUI via API", "description": "", "python_module": "custom_nodes.ComfyUI-TTS-Webui", "category": "Audio/TTS", "output_node": false}, "TTS_KokoroNode": {"input": {"required": {"text": ["STRING", {"multiline": true, "default": "Hello"}], "api_base": ["STRING", {"default": "http://127.0.0.1:7778"}], "voice": ["STRING", {"default": "af_heart"}], "speed": ["FLOAT", {"default": 1.0, "min": 0.25, "max": 4.0, "step": 0.05}], "model_name": ["STRING", {"default": "hexgrad/Kokoro-82M"}]}, "optional": {"api_key": ["STRING", {"default": "", "password": true}], "use_gpu": ["BOOLEAN", {"default": true}], "timeout_sec": ["INT", {"default": 120, "min": 1, "max": 600}], "channels_first": ["BOOLEAN", {"default": true}], "also_save_wav": ["BOOLEAN", {"default": false}], "save_prefix": ["STRING", {"default": "tts"}], "return_metadata": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["text", "api_base", "voice", "speed", "model_name"], "optional": ["api_key", "use_gpu", "timeout_sec", "channels_first", "also_save_wav", "save_prefix", "return_metadata"]}, "output": ["AUDIO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["audio", "wav_path", "metadata_json"], "name": "TTS_KokoroNode", "display_name": "TTS WebUI Kokoro", "description": "", "python_module": "custom_nodes.ComfyUI-TTS-Webui", "category": "Audio/TTS", "output_node": false}, "TTS_ChatterboxNode": {"input": {"required": {"text": ["STRING", {"multiline": true, "default": "Hello"}], "api_base": ["STRING", {"default": "http://127.0.0.1:7778"}]}, "optional": {"api_key": ["STRING", {"default": "", "password": true}], "exaggeration": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 2.0, "step": 0.01}], "cfg_weight": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 2.0, "step": 0.01}], "temperature": ["FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.01}], "audio_prompt_path": ["STRING", {"default": ""}], "model_name": ["STRING", {"default": "just_a_placeholder"}], "language_id": ["STRING", {"default": "en"}], "device": ["STRING", {"default": "cuda"}], "dtype": ["STRING", {"default": "float32"}], "cpu_offload": ["BOOLEAN", {"default": false}], "chunked": ["BOOLEAN", {"default": false}], "cache_voice": ["BOOLEAN", {"default": false}], "desired_length": ["INT", {"default": 200, "min": 1, "max": 4000}], "max_length": ["INT", {"default": 300, "min": 1, "max": 4000}], "halve_first_chunk": ["BOOLEAN", {"default": false}], "seed": ["INT", {"default": -1, "min": -1, "max": 2147483647}], "streaming": ["BOOLEAN", {"default": false}], "max_new_tokens": ["INT", {"default": 1000, "min": 1, "max": 4096}], "max_cache_len": ["INT", {"default": 1500, "min": 1, "max": 8192}], "initial_forward_pass_backend": ["STRING", {"default": "eager"}], "generate_token_backend": ["STRING", {"default": "cudagraphs-manual"}], "timeout_sec": ["INT", {"default": 120, "min": 1, "max": 600}], "channels_first": ["BOOLEAN", {"default": true}], "also_save_wav": ["BOOLEAN", {"default": false}], "save_prefix": ["STRING", {"default": "tts"}], "return_metadata": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["text", "api_base"], "optional": ["api_key", "exaggeration", "cfg_weight", "temperature", "audio_prompt_path", "model_name", "language_id", "device", "dtype", "cpu_offload", "chunked", "cache_voice", "desired_length", "max_length", "halve_first_chunk", "seed", "streaming", "max_new_tokens", "max_cache_len", "initial_forward_pass_backend", "generate_token_backend", "timeout_sec", "channels_first", "also_save_wav", "save_prefix", "return_metadata"]}, "output": ["AUDIO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["audio", "wav_path", "metadata_json"], "name": "TTS_ChatterboxNode", "display_name": "TTS WebUI Chatterbox", "description": "", "python_module": "custom_nodes.ComfyUI-TTS-Webui", "category": "Audio/TTS", "output_node": false}, "TTS_StyleTTS2Node": {"input": {"required": {"text": ["STRING", {"multiline": true, "default": "Hello"}], "api_base": ["STRING", {"default": "http://127.0.0.1:7778"}]}, "optional": {"api_key": ["STRING", {"default": "", "password": true}], "alpha": ["FLOAT", {"default": 0.3, "min": 0.0, "max": 1.0, "step": 0.01}], "beta": ["FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01}], "diffusion_steps": ["INT", {"default": 5, "min": 1, "max": 200}], "embedding_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 5.0, "step": 0.01}], "timeout_sec": ["INT", {"default": 120, "min": 1, "max": 600}], "channels_first": ["BOOLEAN", {"default": true}], "also_save_wav": ["BOOLEAN", {"default": false}], "save_prefix": ["STRING", {"default": "tts"}], "return_metadata": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["text", "api_base"], "optional": ["api_key", "alpha", "beta", "diffusion_steps", "embedding_scale", "timeout_sec", "channels_first", "also_save_wav", "save_prefix", "return_metadata"]}, "output": ["AUDIO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["audio", "wav_path", "metadata_json"], "name": "TTS_StyleTTS2Node", "display_name": "TTS WebUI StyleTTS2", "description": "", "python_module": "custom_nodes.ComfyUI-TTS-Webui", "category": "Audio/TTS", "output_node": false}, "TTS_KittenTTSNode": {"input": {"required": {"text": ["STRING", {"multiline": true, "default": "Hello"}], "api_base": ["STRING", {"default": "http://127.0.0.1:7778"}], "voice": ["STRING", {"default": "random"}]}, "optional": {"api_key": ["STRING", {"default": "", "password": true}], "model_name": ["STRING", {"default": "KittenML/kitten-tts-mini-0.1"}], "speed": ["FLOAT", {"default": 1.0, "min": 0.25, "max": 4.0, "step": 0.05}], "timeout_sec": ["INT", {"default": 120, "min": 1, "max": 600}], "channels_first": ["BOOLEAN", {"default": true}], "also_save_wav": ["BOOLEAN", {"default": false}], "save_prefix": ["STRING", {"default": "tts"}], "return_metadata": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["text", "api_base", "voice"], "optional": ["api_key", "model_name", "speed", "timeout_sec", "channels_first", "also_save_wav", "save_prefix", "return_metadata"]}, "output": ["AUDIO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["audio", "wav_path", "metadata_json"], "name": "TTS_KittenTTSNode", "display_name": "TTS WebUI Kitten TTS", "description": "", "python_module": "custom_nodes.ComfyUI-TTS-Webui", "category": "Audio/TTS", "output_node": false}, "TTS_F5TTSNode": {"input": {"required": {"text": ["STRING", {"multiline": true, "default": "Hello"}], "api_base": ["STRING", {"default": "http://127.0.0.1:7778"}]}, "optional": {"api_key": ["STRING", {"default": "", "password": true}], "ref_audio_orig": ["STRING", {"default": ""}], "ref_text": ["STRING", {"default": ""}], "model": ["STRING", {"default": "default"}], "remove_silence": ["BOOLEAN", {"default": false}], "cross_fade_duration": ["FLOAT", {"default": 0.15, "min": 0.0, "max": 5.0, "step": 0.01}], "nfe_step": ["INT", {"default": 32, "min": 1, "max": 256}], "speed": ["FLOAT", {"default": 1.0, "min": 0.25, "max": 4.0, "step": 0.05}], "show_info": ["BOOLEAN", {"default": false}], "timeout_sec": ["INT", {"default": 120, "min": 1, "max": 600}], "channels_first": ["BOOLEAN", {"default": true}], "also_save_wav": ["BOOLEAN", {"default": false}], "save_prefix": ["STRING", {"default": "tts"}], "return_metadata": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["text", "api_base"], "optional": ["api_key", "ref_audio_orig", "ref_text", "model", "remove_silence", "cross_fade_duration", "nfe_step", "speed", "show_info", "timeout_sec", "channels_first", "also_save_wav", "save_prefix", "return_metadata"]}, "output": ["AUDIO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["audio", "wav_path", "metadata_json"], "name": "TTS_F5TTSNode", "display_name": "TTS WebUI F5-TTS", "description": "", "python_module": "custom_nodes.ComfyUI-TTS-Webui", "category": "Audio/TTS", "output_node": false}, "TTS_GlobalPresetNode": {"input": {"required": {"text": ["STRING", {"multiline": true, "default": "Hello"}], "api_base": ["STRING", {"default": "http://127.0.0.1:7778"}]}, "optional": {"api_key": ["STRING", {"default": "", "password": true}], "voice": ["STRING", {"default": "random"}], "preset": ["STRING", {"default": ""}], "speed": ["FLOAT", {"default": 1.0, "min": 0.25, "max": 4.0, "step": 0.05}], "timeout_sec": ["INT", {"default": 120, "min": 1, "max": 600}], "channels_first": ["BOOLEAN", {"default": true}], "also_save_wav": ["BOOLEAN", {"default": false}], "save_prefix": ["STRING", {"default": "tts"}], "return_metadata": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["text", "api_base"], "optional": ["api_key", "voice", "preset", "speed", "timeout_sec", "channels_first", "also_save_wav", "save_prefix", "return_metadata"]}, "output": ["AUDIO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["audio", "wav_path", "metadata_json"], "name": "TTS_GlobalPresetNode", "display_name": "TTS WebUI Preset", "description": "", "python_module": "custom_nodes.ComfyUI-TTS-Webui", "category": "Audio/TTS", "output_node": false}, "TTS_MegaTTS3Node": {"input": {"required": {"text": ["STRING", {"multiline": true, "default": "Hello"}], "api_base": ["STRING", {"default": "http://127.0.0.1:7778"}]}, "optional": {"api_key": ["STRING", {"default": "", "password": true}], "reference_audio_path": ["STRING", {"default": ""}], "latent_npy_path": ["STRING", {"default": ""}], "inference_steps": ["INT", {"default": 32, "min": 1, "max": 200}], "intelligibility_weight": ["FLOAT", {"default": 0.8, "min": 0.0, "max": 1.0, "step": 0.05}], "similarity_weight": ["FLOAT", {"default": 0.8, "min": 0.0, "max": 1.0, "step": 0.05}], "timeout_sec": ["INT", {"default": 120, "min": 1, "max": 600}], "channels_first": ["BOOLEAN", {"default": true}], "also_save_wav": ["BOOLEAN", {"default": false}], "save_prefix": ["STRING", {"default": "tts"}], "return_metadata": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["text", "api_base"], "optional": ["api_key", "reference_audio_path", "latent_npy_path", "inference_steps", "intelligibility_weight", "similarity_weight", "timeout_sec", "channels_first", "also_save_wav", "save_prefix", "return_metadata"]}, "output": ["AUDIO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["audio", "wav_path", "metadata_json"], "name": "TTS_MegaTTS3Node", "display_name": "TTS WebUI MegaTTS3", "description": "", "python_module": "custom_nodes.ComfyUI-TTS-Webui", "category": "Audio/TTS", "output_node": false}, "TTS_FireRedTTS2Node": {"input": {"required": {"text": ["STRING", {"multiline": true, "default": "Hello"}], "api_base": ["STRING", {"default": "http://127.0.0.1:7778"}]}, "optional": {"api_key": ["STRING", {"default": "", "password": true}], "temperature": ["FLOAT", {"default": 0.9, "min": 0.0, "max": 2.0, "step": 0.05}], "topk": ["INT", {"default": 30, "min": 1, "max": 100}], "prompt_wav": ["STRING", {"default": ""}], "prompt_text": ["STRING", {"default": ""}], "model_name": ["STRING", {"default": "monologue"}], "device": ["STRING", {"default": "cuda"}], "timeout_sec": ["INT", {"default": 120, "min": 1, "max": 600}], "channels_first": ["BOOLEAN", {"default": true}], "also_save_wav": ["BOOLEAN", {"default": false}], "save_prefix": ["STRING", {"default": "tts"}], "return_metadata": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["text", "api_base"], "optional": ["api_key", "temperature", "topk", "prompt_wav", "prompt_text", "model_name", "device", "timeout_sec", "channels_first", "also_save_wav", "save_prefix", "return_metadata"]}, "output": ["AUDIO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["audio", "wav_path", "metadata_json"], "name": "TTS_FireRedTTS2Node", "display_name": "TTS WebUI FireRedTTS2", "description": "", "python_module": "custom_nodes.ComfyUI-TTS-Webui", "category": "Audio/TTS", "output_node": false}, "TTS_HiggsV2Node": {"input": {"required": {"text": ["STRING", {"multiline": true, "default": "Hello"}], "api_base": ["STRING", {"default": "http://127.0.0.1:7778"}]}, "optional": {"api_key": ["STRING", {"default": "", "password": true}], "temperature": ["FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.05}], "audio_prompt_path": ["STRING", {"default": ""}], "seed": ["INT", {"default": -1, "min": -1, "max": 2147483647}], "scene_description": ["STRING", {"default": "", "multiline": true}], "timeout_sec": ["INT", {"default": 120, "min": 1, "max": 600}], "channels_first": ["BOOLEAN", {"default": true}], "also_save_wav": ["BOOLEAN", {"default": false}], "save_prefix": ["STRING", {"default": "tts"}], "return_metadata": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["text", "api_base"], "optional": ["api_key", "temperature", "audio_prompt_path", "seed", "scene_description", "timeout_sec", "channels_first", "also_save_wav", "save_prefix", "return_metadata"]}, "output": ["AUDIO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["audio", "wav_path", "metadata_json"], "name": "TTS_HiggsV2Node", "display_name": "TTS WebUI Higgs V2", "description": "", "python_module": "custom_nodes.ComfyUI-TTS-Webui", "category": "Audio/TTS", "output_node": false}, "TTS_MMSNode": {"input": {"required": {"text": ["STRING", {"multiline": true, "default": "Hello"}], "api_base": ["STRING", {"default": "http://127.0.0.1:7778"}]}, "optional": {"api_key": ["STRING", {"default": "", "password": true}], "language": ["STRING", {"default": "eng"}], "speaking_rate": ["FLOAT", {"default": 1.0, "min": 0.25, "max": 4.0, "step": 0.05}], "noise_scale": ["FLOAT", {"default": 0.667, "min": 0.0, "max": 2.0, "step": 0.01}], "noise_scale_duration": ["FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.01}], "timeout_sec": ["INT", {"default": 120, "min": 1, "max": 600}], "channels_first": ["BOOLEAN", {"default": true}], "also_save_wav": ["BOOLEAN", {"default": false}], "save_prefix": ["STRING", {"default": "tts"}], "return_metadata": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["text", "api_base"], "optional": ["api_key", "language", "speaking_rate", "noise_scale", "noise_scale_duration", "timeout_sec", "channels_first", "also_save_wav", "save_prefix", "return_metadata"]}, "output": ["AUDIO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["audio", "wav_path", "metadata_json"], "name": "TTS_MMSNode", "display_name": "TTS WebUI MMS", "description": "", "python_module": "custom_nodes.ComfyUI-TTS-Webui", "category": "Audio/TTS", "output_node": false}, "TTS_ParlerTTSNode": {"input": {"required": {"text": ["STRING", {"multiline": true, "default": "Hello"}], "api_base": ["STRING", {"default": "http://127.0.0.1:7778"}]}, "optional": {"api_key": ["STRING", {"default": "", "password": true}], "description": ["STRING", {"default": "A neutral voice.", "multiline": true}], "model_name": ["STRING", {"default": "parler-tts/parler-tts-mini-v1"}], "attn_implementation": ["STRING", {"default": "eager"}], "compile_mode": ["STRING", {"default": ""}], "timeout_sec": ["INT", {"default": 120, "min": 1, "max": 600}], "channels_first": ["BOOLEAN", {"default": true}], "also_save_wav": ["BOOLEAN", {"default": false}], "save_prefix": ["STRING", {"default": "tts"}], "return_metadata": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["text", "api_base"], "optional": ["api_key", "description", "model_name", "attn_implementation", "compile_mode", "timeout_sec", "channels_first", "also_save_wav", "save_prefix", "return_metadata"]}, "output": ["AUDIO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["audio", "wav_path", "metadata_json"], "name": "TTS_ParlerTTSNode", "display_name": "TTS WebUI Parler TTS", "description": "", "python_module": "custom_nodes.ComfyUI-TTS-Webui", "category": "Audio/TTS", "output_node": false}, "TTS_PiperTTSNode": {"input": {"required": {"text": ["STRING", {"multiline": true, "default": "Hello"}], "api_base": ["STRING", {"default": "http://127.0.0.1:7778"}]}, "optional": {"api_key": ["STRING", {"default": "", "password": true}], "voice_name": ["STRING", {"default": ""}], "speed": ["FLOAT", {"default": 1.0, "min": 0.25, "max": 4.0, "step": 0.05}], "noise_scale": ["FLOAT", {"default": 0.667, "min": 0.0, "max": 2.0, "step": 0.01}], "noise_w": ["FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.01}], "sentence_silence": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 2.0, "step": 0.01}], "timeout_sec": ["INT", {"default": 120, "min": 1, "max": 600}], "channels_first": ["BOOLEAN", {"default": true}], "also_save_wav": ["BOOLEAN", {"default": false}], "save_prefix": ["STRING", {"default": "tts"}], "return_metadata": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["text", "api_base"], "optional": ["api_key", "voice_name", "speed", "noise_scale", "noise_w", "sentence_silence", "timeout_sec", "channels_first", "also_save_wav", "save_prefix", "return_metadata"]}, "output": ["AUDIO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["audio", "wav_path", "metadata_json"], "name": "TTS_PiperTTSNode", "display_name": "TTS WebUI Piper TTS", "description": "", "python_module": "custom_nodes.ComfyUI-TTS-Webui", "category": "Audio/TTS", "output_node": false}, "TTS_VallEXNode": {"input": {"required": {"text": ["STRING", {"multiline": true, "default": "Hello"}], "api_base": ["STRING", {"default": "http://127.0.0.1:7778"}]}, "optional": {"api_key": ["STRING", {"default": "", "password": true}], "prompt": ["STRING", {"default": "", "multiline": true}], "language": ["STRING", {"default": "English"}], "accent": ["STRING", {"default": "no-accent"}], "mode": ["STRING", {"default": "short"}], "timeout_sec": ["INT", {"default": 120, "min": 1, "max": 600}], "channels_first": ["BOOLEAN", {"default": true}], "also_save_wav": ["BOOLEAN", {"default": false}], "save_prefix": ["STRING", {"default": "tts"}], "return_metadata": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["text", "api_base"], "optional": ["api_key", "prompt", "language", "accent", "mode", "timeout_sec", "channels_first", "also_save_wav", "save_prefix", "return_metadata"]}, "output": ["AUDIO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["audio", "wav_path", "metadata_json"], "name": "TTS_VallEXNode", "display_name": "TTS WebUI Vall-E-X", "description": "", "python_module": "custom_nodes.ComfyUI-TTS-Webui", "category": "Audio/TTS", "output_node": false}, "SleepNodeAny": {"input": {"required": {"interval": ["FLOAT", {"default": 0.0}]}, "optional": {"inputs": ["*", {"default": 0.0}]}}, "input_order": {"required": ["interval"], "optional": ["inputs"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "SleepNodeAny", "display_name": "SleepNode", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Misc", "output_node": false}, "SleepNodeImage": {"input": {"required": {"interval": ["FLOAT", {"default": 0.0}], "image": ["*"]}}, "input_order": {"required": ["interval", "image"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "SleepNodeImage", "display_name": "Sleep (Image tunnel)", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Misc", "output_node": false}, "ErrorNode": {"input": {"required": {"error_msg": ["STRING", {"default": "Error"}]}}, "input_order": {"required": ["error_msg"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "ErrorNode", "display_name": "ErrorNode", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Misc", "output_node": false}, "CurrentTimestamp": {"input": {"required": {"format_string": ["STRING", {"default": "", "display": "text", "comment": "Leave blank for raw timestamp, or use format directives like '%Y-%m-%d %H:%M:%S'"}]}}, "input_order": {"required": ["format_string"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "CurrentTimestamp", "display_name": "Current Timestamp", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "DebugComboInputNode": {"input": {"required": {"input1": [["0", "1", "2"], {"default": "0"}]}}, "input_order": {"required": ["input1"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "DebugComboInputNode", "display_name": "Debug Combo Input", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Misc", "output_node": false}, "TextPreviewNode": {"input": {"required": {"text": ["*", {"default": "text", "type": "output"}]}}, "input_order": {"required": ["text"]}, "output": [], "output_is_list": [], "output_name": [], "name": "TextPreviewNode", "display_name": "Text Preview", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Misc", "output_node": true}, "ParseExifNode": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "ParseExifNode", "display_name": "Parse Exif", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Misc", "output_node": false}, "SaveImageCustomNode": {"input": {"required": {"images": ["IMAGE"], "filename_prefix": ["STRING", {"default": "ComfyUI"}], "subfolder_dir": ["STRING", {"default": ""}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "filename_prefix", "subfolder_dir"], "hidden": ["prompt", "extra_pnginfo"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "SaveImageCustomNode", "display_name": "Save Image Custom Node", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": true}, "SaveTextCustomNode": {"input": {"required": {"text": ["*"], "filename_prefix": ["STRING", {"default": "ComfyUI"}], "subfolder_dir": ["STRING", {"default": ""}], "filename": ["STRING", {"default": ""}]}}, "input_order": {"required": ["text", "filename_prefix", "subfolder_dir", "filename"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "SaveTextCustomNode", "display_name": "Save Text Custom Node", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "text", "output_node": true}, "DumpTextJsonlNode": {"input": {"required": {"text": ["*"], "filename_prefix": ["STRING", {"default": "ComfyUI"}], "subfolder_dir": ["STRING", {"default": ""}], "filename": ["STRING", {"default": "dump.jsonl"}], "keyname": ["STRING", {"default": "text"}]}}, "input_order": {"required": ["text", "filename_prefix", "subfolder_dir", "filename", "keyname"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "DumpTextJsonlNode", "display_name": "Dump Text JSONL Node", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "text", "output_node": true}, "ConcatGridNode": {"input": {"required": {"images": ["IMAGE"], "direction": [["horizontal", "vertical", "square-like"], {"default": "horizontal"}], "match_method": [["resize", "pad"], {"default": "resize"}]}}, "input_order": {"required": ["images", "direction", "match_method"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ConcatGridNode", "display_name": "Concat Grid (Batch to single grid)", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "ConcatTwoImagesNode": {"input": {"required": {"imageA": ["IMAGE"], "imageB": ["IMAGE"], "direction": [["horizontal", "vertical"], {"default": "horizontal"}], "match_method": [["resize", "pad"], {"default": "resize"}]}}, "input_order": {"required": ["imageA", "imageB", "direction", "match_method"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ConcatTwoImagesNode", "display_name": "Concat 2 Images to Grid", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "SaveCustomJPGNode": {"input": {"required": {"images": ["IMAGE"], "filename_prefix": ["STRING", {"default": "ComfyUI"}], "subfolder_dir": ["STRING", {"default": ""}]}, "optional": {"quality": ["INT", {"default": 95}], "optimize": ["BOOLEAN", {"default": true}], "metadata_string": ["STRING", {"default": ""}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "filename_prefix", "subfolder_dir"], "optional": ["quality", "optimize", "metadata_string"], "hidden": ["prompt", "extra_pnginfo"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "SaveCustomJPGNode", "display_name": "Save Custom JPG Node", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": true}, "SaveImageWebpCustomNode": {"input": {"required": {"images": ["IMAGE"], "filename_prefix": ["STRING", {"default": "ComfyUI"}], "subfolder_dir": ["STRING", {"default": ""}]}, "optional": {"quality": ["INT", {"default": 100}], "lossless": ["BOOLEAN", {"default": false}], "compression": ["INT", {"default": 4}], "optimize": ["BOOLEAN", {"default": false}], "metadata_string": ["STRING", {"default": ""}], "optional_additional_metadata": ["STRING", {"default": ""}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "filename_prefix", "subfolder_dir"], "optional": ["quality", "lossless", "compression", "optimize", "metadata_string", "optional_additional_metadata"], "hidden": ["prompt", "extra_pnginfo"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "SaveImageWebpCustomNode", "display_name": "Save Image Webp Node", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": true}, "ComposeRGBAImageFromMask": {"input": {"required": {"image": ["IMAGE"], "mask": ["MASK"], "invert": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["image", "mask", "invert"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ComposeRGBAImageFromMask", "display_name": "Compose RGBA Image From Mask", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "ResizeImageNode": {"input": {"required": {"image": ["IMAGE"], "width": ["INT", {"default": 512}], "height": ["INT", {"default": 512}], "method": [["NEAREST", "LANCZOS", "BICUBIC"]]}}, "input_order": {"required": ["image", "width", "height", "method"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ResizeImageNode", "display_name": "Resize Image", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "ResizeImageResolution": {"input": {"required": {"image": ["IMAGE"], "resolution": ["INT", {"default": 512}], "method": [["NEAREST", "LANCZOS", "BICUBIC"]]}}, "input_order": {"required": ["image", "resolution", "method"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ResizeImageResolution", "display_name": "Resize Image With Resolution", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "ResizeImageEnsuringMultiple": {"input": {"required": {"image": ["IMAGE"], "multiple": ["INT", {"default": 32}], "method": [["NEAREST", "LANCZOS", "BICUBIC"]]}}, "input_order": {"required": ["image", "multiple", "method"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ResizeImageEnsuringMultiple", "display_name": "Resize Image Ensuring W/H Multiple", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "ResizeImageResolutionIfBigger": {"input": {"required": {"image": ["IMAGE"], "resolution": ["INT", {"default": 512}], "method": [["NEAREST", "LANCZOS", "BICUBIC"]]}}, "input_order": {"required": ["image", "resolution", "method"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ResizeImageResolutionIfBigger", "display_name": "Resize Image With Resolution If Bigger", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "ResizeImageResolutionIfSmaller": {"input": {"required": {"image": ["IMAGE"], "resolution": ["INT", {"default": 512}], "method": [["NEAREST", "LANCZOS", "BICUBIC"]]}}, "input_order": {"required": ["image", "resolution", "method"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ResizeImageResolutionIfSmaller", "display_name": "Resize Image With Resolution If Smaller", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "Base64DecodeNode": {"input": {"required": {"base64_string": ["STRING"]}}, "input_order": {"required": ["base64_string"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "Base64DecodeNode", "display_name": "Base64 Decode to Image", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "ImageFromURLNode": {"input": {"required": {"url": ["STRING"]}}, "input_order": {"required": ["url"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageFromURLNode", "display_name": "Download Image from URL", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "Base64EncodeNode": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"quality": ["INT", {"default": 100}], "format": [["PNG", "WEBP", "JPG"], {"default": "PNG"}], "gzip_compress": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["image"], "optional": ["quality", "format", "gzip_compress"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Base64EncodeNode", "display_name": "Image to Base64 Encode", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "StringToBase64Node": {"input": {"required": {"string": ["STRING"]}, "optional": {"gzip_compress": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["string"], "optional": ["gzip_compress"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "StringToBase64Node", "display_name": "String to Base64 Encode", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "Base64ToStringNode": {"input": {"required": {"base64_string": ["STRING"]}}, "input_order": {"required": ["base64_string"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "Base64ToStringNode", "display_name": "Base64 to String Decode", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "InvertImageNode": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "InvertImageNode", "display_name": "Invert Image", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "ResizeScaleImageNode": {"input": {"required": {"image": ["IMAGE"], "scale": ["INT", {"default": 2}], "method": [["NEAREST", "LANCZOS", "BICUBIC"]]}}, "input_order": {"required": ["image", "scale", "method"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ResizeScaleImageNode", "display_name": "Resize Scale Image", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "ResizeShortestToNode": {"input": {"required": {"image": ["IMAGE"], "size": ["INT", {"default": 512}], "method": [["NEAREST", "LANCZOS", "BICUBIC"]]}}, "input_order": {"required": ["image", "size", "method"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ResizeShortestToNode", "display_name": "Resize Shortest To", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "ResizeLongestToNode": {"input": {"required": {"image": ["IMAGE"], "size": ["INT", {"default": 512}], "method": [["NEAREST", "LANCZOS", "BICUBIC"]]}}, "input_order": {"required": ["image", "size", "method"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ResizeLongestToNode", "display_name": "Resize Longest To", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "ConvertGreyscaleNode": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ConvertGreyscaleNode", "display_name": "Convert Greyscale", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "RotateImageNode": {"input": {"required": {"image": ["IMAGE"], "angle": ["INT", {"default": 0}]}}, "input_order": {"required": ["image", "angle"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "RotateImageNode", "display_name": "Rotate Image", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "BrightnessNode": {"input": {"required": {"image": ["IMAGE"], "factor": ["FLOAT", {"default": 1.0}]}}, "input_order": {"required": ["image", "factor"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "BrightnessNode", "display_name": "Brightness", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "ContrastNode": {"input": {"required": {"image": ["IMAGE"], "factor": ["FLOAT", {"default": 1.0}]}}, "input_order": {"required": ["image", "factor"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ContrastNode", "display_name": "Contrast", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "SharpnessNode": {"input": {"required": {"image": ["IMAGE"], "factor": ["FLOAT", {"default": 1.0}]}}, "input_order": {"required": ["image", "factor"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "SharpnessNode", "display_name": "Sharpness", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "ColorNode": {"input": {"required": {"image": ["IMAGE"], "factor": ["FLOAT", {"default": 1.0}]}}, "input_order": {"required": ["image", "factor"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ColorNode", "display_name": "Color", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "ConvertRGBNode": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ConvertRGBNode", "display_name": "Convert RGB", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "FFTNode": {"input": {"required": {"image": ["IMAGE"], "mask_radius": ["INT", {"default": 50}]}}, "input_order": {"required": ["image", "mask_radius"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "FFTNode", "display_name": "FFT Image", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "GetImageInfoNode": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["WIDTH", "HEIGHT", "TOTAL_PIXELS"], "output_is_list": [false, false, false], "output_name": ["WIDTH", "HEIGHT", "TOTAL_PIXELS"], "name": "GetImageInfoNode", "display_name": "Get Image Info", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "ThresholdNode": {"input": {"required": {"image": ["IMAGE"], "threshold": ["INT", {"default": 128}]}}, "input_order": {"required": ["image", "threshold"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ThresholdNode", "display_name": "Threshold image with value", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "LogicGateCompare": {"input": {"required": {"input1": ["*", {"default": 0}], "input2": ["*", {"default": 0}]}}, "input_order": {"required": ["input1", "input2"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "LogicGateCompare", "display_name": "ABiggerThanB", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "LogicGateInvertBasic": {"input": {"required": {"input1": ["*", {"default": 0}]}}, "input_order": {"required": ["input1"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "LogicGateInvertBasic", "display_name": "Invert Basic", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "LogicGateNegateValue": {"input": {"required": {"input1": ["*", {"default": 0}]}}, "input_order": {"required": ["input1"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "LogicGateNegateValue", "display_name": "Negate Value", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "LogicGateBitwiseShift": {"input": {"required": {"input1": ["INT", {"default": 0}], "input2": ["INT", {"default": 0}]}}, "input_order": {"required": ["input1", "input2"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "LogicGateBitwiseShift", "display_name": "Bitwise Shift", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "LogicGateBitwiseAnd": {"input": {"required": {"input1": ["INT", {"default": 0}], "input2": ["INT", {"default": 0}]}}, "input_order": {"required": ["input1", "input2"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "LogicGateBitwiseAnd", "display_name": "Bitwise And", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "LogicGateBitwiseOr": {"input": {"required": {"input1": ["INT", {"default": 0}], "input2": ["INT", {"default": 0}]}}, "input_order": {"required": ["input1", "input2"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "LogicGateBitwiseOr", "display_name": "Bitwise Or", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "LogicGateBitwiseXor": {"input": {"required": {"input1": ["INT", {"default": 0}], "input2": ["INT", {"default": 0}]}}, "input_order": {"required": ["input1", "input2"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "LogicGateBitwiseXor", "display_name": "Bitwise Xor", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "LogicGateBitwiseNot": {"input": {"required": {"input1": ["INT", {"default": 0}]}}, "input_order": {"required": ["input1"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "LogicGateBitwiseNot", "display_name": "Bitwise Not", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "LogicGateCompareString": {"input": {"required": {"regex": ["STRING", {"default": ""}], "input2": ["STRING", {"default": ""}]}}, "input_order": {"required": ["regex", "input2"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "LogicGateCompareString", "display_name": "AContainsB(String)", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "GetLengthString": {"input": {"required": {"string": ["STRING", {"default": ""}]}}, "input_order": {"required": ["string"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "GetLengthString", "display_name": "Length of String", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "StaticNumberInt": {"input": {"required": {"number": ["INT", {"default": 0}]}}, "input_order": {"required": ["number"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "StaticNumberInt", "display_name": "Static Number Int", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "StaticNumberFloat": {"input": {"required": {"number": ["FLOAT", {"default": 0.0}]}}, "input_order": {"required": ["number"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "StaticNumberFloat", "display_name": "Static Number Float", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "StaticString": {"input": {"required": {"string": ["STRING", {"default": ""}]}}, "input_order": {"required": ["string"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "StaticString", "display_name": "Static String", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "LogicGateAnd": {"input": {"required": {"input1": ["*", {"default": 0.0}], "input2": ["*", {"default": 0.0}]}}, "input_order": {"required": ["input1", "input2"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "LogicGateAnd", "display_name": "AAndBGate", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "LogicGateOr": {"input": {"required": {"input1": ["*", {"default": 0}], "input2": ["*", {"default": 0}]}}, "input_order": {"required": ["input1", "input2"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "LogicGateOr", "display_name": "AOrBGate", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "LogicGateEither": {"input": {"required": {"condition": ["*", {"default": 0}], "input1": ["*", {"default": ""}], "input2": ["*", {"default": ""}]}}, "input_order": {"required": ["condition", "input1", "input2"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "LogicGateEither", "display_name": "ReturnAorBValue", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "AddNode": {"input": {"required": {"input1": ["*", {"default": 0}], "input2": ["*", {"default": 0}]}}, "input_order": {"required": ["input1", "input2"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "AddNode", "display_name": "Add Values", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "MergeString": {"input": {"required": {"input1": ["*", {"default": ""}], "input2": ["*", {"default": ""}]}}, "input_order": {"required": ["input1", "input2"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "MergeString", "display_name": "Merge String", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "ReplaceString": {"input": {"required": {"String": ["STRING", {"default": ""}], "Regex": ["STRING", {"default": ""}], "ReplaceWith": ["STRING", {"default": ""}]}}, "input_order": {"required": ["String", "Regex", "ReplaceWith"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "ReplaceString", "display_name": "Replace String", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "MemoryNode": {"input": {"required": {"input1": ["*", {"default": ""}], "flag": ["*", {"default": 0}]}}, "input_order": {"required": ["input1", "flag"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "MemoryNode", "display_name": "Memory String", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "SystemRandomFloat": {"input": {"required": {"min_val": ["FLOAT", {"default": 0.0, "min": -999999999, "max": 999999999.0, "step": 0.01, "display": "number"}], "max_val": ["FLOAT", {"default": 1.0, "min": -999999999, "max": 999999999.0, "step": 0.01, "display": "number"}], "precision": ["INT", {"default": 0, "min": 0, "max": 10, "step": 1, "display": "number"}]}}, "input_order": {"required": ["min_val", "max_val", "precision"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "SystemRandomFloat", "display_name": "System Random Float", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "DimensionSelectorWithSeedNode": {"input": {"required": {"resolution": ["INT", {"default": 1024}], "min_ratio": ["FLOAT", {"default": 0.6}], "max_ratio": ["FLOAT", {"default": 1.6}], "multiples": ["INT", {"default": 32}], "seed": ["INT", {"default": 0}]}}, "input_order": {"required": ["resolution", "min_ratio", "max_ratio", "multiples", "seed"]}, "output": ["INT", "INT"], "output_is_list": [false, false], "output_name": ["INT", "INT"], "name": "DimensionSelectorWithSeedNode", "display_name": "Random Width/Height with Resolution", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "SystemRandomInt": {"input": {"required": {"min_val": ["INT", {"default": 0, "min": -9223372036854775807, "max": 9223372036854775807, "step": 1, "display": "number"}], "max_val": ["INT", {"default": 9223372036854775807, "min": -9223372036854775807, "max": 9223372036854775807, "step": 1, "display": "number"}]}}, "input_order": {"required": ["min_val", "max_val"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "SystemRandomInt", "display_name": "System Random Int", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "SystemUUIDGenerator": {"input": {"required": {"length": ["INT", {"default": 36, "min": 1, "max": 36, "step": 1, "display": "number"}]}}, "input_order": {"required": ["length"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "SystemUUIDGenerator", "display_name": "UUID Generator", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "UniformRandomFloat": {"input": {"required": {"min_val": ["FLOAT", {"default": 0.0, "min": -999999999, "max": 999999999.0, "step": 0.02, "display": "number"}], "max_val": ["FLOAT", {"default": 1.0, "min": -999999999, "max": 999999999.0, "step": 0.02, "display": "number"}], "decimal_places": ["INT", {"default": 1, "min": 0, "max": 10, "step": 1, "display": "number"}], "seed": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1, "display": "number"}]}}, "input_order": {"required": ["min_val", "max_val", "decimal_places", "seed"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "UniformRandomFloat", "display_name": "Uniform Random Float", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "TriangularRandomFloat": {"input": {"required": {"low": ["FLOAT", {"default": 0.0, "min": -999999999, "max": 999999999.0, "step": 0.02, "display": "number"}], "high": ["FLOAT", {"default": 1.0, "min": -999999999, "max": 999999999.0, "step": 0.02, "display": "number"}], "mode": ["FLOAT", {"default": 0.5, "min": -999999999, "max": 999999999.0, "step": 0.02, "display": "number"}], "seed": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1, "display": "number"}]}}, "input_order": {"required": ["low", "high", "mode", "seed"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "TriangularRandomFloat", "display_name": "Triangular Random Float", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "WeightedRandomChoice": {"input": {"required": {"input_string": ["STRING", {"default": "apple|10$banana|1$orange|3", "display": "text"}], "separator": ["STRING", {"default": "$", "display": "text"}], "seed": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1, "display": "number"}]}}, "input_order": {"required": ["input_string", "separator", "seed"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "WeightedRandomChoice", "display_name": "Weighted Random Choice", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "RandomGaussianFloat": {"input": {"required": {"mean": ["FLOAT", {"default": 0.0, "min": -999999999, "max": 999999999.0, "step": 0.01}], "std_dev": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 999999999.0, "step": 0.01}], "decimal_places": ["INT", {"default": 2, "min": 0, "max": 10, "step": 1}], "seed": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1}]}}, "input_order": {"required": ["mean", "std_dev", "decimal_places", "seed"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "RandomGaussianFloat", "display_name": "Random Gaussian Float", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "SystemRandomGaussianFloat": {"input": {"required": {"mean": ["FLOAT", {"default": 0.0, "min": -999999999, "max": 999999999.0, "step": 0.01}], "std_dev": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 999999999.0, "step": 0.01}], "decimal_places": ["INT", {"default": 2, "min": 0, "max": 10, "step": 1}]}}, "input_order": {"required": ["mean", "std_dev", "decimal_places"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "SystemRandomGaussianFloat", "display_name": "System Random Gaussian Float", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "ProbabilityGate": {"input": {"required": {"probability": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "seed": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1}]}}, "input_order": {"required": ["probability", "seed"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "ProbabilityGate", "display_name": "Probability Gate", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "UniformRandomInt": {"input": {"required": {"min_val": ["INT", {"default": 0, "min": -999999999, "max": 999999999, "step": 1, "display": "number"}], "max_val": ["INT", {"default": 1, "min": -999999999, "max": 999999999, "step": 1, "display": "number"}], "seed": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1, "display": "number"}]}}, "input_order": {"required": ["min_val", "max_val", "seed"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "UniformRandomInt", "display_name": "Uniform Random Int", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "UniformRandomChoice": {"input": {"required": {"input_string": ["STRING", {"default": "a$b$c", "display": "text"}], "separator": ["STRING", {"default": "$", "display": "text"}], "seed": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1, "display": "number"}]}}, "input_order": {"required": ["input_string", "separator", "seed"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "UniformRandomChoice", "display_name": "Uniform Random Choice", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "ManualChoiceString": {"input": {"required": {"input_string": ["STRING", {"default": "a$b$c", "display": "text"}], "separator": ["STRING", {"default": "$", "display": "text"}], "index": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1, "display": "number"}]}}, "input_order": {"required": ["input_string", "separator", "index"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "ManualChoiceString", "display_name": "Manual Choice String", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "ManualChoiceInt": {"input": {"required": {"input_string": ["STRING", {"default": "1$2$3", "display": "text"}], "separator": ["STRING", {"default": "$", "display": "text"}], "index": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1, "display": "number"}]}}, "input_order": {"required": ["input_string", "separator", "index"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "ManualChoiceInt", "display_name": "Manual Choice Int", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "ManualChoiceFloat": {"input": {"required": {"input_string": ["STRING", {"default": "1.0$2.0$3.0", "display": "text"}], "separator": ["STRING", {"default": "$", "display": "text"}], "index": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1, "display": "number"}]}}, "input_order": {"required": ["input_string", "separator", "index"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "ManualChoiceFloat", "display_name": "Manual Choice Float", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "RandomShuffleInt": {"input": {"required": {"input_string": ["STRING", {"default": "1$2$3", "display": "text"}], "separator": ["STRING", {"default": "$", "display": "text"}], "seed": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1, "display": "number"}]}}, "input_order": {"required": ["input_string", "separator", "seed"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "RandomShuffleInt", "display_name": "Random Shuffle Int", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "RandomShuffleFloat": {"input": {"required": {"input_string": ["STRING", {"default": "1.0$2.0$3.0", "display": "text"}], "separator": ["STRING", {"default": "$", "display": "text"}], "seed": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1, "display": "number"}]}}, "input_order": {"required": ["input_string", "separator", "seed"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "RandomShuffleFloat", "display_name": "Random Shuffle Float", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "RandomShuffleString": {"input": {"required": {"input_string": ["STRING", {"default": "a$b$c", "display": "text"}], "separator": ["STRING", {"default": "$", "display": "text"}], "seed": ["INT", {"default": 0, "min": 0, "max": 9223372036854775807, "step": 1, "display": "number"}]}}, "input_order": {"required": ["input_string", "separator", "seed"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "RandomShuffleString", "display_name": "Random Shuffle String", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "CounterInteger": {"input": {"required": {"start": ["FLOAT", {"default": 0.0, "min": -9223372036854775807, "max": 9223372036854775807, "step": 1.0, "display": "number"}]}, "optional": {"reset": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["start"], "optional": ["reset"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "CounterInteger", "display_name": "Counter Integer", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "CounterFloat": {"input": {"required": {"start": ["FLOAT", {"default": 0.0, "min": -9223372036854775807, "max": 9223372036854775807, "step": 1.0, "display": "number"}]}, "optional": {"reset": "BOOLEAN", "step": ["FLOAT", {"default": 1.0, "min": -9223372036854775807, "max": 9223372036854775807, "step": 1.0, "display": "number"}]}}, "input_order": {"required": ["start"], "optional": ["reset", "step"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "CounterFloat", "display_name": "Counter Float", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "YieldableIteratorString": {"input": {"required": {"input_string": ["STRING", {"default": "a$b$c", "display": "text"}], "separator": ["STRING", {"default": "$", "display": "text"}], "reset": "BOOLEAN"}}, "input_order": {"required": ["input_string", "separator", "reset"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "YieldableIteratorString", "display_name": "Yieldable Iterator String", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "YieldableIteratorInt": {"input": {"required": {"start": ["INT", {"default": 0, "min": -9223372036854775807, "max": 9223372036854775807, "step": 1, "display": "number"}], "end": ["INT", {"default": 10, "min": -9223372036854775807, "max": 9223372036854775807, "step": 1, "display": "number"}], "step": ["INT", {"default": 1, "min": -9223372036854775807, "max": 9223372036854775807, "step": 1, "display": "number"}], "reset": "BOOLEAN"}}, "input_order": {"required": ["start", "end", "step", "reset"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "YieldableIteratorInt", "display_name": "Yieldable (Sequential) Iterator Int", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": true}, "StringListToCombo": {"input": {"required": {"string": ["STRING", {"default": ""}], "separator": ["STRING", {"default": "$"}]}, "optional": {"index": ["INT", {"default": 0}]}}, "input_order": {"required": ["string", "separator"], "optional": ["index"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "StringListToCombo", "display_name": "String List to Combo", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "ConvertComboToString": {"input": {"required": {"combo": ["*", {"default": []}], "separator": ["STRING", {"default": "$"}]}}, "input_order": {"required": ["combo", "separator"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "ConvertComboToString", "display_name": "Convert Combo to String", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Logic Gates", "output_node": false}, "ConvertAny2Int": {"input": {"required": {"input1": ["*", {"default": 0.0}]}}, "input_order": {"required": ["input1"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "ConvertAny2Int", "display_name": "Convert to Int", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Conversion", "output_node": false}, "ConvertAny2Float": {"input": {"required": {"input1": ["*", {"default": 0.0}]}}, "input_order": {"required": ["input1"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "ConvertAny2Float", "display_name": "Convert to Float", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Conversion", "output_node": false}, "ConvertAny2Boolean": {"input": {"required": {"input1": ["*", {"default": 0.0}]}}, "input_order": {"required": ["input1"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "ConvertAny2Boolean", "display_name": "Convert to Boolean", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Conversion", "output_node": false}, "ConvertAny2String": {"input": {"required": {"input1": ["*", {"default": 0.0}]}}, "input_order": {"required": ["input1"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "ConvertAny2String", "display_name": "Convert to String", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Conversion", "output_node": false}, "MinNode": {"input": {"required": {"input1": ["*"], "input2": ["*"]}}, "input_order": {"required": ["input1", "input2"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "MinNode", "display_name": "Min", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Math", "output_node": false}, "MaxNode": {"input": {"required": {"input1": ["*"], "input2": ["*"]}}, "input_order": {"required": ["input1", "input2"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "MaxNode", "display_name": "Max", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Math", "output_node": false}, "RoundNode": {"input": {"required": {"input1": ["*"]}}, "input_order": {"required": ["input1"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "RoundNode", "display_name": "Round", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Math", "output_node": false}, "AbsNode": {"input": {"required": {"input1": ["*"]}}, "input_order": {"required": ["input1"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "AbsNode", "display_name": "Abs", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Math", "output_node": false}, "FloorNode": {"input": {"required": {"input1": ["*"]}}, "input_order": {"required": ["input1"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "FloorNode", "display_name": "Floor", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Math", "output_node": false}, "CeilNode": {"input": {"required": {"input1": ["*"]}}, "input_order": {"required": ["input1"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "name": "CeilNode", "display_name": "Ceil", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Math", "output_node": false}, "PowerNode": {"input": {"required": {"input1": ["*"], "power": ["*"]}}, "input_order": {"required": ["input1", "power"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "PowerNode", "display_name": "Power", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Math", "output_node": false}, "SigmoidNode": {"input": {"required": {"input1": ["FLOAT"]}}, "input_order": {"required": ["input1"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "SigmoidNode", "display_name": "Sigmoid", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Math", "output_node": false}, "IsPrimeNode": {"input": {"required": {"value": ["INT", {"default": 1, "min": -9999999999, "max": 9999999999, "step": 1}]}, "optional": {"threshold": ["INT", {"default": 10000000, "min": 1, "max": 9999999999, "step": 1}], "miller_rabin_rounds": ["INT", {"default": 5, "min": 1, "max": 50, "step": 1}]}}, "input_order": {"required": ["value"], "optional": ["threshold", "miller_rabin_rounds"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "name": "IsPrimeNode", "display_name": "Is Prime?", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Math", "output_node": false}, "RAMPNode": {"input": {"required": {"input1": ["FLOAT"]}}, "input_order": {"required": ["input1"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "RAMPNode", "display_name": "RAMP", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Math", "output_node": false}, "LogNode": {"input": {"required": {"input1": ["FLOAT"], "base": ["FLOAT"]}}, "input_order": {"required": ["input1", "base"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "LogNode", "display_name": "Log", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Math", "output_node": false}, "MultiplyNode": {"input": {"required": {"input1": ["*"], "input2": ["*"]}}, "input_order": {"required": ["input1", "input2"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "MultiplyNode", "display_name": "Multiply", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Math", "output_node": false}, "DivideNode": {"input": {"required": {"input1": ["*"], "input2": ["*"]}}, "input_order": {"required": ["input1", "input2"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "name": "DivideNode", "display_name": "Divide", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Math", "output_node": false}, "SDWebuiAPINode": {"input": {"required": {"prompt": ["STRING", {"default": ""}], "api_endpoint": ["STRING", {"default": ""}]}, "optional": {"auth": ["STRING", {"default": ""}], "seed": ["INT", {"default": -1}], "negative_prompt": ["STRING", {"default": ""}], "steps": ["INT", {"default": 28}], "width": ["INT", {"default": 1024}], "height": ["INT", {"default": 1024}], "hr_scale": ["FLOAT", {"default": 1.5}], "hr_upscale": ["STRING", {"default": "Latent"}], "enable_hr": ["BOOLEAN", {"default": false}], "cfg_scale": ["INT", {"default": 7}]}}, "input_order": {"required": ["prompt", "api_endpoint"], "optional": ["auth", "seed", "negative_prompt", "steps", "width", "height", "hr_scale", "hr_upscale", "enable_hr", "cfg_scale"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "SDWebuiAPINode", "display_name": "Get Image From Prompt", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "WebUI API", "output_node": false}, "SDWebuiAPIFallbackNode": {"input": {"required": {"prompt": ["STRING", {"default": ""}], "api_endpoint": ["STRING", {"default": ""}]}, "optional": {"auth": ["STRING", {"default": ""}], "seed": ["INT", {"default": -1}], "negative_prompt": ["STRING", {"default": ""}], "steps": ["INT", {"default": 28}], "width": ["INT", {"default": 1024}], "height": ["INT", {"default": 1024}], "hr_scale": ["FLOAT", {"default": 1.5}], "hr_upscale": ["STRING", {"default": "Latent"}], "enable_hr": ["BOOLEAN", {"default": false}], "cfg_scale": ["INT", {"default": 7}]}}, "input_order": {"required": ["prompt", "api_endpoint"], "optional": ["auth", "seed", "negative_prompt", "steps", "width", "height", "hr_scale", "hr_upscale", "enable_hr", "cfg_scale"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "SDWebuiAPIFallbackNode", "display_name": "Get Image From Prompt (Fallback)", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "WebUI API", "output_node": false}, "GetRatingNode": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"model_name": [["EVA02_Large", "ViT_Large", "SwinV2", "ConvNext", "ConvNextV2", "ViT", "MOAT", "SwinV2_v3", "ConvNext_v3", "ViT_v3"], {"default": "EVA02_Large"}]}}, "input_order": {"required": ["image"], "optional": ["model_name"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "GetRatingNode", "display_name": "Get Rating Class", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "tagger", "output_node": false}, "GetRatingFromTextNode": {"input": {"required": {"image": ["STRING", {"default": "/path/to/image.jpg"}]}, "optional": {"model_name": [["EVA02_Large", "ViT_Large", "SwinV2", "ConvNext", "ConvNextV2", "ViT", "MOAT", "SwinV2_v3", "ConvNext_v3", "ViT_v3"], {"default": "EVA02_Large"}]}}, "input_order": {"required": ["image"], "optional": ["model_name"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "GetRatingFromTextNode", "display_name": "Get Rating Class From Text", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "tagger", "output_node": false}, "CensorImageByRating": {"input": {"required": {"image": ["IMAGE"], "rating_threshold": [["general", "sensitive", "questionable", "explicit"]], "censor_method": [["blur", "white", "pixelate"]]}, "optional": {"model_name": [["EVA02_Large", "ViT_Large", "SwinV2", "ConvNext", "ConvNextV2", "ViT", "MOAT", "SwinV2_v3", "ConvNext_v3", "ViT_v3"], {"default": "EVA02_Large"}]}}, "input_order": {"required": ["image", "rating_threshold", "censor_method"], "optional": ["model_name"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "CensorImageByRating", "display_name": "Censor Image by Rating", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "FilterTagsNode": {"input": {"required": {"tags": ["STRING"], "filter_tags": ["STRING"]}, "optional": {"separator": ["STRING", {"default": ","}]}}, "input_order": {"required": ["tags", "filter_tags"], "optional": ["separator"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "FilterTagsNode", "display_name": "Filter Tags", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "safety", "output_node": false}, "GetTagsAboveThresholdNode": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"threshold": ["FLOAT", {"default": 0.4}], "replace": ["BOOLEAN", {"default": false}], "model_name": [["EVA02_Large", "ViT_Large", "SwinV2", "ConvNext", "ConvNextV2", "ViT", "MOAT", "SwinV2_v3", "ConvNext_v3", "ViT_v3"], {"default": "EVA02_Large"}]}}, "input_order": {"required": ["image"], "optional": ["threshold", "replace", "model_name"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "GetTagsAboveThresholdNode", "display_name": "Get Tags Above Threshold", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "tagger", "output_node": false}, "GetTagsAboveThresholdFromTextNode": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"threshold": ["FLOAT", {"default": 0.4}], "replace": ["BOOLEAN", {"default": false}], "model_name": [["EVA02_Large", "ViT_Large", "SwinV2", "ConvNext", "ConvNextV2", "ViT", "MOAT", "SwinV2_v3", "ConvNext_v3", "ViT_v3"], {"default": "EVA02_Large"}]}}, "input_order": {"required": ["image"], "optional": ["threshold", "replace", "model_name"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "GetTagsAboveThresholdFromTextNode", "display_name": "Get Tags Above Threshold From Text", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "tagger", "output_node": false}, "GetCharactersAboveThresholdNode": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"threshold": ["FLOAT", {"default": 0.4}], "replace": ["BOOLEAN", {"default": false}], "model_name": [["EVA02_Large", "ViT_Large", "SwinV2", "ConvNext", "ConvNextV2", "ViT", "MOAT", "SwinV2_v3", "ConvNext_v3", "ViT_v3"], {"default": "EVA02_Large"}]}}, "input_order": {"required": ["image"], "optional": ["threshold", "replace", "model_name"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "GetCharactersAboveThresholdNode", "display_name": "Get Chars Above Threshold", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "tagger", "output_node": false}, "GetCharactersAboveThresholdFromTextNode": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"threshold": ["FLOAT", {"default": 0.4}], "replace": ["BOOLEAN", {"default": false}], "model_name": [["EVA02_Large", "ViT_Large", "SwinV2", "ConvNext", "ConvNextV2", "ViT", "MOAT", "SwinV2_v3", "ConvNext_v3", "ViT_v3"], {"default": "EVA02_Large"}]}}, "input_order": {"required": ["image"], "optional": ["threshold", "replace", "model_name"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "GetCharactersAboveThresholdFromTextNode", "display_name": "Get Chars Above Threshold From Text", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "tagger", "output_node": false}, "GetAllTagsAboveThresholdNode": {"input": {"required": {"image": ["IMAGE"]}, "optional": {"threshold": ["FLOAT", {"default": 0.4}], "replace": ["BOOLEAN", {"default": false}], "model_name": [["EVA02_Large", "ViT_Large", "SwinV2", "ConvNext", "ConvNextV2", "ViT", "MOAT", "SwinV2_v3", "ConvNext_v3", "ViT_v3"], {"default": "EVA02_Large"}]}}, "input_order": {"required": ["image"], "optional": ["threshold", "replace", "model_name"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "GetAllTagsAboveThresholdNode", "display_name": "Get All Tags Above Threshold", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "tagger", "output_node": false}, "SecureBase64Encrypt": {"input": {"required": {"images": ["IMAGE"], "public_key_pem": ["STRING", {"multiline": true, "default": ""}]}}, "input_order": {"required": ["images", "public_key_pem"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["encrypted_base64"], "name": "SecureBase64Encrypt", "display_name": "Secure Base64 Encrypt", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": true}, "SecureWebPDecrypt": {"input": {"required": {"encrypted_base64": ["STRING", {"multiline": true, "default": ""}], "private_key_pem": ["STRING", {"multiline": true, "default": ""}]}}, "input_order": {"required": ["encrypted_base64", "private_key_pem"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["Decrypted_Image"], "name": "SecureWebPDecrypt", "display_name": "Secure WebP Decrypt", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "image", "output_node": false}, "JsonParseNode": {"input": {"required": {"json_string": ["STRING", {"default": "{\"key\": \"value\"}"}]}}, "input_order": {"required": ["json_string"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "JsonParseNode", "display_name": "Pyobjects/JSON -> PyObject", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "JsonDumpNode": {"input": {"required": {"py_obj": ["*"]}, "optional": {"indent": ["INT", {"default": 0}]}}, "input_order": {"required": ["py_obj"], "optional": ["indent"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "JsonDumpNode", "display_name": "Pyobjects/PyObject -> JSON", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "JsonDumpAnyStructureNode": {"input": {"required": {"py_obj": ["*"]}, "optional": {"indent": ["INT", {"default": 0}]}}, "input_order": {"required": ["py_obj"], "optional": ["indent"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "JsonDumpAnyStructureNode", "display_name": "Pyobjects/PyStructure -> JSON", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "DictCreateNode": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["DICT"], "output_is_list": [false], "output_name": ["DICT"], "name": "DictCreateNode", "display_name": "Pyobjects/Create Dict", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "DictSetNode": {"input": {"required": {"py_dict": ["DICT"], "key": ["STRING", {"default": "some_key"}], "value": ["*", {"default": "some_value"}]}}, "input_order": {"required": ["py_dict", "key", "value"]}, "output": ["DICT"], "output_is_list": [false], "output_name": ["DICT"], "name": "DictSetNode", "display_name": "Pyobjects/Dict Set", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "DictGetNode": {"input": {"required": {"py_dict": ["DICT"], "key": ["STRING", {"default": "some_key"}]}}, "input_order": {"required": ["py_dict", "key"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "DictGetNode", "display_name": "Pyobjects/Dict Get", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "DictRemoveKeyNode": {"input": {"required": {"py_dict": ["DICT"], "key": ["STRING", {"default": "some_key"}]}}, "input_order": {"required": ["py_dict", "key"]}, "output": ["DICT"], "output_is_list": [false], "output_name": ["DICT"], "name": "DictRemoveKeyNode", "display_name": "Pyobjects/Dict Remove Key", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "DictMergeNode": {"input": {"required": {"dict_a": ["DICT"], "dict_b": ["DICT"]}, "optional": {"in_place": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["dict_a", "dict_b"], "optional": ["in_place"]}, "output": ["DICT"], "output_is_list": [false], "output_name": ["DICT"], "name": "DictMergeNode", "display_name": "Pyobjects/Dict Merge", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "DictKeysNode": {"input": {"required": {"py_dict": ["DICT"]}}, "input_order": {"required": ["py_dict"]}, "output": ["LIST"], "output_is_list": [false], "output_name": ["LIST"], "name": "DictKeysNode", "display_name": "Pyobjects/Dict Keys", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "DictValuesNode": {"input": {"required": {"py_dict": ["DICT"]}}, "input_order": {"required": ["py_dict"]}, "output": ["LIST"], "output_is_list": [false], "output_name": ["LIST"], "name": "DictValuesNode", "display_name": "Pyobjects/Dict Values", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "DictItemsNode": {"input": {"required": {"py_dict": ["DICT"]}}, "input_order": {"required": ["py_dict"]}, "output": ["LIST"], "output_is_list": [false], "output_name": ["LIST"], "name": "DictItemsNode", "display_name": "Pyobjects/Dict Items", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "DictPointer": {"input": {"required": {"py_dict": ["DICT"]}, "optional": {"reset": ["BOOLEAN"]}}, "input_order": {"required": ["py_dict"], "optional": ["reset"]}, "output": ["DICT"], "output_is_list": [false], "output_name": ["DICT"], "name": "DictPointer", "display_name": "Pyobjects/Dict Pointer", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "GlobalVarSetNode": {"input": {"required": {"key": ["STRING", {"default": "my_key"}], "value": ["*", {"default": "my_value"}]}}, "input_order": {"required": ["key", "value"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "GlobalVarSetNode", "display_name": "Pyobjects/Global Var Set", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "GlobalVarSetIfNotExistsNode": {"input": {"required": {"key": ["STRING", {"default": "my_key"}], "value": ["*", {"default": "my_value"}]}}, "input_order": {"required": ["key", "value"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "GlobalVarSetIfNotExistsNode", "display_name": "Pyobjects/Global Var Set If Not Exists", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "GlobalVarGetNode": {"input": {"required": {"key": ["STRING", {"default": "my_key"}]}}, "input_order": {"required": ["key"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "GlobalVarGetNode", "display_name": "Pyobjects/Global Var Get", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "GlobalVarRemoveNode": {"input": {"required": {"key": ["STRING", {"default": "my_key"}]}}, "input_order": {"required": ["key"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "GlobalVarRemoveNode", "display_name": "Pyobjects/Global Var Remove", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "GlobalVarSaveNode": {"input": {"required": {"key": ["STRING", {"default": "my_key"}], "filepath": ["STRING", {"default": "my_global_var.json"}]}, "optional": {"allow_missing": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["key", "filepath"], "optional": ["allow_missing"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "GlobalVarSaveNode", "display_name": "Pyobjects/Global Var Save", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "GlobalVarLoadNode": {"input": {"required": {"key": ["STRING", {"default": "my_key"}], "filepath": ["STRING", {"default": "my_global_var.json"}]}, "optional": {"allow_missing": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["key", "filepath"], "optional": ["allow_missing"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "GlobalVarLoadNode", "display_name": "Pyobjects/Global Var Load", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "ListCreateNode": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["LIST"], "output_is_list": [false], "output_name": ["LIST"], "name": "ListCreateNode", "display_name": "Pyobjects/Create List", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "ListAppendNode": {"input": {"required": {"py_list": ["LIST"], "item": ["*"]}}, "input_order": {"required": ["py_list", "item"]}, "output": ["LIST"], "output_is_list": [false], "output_name": ["LIST"], "name": "ListAppendNode", "display_name": "Pyobjects/List Append", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "ListGetNode": {"input": {"required": {"py_list": ["LIST"], "index": ["INT", {"default": 0}]}}, "input_order": {"required": ["py_list", "index"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "ListGetNode", "display_name": "Pyobjects/List Get", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "ListRemoveNode": {"input": {"required": {"py_list": ["LIST"], "item": ["*"]}}, "input_order": {"required": ["py_list", "item"]}, "output": ["LIST"], "output_is_list": [false], "output_name": ["LIST"], "name": "ListRemoveNode", "display_name": "Pyobjects/List Remove", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "ListPopNode": {"input": {"required": {"py_list": ["LIST"]}, "optional": {"index": ["INT", {"default": -1}]}}, "input_order": {"required": ["py_list"], "optional": ["index"]}, "output": ["*", "LIST"], "output_is_list": [false, false], "output_name": ["*", "LIST"], "name": "ListPopNode", "display_name": "Pyobjects/List Pop", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "ListInsertNode": {"input": {"required": {"py_list": ["LIST"], "index": ["INT", {"default": 0}], "item": ["*"]}}, "input_order": {"required": ["py_list", "index", "item"]}, "output": ["LIST"], "output_is_list": [false], "output_name": ["LIST"], "name": "ListInsertNode", "display_name": "Pyobjects/List Insert", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "ListExtendNode": {"input": {"required": {"list_a": ["LIST"], "list_b": ["LIST"]}}, "input_order": {"required": ["list_a", "list_b"]}, "output": ["LIST"], "output_is_list": [false], "output_name": ["LIST"], "name": "ListExtendNode", "display_name": "Pyobjects/List Extend", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "ToListTypeNode": {"input": {"required": {"py_obj": ["*"]}}, "input_order": {"required": ["py_obj"]}, "output": ["LIST"], "output_is_list": [false], "output_name": ["LIST"], "name": "ToListTypeNode", "display_name": "Pyobjects/Cast to LIST", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "ToSetTypeNode": {"input": {"required": {"py_obj": ["*"]}}, "input_order": {"required": ["py_obj"]}, "output": ["SET"], "output_is_list": [false], "output_name": ["SET"], "name": "ToSetTypeNode", "display_name": "Pyobjects/Cast to SET", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "SetCreateNode": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["SET"], "output_is_list": [false], "output_name": ["SET"], "name": "SetCreateNode", "display_name": "Pyobjects/Create Set", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "SetAddNode": {"input": {"required": {"py_set": ["SET"], "item": ["*"]}}, "input_order": {"required": ["py_set", "item"]}, "output": ["SET"], "output_is_list": [false], "output_name": ["SET"], "name": "SetAddNode", "display_name": "Pyobjects/Set Add", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "SetRemoveNode": {"input": {"required": {"py_set": ["SET"], "item": ["*"]}}, "input_order": {"required": ["py_set", "item"]}, "output": ["SET"], "output_is_list": [false], "output_name": ["SET"], "name": "SetRemoveNode", "display_name": "Pyobjects/Set Remove", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "SetUnionNode": {"input": {"required": {"py_set_a": ["SET"], "py_set_b": ["SET"]}}, "input_order": {"required": ["py_set_a", "py_set_b"]}, "output": ["SET"], "output_is_list": [false], "output_name": ["SET"], "name": "SetUnionNode", "display_name": "Pyobjects/Set Union", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "SetIntersectionNode": {"input": {"required": {"py_set_a": ["SET"], "py_set_b": ["SET"]}}, "input_order": {"required": ["py_set_a", "py_set_b"]}, "output": ["SET"], "output_is_list": [false], "output_name": ["SET"], "name": "SetIntersectionNode", "display_name": "Pyobjects/Set Intersection", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "SetDifferenceNode": {"input": {"required": {"py_set_a": ["SET"], "py_set_b": ["SET"]}}, "input_order": {"required": ["py_set_a", "py_set_b"]}, "output": ["SET"], "output_is_list": [false], "output_name": ["SET"], "name": "SetDifferenceNode", "display_name": "Pyobjects/Set Difference", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "SetSymDifferenceNode": {"input": {"required": {"py_set_a": ["SET"], "py_set_b": ["SET"]}}, "input_order": {"required": ["py_set_a", "py_set_b"]}, "output": ["SET"], "output_is_list": [false], "output_name": ["SET"], "name": "SetSymDifferenceNode", "display_name": "Pyobjects/Set Symmetric Difference", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "SetClearNode": {"input": {"required": {"py_set": ["SET"]}}, "input_order": {"required": ["py_set"]}, "output": ["SET"], "output_is_list": [false], "output_name": ["SET"], "name": "SetClearNode", "display_name": "Pyobjects/Set Clear", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "SetToListNode": {"input": {"required": {"py_set": ["SET"]}}, "input_order": {"required": ["py_set"]}, "output": ["LIST"], "output_is_list": [false], "output_name": ["LIST"], "name": "SetToListNode", "display_name": "Pyobjects/Set to List", "description": "", "python_module": "custom_nodes.ComfyUI-LogicUtils", "category": "Data", "output_node": true}, "LoraLoader|pysssss": {"input": {"required": {"model": ["MODEL", {"tooltip": "The diffusion model the LoRA will be applied to."}], "clip": ["CLIP", {"tooltip": "The CLIP model the LoRA will be applied to."}], "lora_name": [["BiFangBird.safetensors", "DrugPony.safetensors", "Harrlogos_v2.0.safetensors", "Inquisition_v1.safetensors", "Iridescence.safetensors", "Luxury_Houses_V1-000009.safetensors", "MJ52_v2.0.safetensors", "Textimprover-FLUX-V0.4.safetensors", "animemix_v3_offset.safetensors", "ff7r_style_ned_offset.safetensors", "first_stage-10.safetensors", "fractalized.safetensors", "hyvideo_FastVideo_LoRA-fp8.safetensors", "neoclassical villa - PHK.safetensors", "pokemon_v3_offset.safetensors", "polyhedron_new_skin_v1.1.safetensors", "poms-funtime-mlora-emporium/LiquidAF-0-1.safetensors", "poms-funtime-mlora-emporium/Smoooth-0-1.safetensors", "poms-funtime-mlora-emporium/WAS26.safetensors", "psychedelic_portrait.safetensors", "sd_xl_offset_example-lora_1.0.safetensors"], {"tooltip": "The name of the LoRA."}], "strength_model": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01, "tooltip": "How strongly to modify the diffusion model. This value can be negative."}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01, "tooltip": "How strongly to modify the CLIP model. This value can be negative."}]}, "optional": {"prompt": ["STRING", {"hidden": true}]}}, "input_order": {"required": ["model", "clip", "lora_name", "strength_model", "strength_clip"], "optional": ["prompt"]}, "output": ["MODEL", "CLIP", "STRING"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "example"], "name": "LoraLoader|pysssss", "display_name": "Lora Loader \ud83d\udc0d", "description": "LoRAs are used to modify diffusion and CLIP models, altering the way in which latents are denoised such as applying styles. Multiple LoRA nodes can be linked together.", "python_module": "custom_nodes.ComfyUI-Custom-Scripts", "category": "loaders", "output_node": false, "output_tooltips": ["The modified diffusion model.", "The modified CLIP model."]}, "CheckpointLoader|pysssss": {"input": {"required": {"ckpt_name": [["Artfusion Surreal XL.safetensors", "Flux_dev_turbo_krea_mix.safetensors", "Flux_dev_v1.safetensors", "XLbluePencilXL_v700.safetensors", "XLrealbluejuggernautmi_v10.safetensors", "animagineXLRealistic_v5.safetensors", "animeIllustDiffusion_v08.safetensors", "artfusionXL_v11Lightning.safetensors", "cyberrealisticXL_v5.safetensors", "dreamshaperXL_v21TurboDPMSDE.safetensors", "electricDreams_electricDreamsV04.safetensors", "epicrealismXL_vxvAnewstoryRealism.safetensors", "illustrationStyleIV.nR7A.safetensors", "illustrationXL_v10.safetensors", "jibMixRealisticXL_v170SmokeSheen.safetensors", "jruTheJourneyRemains_v20XL.safetensors", "midgardPonyTHLSDXL_v32.safetensors", "pixniteXL_v10.safetensors", "reymixXL_v20.safetensors", "sd_xl_base_1.0.safetensors", "sd_xl_refiner_1.0.safetensors", "sdxlFaetastic_v10.safetensors", "sdxlInkpunkstyle_v01.safetensors", "v1-5-pruned-emaonly.safetensors", "xl6HEPHAISTOSSD10XLSFW_v331BF16Experimental.safetensors"], {"tooltip": "The name of the checkpoint (model) to load."}]}, "optional": {"prompt": ["STRING", {"hidden": true}]}}, "input_order": {"required": ["ckpt_name"], "optional": ["prompt"]}, "output": ["MODEL", "CLIP", "VAE", "STRING"], "output_is_list": [false, false, false, false], "output_name": ["MODEL", "CLIP", "VAE", "example"], "name": "CheckpointLoader|pysssss", "display_name": "Checkpoint Loader \ud83d\udc0d", "description": "Loads a diffusion model checkpoint, diffusion models are used to denoise latents.", "python_module": "custom_nodes.ComfyUI-Custom-Scripts", "category": "loaders", "output_node": false, "output_tooltips": ["The model used for denoising latents.", "The CLIP model used for encoding text prompts.", "The VAE model used for encoding and decoding images to and from latent space."]}, "LoadText|pysssss": {"input": {"required": {"root_dir": [["input", "output", "temp"], {}], "file": [["[none]"], {"pysssss.binding": [{"source": "root_dir", "callback": [{"type": "set", "target": "$this.disabled", "value": true}, {"type": "fetch", "url": "/pysssss/text-file/{$source.value}", "then": [{"type": "set", "target": "$this.options.values", "value": "$result"}, {"type": "validate-combo"}, {"type": "set", "target": "$this.disabled", "value": false}]}]}]}]}}, "input_order": {"required": ["root_dir", "file"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "LoadText|pysssss", "display_name": "Load Text \ud83d\udc0d", "description": "", "python_module": "custom_nodes.ComfyUI-Custom-Scripts", "category": "utils", "output_node": false}, "SaveText|pysssss": {"input": {"required": {"root_dir": [["input", "output", "temp"], {}], "file": ["STRING", {"default": "file.txt"}], "append": [["append", "overwrite", "new only"], {}], "insert": ["BOOLEAN", {"default": true, "label_on": "new line", "label_off": "none", "pysssss.binding": [{"source": "append", "callback": [{"type": "if", "condition": [{"left": "$source.value", "op": "eq", "right": "\"append\""}], "true": [{"type": "set", "target": "$this.disabled", "value": false}], "false": [{"type": "set", "target": "$this.disabled", "value": true}]}]}]}], "text": ["STRING", {"forceInput": true, "multiline": true}]}}, "input_order": {"required": ["root_dir", "file", "append", "insert", "text"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "SaveText|pysssss", "display_name": "Save Text \ud83d\udc0d", "description": "", "python_module": "custom_nodes.ComfyUI-Custom-Scripts", "category": "utils", "output_node": true}, "ConstrainImage|pysssss": {"input": {"required": {"images": ["IMAGE"], "max_width": ["INT", {"default": 1024, "min": 0}], "max_height": ["INT", {"default": 1024, "min": 0}], "min_width": ["INT", {"default": 0, "min": 0}], "min_height": ["INT", {"default": 0, "min": 0}], "crop_if_required": [["yes", "no"], {"default": "no"}]}}, "input_order": {"required": ["images", "max_width", "max_height", "min_width", "min_height", "crop_if_required"]}, "output": ["IMAGE"], "output_is_list": [true], "output_name": ["IMAGE"], "name": "ConstrainImage|pysssss", "display_name": "Constrain Image \ud83d\udc0d", "description": "", "python_module": "custom_nodes.ComfyUI-Custom-Scripts", "category": "image", "output_node": false}, "PlaySound|pysssss": {"input": {"required": {"any": ["*", {}], "mode": [["always", "on empty queue"], {}], "volume": ["FLOAT", {"min": 0, "max": 1, "step": 0.1, "default": 0.5}], "file": ["STRING", {"default": "notify.mp3"}]}}, "input_order": {"required": ["any", "mode", "volume", "file"]}, "output": ["*"], "output_is_list": [true], "output_name": ["*"], "name": "PlaySound|pysssss", "display_name": "PlaySound \ud83d\udc0d", "description": "", "python_module": "custom_nodes.ComfyUI-Custom-Scripts", "category": "utils", "output_node": true}, "SystemNotification|pysssss": {"input": {"required": {"message": ["STRING", {"default": "Your notification has triggered."}], "any": ["*", {}], "mode": [["always", "on empty queue"], {}]}}, "input_order": {"required": ["message", "any", "mode"]}, "output": ["*"], "output_is_list": [true], "output_name": ["*"], "name": "SystemNotification|pysssss", "display_name": "SystemNotification \ud83d\udc0d", "description": "", "python_module": "custom_nodes.ComfyUI-Custom-Scripts", "category": "utils", "output_node": true}, "ShowText|pysssss": {"input": {"required": {"text": ["STRING", {"forceInput": true}]}, "hidden": {"unique_id": "UNIQUE_ID", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["text"], "hidden": ["unique_id", "extra_pnginfo"]}, "output": ["STRING"], "output_is_list": [true], "output_name": ["STRING"], "name": "ShowText|pysssss", "display_name": "Show Text \ud83d\udc0d", "description": "", "python_module": "custom_nodes.ComfyUI-Custom-Scripts", "category": "utils", "output_node": true}, "StringFunction|pysssss": {"input": {"required": {"action": [["append", "replace"], {}], "tidy_tags": [["yes", "no"], {}]}, "optional": {"text_a": ["STRING", {"multiline": true, "dynamicPrompts": false}], "text_b": ["STRING", {"multiline": true, "dynamicPrompts": false}], "text_c": ["STRING", {"multiline": true, "dynamicPrompts": false}]}}, "input_order": {"required": ["action", "tidy_tags"], "optional": ["text_a", "text_b", "text_c"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "name": "StringFunction|pysssss", "display_name": "String Function \ud83d\udc0d", "description": "", "python_module": "custom_nodes.ComfyUI-Custom-Scripts", "category": "utils", "output_node": true}, "MathExpression|pysssss": {"input": {"required": {"expression": ["STRING", {"multiline": true, "dynamicPrompts": false, "pysssss.autocomplete": {"words": [{"text": "round", "value": "round()", "showValue": false, "hint": "number, dp? = 0", "caretOffset": -1}, {"text": "ceil", "value": "ceil()", "showValue": false, "hint": "number", "caretOffset": -1}, {"text": "floor", "value": "floor()", "showValue": false, "hint": "number", "caretOffset": -1}, {"text": "min", "value": "min()", "showValue": false, "hint": "...numbers", "caretOffset": -1}, {"text": "max", "value": "max()", "showValue": false, "hint": "...numbers", "caretOffset": -1}, {"text": "randomint", "value": "randomint()", "showValue": false, "hint": "min, max", "caretOffset": -1}, {"text": "randomchoice", "value": "randomchoice()", "showValue": false, "hint": "...numbers", "caretOffset": -1}, {"text": "sqrt", "value": "sqrt()", "showValue": false, "hint": "number", "caretOffset": -1}, {"text": "int", "value": "int()", "showValue": false, "hint": "number", "caretOffset": -1}, {"text": "iif", "value": "iif()", "showValue": false, "hint": "value, truepart, falsepart", "caretOffset": -1}], "separator": ""}}]}, "optional": {"a": ["*"], "b": ["*"], "c": ["*"]}, "hidden": {"extra_pnginfo": "EXTRA_PNGINFO", "prompt": "PROMPT"}}, "input_order": {"required": ["expression"], "optional": ["a", "b", "c"], "hidden": ["extra_pnginfo", "prompt"]}, "output": ["INT", "FLOAT"], "output_is_list": [false, false], "output_name": ["INT", "FLOAT"], "name": "MathExpression|pysssss", "display_name": "Math Expression \ud83d\udc0d", "description": "", "python_module": "custom_nodes.ComfyUI-Custom-Scripts", "category": "utils", "output_node": true}, "Repeater|pysssss": {"input": {"required": {"source": ["*", {}], "repeats": ["INT", {"min": 0, "max": 5000, "default": 2}], "output": [["single", "multi"], {}], "node_mode": [["reuse", "create"], {}]}}, "input_order": {"required": ["source", "repeats", "output", "node_mode"]}, "output": ["*"], "output_is_list": [true], "output_name": ["*"], "name": "Repeater|pysssss", "display_name": "Repeater \ud83d\udc0d", "description": "", "python_module": "custom_nodes.ComfyUI-Custom-Scripts", "category": "utils", "output_node": false}, "ConstrainImageforVideo|pysssss": {"input": {"required": {"images": ["IMAGE"], "max_width": ["INT", {"default": 1024, "min": 0}], "max_height": ["INT", {"default": 1024, "min": 0}], "min_width": ["INT", {"default": 0, "min": 0}], "min_height": ["INT", {"default": 0, "min": 0}], "crop_if_required": [["yes", "no"], {"default": "no"}]}}, "input_order": {"required": ["images", "max_width", "max_height", "min_width", "min_height", "crop_if_required"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ConstrainImageforVideo|pysssss", "display_name": "Constrain Image for Video \ud83d\udc0d", "description": "", "python_module": "custom_nodes.ComfyUI-Custom-Scripts", "category": "image", "output_node": false}, "ReroutePrimitive|pysssss": {"input": {"required": {"value": ["*"]}}, "input_order": {"required": ["value"]}, "output": ["*"], "output_is_list": [false], "output_name": ["*"], "name": "ReroutePrimitive|pysssss", "display_name": "Reroute Primitive \ud83d\udc0d", "description": "", "python_module": "custom_nodes.ComfyUI-Custom-Scripts", "category": "__hidden__", "output_node": false}}